{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "signate1_28.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wakepon21/Masa/blob/master/signate1_28.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF8YmhdLO5HG",
        "colab_type": "text"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79O4w9ClXgJs",
        "colab_type": "text"
      },
      "source": [
        "## import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1lgD7CtO5G-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "f0cbe402-67d6-40dc-e361-f2f281cec88a"
      },
      "source": [
        "# Dataset\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Imbalanced-learn\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# LightGBM\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# LogisticRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# RandomForest\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KI1Zd3haLl8a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b2903174-e72f-43b7-e2f9-660812560de4"
      },
      "source": [
        "#control\n",
        "#!pip install git+https://github.com/pandas-profiling/pandas-profiling.git\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "#import pandas_profiling\n",
        "import seaborn as sns\n",
        "#from pandas_profiling.utils.cache import cache_file\n",
        "\n",
        "#Optuna\n",
        "!pip install optuna\n",
        "import optuna\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "#何で必要なのか分かってない\n",
        "%matplotlib inline\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/b0/9a6313c78bca92abfacc08a2ad8b27bfe845256f615786ee2b6452ae1978/optuna-2.0.0.tar.gz (226kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 5.3MB/s \n",
            "\u001b[?25hCollecting alembic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/1e/cabc75a189de0fbb2841d0975243e59bde8b7822bacbb95008ac6fe9ad47/alembic-1.4.2.tar.gz (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 18.1MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cliff\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/06/03b1f92d46546a18eabf33ff7f37ef422c18c93d5a926bf590fee32ebe75/cliff-3.4.0-py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.1MB/s \n",
            "\u001b[?25hCollecting cmaes>=0.5.1\n",
            "  Downloading https://files.pythonhosted.org/packages/63/88/d5e9b78151dce671d7e78ee4cc8905d83208254caa2a386b163ae0ab0027/cmaes-0.6.0-py3-none-any.whl\n",
            "Collecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/2a/81/12d77537c82c5d46aa2721dfee25a0e873ef5920ebd0827152f411effb57/colorlog-4.2.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from optuna) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from optuna) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from optuna) (20.4)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.3.18)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from optuna) (4.41.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from alembic->optuna) (2.8.1)\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.1MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (3.13)\n",
            "Collecting stevedore>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/f4/041afc90e684f2b7d00a7f49abcbaf0b8c03e916bbc398ce49dce2a3c408/stevedore-3.2.0-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.3MB/s \n",
            "\u001b[?25hCollecting cmd2!=0.8.3,>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/f3/c1ebff567b8dba74eaa26f52bceda3242200ef092fafb56fcc4e105d5953/cmd2-1.3.4-py3-none-any.whl (130kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 30.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (1.15.0)\n",
            "Requirement already satisfied: PrettyTable<0.8,>=0.7.2 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (0.7.2)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/ba/aa953a11ec014b23df057ecdbc922fdb40ca8463466b1193f3367d2711a6/pbr-5.4.5-py2.py3-none-any.whl (110kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 33.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (2.4.7)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->optuna) (1.1.1)\n",
            "Requirement already satisfied: importlib-metadata>=1.7.0; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from stevedore>=2.0.1->cliff->optuna) (1.7.0)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/f6/5b/55866e1cde0f86f5eec59dab5de8a66628cb0d53da74b8dbc15ad8dabda3/pyperclip-1.8.0.tar.gz\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: setuptools>=34.4 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (49.2.0)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (19.3.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=1.7.0; python_version < \"3.8\"->stevedore>=2.0.1->cliff->optuna) (3.1.0)\n",
            "Building wheels for collected packages: alembic\n",
            "  Building wheel for alembic (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alembic: filename=alembic-1.4.2-cp36-none-any.whl size=159543 sha256=2819749ef5b13fe31f1c0c65794dfdb88688d5cef40182a983d9449d745990ef\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/04/83/76023f7a4c14688c0b5c2682a96392cfdd3ee4449eaaa287ef\n",
            "Successfully built alembic\n",
            "Building wheels for collected packages: optuna, pyperclip\n",
            "  Building wheel for optuna (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for optuna: filename=optuna-2.0.0-cp36-none-any.whl size=312964 sha256=436230d06b174799d73f3db6db98ba292b6a443da9081b27801e39c26a38de78\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/c9/03/c45484454bf657ffed0ed6af153bd3d213928df115eb2a56eb\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.0-cp36-none-any.whl size=8693 sha256=75956a443fb23504e08e69c20d26c7262eb932a4887170635aa3508df3ffc31b\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/ac/0a/b784f0afe26eaf52e88a7e15c7369090deea0354fa1c6fc689\n",
            "Successfully built optuna pyperclip\n",
            "Installing collected packages: Mako, python-editor, alembic, pbr, stevedore, pyperclip, colorama, cmd2, cliff, cmaes, colorlog, optuna\n",
            "Successfully installed Mako-1.1.3 alembic-1.4.2 cliff-3.4.0 cmaes-0.6.0 cmd2-1.3.4 colorama-0.4.3 colorlog-4.2.1 optuna-2.0.0 pbr-5.4.5 pyperclip-1.8.0 python-editor-1.0.4 stevedore-3.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzJ9EVq8XjkJ",
        "colab_type": "text"
      },
      "source": [
        "## upload"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jw4TmFfKx2SL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "fe3cebe1-a031-4a37-f97b-9b5d02e881d3"
      },
      "source": [
        "#train,test,submit_sampleのみっつがそろっているか確認\n",
        "!ls"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\t\t\t   submit_sample.csv  train.csv\n",
            "submission_LGB_LR_RF_ensemble.csv  test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHdnUDx0ufsI",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "outputId": "f8a8fa9d-fc1c-491b-d741-5da9c947176a"
      },
      "source": [
        "#そろっていなかったら選択\n",
        "from google.colab import files\n",
        "train_up = files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9b18d8e8-6b20-4ba4-9341-90b05665ddc4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9b18d8e8-6b20-4ba4-9341-90b05665ddc4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving submit_sample.csv to submit_sample.csv\n",
            "Saving test.csv to test.csv\n",
            "Saving train.csv to train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WvfG-6QXmnh",
        "colab_type": "text"
      },
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pN5JFRzPLz7N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub = pd.read_csv(\"submit_sample.csv\",names=(\"A\",\"B\"))\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "data = pd.concat([train,test], sort=False)\n",
        "\n",
        "#特徴量をエンジニアリング\n",
        "data[\"income\"]=data[\"job\"].copy()\n",
        "data[\"goodincome\"]=data[\"job\"].copy()\n",
        "data[\"job\"].replace(['blue-collar','management','technician','admin.','services',\\\n",
        "                     'unknown','self-employed','entrepreneur','student','retired',\\\n",
        "                     'unemployed','housemaid'],[0,1,2,3,4,5,6,7,8,9,10,11],inplace=True)\n",
        "data[\"loan\"].replace(['yes','no'],[1,0],inplace=True)\n",
        "data[\"married\"]=data[\"marital\"]\n",
        "data[\"single\"]=data[\"marital\"]\n",
        "data['education'].replace(['secondary','tertiary','primary','unknown'],[3,1,0,2],inplace=True)\n",
        "data[\"housing\"].replace(['yes','no'],[1,0],inplace=True)\n",
        "data[\"contact\"].replace(['cellular','telephone','unknown'],[2,1,0],inplace=True)\n",
        "data[\"poutcome\"].replace(['success','failure','unknown','other'],[3,1,2,0],inplace=True)\n",
        "data[\"month\"].replace(['jan','feb','mar','apr','may','jun','jul','aug','sep','oct','nov','des'],\\\n",
        "                      [3,4,5,6,7,8,9,10,11,0,1,2],inplace=True)\n",
        "\n",
        "#ここから追加\n",
        "data[\"year\"]=data[\"month\"]*30+data[\"day\"]\n",
        "data[\"campaign+previous\"]=data[\"campaign\"] + data[\"previous\"]\n",
        "data[\"poutcome/pdays\"]=data[\"poutcome\"] / (data[\"pdays\"]+10) * 10000\n",
        "data[\"poutcome/pdays\"] = data[\"poutcome/pdays\"].astype(np.int64)\n",
        "data[\"income\"].replace(['blue-collar','management','technician',\\\n",
        "                                         'admin.','services','unknown','self-employed',\\\n",
        "                                         'entrepreneur','student','retired','unemployed','housemaid'],\\\n",
        "                                        [0,0,0,0,0,0,0,0,1,1,1,0],inplace=True)\n",
        "data[\"goodincome\"].replace(['blue-collar','management','technician','admin.','services','unknown','self-employed','entrepreneur','student','retired','unemployed','housemaid'],\\\n",
        "                                                [0,1,0,1,0,0,1,1,0,0,0,0],inplace=True)\n",
        "data[\"housing+loan\"] = data[\"housing\"] + data[\"loan\"]\n",
        "data[\"duration*campaign\"] = data[\"duration\"] * data[\"campaign\"] \n",
        "data[\"married\"].replace(['married','single','divorced'],[1,0,1],inplace=True)\n",
        "data[\"single\"].replace(['married','single','divorced'],[1,0,0],inplace=True)\n",
        "data[\"retirement\"] = (data[\"age\"] > 59).astype(int)\n",
        "\n",
        "\n",
        "train[\"y\"]=train[\"y\"].astype(np.int64)\n",
        "\n",
        "delete_columns = ['id', 'default', 'marital']\n",
        "data=data.drop(delete_columns, axis=1)\n",
        "\n",
        "\n",
        "categorical_features = ['job','education','housing','loan','contact','poutcome',\n",
        "                        \"income\",'goodincome','married',\"single\",'housing+loan',\n",
        "                        \"retirement\"]\n",
        "data[categorical_features] = data[categorical_features].astype('category')\n",
        "\n",
        "#trainとtestを再度切り分け\n",
        "train = data[:len(train)]\n",
        "test = data[len(train):]\n",
        "\n",
        "#train,testを、さらに説明変数Xと、予測変数yに切り分け。y_testは与えられていないのでなし。三種類がでる\n",
        "y = train['y']\n",
        "X = train.drop('y', axis = 1)\n",
        "X_sub = test.drop('y', axis = 1)\n",
        "\n"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWHraeskevqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIffNLkWcpMQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b79b13b7-8cc7-4f5b-d939-de61b17ec033"
      },
      "source": [
        "delete_columns"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['id', 'default', 'marital']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hxMQjovcNZS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "0aa24d3f-b5ba-45af-829a-1cfaac85af87"
      },
      "source": [
        "data"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>job</th>\n",
              "      <th>education</th>\n",
              "      <th>balance</th>\n",
              "      <th>housing</th>\n",
              "      <th>loan</th>\n",
              "      <th>contact</th>\n",
              "      <th>day</th>\n",
              "      <th>month</th>\n",
              "      <th>duration</th>\n",
              "      <th>campaign</th>\n",
              "      <th>pdays</th>\n",
              "      <th>previous</th>\n",
              "      <th>poutcome</th>\n",
              "      <th>y</th>\n",
              "      <th>income</th>\n",
              "      <th>goodincome</th>\n",
              "      <th>married</th>\n",
              "      <th>single</th>\n",
              "      <th>year</th>\n",
              "      <th>campaign+previous</th>\n",
              "      <th>poutcome/pdays</th>\n",
              "      <th>housing+loan</th>\n",
              "      <th>duration*campaign</th>\n",
              "      <th>retirement</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>12294</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>101</td>\n",
              "      <td>3</td>\n",
              "      <td>498</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>51</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>303</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>29</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>43027</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>22</td>\n",
              "      <td>10</td>\n",
              "      <td>158</td>\n",
              "      <td>2</td>\n",
              "      <td>702</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>322</td>\n",
              "      <td>2</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>316</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>12252</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>351</td>\n",
              "      <td>1</td>\n",
              "      <td>826</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>351</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>99121</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>7</td>\n",
              "      <td>658</td>\n",
              "      <td>2</td>\n",
              "      <td>120</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>226</td>\n",
              "      <td>2</td>\n",
              "      <td>76</td>\n",
              "      <td>2</td>\n",
              "      <td>1316</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>48</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>42005</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>177</td>\n",
              "      <td>1</td>\n",
              "      <td>273</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>183</td>\n",
              "      <td>1</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>177</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18045</th>\n",
              "      <td>49</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>98357</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>101</td>\n",
              "      <td>2</td>\n",
              "      <td>417</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>276</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>202</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18046</th>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>29621</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>345</td>\n",
              "      <td>1</td>\n",
              "      <td>815</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>222</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>345</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18047</th>\n",
              "      <td>34</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>94260</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>7</td>\n",
              "      <td>121</td>\n",
              "      <td>2</td>\n",
              "      <td>370</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>226</td>\n",
              "      <td>2</td>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>242</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18048</th>\n",
              "      <td>31</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>65483</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>345</td>\n",
              "      <td>2</td>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>225</td>\n",
              "      <td>2</td>\n",
              "      <td>392</td>\n",
              "      <td>1</td>\n",
              "      <td>690</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18049</th>\n",
              "      <td>30</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>6474</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>10</td>\n",
              "      <td>158</td>\n",
              "      <td>1</td>\n",
              "      <td>699</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>313</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>158</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>45150 rows × 25 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       age job education  ...  housing+loan duration*campaign retirement\n",
              "0       31   4         3  ...             1               303          0\n",
              "1       29   7         1  ...             0               316          0\n",
              "2       35   1         1  ...             1               351          0\n",
              "3       31   2         3  ...             2              1316          0\n",
              "4       48  10         0  ...             1               177          0\n",
              "...    ...  ..       ...  ...           ...               ...        ...\n",
              "18045   49   6         1  ...             1               202          0\n",
              "18046   34   0         3  ...             1               345          0\n",
              "18047   34   3         3  ...             1               242          0\n",
              "18048   31   2         3  ...             1               690          0\n",
              "18049   30   9         0  ...             0               158          0\n",
              "\n",
              "[45150 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k24AZlklO5Hl",
        "colab_type": "text"
      },
      "source": [
        "# LightGBM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsVRoAv_XYLr",
        "colab_type": "text"
      },
      "source": [
        "## def LGB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8r5hXuIO5Hg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LightGBMのデータ分割\n",
        "X_train_LGB, X_test_LGB, y_train_LGB, y_test_LGB = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "X_train2_LGB, X_valid_LGB, y_train2_LGB, y_valid_LGB = train_test_split(X, y, test_size=0.2, random_state=1)"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lja5ioHeO5Ht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lgbm_train(X_train_df, X_valid_df, y_train_df, y_valid_df, lgbm_params):\n",
        "    lgb_train = lgb.Dataset(X_train_df, y_train_df)\n",
        "    lgb_eval = lgb.Dataset(X_valid_df, y_valid_df, reference=lgb_train)\n",
        "\n",
        "    # 上記のパラメータでモデルを学習する\n",
        "    model = lgb.train(lgbm_params, lgb_train,\n",
        "                      # モデルの評価用データを渡す\n",
        "                      valid_sets=lgb_eval,\n",
        "                      # 最大で 1000 ラウンドまで学習する\n",
        "                      num_boost_round=1000,\n",
        "                      # 10 ラウンド経過しても性能が向上しないときは学習を打ち切る\n",
        "                      early_stopping_rounds=10)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0fx5If5eK0_",
        "colab_type": "text"
      },
      "source": [
        "## Optuna of LGB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpLXQfdmO5H8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def objective(trial):\n",
        "    params = {\n",
        "        'objective': 'binary',\n",
        "        'max_bin': trial.suggest_int('max_bin', 255, 500),\n",
        "        'learning_rate': 0.15,\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 32, 128),\n",
        "    }\n",
        "\n",
        "    lgb_train = lgb.Dataset(X_train_LGB, y_train_LGB)\n",
        "    lgb_eval = lgb.Dataset(X_valid_LGB, y_valid_LGB, reference=lgb_train)\n",
        "\n",
        "    model = lgb.train(params, lgb_train,\n",
        "                                   valid_sets=[lgb_train, lgb_eval],\n",
        "                                   verbose_eval=10,\n",
        "                                   num_boost_round=1000,\n",
        "                                   early_stopping_rounds=10)\n",
        "\n",
        "    y_pred_valid_LGB = model.predict(X_valid_LGB, num_iteration=model.best_iteration)\n",
        "    score = log_loss(y_valid_LGB, y_pred_valid_LGB)\n",
        "    return score"
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZP6cLcCvX5bi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "46189ffc-a86e-406a-8b3c-c56bb6de400a"
      },
      "source": [
        "study = optuna.create_study(sampler=optuna.samplers.RandomSampler(seed=0))\n",
        "study.optimize(objective, n_trials=30)"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.183185\tvalid_1's binary_logloss: 0.165843\n",
            "[20]\ttraining's binary_logloss: 0.152312\tvalid_1's binary_logloss: 0.141168\n",
            "[30]\ttraining's binary_logloss: 0.130338\tvalid_1's binary_logloss: 0.126298\n",
            "[40]\ttraining's binary_logloss: 0.113954\tvalid_1's binary_logloss: 0.113959\n",
            "[50]\ttraining's binary_logloss: 0.100857\tvalid_1's binary_logloss: 0.105269\n",
            "[60]\ttraining's binary_logloss: 0.0905326\tvalid_1's binary_logloss: 0.0984232\n",
            "[70]\ttraining's binary_logloss: 0.0813099\tvalid_1's binary_logloss: 0.0919385\n",
            "[80]\ttraining's binary_logloss: 0.0734049\tvalid_1's binary_logloss: 0.0864496\n",
            "[90]\ttraining's binary_logloss: 0.0663634\tvalid_1's binary_logloss: 0.0821787\n",
            "[100]\ttraining's binary_logloss: 0.0603149\tvalid_1's binary_logloss: 0.0781767\n",
            "[110]\ttraining's binary_logloss: 0.0541766\tvalid_1's binary_logloss: 0.0743709\n",
            "[120]\ttraining's binary_logloss: 0.0486519\tvalid_1's binary_logloss: 0.0700578\n",
            "[130]\ttraining's binary_logloss: 0.0447429\tvalid_1's binary_logloss: 0.0676335\n",
            "[140]\ttraining's binary_logloss: 0.0404429\tvalid_1's binary_logloss: 0.0647663\n",
            "[150]\ttraining's binary_logloss: 0.0367622\tvalid_1's binary_logloss: 0.0615332\n",
            "[160]\ttraining's binary_logloss: 0.0334213\tvalid_1's binary_logloss: 0.0591514\n",
            "[170]\ttraining's binary_logloss: 0.0304172\tvalid_1's binary_logloss: 0.0571365\n",
            "[180]\ttraining's binary_logloss: 0.0274923\tvalid_1's binary_logloss: 0.0559086\n",
            "[190]\ttraining's binary_logloss: 0.0251564\tvalid_1's binary_logloss: 0.0547827\n",
            "[200]\ttraining's binary_logloss: 0.0227521\tvalid_1's binary_logloss: 0.0537072\n",
            "[210]\ttraining's binary_logloss: 0.0205936\tvalid_1's binary_logloss: 0.0525731\n",
            "[220]\ttraining's binary_logloss: 0.0185812\tvalid_1's binary_logloss: 0.05127\n",
            "[230]\ttraining's binary_logloss: 0.016954\tvalid_1's binary_logloss: 0.0506201\n",
            "[240]\ttraining's binary_logloss: 0.0156024\tvalid_1's binary_logloss: 0.0500963\n",
            "[250]\ttraining's binary_logloss: 0.0142041\tvalid_1's binary_logloss: 0.0496046\n",
            "[260]\ttraining's binary_logloss: 0.0129605\tvalid_1's binary_logloss: 0.0492867\n",
            "[270]\ttraining's binary_logloss: 0.0117486\tvalid_1's binary_logloss: 0.0488247\n",
            "[280]\ttraining's binary_logloss: 0.0105446\tvalid_1's binary_logloss: 0.0485238\n",
            "[290]\ttraining's binary_logloss: 0.00975077\tvalid_1's binary_logloss: 0.0487086\n",
            "Early stopping, best iteration is:\n",
            "[280]\ttraining's binary_logloss: 0.0105446\tvalid_1's binary_logloss: 0.0485238\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-24 12:42:22,616] Trial 0 finished with value: 0.048523823989085675 and parameters: {'max_bin': 427, 'num_leaves': 79}. Best is trial 0 with value: 0.048523823989085675.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.176956\tvalid_1's binary_logloss: 0.16222\n",
            "[20]\ttraining's binary_logloss: 0.144301\tvalid_1's binary_logloss: 0.137977\n",
            "[30]\ttraining's binary_logloss: 0.119363\tvalid_1's binary_logloss: 0.120048\n",
            "[40]\ttraining's binary_logloss: 0.101942\tvalid_1's binary_logloss: 0.107525\n",
            "[50]\ttraining's binary_logloss: 0.0882003\tvalid_1's binary_logloss: 0.0982029\n",
            "[60]\ttraining's binary_logloss: 0.0775942\tvalid_1's binary_logloss: 0.090586\n",
            "[70]\ttraining's binary_logloss: 0.0682231\tvalid_1's binary_logloss: 0.0845657\n",
            "[80]\ttraining's binary_logloss: 0.0605564\tvalid_1's binary_logloss: 0.0796208\n",
            "[90]\ttraining's binary_logloss: 0.0532918\tvalid_1's binary_logloss: 0.0741255\n",
            "[100]\ttraining's binary_logloss: 0.0481037\tvalid_1's binary_logloss: 0.0706625\n",
            "[110]\ttraining's binary_logloss: 0.0429041\tvalid_1's binary_logloss: 0.0670822\n",
            "[120]\ttraining's binary_logloss: 0.0385013\tvalid_1's binary_logloss: 0.0642672\n",
            "[130]\ttraining's binary_logloss: 0.0340742\tvalid_1's binary_logloss: 0.0616224\n",
            "[140]\ttraining's binary_logloss: 0.0305181\tvalid_1's binary_logloss: 0.0593028\n",
            "[150]\ttraining's binary_logloss: 0.0275885\tvalid_1's binary_logloss: 0.0573782\n",
            "[160]\ttraining's binary_logloss: 0.0247197\tvalid_1's binary_logloss: 0.0558627\n",
            "[170]\ttraining's binary_logloss: 0.0222277\tvalid_1's binary_logloss: 0.0545275\n",
            "[180]\ttraining's binary_logloss: 0.0198173\tvalid_1's binary_logloss: 0.0532386\n",
            "[190]\ttraining's binary_logloss: 0.0176745\tvalid_1's binary_logloss: 0.0525035\n",
            "[200]\ttraining's binary_logloss: 0.0152959\tvalid_1's binary_logloss: 0.0511961\n",
            "[210]\ttraining's binary_logloss: 0.0135581\tvalid_1's binary_logloss: 0.050367\n",
            "[220]\ttraining's binary_logloss: 0.0120675\tvalid_1's binary_logloss: 0.0497819\n",
            "[230]\ttraining's binary_logloss: 0.0108204\tvalid_1's binary_logloss: 0.049468\n",
            "[240]\ttraining's binary_logloss: 0.00975163\tvalid_1's binary_logloss: 0.0492713\n",
            "[250]\ttraining's binary_logloss: 0.00875074\tvalid_1's binary_logloss: 0.0491781\n",
            "Early stopping, best iteration is:\n",
            "[248]\ttraining's binary_logloss: 0.00890525\tvalid_1's binary_logloss: 0.0491034\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-24 12:42:25,472] Trial 1 finished with value: 0.04910344546188399 and parameters: {'max_bin': 372, 'num_leaves': 96}. Best is trial 0 with value: 0.048523823989085675.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.17688\tvalid_1's binary_logloss: 0.162437\n",
            "[20]\ttraining's binary_logloss: 0.143662\tvalid_1's binary_logloss: 0.136135\n",
            "[30]\ttraining's binary_logloss: 0.119455\tvalid_1's binary_logloss: 0.118749\n",
            "[40]\ttraining's binary_logloss: 0.102071\tvalid_1's binary_logloss: 0.106072\n",
            "[50]\ttraining's binary_logloss: 0.0883508\tvalid_1's binary_logloss: 0.0967712\n",
            "[60]\ttraining's binary_logloss: 0.0771405\tvalid_1's binary_logloss: 0.0888738\n",
            "[70]\ttraining's binary_logloss: 0.0683603\tvalid_1's binary_logloss: 0.0832056\n",
            "[80]\ttraining's binary_logloss: 0.0595594\tvalid_1's binary_logloss: 0.0772371\n",
            "[90]\ttraining's binary_logloss: 0.0525642\tvalid_1's binary_logloss: 0.0722784\n",
            "[100]\ttraining's binary_logloss: 0.0469586\tvalid_1's binary_logloss: 0.068936\n",
            "[110]\ttraining's binary_logloss: 0.042054\tvalid_1's binary_logloss: 0.0655499\n",
            "[120]\ttraining's binary_logloss: 0.0373672\tvalid_1's binary_logloss: 0.0625969\n",
            "[130]\ttraining's binary_logloss: 0.0332287\tvalid_1's binary_logloss: 0.0595807\n",
            "[140]\ttraining's binary_logloss: 0.0293962\tvalid_1's binary_logloss: 0.0572298\n",
            "[150]\ttraining's binary_logloss: 0.0260661\tvalid_1's binary_logloss: 0.0556741\n",
            "[160]\ttraining's binary_logloss: 0.0230502\tvalid_1's binary_logloss: 0.0538208\n",
            "[170]\ttraining's binary_logloss: 0.020337\tvalid_1's binary_logloss: 0.0523748\n",
            "[180]\ttraining's binary_logloss: 0.0184482\tvalid_1's binary_logloss: 0.051689\n",
            "[190]\ttraining's binary_logloss: 0.0165697\tvalid_1's binary_logloss: 0.0511063\n",
            "[200]\ttraining's binary_logloss: 0.0146761\tvalid_1's binary_logloss: 0.050501\n",
            "[210]\ttraining's binary_logloss: 0.0127784\tvalid_1's binary_logloss: 0.0496062\n",
            "[220]\ttraining's binary_logloss: 0.0111949\tvalid_1's binary_logloss: 0.048747\n",
            "[230]\ttraining's binary_logloss: 0.0100472\tvalid_1's binary_logloss: 0.0488575\n",
            "Early stopping, best iteration is:\n",
            "[227]\ttraining's binary_logloss: 0.0104538\tvalid_1's binary_logloss: 0.0486065\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-24 12:42:28,137] Trial 2 finished with value: 0.04860653171667743 and parameters: {'max_bin': 322, 'num_leaves': 99}. Best is trial 0 with value: 0.048523823989085675.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.198065\tvalid_1's binary_logloss: 0.179012\n",
            "[20]\ttraining's binary_logloss: 0.177158\tvalid_1's binary_logloss: 0.160308\n",
            "[30]\ttraining's binary_logloss: 0.162286\tvalid_1's binary_logloss: 0.149447\n",
            "[40]\ttraining's binary_logloss: 0.150835\tvalid_1's binary_logloss: 0.141501\n",
            "[50]\ttraining's binary_logloss: 0.140527\tvalid_1's binary_logloss: 0.134217\n",
            "[60]\ttraining's binary_logloss: 0.131862\tvalid_1's binary_logloss: 0.127786\n",
            "[70]\ttraining's binary_logloss: 0.122729\tvalid_1's binary_logloss: 0.121443\n",
            "[80]\ttraining's binary_logloss: 0.116287\tvalid_1's binary_logloss: 0.116826\n",
            "[90]\ttraining's binary_logloss: 0.110292\tvalid_1's binary_logloss: 0.112864\n",
            "[100]\ttraining's binary_logloss: 0.104143\tvalid_1's binary_logloss: 0.108046\n",
            "[110]\ttraining's binary_logloss: 0.0988094\tvalid_1's binary_logloss: 0.104393\n",
            "[120]\ttraining's binary_logloss: 0.0940544\tvalid_1's binary_logloss: 0.100683\n",
            "[130]\ttraining's binary_logloss: 0.0893746\tvalid_1's binary_logloss: 0.0974154\n",
            "[140]\ttraining's binary_logloss: 0.0847532\tvalid_1's binary_logloss: 0.0941615\n",
            "[150]\ttraining's binary_logloss: 0.0806495\tvalid_1's binary_logloss: 0.0911832\n",
            "[160]\ttraining's binary_logloss: 0.0770825\tvalid_1's binary_logloss: 0.0886195\n",
            "[170]\ttraining's binary_logloss: 0.0727727\tvalid_1's binary_logloss: 0.0860409\n",
            "[180]\ttraining's binary_logloss: 0.0688115\tvalid_1's binary_logloss: 0.0835002\n",
            "[190]\ttraining's binary_logloss: 0.0656991\tvalid_1's binary_logloss: 0.0811468\n",
            "[200]\ttraining's binary_logloss: 0.0623139\tvalid_1's binary_logloss: 0.0787851\n",
            "[210]\ttraining's binary_logloss: 0.0594617\tvalid_1's binary_logloss: 0.0769459\n",
            "[220]\ttraining's binary_logloss: 0.0571662\tvalid_1's binary_logloss: 0.0754432\n",
            "[230]\ttraining's binary_logloss: 0.0541128\tvalid_1's binary_logloss: 0.0734774\n",
            "[240]\ttraining's binary_logloss: 0.0519875\tvalid_1's binary_logloss: 0.0717938\n",
            "[250]\ttraining's binary_logloss: 0.0496597\tvalid_1's binary_logloss: 0.0701814\n",
            "[260]\ttraining's binary_logloss: 0.0470907\tvalid_1's binary_logloss: 0.0686797\n",
            "[270]\ttraining's binary_logloss: 0.0450688\tvalid_1's binary_logloss: 0.0675345\n",
            "[280]\ttraining's binary_logloss: 0.0427367\tvalid_1's binary_logloss: 0.0664321\n",
            "[290]\ttraining's binary_logloss: 0.0404168\tvalid_1's binary_logloss: 0.0653097\n",
            "[300]\ttraining's binary_logloss: 0.0384722\tvalid_1's binary_logloss: 0.0640465\n",
            "[310]\ttraining's binary_logloss: 0.0363987\tvalid_1's binary_logloss: 0.0634195\n",
            "[320]\ttraining's binary_logloss: 0.0344653\tvalid_1's binary_logloss: 0.0622602\n",
            "[330]\ttraining's binary_logloss: 0.0331916\tvalid_1's binary_logloss: 0.0614211\n",
            "[340]\ttraining's binary_logloss: 0.0318939\tvalid_1's binary_logloss: 0.0604147\n",
            "[350]\ttraining's binary_logloss: 0.0303552\tvalid_1's binary_logloss: 0.0595543\n",
            "[360]\ttraining's binary_logloss: 0.0288783\tvalid_1's binary_logloss: 0.0586125\n",
            "[370]\ttraining's binary_logloss: 0.027497\tvalid_1's binary_logloss: 0.0578905\n",
            "[380]\ttraining's binary_logloss: 0.0262341\tvalid_1's binary_logloss: 0.0574348\n",
            "[390]\ttraining's binary_logloss: 0.0251252\tvalid_1's binary_logloss: 0.0566181\n",
            "[400]\ttraining's binary_logloss: 0.0240089\tvalid_1's binary_logloss: 0.0559896\n",
            "[410]\ttraining's binary_logloss: 0.022866\tvalid_1's binary_logloss: 0.0553443\n",
            "[420]\ttraining's binary_logloss: 0.022\tvalid_1's binary_logloss: 0.0549213\n",
            "[430]\ttraining's binary_logloss: 0.0209579\tvalid_1's binary_logloss: 0.054438\n",
            "[440]\ttraining's binary_logloss: 0.0200702\tvalid_1's binary_logloss: 0.0543776\n",
            "[450]\ttraining's binary_logloss: 0.0190738\tvalid_1's binary_logloss: 0.0538964\n",
            "[460]\ttraining's binary_logloss: 0.0181403\tvalid_1's binary_logloss: 0.0535893\n",
            "[470]\ttraining's binary_logloss: 0.0173661\tvalid_1's binary_logloss: 0.0531232\n",
            "[480]\ttraining's binary_logloss: 0.0165529\tvalid_1's binary_logloss: 0.0527983\n",
            "[490]\ttraining's binary_logloss: 0.0159217\tvalid_1's binary_logloss: 0.052515\n",
            "[500]\ttraining's binary_logloss: 0.0153142\tvalid_1's binary_logloss: 0.0522073\n",
            "[510]\ttraining's binary_logloss: 0.0145867\tvalid_1's binary_logloss: 0.051853\n",
            "[520]\ttraining's binary_logloss: 0.0138952\tvalid_1's binary_logloss: 0.0516109\n",
            "[530]\ttraining's binary_logloss: 0.0132068\tvalid_1's binary_logloss: 0.0511933\n",
            "[540]\ttraining's binary_logloss: 0.0125536\tvalid_1's binary_logloss: 0.0510799\n",
            "[550]\ttraining's binary_logloss: 0.0120507\tvalid_1's binary_logloss: 0.050872\n",
            "[560]\ttraining's binary_logloss: 0.0114348\tvalid_1's binary_logloss: 0.0510987\n",
            "Early stopping, best iteration is:\n",
            "[550]\ttraining's binary_logloss: 0.0120507\tvalid_1's binary_logloss: 0.050872\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-24 12:42:32,118] Trial 3 finished with value: 0.05087199763502697 and parameters: {'max_bin': 358, 'num_leaves': 41}. Best is trial 0 with value: 0.048523823989085675.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.19276\tvalid_1's binary_logloss: 0.174827\n",
            "[20]\ttraining's binary_logloss: 0.168206\tvalid_1's binary_logloss: 0.155272\n",
            "[30]\ttraining's binary_logloss: 0.15066\tvalid_1's binary_logloss: 0.142329\n",
            "[40]\ttraining's binary_logloss: 0.137063\tvalid_1's binary_logloss: 0.132151\n",
            "[50]\ttraining's binary_logloss: 0.126174\tvalid_1's binary_logloss: 0.123932\n",
            "[60]\ttraining's binary_logloss: 0.117021\tvalid_1's binary_logloss: 0.117753\n",
            "[70]\ttraining's binary_logloss: 0.108346\tvalid_1's binary_logloss: 0.111137\n",
            "[80]\ttraining's binary_logloss: 0.101309\tvalid_1's binary_logloss: 0.106769\n",
            "[90]\ttraining's binary_logloss: 0.0943108\tvalid_1's binary_logloss: 0.102238\n",
            "[100]\ttraining's binary_logloss: 0.0889872\tvalid_1's binary_logloss: 0.0985861\n",
            "[110]\ttraining's binary_logloss: 0.0823832\tvalid_1's binary_logloss: 0.0933249\n",
            "[120]\ttraining's binary_logloss: 0.077071\tvalid_1's binary_logloss: 0.0899472\n",
            "[130]\ttraining's binary_logloss: 0.0716225\tvalid_1's binary_logloss: 0.0865968\n",
            "[140]\ttraining's binary_logloss: 0.0668118\tvalid_1's binary_logloss: 0.0835378\n",
            "[150]\ttraining's binary_logloss: 0.0626849\tvalid_1's binary_logloss: 0.0804844\n",
            "[160]\ttraining's binary_logloss: 0.0588514\tvalid_1's binary_logloss: 0.0780039\n",
            "[170]\ttraining's binary_logloss: 0.0548154\tvalid_1's binary_logloss: 0.0755707\n",
            "[180]\ttraining's binary_logloss: 0.0514794\tvalid_1's binary_logloss: 0.0735134\n",
            "[190]\ttraining's binary_logloss: 0.0480012\tvalid_1's binary_logloss: 0.0711601\n",
            "[200]\ttraining's binary_logloss: 0.0451305\tvalid_1's binary_logloss: 0.0688587\n",
            "[210]\ttraining's binary_logloss: 0.0421075\tvalid_1's binary_logloss: 0.0664989\n",
            "[220]\ttraining's binary_logloss: 0.0394494\tvalid_1's binary_logloss: 0.0648214\n",
            "[230]\ttraining's binary_logloss: 0.0368469\tvalid_1's binary_logloss: 0.0629453\n",
            "[240]\ttraining's binary_logloss: 0.0345654\tvalid_1's binary_logloss: 0.0616971\n",
            "[250]\ttraining's binary_logloss: 0.0327064\tvalid_1's binary_logloss: 0.0607742\n",
            "[260]\ttraining's binary_logloss: 0.0307478\tvalid_1's binary_logloss: 0.0596962\n",
            "[270]\ttraining's binary_logloss: 0.0290831\tvalid_1's binary_logloss: 0.0586294\n",
            "[280]\ttraining's binary_logloss: 0.0273009\tvalid_1's binary_logloss: 0.0572081\n",
            "[290]\ttraining's binary_logloss: 0.0253682\tvalid_1's binary_logloss: 0.0560038\n",
            "[300]\ttraining's binary_logloss: 0.0238578\tvalid_1's binary_logloss: 0.0552232\n",
            "[310]\ttraining's binary_logloss: 0.0224785\tvalid_1's binary_logloss: 0.0538867\n",
            "[320]\ttraining's binary_logloss: 0.0210009\tvalid_1's binary_logloss: 0.0527676\n",
            "[330]\ttraining's binary_logloss: 0.0195121\tvalid_1's binary_logloss: 0.051771\n",
            "[340]\ttraining's binary_logloss: 0.0182346\tvalid_1's binary_logloss: 0.0508756\n",
            "[350]\ttraining's binary_logloss: 0.0172013\tvalid_1's binary_logloss: 0.0502626\n",
            "[360]\ttraining's binary_logloss: 0.0160644\tvalid_1's binary_logloss: 0.049716\n",
            "[370]\ttraining's binary_logloss: 0.0150906\tvalid_1's binary_logloss: 0.0495697\n",
            "[380]\ttraining's binary_logloss: 0.0140702\tvalid_1's binary_logloss: 0.049124\n",
            "[390]\ttraining's binary_logloss: 0.0132278\tvalid_1's binary_logloss: 0.0485768\n",
            "[400]\ttraining's binary_logloss: 0.0124244\tvalid_1's binary_logloss: 0.0484636\n",
            "[410]\ttraining's binary_logloss: 0.011534\tvalid_1's binary_logloss: 0.0479325\n",
            "[420]\ttraining's binary_logloss: 0.0107593\tvalid_1's binary_logloss: 0.0477253\n",
            "[430]\ttraining's binary_logloss: 0.0100868\tvalid_1's binary_logloss: 0.0476357\n",
            "[440]\ttraining's binary_logloss: 0.00951313\tvalid_1's binary_logloss: 0.0475192\n",
            "Early stopping, best iteration is:\n",
            "[434]\ttraining's binary_logloss: 0.00983701\tvalid_1's binary_logloss: 0.0474778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-24 12:42:35,944] Trial 4 finished with value: 0.04747782589205702 and parameters: {'max_bin': 466, 'num_leaves': 53}. Best is trial 4 with value: 0.04747782589205702.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.18721\tvalid_1's binary_logloss: 0.171059\n",
            "[20]\ttraining's binary_logloss: 0.159914\tvalid_1's binary_logloss: 0.148653\n",
            "[30]\ttraining's binary_logloss: 0.139752\tvalid_1's binary_logloss: 0.133987\n",
            "[40]\ttraining's binary_logloss: 0.123935\tvalid_1's binary_logloss: 0.122893\n",
            "[50]\ttraining's binary_logloss: 0.112515\tvalid_1's binary_logloss: 0.114722\n",
            "[60]\ttraining's binary_logloss: 0.102415\tvalid_1's binary_logloss: 0.108093\n",
            "[70]\ttraining's binary_logloss: 0.0923242\tvalid_1's binary_logloss: 0.100383\n",
            "[80]\ttraining's binary_logloss: 0.0836498\tvalid_1's binary_logloss: 0.094289\n",
            "[90]\ttraining's binary_logloss: 0.0762047\tvalid_1's binary_logloss: 0.089108\n",
            "[100]\ttraining's binary_logloss: 0.0697073\tvalid_1's binary_logloss: 0.0853267\n",
            "[110]\ttraining's binary_logloss: 0.0640495\tvalid_1's binary_logloss: 0.0815675\n",
            "[120]\ttraining's binary_logloss: 0.0590403\tvalid_1's binary_logloss: 0.0783955\n",
            "[130]\ttraining's binary_logloss: 0.054272\tvalid_1's binary_logloss: 0.0755262\n",
            "[140]\ttraining's binary_logloss: 0.050316\tvalid_1's binary_logloss: 0.0729583\n",
            "[150]\ttraining's binary_logloss: 0.0460479\tvalid_1's binary_logloss: 0.0701455\n",
            "[160]\ttraining's binary_logloss: 0.0425754\tvalid_1's binary_logloss: 0.0683633\n",
            "[170]\ttraining's binary_logloss: 0.0393582\tvalid_1's binary_logloss: 0.066522\n",
            "[180]\ttraining's binary_logloss: 0.0367029\tvalid_1's binary_logloss: 0.0645398\n",
            "[190]\ttraining's binary_logloss: 0.0338794\tvalid_1's binary_logloss: 0.0628768\n",
            "[200]\ttraining's binary_logloss: 0.0313424\tvalid_1's binary_logloss: 0.0614299\n",
            "[210]\ttraining's binary_logloss: 0.0290535\tvalid_1's binary_logloss: 0.0602711\n",
            "[220]\ttraining's binary_logloss: 0.0262381\tvalid_1's binary_logloss: 0.0582403\n",
            "[230]\ttraining's binary_logloss: 0.0243815\tvalid_1's binary_logloss: 0.0567163\n",
            "[240]\ttraining's binary_logloss: 0.0223224\tvalid_1's binary_logloss: 0.055417\n",
            "[250]\ttraining's binary_logloss: 0.0206138\tvalid_1's binary_logloss: 0.0546749\n",
            "[260]\ttraining's binary_logloss: 0.0191724\tvalid_1's binary_logloss: 0.0541938\n",
            "[270]\ttraining's binary_logloss: 0.0173999\tvalid_1's binary_logloss: 0.0530916\n",
            "[280]\ttraining's binary_logloss: 0.0160227\tvalid_1's binary_logloss: 0.0523865\n",
            "[290]\ttraining's binary_logloss: 0.0147068\tvalid_1's binary_logloss: 0.0519319\n",
            "[300]\ttraining's binary_logloss: 0.0137708\tvalid_1's binary_logloss: 0.0515981\n",
            "[310]\ttraining's binary_logloss: 0.0126475\tvalid_1's binary_logloss: 0.0509163\n",
            "[320]\ttraining's binary_logloss: 0.0117409\tvalid_1's binary_logloss: 0.0506092\n",
            "[330]\ttraining's binary_logloss: 0.0110073\tvalid_1's binary_logloss: 0.0505001\n",
            "Early stopping, best iteration is:\n",
            "[327]\ttraining's binary_logloss: 0.011225\tvalid_1's binary_logloss: 0.0503431\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-24 12:42:39,236] Trial 5 finished with value: 0.05034306080535833 and parameters: {'max_bin': 497, 'num_leaves': 68}. Best is trial 4 with value: 0.04747782589205702.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.175572\tvalid_1's binary_logloss: 0.16189\n",
            "[20]\ttraining's binary_logloss: 0.142681\tvalid_1's binary_logloss: 0.135656\n",
            "[30]\ttraining's binary_logloss: 0.118073\tvalid_1's binary_logloss: 0.117951\n",
            "[40]\ttraining's binary_logloss: 0.0997176\tvalid_1's binary_logloss: 0.105395\n",
            "[50]\ttraining's binary_logloss: 0.0867597\tvalid_1's binary_logloss: 0.0963371\n",
            "[60]\ttraining's binary_logloss: 0.0756639\tvalid_1's binary_logloss: 0.0890725\n",
            "[70]\ttraining's binary_logloss: 0.0660858\tvalid_1's binary_logloss: 0.0822194\n",
            "[80]\ttraining's binary_logloss: 0.0587123\tvalid_1's binary_logloss: 0.0764058\n",
            "[90]\ttraining's binary_logloss: 0.0517081\tvalid_1's binary_logloss: 0.0716602\n",
            "[100]\ttraining's binary_logloss: 0.0454871\tvalid_1's binary_logloss: 0.0676554\n",
            "[110]\ttraining's binary_logloss: 0.0409332\tvalid_1's binary_logloss: 0.0647064\n",
            "[120]\ttraining's binary_logloss: 0.0357061\tvalid_1's binary_logloss: 0.0613918\n",
            "[130]\ttraining's binary_logloss: 0.0311098\tvalid_1's binary_logloss: 0.0581139\n",
            "[140]\ttraining's binary_logloss: 0.0272281\tvalid_1's binary_logloss: 0.0557895\n",
            "[150]\ttraining's binary_logloss: 0.0242215\tvalid_1's binary_logloss: 0.0541899\n",
            "[160]\ttraining's binary_logloss: 0.0212139\tvalid_1's binary_logloss: 0.0528187\n",
            "[170]\ttraining's binary_logloss: 0.0186908\tvalid_1's binary_logloss: 0.051543\n",
            "[180]\ttraining's binary_logloss: 0.0163322\tvalid_1's binary_logloss: 0.0501706\n",
            "[190]\ttraining's binary_logloss: 0.0141951\tvalid_1's binary_logloss: 0.049092\n",
            "[200]\ttraining's binary_logloss: 0.0126239\tvalid_1's binary_logloss: 0.0486811\n",
            "[210]\ttraining's binary_logloss: 0.0113463\tvalid_1's binary_logloss: 0.048309\n",
            "[220]\ttraining's binary_logloss: 0.0102158\tvalid_1's binary_logloss: 0.0481505\n",
            "[230]\ttraining's binary_logloss: 0.00916455\tvalid_1's binary_logloss: 0.0478524\n",
            "[240]\ttraining's binary_logloss: 0.00805015\tvalid_1's binary_logloss: 0.0473843\n",
            "[250]\ttraining's binary_logloss: 0.00714805\tvalid_1's binary_logloss: 0.0468318\n",
            "[260]\ttraining's binary_logloss: 0.0063123\tvalid_1's binary_logloss: 0.0468214\n",
            "[270]\ttraining's binary_logloss: 0.00562212\tvalid_1's binary_logloss: 0.0467954\n",
            "Early stopping, best iteration is:\n",
            "[263]\ttraining's binary_logloss: 0.0060531\tvalid_1's binary_logloss: 0.0466807\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-24 12:42:42,460] Trial 6 finished with value: 0.04668074230693663 and parameters: {'max_bin': 342, 'num_leaves': 102}. Best is trial 6 with value: 0.04668074230693663.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.17069\tvalid_1's binary_logloss: 0.159099\n",
            "[20]\ttraining's binary_logloss: 0.134246\tvalid_1's binary_logloss: 0.131066\n",
            "[30]\ttraining's binary_logloss: 0.108033\tvalid_1's binary_logloss: 0.111438\n",
            "[40]\ttraining's binary_logloss: 0.0904789\tvalid_1's binary_logloss: 0.0992564\n",
            "[50]\ttraining's binary_logloss: 0.0766318\tvalid_1's binary_logloss: 0.0896691\n",
            "[60]\ttraining's binary_logloss: 0.0648179\tvalid_1's binary_logloss: 0.0810762\n",
            "[70]\ttraining's binary_logloss: 0.0563984\tvalid_1's binary_logloss: 0.0755939\n",
            "[80]\ttraining's binary_logloss: 0.0480295\tvalid_1's binary_logloss: 0.0695077\n",
            "[90]\ttraining's binary_logloss: 0.0409322\tvalid_1's binary_logloss: 0.0642333\n",
            "[100]\ttraining's binary_logloss: 0.0354812\tvalid_1's binary_logloss: 0.0605341\n",
            "[110]\ttraining's binary_logloss: 0.031163\tvalid_1's binary_logloss: 0.0580467\n",
            "[120]\ttraining's binary_logloss: 0.0265634\tvalid_1's binary_logloss: 0.0548356\n",
            "[130]\ttraining's binary_logloss: 0.0231408\tvalid_1's binary_logloss: 0.052524\n",
            "[140]\ttraining's binary_logloss: 0.0198277\tvalid_1's binary_logloss: 0.050917\n",
            "[150]\ttraining's binary_logloss: 0.0171759\tvalid_1's binary_logloss: 0.0499466\n",
            "[160]\ttraining's binary_logloss: 0.0148208\tvalid_1's binary_logloss: 0.0487344\n",
            "[170]\ttraining's binary_logloss: 0.012637\tvalid_1's binary_logloss: 0.0480377\n",
            "[180]\ttraining's binary_logloss: 0.0108749\tvalid_1's binary_logloss: 0.0473362\n",
            "[190]\ttraining's binary_logloss: 0.00935897\tvalid_1's binary_logloss: 0.0469105\n",
            "[200]\ttraining's binary_logloss: 0.00820694\tvalid_1's binary_logloss: 0.0467446\n",
            "[210]\ttraining's binary_logloss: 0.00721676\tvalid_1's binary_logloss: 0.0468671\n",
            "Early stopping, best iteration is:\n",
            "[207]\ttraining's binary_logloss: 0.00750443\tvalid_1's binary_logloss: 0.0465702\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-24 12:42:45,394] Trial 7 finished with value: 0.046570177200944515 and parameters: {'max_bin': 471, 'num_leaves': 120}. Best is trial 7 with value: 0.046570177200944515.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.179255\tvalid_1's binary_logloss: 0.164107\n",
            "[20]\ttraining's binary_logloss: 0.146915\tvalid_1's binary_logloss: 0.139509\n",
            "[30]\ttraining's binary_logloss: 0.124053\tvalid_1's binary_logloss: 0.121475\n",
            "[40]\ttraining's binary_logloss: 0.107846\tvalid_1's binary_logloss: 0.110031\n",
            "[50]\ttraining's binary_logloss: 0.0939155\tvalid_1's binary_logloss: 0.100938\n",
            "[60]\ttraining's binary_logloss: 0.0832384\tvalid_1's binary_logloss: 0.0932464\n",
            "[70]\ttraining's binary_logloss: 0.0746145\tvalid_1's binary_logloss: 0.0871167\n",
            "[80]\ttraining's binary_logloss: 0.0654965\tvalid_1's binary_logloss: 0.0805072\n",
            "[90]\ttraining's binary_logloss: 0.0582851\tvalid_1's binary_logloss: 0.0751736\n",
            "[100]\ttraining's binary_logloss: 0.0522704\tvalid_1's binary_logloss: 0.071604\n",
            "[110]\ttraining's binary_logloss: 0.0474008\tvalid_1's binary_logloss: 0.0685269\n",
            "[120]\ttraining's binary_logloss: 0.0428558\tvalid_1's binary_logloss: 0.0653171\n",
            "[130]\ttraining's binary_logloss: 0.0379056\tvalid_1's binary_logloss: 0.0620001\n",
            "[140]\ttraining's binary_logloss: 0.0341375\tvalid_1's binary_logloss: 0.0595666\n",
            "[150]\ttraining's binary_logloss: 0.0302861\tvalid_1's binary_logloss: 0.0566404\n",
            "[160]\ttraining's binary_logloss: 0.0276193\tvalid_1's binary_logloss: 0.0555718\n",
            "[170]\ttraining's binary_logloss: 0.0248907\tvalid_1's binary_logloss: 0.0541923\n",
            "[180]\ttraining's binary_logloss: 0.0222393\tvalid_1's binary_logloss: 0.0526289\n",
            "[190]\ttraining's binary_logloss: 0.0199816\tvalid_1's binary_logloss: 0.0516538\n",
            "[200]\ttraining's binary_logloss: 0.0178169\tvalid_1's binary_logloss: 0.0503546\n",
            "[210]\ttraining's binary_logloss: 0.0159321\tvalid_1's binary_logloss: 0.04935\n",
            "[220]\ttraining's binary_logloss: 0.0143063\tvalid_1's binary_logloss: 0.0489259\n",
            "[230]\ttraining's binary_logloss: 0.0128171\tvalid_1's binary_logloss: 0.0485871\n",
            "[240]\ttraining's binary_logloss: 0.0112093\tvalid_1's binary_logloss: 0.0478692\n",
            "[250]\ttraining's binary_logloss: 0.0101857\tvalid_1's binary_logloss: 0.0477837\n",
            "[260]\ttraining's binary_logloss: 0.00924522\tvalid_1's binary_logloss: 0.0474957\n",
            "[270]\ttraining's binary_logloss: 0.00833804\tvalid_1's binary_logloss: 0.0474321\n",
            "Early stopping, best iteration is:\n",
            "[266]\ttraining's binary_logloss: 0.00868386\tvalid_1's binary_logloss: 0.0473308\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-24 12:42:48,395] Trial 8 finished with value: 0.047330834898207705 and parameters: {'max_bin': 395, 'num_leaves': 90}. Best is trial 7 with value: 0.046570177200944515.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.185955\tvalid_1's binary_logloss: 0.17052\n",
            "[20]\ttraining's binary_logloss: 0.157432\tvalid_1's binary_logloss: 0.147579\n",
            "[30]\ttraining's binary_logloss: 0.137071\tvalid_1's binary_logloss: 0.131779\n",
            "[40]\ttraining's binary_logloss: 0.120948\tvalid_1's binary_logloss: 0.120498\n",
            "[50]\ttraining's binary_logloss: 0.107898\tvalid_1's binary_logloss: 0.110841\n",
            "[60]\ttraining's binary_logloss: 0.0982561\tvalid_1's binary_logloss: 0.10287\n",
            "[70]\ttraining's binary_logloss: 0.0895208\tvalid_1's binary_logloss: 0.0971739\n",
            "[80]\ttraining's binary_logloss: 0.0825497\tvalid_1's binary_logloss: 0.092343\n",
            "[90]\ttraining's binary_logloss: 0.0762464\tvalid_1's binary_logloss: 0.088318\n",
            "[100]\ttraining's binary_logloss: 0.0693052\tvalid_1's binary_logloss: 0.0838065\n",
            "[110]\ttraining's binary_logloss: 0.0633194\tvalid_1's binary_logloss: 0.0799493\n",
            "[120]\ttraining's binary_logloss: 0.0578709\tvalid_1's binary_logloss: 0.0764501\n",
            "[130]\ttraining's binary_logloss: 0.0526059\tvalid_1's binary_logloss: 0.0733678\n",
            "[140]\ttraining's binary_logloss: 0.0481059\tvalid_1's binary_logloss: 0.0703912\n",
            "[150]\ttraining's binary_logloss: 0.0444342\tvalid_1's binary_logloss: 0.0679365\n",
            "[160]\ttraining's binary_logloss: 0.0407456\tvalid_1's binary_logloss: 0.0654598\n",
            "[170]\ttraining's binary_logloss: 0.0376288\tvalid_1's binary_logloss: 0.0632224\n",
            "[180]\ttraining's binary_logloss: 0.0347937\tvalid_1's binary_logloss: 0.0617135\n",
            "[190]\ttraining's binary_logloss: 0.0315018\tvalid_1's binary_logloss: 0.0597049\n",
            "[200]\ttraining's binary_logloss: 0.0286137\tvalid_1's binary_logloss: 0.057682\n",
            "[210]\ttraining's binary_logloss: 0.0260075\tvalid_1's binary_logloss: 0.0562274\n",
            "[220]\ttraining's binary_logloss: 0.02362\tvalid_1's binary_logloss: 0.0548273\n",
            "[230]\ttraining's binary_logloss: 0.0215851\tvalid_1's binary_logloss: 0.0538191\n",
            "[240]\ttraining's binary_logloss: 0.0198681\tvalid_1's binary_logloss: 0.0528828\n",
            "[250]\ttraining's binary_logloss: 0.0184441\tvalid_1's binary_logloss: 0.0519954\n",
            "[260]\ttraining's binary_logloss: 0.0171434\tvalid_1's binary_logloss: 0.0513622\n",
            "[270]\ttraining's binary_logloss: 0.0159274\tvalid_1's binary_logloss: 0.0508385\n",
            "[280]\ttraining's binary_logloss: 0.0145818\tvalid_1's binary_logloss: 0.0502538\n",
            "[290]\ttraining's binary_logloss: 0.0134146\tvalid_1's binary_logloss: 0.049891\n",
            "[300]\ttraining's binary_logloss: 0.012459\tvalid_1's binary_logloss: 0.0495935\n",
            "[310]\ttraining's binary_logloss: 0.0114312\tvalid_1's binary_logloss: 0.0490977\n",
            "[320]\ttraining's binary_logloss: 0.0106803\tvalid_1's binary_logloss: 0.049108\n",
            "[330]\ttraining's binary_logloss: 0.00975781\tvalid_1's binary_logloss: 0.0487623\n",
            "[340]\ttraining's binary_logloss: 0.008976\tvalid_1's binary_logloss: 0.0483164\n",
            "[350]\ttraining's binary_logloss: 0.00812216\tvalid_1's binary_logloss: 0.048164\n",
            "[360]\ttraining's binary_logloss: 0.00745596\tvalid_1's binary_logloss: 0.0479546\n",
            "Early stopping, best iteration is:\n",
            "[355]\ttraining's binary_logloss: 0.00777184\tvalid_1's binary_logloss: 0.047854\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-24 12:42:51,955] Trial 9 finished with value: 0.04785395839897702 and parameters: {'max_bin': 448, 'num_leaves': 71}. Best is trial 7 with value: 0.046570177200944515.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.18327\tvalid_1's binary_logloss: 0.166825\n",
            "[20]\ttraining's binary_logloss: 0.153732\tvalid_1's binary_logloss: 0.143018\n",
            "[30]\ttraining's binary_logloss: 0.132043\tvalid_1's binary_logloss: 0.127576\n",
            "[40]\ttraining's binary_logloss: 0.116144\tvalid_1's binary_logloss: 0.116398\n",
            "[50]\ttraining's binary_logloss: 0.104052\tvalid_1's binary_logloss: 0.107517\n",
            "[60]\ttraining's binary_logloss: 0.0936577\tvalid_1's binary_logloss: 0.100627\n",
            "[70]\ttraining's binary_logloss: 0.084206\tvalid_1's binary_logloss: 0.094506\n",
            "[80]\ttraining's binary_logloss: 0.0770498\tvalid_1's binary_logloss: 0.0895408\n",
            "[90]\ttraining's binary_logloss: 0.0692014\tvalid_1's binary_logloss: 0.0844135\n",
            "[100]\ttraining's binary_logloss: 0.0622884\tvalid_1's binary_logloss: 0.0799384\n",
            "[110]\ttraining's binary_logloss: 0.0566083\tvalid_1's binary_logloss: 0.0761414\n",
            "[120]\ttraining's binary_logloss: 0.050863\tvalid_1's binary_logloss: 0.0719511\n",
            "[130]\ttraining's binary_logloss: 0.0457476\tvalid_1's binary_logloss: 0.068243\n",
            "[140]\ttraining's binary_logloss: 0.0420498\tvalid_1's binary_logloss: 0.0654559\n",
            "[150]\ttraining's binary_logloss: 0.0387105\tvalid_1's binary_logloss: 0.0635431\n",
            "[160]\ttraining's binary_logloss: 0.0351115\tvalid_1's binary_logloss: 0.0614219\n",
            "[170]\ttraining's binary_logloss: 0.0318825\tvalid_1's binary_logloss: 0.0593365\n",
            "[180]\ttraining's binary_logloss: 0.0293971\tvalid_1's binary_logloss: 0.0576531\n",
            "[190]\ttraining's binary_logloss: 0.0266793\tvalid_1's binary_logloss: 0.0562136\n",
            "[200]\ttraining's binary_logloss: 0.0242871\tvalid_1's binary_logloss: 0.0547636\n",
            "[210]\ttraining's binary_logloss: 0.0223631\tvalid_1's binary_logloss: 0.0536397\n",
            "[220]\ttraining's binary_logloss: 0.0203569\tvalid_1's binary_logloss: 0.0527082\n",
            "[230]\ttraining's binary_logloss: 0.0188157\tvalid_1's binary_logloss: 0.0521384\n",
            "[240]\ttraining's binary_logloss: 0.0169862\tvalid_1's binary_logloss: 0.0512273\n",
            "[250]\ttraining's binary_logloss: 0.0153516\tvalid_1's binary_logloss: 0.0504964\n",
            "[260]\ttraining's binary_logloss: 0.0138142\tvalid_1's binary_logloss: 0.0497074\n",
            "[270]\ttraining's binary_logloss: 0.0126338\tvalid_1's binary_logloss: 0.049298\n",
            "[280]\ttraining's binary_logloss: 0.0116018\tvalid_1's binary_logloss: 0.0491757\n",
            "[290]\ttraining's binary_logloss: 0.0105582\tvalid_1's binary_logloss: 0.0490378\n",
            "[300]\ttraining's binary_logloss: 0.00953507\tvalid_1's binary_logloss: 0.0485376\n",
            "[310]\ttraining's binary_logloss: 0.00873734\tvalid_1's binary_logloss: 0.0483839\n",
            "[320]\ttraining's binary_logloss: 0.00803027\tvalid_1's binary_logloss: 0.0482451\n",
            "Early stopping, best iteration is:\n",
            "[317]\ttraining's binary_logloss: 0.00823652\tvalid_1's binary_logloss: 0.0482008\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-24 12:42:55,203] Trial 10 finished with value: 0.04820077539507835 and parameters: {'max_bin': 342, 'num_leaves': 78}. Best is trial 7 with value: 0.046570177200944515.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.171923\tvalid_1's binary_logloss: 0.1579\n",
            "[20]\ttraining's binary_logloss: 0.136244\tvalid_1's binary_logloss: 0.13003\n",
            "[30]\ttraining's binary_logloss: 0.111014\tvalid_1's binary_logloss: 0.112522\n",
            "[40]\ttraining's binary_logloss: 0.0930938\tvalid_1's binary_logloss: 0.0998608\n",
            "[50]\ttraining's binary_logloss: 0.0791676\tvalid_1's binary_logloss: 0.0910605\n",
            "[60]\ttraining's binary_logloss: 0.068705\tvalid_1's binary_logloss: 0.0839189\n",
            "[70]\ttraining's binary_logloss: 0.0594573\tvalid_1's binary_logloss: 0.0773896\n",
            "[80]\ttraining's binary_logloss: 0.0516957\tvalid_1's binary_logloss: 0.0728773\n",
            "[90]\ttraining's binary_logloss: 0.045333\tvalid_1's binary_logloss: 0.0688908\n",
            "[100]\ttraining's binary_logloss: 0.0397511\tvalid_1's binary_logloss: 0.0650085\n",
            "[110]\ttraining's binary_logloss: 0.0347048\tvalid_1's binary_logloss: 0.0618027\n",
            "[120]\ttraining's binary_logloss: 0.0304498\tvalid_1's binary_logloss: 0.0594084\n",
            "[130]\ttraining's binary_logloss: 0.0266284\tvalid_1's binary_logloss: 0.0568361\n",
            "[140]\ttraining's binary_logloss: 0.0230989\tvalid_1's binary_logloss: 0.0550567\n",
            "[150]\ttraining's binary_logloss: 0.0202418\tvalid_1's binary_logloss: 0.0533629\n",
            "[160]\ttraining's binary_logloss: 0.0173698\tvalid_1's binary_logloss: 0.0514888\n",
            "[170]\ttraining's binary_logloss: 0.0153337\tvalid_1's binary_logloss: 0.0504455\n",
            "[180]\ttraining's binary_logloss: 0.013347\tvalid_1's binary_logloss: 0.0494745\n",
            "[190]\ttraining's binary_logloss: 0.0118614\tvalid_1's binary_logloss: 0.0490478\n",
            "[200]\ttraining's binary_logloss: 0.0103329\tvalid_1's binary_logloss: 0.0489966\n",
            "[210]\ttraining's binary_logloss: 0.00883325\tvalid_1's binary_logloss: 0.0488976\n",
            "[220]\ttraining's binary_logloss: 0.0078048\tvalid_1's binary_logloss: 0.0488786\n",
            "Early stopping, best iteration is:\n",
            "[218]\ttraining's binary_logloss: 0.00796713\tvalid_1's binary_logloss: 0.0488058\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-24 12:42:58,016] Trial 11 finished with value: 0.04880581062222224 and parameters: {'max_bin': 343, 'num_leaves': 113}. Best is trial 7 with value: 0.046570177200944515.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.191144\tvalid_1's binary_logloss: 0.171928\n",
            "[20]\ttraining's binary_logloss: 0.166361\tvalid_1's binary_logloss: 0.151206\n",
            "[30]\ttraining's binary_logloss: 0.1481\tvalid_1's binary_logloss: 0.138537\n",
            "[40]\ttraining's binary_logloss: 0.134891\tvalid_1's binary_logloss: 0.129581\n",
            "[50]\ttraining's binary_logloss: 0.12338\tvalid_1's binary_logloss: 0.121242\n",
            "[60]\ttraining's binary_logloss: 0.112944\tvalid_1's binary_logloss: 0.114286\n",
            "[70]\ttraining's binary_logloss: 0.104489\tvalid_1's binary_logloss: 0.108021\n",
            "[80]\ttraining's binary_logloss: 0.0967887\tvalid_1's binary_logloss: 0.10271\n",
            "[90]\ttraining's binary_logloss: 0.0892779\tvalid_1's binary_logloss: 0.0985393\n",
            "[100]\ttraining's binary_logloss: 0.0831859\tvalid_1's binary_logloss: 0.0944849\n",
            "[110]\ttraining's binary_logloss: 0.0778004\tvalid_1's binary_logloss: 0.0909106\n",
            "[120]\ttraining's binary_logloss: 0.0727367\tvalid_1's binary_logloss: 0.087614\n",
            "[130]\ttraining's binary_logloss: 0.067822\tvalid_1's binary_logloss: 0.0841087\n",
            "[140]\ttraining's binary_logloss: 0.0628159\tvalid_1's binary_logloss: 0.0810017\n",
            "[150]\ttraining's binary_logloss: 0.0586113\tvalid_1's binary_logloss: 0.0780519\n",
            "[160]\ttraining's binary_logloss: 0.0544851\tvalid_1's binary_logloss: 0.0756508\n",
            "[170]\ttraining's binary_logloss: 0.0503869\tvalid_1's binary_logloss: 0.0724984\n",
            "[180]\ttraining's binary_logloss: 0.0471752\tvalid_1's binary_logloss: 0.0709983\n",
            "[190]\ttraining's binary_logloss: 0.0441158\tvalid_1's binary_logloss: 0.0688887\n",
            "[200]\ttraining's binary_logloss: 0.0413383\tvalid_1's binary_logloss: 0.066937\n",
            "[210]\ttraining's binary_logloss: 0.0385309\tvalid_1's binary_logloss: 0.0651768\n",
            "[220]\ttraining's binary_logloss: 0.0361331\tvalid_1's binary_logloss: 0.0632346\n",
            "[230]\ttraining's binary_logloss: 0.0337453\tvalid_1's binary_logloss: 0.061887\n",
            "[240]\ttraining's binary_logloss: 0.0313305\tvalid_1's binary_logloss: 0.0603935\n",
            "[250]\ttraining's binary_logloss: 0.0292283\tvalid_1's binary_logloss: 0.0589752\n",
            "[260]\ttraining's binary_logloss: 0.0275831\tvalid_1's binary_logloss: 0.0580865\n",
            "[270]\ttraining's binary_logloss: 0.0260652\tvalid_1's binary_logloss: 0.0572974\n",
            "[280]\ttraining's binary_logloss: 0.0245028\tvalid_1's binary_logloss: 0.0565653\n",
            "[290]\ttraining's binary_logloss: 0.0229546\tvalid_1's binary_logloss: 0.0557239\n",
            "[300]\ttraining's binary_logloss: 0.0209804\tvalid_1's binary_logloss: 0.0542302\n",
            "[310]\ttraining's binary_logloss: 0.0194693\tvalid_1's binary_logloss: 0.0537361\n",
            "[320]\ttraining's binary_logloss: 0.0184101\tvalid_1's binary_logloss: 0.053235\n",
            "[330]\ttraining's binary_logloss: 0.0171385\tvalid_1's binary_logloss: 0.0525639\n",
            "[340]\ttraining's binary_logloss: 0.0159236\tvalid_1's binary_logloss: 0.0517974\n",
            "[350]\ttraining's binary_logloss: 0.0147031\tvalid_1's binary_logloss: 0.051429\n",
            "[360]\ttraining's binary_logloss: 0.0136902\tvalid_1's binary_logloss: 0.0509469\n",
            "[370]\ttraining's binary_logloss: 0.012729\tvalid_1's binary_logloss: 0.0504755\n",
            "[380]\ttraining's binary_logloss: 0.0120041\tvalid_1's binary_logloss: 0.0501965\n",
            "[390]\ttraining's binary_logloss: 0.0112326\tvalid_1's binary_logloss: 0.0499148\n",
            "[400]\ttraining's binary_logloss: 0.0105174\tvalid_1's binary_logloss: 0.0496105\n",
            "Early stopping, best iteration is:\n",
            "[399]\ttraining's binary_logloss: 0.0105527\tvalid_1's binary_logloss: 0.0495952\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-24 12:43:01,532] Trial 12 finished with value: 0.0495952386461584 and parameters: {'max_bin': 420, 'num_leaves': 57}. Best is trial 7 with value: 0.046570177200944515.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.175234\tvalid_1's binary_logloss: 0.162095\n",
            "[20]\ttraining's binary_logloss: 0.141586\tvalid_1's binary_logloss: 0.136616\n",
            "[30]\ttraining's binary_logloss: 0.11635\tvalid_1's binary_logloss: 0.118206\n",
            "[40]\ttraining's binary_logloss: 0.0984738\tvalid_1's binary_logloss: 0.106184\n",
            "[50]\ttraining's binary_logloss: 0.0845473\tvalid_1's binary_logloss: 0.0963438\n",
            "[60]\ttraining's binary_logloss: 0.0738774\tvalid_1's binary_logloss: 0.0887411\n",
            "[70]\ttraining's binary_logloss: 0.0643233\tvalid_1's binary_logloss: 0.0818401\n",
            "[80]\ttraining's binary_logloss: 0.0566236\tvalid_1's binary_logloss: 0.0763954\n",
            "[90]\ttraining's binary_logloss: 0.049634\tvalid_1's binary_logloss: 0.0716299\n",
            "[100]\ttraining's binary_logloss: 0.0434814\tvalid_1's binary_logloss: 0.0679162\n",
            "[110]\ttraining's binary_logloss: 0.0379385\tvalid_1's binary_logloss: 0.0640787\n",
            "[120]\ttraining's binary_logloss: 0.0337517\tvalid_1's binary_logloss: 0.0611084\n",
            "[130]\ttraining's binary_logloss: 0.0296618\tvalid_1's binary_logloss: 0.0592693\n",
            "[140]\ttraining's binary_logloss: 0.0261121\tvalid_1's binary_logloss: 0.0569875\n",
            "[150]\ttraining's binary_logloss: 0.0231791\tvalid_1's binary_logloss: 0.0551515\n",
            "[160]\ttraining's binary_logloss: 0.0201935\tvalid_1's binary_logloss: 0.0531344\n",
            "[170]\ttraining's binary_logloss: 0.0181585\tvalid_1's binary_logloss: 0.051727\n",
            "[180]\ttraining's binary_logloss: 0.0161531\tvalid_1's binary_logloss: 0.0511701\n",
            "[190]\ttraining's binary_logloss: 0.014056\tvalid_1's binary_logloss: 0.0503633\n",
            "[200]\ttraining's binary_logloss: 0.0124394\tvalid_1's binary_logloss: 0.0494767\n",
            "[210]\ttraining's binary_logloss: 0.0110477\tvalid_1's binary_logloss: 0.0487831\n",
            "[220]\ttraining's binary_logloss: 0.00974715\tvalid_1's binary_logloss: 0.0485755\n",
            "[230]\ttraining's binary_logloss: 0.00864462\tvalid_1's binary_logloss: 0.0486014\n",
            "Early stopping, best iteration is:\n",
            "[221]\ttraining's binary_logloss: 0.0096141\tvalid_1's binary_logloss: 0.0484797\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-24 12:43:04,276] Trial 13 finished with value: 0.048479676005356326 and parameters: {'max_bin': 332, 'num_leaves': 104}. Best is trial 7 with value: 0.046570177200944515.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.193657\tvalid_1's binary_logloss: 0.175304\n",
            "[20]\ttraining's binary_logloss: 0.16996\tvalid_1's binary_logloss: 0.155735\n",
            "[30]\ttraining's binary_logloss: 0.15195\tvalid_1's binary_logloss: 0.141889\n",
            "[40]\ttraining's binary_logloss: 0.138298\tvalid_1's binary_logloss: 0.1326\n",
            "[50]\ttraining's binary_logloss: 0.12772\tvalid_1's binary_logloss: 0.125144\n",
            "[60]\ttraining's binary_logloss: 0.118162\tvalid_1's binary_logloss: 0.118562\n",
            "[70]\ttraining's binary_logloss: 0.109259\tvalid_1's binary_logloss: 0.112161\n",
            "[80]\ttraining's binary_logloss: 0.101883\tvalid_1's binary_logloss: 0.106959\n",
            "[90]\ttraining's binary_logloss: 0.0951691\tvalid_1's binary_logloss: 0.102093\n",
            "[100]\ttraining's binary_logloss: 0.0892038\tvalid_1's binary_logloss: 0.0976733\n",
            "[110]\ttraining's binary_logloss: 0.0830644\tvalid_1's binary_logloss: 0.0936035\n",
            "[120]\ttraining's binary_logloss: 0.0779967\tvalid_1's binary_logloss: 0.0903295\n",
            "[130]\ttraining's binary_logloss: 0.073242\tvalid_1's binary_logloss: 0.087208\n",
            "[140]\ttraining's binary_logloss: 0.0685881\tvalid_1's binary_logloss: 0.0836354\n",
            "[150]\ttraining's binary_logloss: 0.0640689\tvalid_1's binary_logloss: 0.0812867\n",
            "[160]\ttraining's binary_logloss: 0.0602301\tvalid_1's binary_logloss: 0.0787223\n",
            "[170]\ttraining's binary_logloss: 0.0564761\tvalid_1's binary_logloss: 0.0764388\n",
            "[180]\ttraining's binary_logloss: 0.0525772\tvalid_1's binary_logloss: 0.0738389\n",
            "[190]\ttraining's binary_logloss: 0.0496057\tvalid_1's binary_logloss: 0.0717776\n",
            "[200]\ttraining's binary_logloss: 0.0467606\tvalid_1's binary_logloss: 0.0703384\n",
            "[210]\ttraining's binary_logloss: 0.0442043\tvalid_1's binary_logloss: 0.0686435\n",
            "[220]\ttraining's binary_logloss: 0.0418141\tvalid_1's binary_logloss: 0.0672086\n",
            "[230]\ttraining's binary_logloss: 0.0395946\tvalid_1's binary_logloss: 0.0656678\n",
            "[240]\ttraining's binary_logloss: 0.037158\tvalid_1's binary_logloss: 0.0638819\n",
            "[250]\ttraining's binary_logloss: 0.0346461\tvalid_1's binary_logloss: 0.062166\n",
            "[260]\ttraining's binary_logloss: 0.0326349\tvalid_1's binary_logloss: 0.0608227\n",
            "[270]\ttraining's binary_logloss: 0.0304833\tvalid_1's binary_logloss: 0.0595178\n",
            "[280]\ttraining's binary_logloss: 0.0286104\tvalid_1's binary_logloss: 0.0586098\n",
            "[290]\ttraining's binary_logloss: 0.0270298\tvalid_1's binary_logloss: 0.0575605\n",
            "[300]\ttraining's binary_logloss: 0.0257185\tvalid_1's binary_logloss: 0.0568014\n",
            "[310]\ttraining's binary_logloss: 0.0243198\tvalid_1's binary_logloss: 0.0560357\n",
            "[320]\ttraining's binary_logloss: 0.0228575\tvalid_1's binary_logloss: 0.0551648\n",
            "[330]\ttraining's binary_logloss: 0.0213654\tvalid_1's binary_logloss: 0.0544586\n",
            "[340]\ttraining's binary_logloss: 0.0201392\tvalid_1's binary_logloss: 0.0537973\n",
            "[350]\ttraining's binary_logloss: 0.0188131\tvalid_1's binary_logloss: 0.0530571\n",
            "[360]\ttraining's binary_logloss: 0.0176985\tvalid_1's binary_logloss: 0.052567\n",
            "[370]\ttraining's binary_logloss: 0.0168558\tvalid_1's binary_logloss: 0.0524661\n",
            "[380]\ttraining's binary_logloss: 0.0158847\tvalid_1's binary_logloss: 0.0520724\n",
            "[390]\ttraining's binary_logloss: 0.0149457\tvalid_1's binary_logloss: 0.0514516\n",
            "[400]\ttraining's binary_logloss: 0.0141134\tvalid_1's binary_logloss: 0.0512818\n",
            "[410]\ttraining's binary_logloss: 0.0131782\tvalid_1's binary_logloss: 0.050852\n",
            "[420]\ttraining's binary_logloss: 0.0124166\tvalid_1's binary_logloss: 0.0505022\n",
            "[430]\ttraining's binary_logloss: 0.0117558\tvalid_1's binary_logloss: 0.0502364\n",
            "[440]\ttraining's binary_logloss: 0.0110335\tvalid_1's binary_logloss: 0.0498838\n",
            "[450]\ttraining's binary_logloss: 0.0103014\tvalid_1's binary_logloss: 0.0497384\n",
            "[460]\ttraining's binary_logloss: 0.00969931\tvalid_1's binary_logloss: 0.0495947\n",
            "[470]\ttraining's binary_logloss: 0.00915611\tvalid_1's binary_logloss: 0.0497911\n",
            "Early stopping, best iteration is:\n",
            "[461]\ttraining's binary_logloss: 0.00961373\tvalid_1's binary_logloss: 0.0495599\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-24 12:43:07,998] Trial 14 finished with value: 0.049559875862597164 and parameters: {'max_bin': 264, 'num_leaves': 52}. Best is trial 7 with value: 0.046570177200944515.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.172661\tvalid_1's binary_logloss: 0.159006\n",
            "[20]\ttraining's binary_logloss: 0.137347\tvalid_1's binary_logloss: 0.132476\n",
            "[30]\ttraining's binary_logloss: 0.111985\tvalid_1's binary_logloss: 0.114458\n",
            "[40]\ttraining's binary_logloss: 0.0939226\tvalid_1's binary_logloss: 0.100861\n",
            "[50]\ttraining's binary_logloss: 0.0803291\tvalid_1's binary_logloss: 0.0915003\n",
            "[60]\ttraining's binary_logloss: 0.0695364\tvalid_1's binary_logloss: 0.0834771\n",
            "[70]\ttraining's binary_logloss: 0.0601318\tvalid_1's binary_logloss: 0.0773557\n",
            "[80]\ttraining's binary_logloss: 0.0518004\tvalid_1's binary_logloss: 0.0714696\n",
            "[90]\ttraining's binary_logloss: 0.044432\tvalid_1's binary_logloss: 0.0667917\n",
            "[100]\ttraining's binary_logloss: 0.0385903\tvalid_1's binary_logloss: 0.0631754\n",
            "[110]\ttraining's binary_logloss: 0.0334617\tvalid_1's binary_logloss: 0.0601157\n",
            "[120]\ttraining's binary_logloss: 0.0294065\tvalid_1's binary_logloss: 0.0577249\n",
            "[130]\ttraining's binary_logloss: 0.0258768\tvalid_1's binary_logloss: 0.0556532\n",
            "[140]\ttraining's binary_logloss: 0.0226115\tvalid_1's binary_logloss: 0.0538437\n",
            "[150]\ttraining's binary_logloss: 0.0196859\tvalid_1's binary_logloss: 0.0522084\n",
            "[160]\ttraining's binary_logloss: 0.017181\tvalid_1's binary_logloss: 0.0508001\n",
            "[170]\ttraining's binary_logloss: 0.0148305\tvalid_1's binary_logloss: 0.0499041\n",
            "[180]\ttraining's binary_logloss: 0.0129923\tvalid_1's binary_logloss: 0.0489318\n",
            "[190]\ttraining's binary_logloss: 0.0113238\tvalid_1's binary_logloss: 0.0480614\n",
            "[200]\ttraining's binary_logloss: 0.00996237\tvalid_1's binary_logloss: 0.0476083\n",
            "[210]\ttraining's binary_logloss: 0.00869304\tvalid_1's binary_logloss: 0.0473694\n",
            "[220]\ttraining's binary_logloss: 0.00769699\tvalid_1's binary_logloss: 0.0472129\n",
            "[230]\ttraining's binary_logloss: 0.00665989\tvalid_1's binary_logloss: 0.0469933\n",
            "Early stopping, best iteration is:\n",
            "[226]\ttraining's binary_logloss: 0.00707421\tvalid_1's binary_logloss: 0.0469045\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-24 12:43:10,922] Trial 15 finished with value: 0.04690452960581192 and parameters: {'max_bin': 370, 'num_leaves': 112}. Best is trial 7 with value: 0.046570177200944515.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.176423\tvalid_1's binary_logloss: 0.161052\n",
            "[20]\ttraining's binary_logloss: 0.142526\tvalid_1's binary_logloss: 0.136061\n",
            "[30]\ttraining's binary_logloss: 0.118136\tvalid_1's binary_logloss: 0.117988\n",
            "[40]\ttraining's binary_logloss: 0.100687\tvalid_1's binary_logloss: 0.105494\n",
            "[50]\ttraining's binary_logloss: 0.086888\tvalid_1's binary_logloss: 0.0955847\n",
            "[60]\ttraining's binary_logloss: 0.0752211\tvalid_1's binary_logloss: 0.0875047\n",
            "[70]\ttraining's binary_logloss: 0.0653332\tvalid_1's binary_logloss: 0.0804671\n",
            "[80]\ttraining's binary_logloss: 0.0574203\tvalid_1's binary_logloss: 0.0750256\n",
            "[90]\ttraining's binary_logloss: 0.0502836\tvalid_1's binary_logloss: 0.0706637\n",
            "[100]\ttraining's binary_logloss: 0.0445081\tvalid_1's binary_logloss: 0.0668791\n",
            "[110]\ttraining's binary_logloss: 0.0391458\tvalid_1's binary_logloss: 0.0632285\n",
            "[120]\ttraining's binary_logloss: 0.0348986\tvalid_1's binary_logloss: 0.0605956\n",
            "[130]\ttraining's binary_logloss: 0.030773\tvalid_1's binary_logloss: 0.0578087\n",
            "[140]\ttraining's binary_logloss: 0.0275585\tvalid_1's binary_logloss: 0.0558149\n",
            "[150]\ttraining's binary_logloss: 0.0244354\tvalid_1's binary_logloss: 0.0540123\n",
            "[160]\ttraining's binary_logloss: 0.0216017\tvalid_1's binary_logloss: 0.0522494\n",
            "[170]\ttraining's binary_logloss: 0.0190216\tvalid_1's binary_logloss: 0.0510188\n",
            "[180]\ttraining's binary_logloss: 0.0170551\tvalid_1's binary_logloss: 0.0500865\n",
            "[190]\ttraining's binary_logloss: 0.0150603\tvalid_1's binary_logloss: 0.0490056\n",
            "[200]\ttraining's binary_logloss: 0.0134162\tvalid_1's binary_logloss: 0.0481969\n",
            "[210]\ttraining's binary_logloss: 0.0118912\tvalid_1's binary_logloss: 0.0476432\n",
            "[220]\ttraining's binary_logloss: 0.010584\tvalid_1's binary_logloss: 0.046753\n",
            "[230]\ttraining's binary_logloss: 0.00940425\tvalid_1's binary_logloss: 0.0467539\n",
            "[240]\ttraining's binary_logloss: 0.00843984\tvalid_1's binary_logloss: 0.0467031\n",
            "[250]\ttraining's binary_logloss: 0.00733385\tvalid_1's binary_logloss: 0.0468183\n",
            "Early stopping, best iteration is:\n",
            "[246]\ttraining's binary_logloss: 0.00771274\tvalid_1's binary_logloss: 0.0465436\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-24 12:43:14,029] Trial 16 finished with value: 0.04654357980084098 and parameters: {'max_bin': 498, 'num_leaves': 101}. Best is trial 16 with value: 0.04654357980084098.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.183232\tvalid_1's binary_logloss: 0.167298\n",
            "[20]\ttraining's binary_logloss: 0.152655\tvalid_1's binary_logloss: 0.143216\n",
            "[30]\ttraining's binary_logloss: 0.13129\tvalid_1's binary_logloss: 0.128127\n",
            "[40]\ttraining's binary_logloss: 0.115214\tvalid_1's binary_logloss: 0.117377\n",
            "[50]\ttraining's binary_logloss: 0.101912\tvalid_1's binary_logloss: 0.107567\n",
            "[60]\ttraining's binary_logloss: 0.09173\tvalid_1's binary_logloss: 0.100741\n",
            "[70]\ttraining's binary_logloss: 0.0829607\tvalid_1's binary_logloss: 0.0947162\n",
            "[80]\ttraining's binary_logloss: 0.0752382\tvalid_1's binary_logloss: 0.0898912\n",
            "[90]\ttraining's binary_logloss: 0.068512\tvalid_1's binary_logloss: 0.0859222\n",
            "[100]\ttraining's binary_logloss: 0.0612591\tvalid_1's binary_logloss: 0.0812135\n",
            "[110]\ttraining's binary_logloss: 0.055542\tvalid_1's binary_logloss: 0.0774257\n",
            "[120]\ttraining's binary_logloss: 0.0501161\tvalid_1's binary_logloss: 0.0739816\n",
            "[130]\ttraining's binary_logloss: 0.0452677\tvalid_1's binary_logloss: 0.0706436\n",
            "[140]\ttraining's binary_logloss: 0.0410578\tvalid_1's binary_logloss: 0.0679646\n",
            "[150]\ttraining's binary_logloss: 0.0373513\tvalid_1's binary_logloss: 0.0658486\n",
            "[160]\ttraining's binary_logloss: 0.0337092\tvalid_1's binary_logloss: 0.0633825\n",
            "[170]\ttraining's binary_logloss: 0.030844\tvalid_1's binary_logloss: 0.0615954\n",
            "[180]\ttraining's binary_logloss: 0.0284119\tvalid_1's binary_logloss: 0.0599378\n",
            "[190]\ttraining's binary_logloss: 0.0258407\tvalid_1's binary_logloss: 0.0581503\n",
            "[200]\ttraining's binary_logloss: 0.0236629\tvalid_1's binary_logloss: 0.0572349\n",
            "[210]\ttraining's binary_logloss: 0.021519\tvalid_1's binary_logloss: 0.0556285\n",
            "[220]\ttraining's binary_logloss: 0.0197803\tvalid_1's binary_logloss: 0.0547883\n",
            "[230]\ttraining's binary_logloss: 0.0183039\tvalid_1's binary_logloss: 0.0539317\n",
            "[240]\ttraining's binary_logloss: 0.0169675\tvalid_1's binary_logloss: 0.0536677\n",
            "[250]\ttraining's binary_logloss: 0.0152407\tvalid_1's binary_logloss: 0.0529746\n",
            "[260]\ttraining's binary_logloss: 0.0134799\tvalid_1's binary_logloss: 0.0519986\n",
            "[270]\ttraining's binary_logloss: 0.0121957\tvalid_1's binary_logloss: 0.0516002\n",
            "[280]\ttraining's binary_logloss: 0.0113108\tvalid_1's binary_logloss: 0.0511117\n",
            "[290]\ttraining's binary_logloss: 0.0101929\tvalid_1's binary_logloss: 0.0505801\n",
            "[300]\ttraining's binary_logloss: 0.00930101\tvalid_1's binary_logloss: 0.0502498\n",
            "[310]\ttraining's binary_logloss: 0.0084674\tvalid_1's binary_logloss: 0.0501205\n",
            "[320]\ttraining's binary_logloss: 0.00771027\tvalid_1's binary_logloss: 0.0497373\n",
            "[330]\ttraining's binary_logloss: 0.00692885\tvalid_1's binary_logloss: 0.0495306\n",
            "Early stopping, best iteration is:\n",
            "[328]\ttraining's binary_logloss: 0.00705203\tvalid_1's binary_logloss: 0.0494078\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-24 12:43:17,458] Trial 17 finished with value: 0.04940779711927887 and parameters: {'max_bin': 334, 'num_leaves': 79}. Best is trial 16 with value: 0.04654357980084098.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.171946\tvalid_1's binary_logloss: 0.159516\n",
            "[20]\ttraining's binary_logloss: 0.137545\tvalid_1's binary_logloss: 0.13337\n",
            "[30]\ttraining's binary_logloss: 0.111578\tvalid_1's binary_logloss: 0.114101\n",
            "[40]\ttraining's binary_logloss: 0.0930709\tvalid_1's binary_logloss: 0.1012\n",
            "[50]\ttraining's binary_logloss: 0.0795632\tvalid_1's binary_logloss: 0.0915863\n",
            "[60]\ttraining's binary_logloss: 0.0687039\tvalid_1's binary_logloss: 0.0835365\n",
            "[70]\ttraining's binary_logloss: 0.0589284\tvalid_1's binary_logloss: 0.0764947\n",
            "[80]\ttraining's binary_logloss: 0.0511812\tvalid_1's binary_logloss: 0.0714022\n",
            "[90]\ttraining's binary_logloss: 0.0443202\tvalid_1's binary_logloss: 0.0665823\n",
            "[100]\ttraining's binary_logloss: 0.0382805\tvalid_1's binary_logloss: 0.0624485\n",
            "[110]\ttraining's binary_logloss: 0.0330922\tvalid_1's binary_logloss: 0.0594681\n",
            "[120]\ttraining's binary_logloss: 0.0289172\tvalid_1's binary_logloss: 0.0569294\n",
            "[130]\ttraining's binary_logloss: 0.025338\tvalid_1's binary_logloss: 0.0552641\n",
            "[140]\ttraining's binary_logloss: 0.02212\tvalid_1's binary_logloss: 0.0535282\n",
            "[150]\ttraining's binary_logloss: 0.0193612\tvalid_1's binary_logloss: 0.0520273\n",
            "[160]\ttraining's binary_logloss: 0.0170508\tvalid_1's binary_logloss: 0.0512232\n",
            "[170]\ttraining's binary_logloss: 0.0146999\tvalid_1's binary_logloss: 0.0503415\n",
            "[180]\ttraining's binary_logloss: 0.0128754\tvalid_1's binary_logloss: 0.0492551\n",
            "[190]\ttraining's binary_logloss: 0.0112213\tvalid_1's binary_logloss: 0.0491602\n",
            "[200]\ttraining's binary_logloss: 0.00981403\tvalid_1's binary_logloss: 0.0488765\n",
            "[210]\ttraining's binary_logloss: 0.00864338\tvalid_1's binary_logloss: 0.0488312\n",
            "[220]\ttraining's binary_logloss: 0.00733362\tvalid_1's binary_logloss: 0.0480957\n",
            "Early stopping, best iteration is:\n",
            "[218]\ttraining's binary_logloss: 0.00760992\tvalid_1's binary_logloss: 0.0479749\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-24 12:43:20,554] Trial 18 finished with value: 0.04797488423885256 and parameters: {'max_bin': 447, 'num_leaves': 114}. Best is trial 16 with value: 0.04654357980084098.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.170692\tvalid_1's binary_logloss: 0.158238\n",
            "[20]\ttraining's binary_logloss: 0.133739\tvalid_1's binary_logloss: 0.130731\n",
            "[30]\ttraining's binary_logloss: 0.107946\tvalid_1's binary_logloss: 0.111763\n",
            "[40]\ttraining's binary_logloss: 0.0894719\tvalid_1's binary_logloss: 0.0988158\n",
            "[50]\ttraining's binary_logloss: 0.0758601\tvalid_1's binary_logloss: 0.0898659\n",
            "[60]\ttraining's binary_logloss: 0.0648223\tvalid_1's binary_logloss: 0.0826662\n",
            "[70]\ttraining's binary_logloss: 0.0555432\tvalid_1's binary_logloss: 0.0760765\n",
            "[80]\ttraining's binary_logloss: 0.0479612\tvalid_1's binary_logloss: 0.071146\n",
            "[90]\ttraining's binary_logloss: 0.0408152\tvalid_1's binary_logloss: 0.0668492\n",
            "[100]\ttraining's binary_logloss: 0.0354148\tvalid_1's binary_logloss: 0.0634147\n",
            "[110]\ttraining's binary_logloss: 0.0304645\tvalid_1's binary_logloss: 0.0601992\n",
            "[120]\ttraining's binary_logloss: 0.0262234\tvalid_1's binary_logloss: 0.0574609\n",
            "[130]\ttraining's binary_logloss: 0.0226598\tvalid_1's binary_logloss: 0.0550823\n",
            "[140]\ttraining's binary_logloss: 0.0199772\tvalid_1's binary_logloss: 0.0534138\n",
            "[150]\ttraining's binary_logloss: 0.0172334\tvalid_1's binary_logloss: 0.0522383\n",
            "[160]\ttraining's binary_logloss: 0.0151047\tvalid_1's binary_logloss: 0.051319\n",
            "[170]\ttraining's binary_logloss: 0.0129677\tvalid_1's binary_logloss: 0.0503202\n",
            "[180]\ttraining's binary_logloss: 0.0112179\tvalid_1's binary_logloss: 0.0500457\n",
            "[190]\ttraining's binary_logloss: 0.00965063\tvalid_1's binary_logloss: 0.0498177\n",
            "[200]\ttraining's binary_logloss: 0.00829191\tvalid_1's binary_logloss: 0.0495543\n",
            "Early stopping, best iteration is:\n",
            "[195]\ttraining's binary_logloss: 0.0089274\tvalid_1's binary_logloss: 0.0493278\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-24 12:43:23,306] Trial 19 finished with value: 0.04932784553312379 and parameters: {'max_bin': 354, 'num_leaves': 120}. Best is trial 16 with value: 0.04654357980084098.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.189832\tvalid_1's binary_logloss: 0.172317\n",
            "[20]\ttraining's binary_logloss: 0.163798\tvalid_1's binary_logloss: 0.151814\n",
            "[30]\ttraining's binary_logloss: 0.144606\tvalid_1's binary_logloss: 0.137441\n",
            "[40]\ttraining's binary_logloss: 0.130479\tvalid_1's binary_logloss: 0.127786\n",
            "[50]\ttraining's binary_logloss: 0.119785\tvalid_1's binary_logloss: 0.119989\n",
            "[60]\ttraining's binary_logloss: 0.109283\tvalid_1's binary_logloss: 0.11192\n",
            "[70]\ttraining's binary_logloss: 0.10066\tvalid_1's binary_logloss: 0.105746\n",
            "[80]\ttraining's binary_logloss: 0.0923099\tvalid_1's binary_logloss: 0.099996\n",
            "[90]\ttraining's binary_logloss: 0.0853027\tvalid_1's binary_logloss: 0.0951592\n",
            "[100]\ttraining's binary_logloss: 0.0786173\tvalid_1's binary_logloss: 0.0901367\n",
            "[110]\ttraining's binary_logloss: 0.072857\tvalid_1's binary_logloss: 0.086416\n",
            "[120]\ttraining's binary_logloss: 0.0673186\tvalid_1's binary_logloss: 0.083167\n",
            "[130]\ttraining's binary_logloss: 0.0629659\tvalid_1's binary_logloss: 0.0801548\n",
            "[140]\ttraining's binary_logloss: 0.0583\tvalid_1's binary_logloss: 0.0770776\n",
            "[150]\ttraining's binary_logloss: 0.0544871\tvalid_1's binary_logloss: 0.0745555\n",
            "[160]\ttraining's binary_logloss: 0.0505343\tvalid_1's binary_logloss: 0.0719555\n",
            "[170]\ttraining's binary_logloss: 0.0470581\tvalid_1's binary_logloss: 0.069991\n",
            "[180]\ttraining's binary_logloss: 0.0436134\tvalid_1's binary_logloss: 0.0675658\n",
            "[190]\ttraining's binary_logloss: 0.0406322\tvalid_1's binary_logloss: 0.0656081\n",
            "[200]\ttraining's binary_logloss: 0.037975\tvalid_1's binary_logloss: 0.0640565\n",
            "[210]\ttraining's binary_logloss: 0.0352993\tvalid_1's binary_logloss: 0.0626567\n",
            "[220]\ttraining's binary_logloss: 0.0330141\tvalid_1's binary_logloss: 0.0613479\n",
            "[230]\ttraining's binary_logloss: 0.0300795\tvalid_1's binary_logloss: 0.0594772\n",
            "[240]\ttraining's binary_logloss: 0.0278499\tvalid_1's binary_logloss: 0.0577594\n",
            "[250]\ttraining's binary_logloss: 0.0257393\tvalid_1's binary_logloss: 0.0564722\n",
            "[260]\ttraining's binary_logloss: 0.0241462\tvalid_1's binary_logloss: 0.0554873\n",
            "[270]\ttraining's binary_logloss: 0.022486\tvalid_1's binary_logloss: 0.054819\n",
            "[280]\ttraining's binary_logloss: 0.0208292\tvalid_1's binary_logloss: 0.0538317\n",
            "[290]\ttraining's binary_logloss: 0.0192638\tvalid_1's binary_logloss: 0.052792\n",
            "[300]\ttraining's binary_logloss: 0.0180199\tvalid_1's binary_logloss: 0.0522566\n",
            "[310]\ttraining's binary_logloss: 0.0170049\tvalid_1's binary_logloss: 0.0520136\n",
            "[320]\ttraining's binary_logloss: 0.0158139\tvalid_1's binary_logloss: 0.0513622\n",
            "[330]\ttraining's binary_logloss: 0.0147597\tvalid_1's binary_logloss: 0.0508231\n",
            "[340]\ttraining's binary_logloss: 0.013792\tvalid_1's binary_logloss: 0.050743\n",
            "[350]\ttraining's binary_logloss: 0.0129725\tvalid_1's binary_logloss: 0.0503931\n",
            "[360]\ttraining's binary_logloss: 0.0120544\tvalid_1's binary_logloss: 0.0502742\n",
            "[370]\ttraining's binary_logloss: 0.0113335\tvalid_1's binary_logloss: 0.0503198\n",
            "Early stopping, best iteration is:\n",
            "[366]\ttraining's binary_logloss: 0.0116308\tvalid_1's binary_logloss: 0.0502398\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-24 12:43:26,794] Trial 20 finished with value: 0.05023976248087581 and parameters: {'max_bin': 432, 'num_leaves': 61}. Best is trial 16 with value: 0.04654357980084098.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.194094\tvalid_1's binary_logloss: 0.175586\n",
            "[20]\ttraining's binary_logloss: 0.170132\tvalid_1's binary_logloss: 0.154786\n",
            "[30]\ttraining's binary_logloss: 0.153641\tvalid_1's binary_logloss: 0.142193\n",
            "[40]\ttraining's binary_logloss: 0.141123\tvalid_1's binary_logloss: 0.133876\n",
            "[50]\ttraining's binary_logloss: 0.130898\tvalid_1's binary_logloss: 0.126432\n",
            "[60]\ttraining's binary_logloss: 0.121851\tvalid_1's binary_logloss: 0.120063\n",
            "[70]\ttraining's binary_logloss: 0.113559\tvalid_1's binary_logloss: 0.113839\n",
            "[80]\ttraining's binary_logloss: 0.105662\tvalid_1's binary_logloss: 0.10894\n",
            "[90]\ttraining's binary_logloss: 0.0980153\tvalid_1's binary_logloss: 0.10383\n",
            "[100]\ttraining's binary_logloss: 0.0912127\tvalid_1's binary_logloss: 0.0987218\n",
            "[110]\ttraining's binary_logloss: 0.0853248\tvalid_1's binary_logloss: 0.0951108\n",
            "[120]\ttraining's binary_logloss: 0.0794897\tvalid_1's binary_logloss: 0.0909813\n",
            "[130]\ttraining's binary_logloss: 0.0751012\tvalid_1's binary_logloss: 0.0878731\n",
            "[140]\ttraining's binary_logloss: 0.0705684\tvalid_1's binary_logloss: 0.0846891\n",
            "[150]\ttraining's binary_logloss: 0.0666989\tvalid_1's binary_logloss: 0.0823581\n",
            "[160]\ttraining's binary_logloss: 0.0627057\tvalid_1's binary_logloss: 0.0801957\n",
            "[170]\ttraining's binary_logloss: 0.05875\tvalid_1's binary_logloss: 0.0778535\n",
            "[180]\ttraining's binary_logloss: 0.0552776\tvalid_1's binary_logloss: 0.0757077\n",
            "[190]\ttraining's binary_logloss: 0.051941\tvalid_1's binary_logloss: 0.0735905\n",
            "[200]\ttraining's binary_logloss: 0.0489639\tvalid_1's binary_logloss: 0.0718714\n",
            "[210]\ttraining's binary_logloss: 0.0455897\tvalid_1's binary_logloss: 0.0691941\n",
            "[220]\ttraining's binary_logloss: 0.0428636\tvalid_1's binary_logloss: 0.0675281\n",
            "[230]\ttraining's binary_logloss: 0.0405522\tvalid_1's binary_logloss: 0.065741\n",
            "[240]\ttraining's binary_logloss: 0.0383171\tvalid_1's binary_logloss: 0.0641466\n",
            "[250]\ttraining's binary_logloss: 0.0357855\tvalid_1's binary_logloss: 0.0625243\n",
            "[260]\ttraining's binary_logloss: 0.0336643\tvalid_1's binary_logloss: 0.0610841\n",
            "[270]\ttraining's binary_logloss: 0.0318326\tvalid_1's binary_logloss: 0.0600097\n",
            "[280]\ttraining's binary_logloss: 0.029859\tvalid_1's binary_logloss: 0.0587625\n",
            "[290]\ttraining's binary_logloss: 0.0281624\tvalid_1's binary_logloss: 0.0580537\n",
            "[300]\ttraining's binary_logloss: 0.0263938\tvalid_1's binary_logloss: 0.0568412\n",
            "[310]\ttraining's binary_logloss: 0.0248895\tvalid_1's binary_logloss: 0.0559014\n",
            "[320]\ttraining's binary_logloss: 0.0234605\tvalid_1's binary_logloss: 0.05534\n",
            "[330]\ttraining's binary_logloss: 0.0220455\tvalid_1's binary_logloss: 0.0544615\n",
            "[340]\ttraining's binary_logloss: 0.0206919\tvalid_1's binary_logloss: 0.0538187\n",
            "[350]\ttraining's binary_logloss: 0.0194525\tvalid_1's binary_logloss: 0.0532187\n",
            "[360]\ttraining's binary_logloss: 0.0183773\tvalid_1's binary_logloss: 0.0528136\n",
            "[370]\ttraining's binary_logloss: 0.0174073\tvalid_1's binary_logloss: 0.0525847\n",
            "[380]\ttraining's binary_logloss: 0.0163636\tvalid_1's binary_logloss: 0.0518222\n",
            "[390]\ttraining's binary_logloss: 0.0154917\tvalid_1's binary_logloss: 0.051531\n",
            "[400]\ttraining's binary_logloss: 0.0145286\tvalid_1's binary_logloss: 0.0512023\n",
            "[410]\ttraining's binary_logloss: 0.0137343\tvalid_1's binary_logloss: 0.0510788\n",
            "[420]\ttraining's binary_logloss: 0.012938\tvalid_1's binary_logloss: 0.0508434\n",
            "[430]\ttraining's binary_logloss: 0.0121601\tvalid_1's binary_logloss: 0.0507935\n",
            "[440]\ttraining's binary_logloss: 0.011459\tvalid_1's binary_logloss: 0.0506466\n",
            "[450]\ttraining's binary_logloss: 0.0108896\tvalid_1's binary_logloss: 0.0508909\n",
            "Early stopping, best iteration is:\n",
            "[440]\ttraining's binary_logloss: 0.011459\tvalid_1's binary_logloss: 0.0506466\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-24 12:43:30,511] Trial 21 finished with value: 0.05064664376535577 and parameters: {'max_bin': 402, 'num_leaves': 51}. Best is trial 16 with value: 0.04654357980084098.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.186183\tvalid_1's binary_logloss: 0.170235\n",
            "[20]\ttraining's binary_logloss: 0.15819\tvalid_1's binary_logloss: 0.148282\n",
            "[30]\ttraining's binary_logloss: 0.137814\tvalid_1's binary_logloss: 0.132805\n",
            "[40]\ttraining's binary_logloss: 0.121563\tvalid_1's binary_logloss: 0.121397\n",
            "[50]\ttraining's binary_logloss: 0.110401\tvalid_1's binary_logloss: 0.11352\n",
            "[60]\ttraining's binary_logloss: 0.0990487\tvalid_1's binary_logloss: 0.105223\n",
            "[70]\ttraining's binary_logloss: 0.0900067\tvalid_1's binary_logloss: 0.0987831\n",
            "[80]\ttraining's binary_logloss: 0.0815419\tvalid_1's binary_logloss: 0.0936365\n",
            "[90]\ttraining's binary_logloss: 0.0741651\tvalid_1's binary_logloss: 0.0886931\n",
            "[100]\ttraining's binary_logloss: 0.0673121\tvalid_1's binary_logloss: 0.0836061\n",
            "[110]\ttraining's binary_logloss: 0.0619169\tvalid_1's binary_logloss: 0.0800665\n",
            "[120]\ttraining's binary_logloss: 0.0568836\tvalid_1's binary_logloss: 0.0768911\n",
            "[130]\ttraining's binary_logloss: 0.051935\tvalid_1's binary_logloss: 0.0734265\n",
            "[140]\ttraining's binary_logloss: 0.0475978\tvalid_1's binary_logloss: 0.070783\n",
            "[150]\ttraining's binary_logloss: 0.0440298\tvalid_1's binary_logloss: 0.0687299\n",
            "[160]\ttraining's binary_logloss: 0.040645\tvalid_1's binary_logloss: 0.0664171\n",
            "[170]\ttraining's binary_logloss: 0.0368539\tvalid_1's binary_logloss: 0.0636733\n",
            "[180]\ttraining's binary_logloss: 0.0339743\tvalid_1's binary_logloss: 0.0619488\n",
            "[190]\ttraining's binary_logloss: 0.0311265\tvalid_1's binary_logloss: 0.0601784\n",
            "[200]\ttraining's binary_logloss: 0.0286891\tvalid_1's binary_logloss: 0.0586541\n",
            "[210]\ttraining's binary_logloss: 0.0262614\tvalid_1's binary_logloss: 0.0571982\n",
            "[220]\ttraining's binary_logloss: 0.0239776\tvalid_1's binary_logloss: 0.0558941\n",
            "[230]\ttraining's binary_logloss: 0.0221045\tvalid_1's binary_logloss: 0.0549667\n",
            "[240]\ttraining's binary_logloss: 0.0204525\tvalid_1's binary_logloss: 0.0541503\n",
            "[250]\ttraining's binary_logloss: 0.0185701\tvalid_1's binary_logloss: 0.0531218\n",
            "[260]\ttraining's binary_logloss: 0.0169623\tvalid_1's binary_logloss: 0.0524376\n",
            "[270]\ttraining's binary_logloss: 0.0157231\tvalid_1's binary_logloss: 0.0518439\n",
            "[280]\ttraining's binary_logloss: 0.014434\tvalid_1's binary_logloss: 0.0510081\n",
            "[290]\ttraining's binary_logloss: 0.0133373\tvalid_1's binary_logloss: 0.0504093\n",
            "[300]\ttraining's binary_logloss: 0.0122258\tvalid_1's binary_logloss: 0.0499039\n",
            "[310]\ttraining's binary_logloss: 0.0112675\tvalid_1's binary_logloss: 0.0497785\n",
            "[320]\ttraining's binary_logloss: 0.0104047\tvalid_1's binary_logloss: 0.0493241\n",
            "[330]\ttraining's binary_logloss: 0.00951991\tvalid_1's binary_logloss: 0.0493415\n",
            "Early stopping, best iteration is:\n",
            "[324]\ttraining's binary_logloss: 0.00997176\tvalid_1's binary_logloss: 0.0490876\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-24 12:43:33,729] Trial 22 finished with value: 0.049087560312302984 and parameters: {'max_bin': 397, 'num_leaves': 71}. Best is trial 16 with value: 0.04654357980084098.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.176582\tvalid_1's binary_logloss: 0.162259\n",
            "[20]\ttraining's binary_logloss: 0.143131\tvalid_1's binary_logloss: 0.136795\n",
            "[30]\ttraining's binary_logloss: 0.119403\tvalid_1's binary_logloss: 0.119488\n",
            "[40]\ttraining's binary_logloss: 0.102168\tvalid_1's binary_logloss: 0.106787\n",
            "[50]\ttraining's binary_logloss: 0.0881537\tvalid_1's binary_logloss: 0.0970057\n",
            "[60]\ttraining's binary_logloss: 0.0771557\tvalid_1's binary_logloss: 0.0896695\n",
            "[70]\ttraining's binary_logloss: 0.0681861\tvalid_1's binary_logloss: 0.0834473\n",
            "[80]\ttraining's binary_logloss: 0.0601748\tvalid_1's binary_logloss: 0.078089\n",
            "[90]\ttraining's binary_logloss: 0.0533647\tvalid_1's binary_logloss: 0.0739285\n",
            "[100]\ttraining's binary_logloss: 0.0473605\tvalid_1's binary_logloss: 0.0701406\n",
            "[110]\ttraining's binary_logloss: 0.0428261\tvalid_1's binary_logloss: 0.0676947\n",
            "[120]\ttraining's binary_logloss: 0.037987\tvalid_1's binary_logloss: 0.0645594\n",
            "[130]\ttraining's binary_logloss: 0.0335159\tvalid_1's binary_logloss: 0.0614417\n",
            "[140]\ttraining's binary_logloss: 0.0302006\tvalid_1's binary_logloss: 0.0590842\n",
            "[150]\ttraining's binary_logloss: 0.0268033\tvalid_1's binary_logloss: 0.0568363\n",
            "[160]\ttraining's binary_logloss: 0.024224\tvalid_1's binary_logloss: 0.0556364\n",
            "[170]\ttraining's binary_logloss: 0.0216248\tvalid_1's binary_logloss: 0.0541108\n",
            "[180]\ttraining's binary_logloss: 0.0192252\tvalid_1's binary_logloss: 0.052794\n",
            "[190]\ttraining's binary_logloss: 0.0170141\tvalid_1's binary_logloss: 0.0514677\n",
            "[200]\ttraining's binary_logloss: 0.0150146\tvalid_1's binary_logloss: 0.0506807\n",
            "[210]\ttraining's binary_logloss: 0.0134229\tvalid_1's binary_logloss: 0.0501787\n",
            "[220]\ttraining's binary_logloss: 0.0119538\tvalid_1's binary_logloss: 0.0498725\n",
            "[230]\ttraining's binary_logloss: 0.0107392\tvalid_1's binary_logloss: 0.0495456\n",
            "[240]\ttraining's binary_logloss: 0.00943298\tvalid_1's binary_logloss: 0.0487209\n",
            "[250]\ttraining's binary_logloss: 0.00832925\tvalid_1's binary_logloss: 0.0486556\n",
            "[260]\ttraining's binary_logloss: 0.00739525\tvalid_1's binary_logloss: 0.0482806\n",
            "Early stopping, best iteration is:\n",
            "[256]\ttraining's binary_logloss: 0.00778525\tvalid_1's binary_logloss: 0.0482066\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-24 12:43:36,684] Trial 23 finished with value: 0.04820656642392687 and parameters: {'max_bin': 287, 'num_leaves': 97}. Best is trial 16 with value: 0.04654357980084098.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.179781\tvalid_1's binary_logloss: 0.164477\n",
            "[20]\ttraining's binary_logloss: 0.147388\tvalid_1's binary_logloss: 0.139673\n",
            "[30]\ttraining's binary_logloss: 0.125266\tvalid_1's binary_logloss: 0.12372\n",
            "[40]\ttraining's binary_logloss: 0.109149\tvalid_1's binary_logloss: 0.111083\n",
            "[50]\ttraining's binary_logloss: 0.0963873\tvalid_1's binary_logloss: 0.102446\n",
            "[60]\ttraining's binary_logloss: 0.085705\tvalid_1's binary_logloss: 0.0960698\n",
            "[70]\ttraining's binary_logloss: 0.0761231\tvalid_1's binary_logloss: 0.0891172\n",
            "[80]\ttraining's binary_logloss: 0.067957\tvalid_1's binary_logloss: 0.0838271\n",
            "[90]\ttraining's binary_logloss: 0.0603637\tvalid_1's binary_logloss: 0.0791764\n",
            "[100]\ttraining's binary_logloss: 0.0548817\tvalid_1's binary_logloss: 0.0748211\n",
            "[110]\ttraining's binary_logloss: 0.0496093\tvalid_1's binary_logloss: 0.0711308\n",
            "[120]\ttraining's binary_logloss: 0.0442951\tvalid_1's binary_logloss: 0.0681436\n",
            "[130]\ttraining's binary_logloss: 0.039557\tvalid_1's binary_logloss: 0.0646108\n",
            "[140]\ttraining's binary_logloss: 0.0360564\tvalid_1's binary_logloss: 0.0625996\n",
            "[150]\ttraining's binary_logloss: 0.0319464\tvalid_1's binary_logloss: 0.060018\n",
            "[160]\ttraining's binary_logloss: 0.0287267\tvalid_1's binary_logloss: 0.0582588\n",
            "[170]\ttraining's binary_logloss: 0.0265649\tvalid_1's binary_logloss: 0.0569181\n",
            "[180]\ttraining's binary_logloss: 0.0241909\tvalid_1's binary_logloss: 0.055711\n",
            "[190]\ttraining's binary_logloss: 0.0223681\tvalid_1's binary_logloss: 0.054545\n",
            "[200]\ttraining's binary_logloss: 0.0202776\tvalid_1's binary_logloss: 0.0534941\n",
            "[210]\ttraining's binary_logloss: 0.0180007\tvalid_1's binary_logloss: 0.0522412\n",
            "[220]\ttraining's binary_logloss: 0.0158999\tvalid_1's binary_logloss: 0.0511732\n",
            "[230]\ttraining's binary_logloss: 0.0143645\tvalid_1's binary_logloss: 0.0505039\n",
            "[240]\ttraining's binary_logloss: 0.012752\tvalid_1's binary_logloss: 0.0499876\n",
            "[250]\ttraining's binary_logloss: 0.0114936\tvalid_1's binary_logloss: 0.0493706\n",
            "[260]\ttraining's binary_logloss: 0.0105011\tvalid_1's binary_logloss: 0.0491115\n",
            "[270]\ttraining's binary_logloss: 0.00941404\tvalid_1's binary_logloss: 0.0488398\n",
            "[280]\ttraining's binary_logloss: 0.00835623\tvalid_1's binary_logloss: 0.0488732\n",
            "[290]\ttraining's binary_logloss: 0.00745368\tvalid_1's binary_logloss: 0.0486591\n",
            "[300]\ttraining's binary_logloss: 0.00676753\tvalid_1's binary_logloss: 0.0489218\n",
            "Early stopping, best iteration is:\n",
            "[292]\ttraining's binary_logloss: 0.00730303\tvalid_1's binary_logloss: 0.0485893\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-24 12:43:39,811] Trial 24 finished with value: 0.04858928921460757 and parameters: {'max_bin': 264, 'num_leaves': 89}. Best is trial 16 with value: 0.04654357980084098.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.188405\tvalid_1's binary_logloss: 0.170606\n",
            "[20]\ttraining's binary_logloss: 0.16181\tvalid_1's binary_logloss: 0.149509\n",
            "[30]\ttraining's binary_logloss: 0.14208\tvalid_1's binary_logloss: 0.136512\n",
            "[40]\ttraining's binary_logloss: 0.128199\tvalid_1's binary_logloss: 0.12705\n",
            "[50]\ttraining's binary_logloss: 0.116571\tvalid_1's binary_logloss: 0.118437\n",
            "[60]\ttraining's binary_logloss: 0.107273\tvalid_1's binary_logloss: 0.111672\n",
            "[70]\ttraining's binary_logloss: 0.0978014\tvalid_1's binary_logloss: 0.10467\n",
            "[80]\ttraining's binary_logloss: 0.090094\tvalid_1's binary_logloss: 0.0988489\n",
            "[90]\ttraining's binary_logloss: 0.0826869\tvalid_1's binary_logloss: 0.0944389\n",
            "[100]\ttraining's binary_logloss: 0.0765738\tvalid_1's binary_logloss: 0.0907958\n",
            "[110]\ttraining's binary_logloss: 0.0696711\tvalid_1's binary_logloss: 0.0865055\n",
            "[120]\ttraining's binary_logloss: 0.0640437\tvalid_1's binary_logloss: 0.0829088\n",
            "[130]\ttraining's binary_logloss: 0.0590705\tvalid_1's binary_logloss: 0.080032\n",
            "[140]\ttraining's binary_logloss: 0.0544337\tvalid_1's binary_logloss: 0.0767462\n",
            "[150]\ttraining's binary_logloss: 0.0500999\tvalid_1's binary_logloss: 0.073852\n",
            "[160]\ttraining's binary_logloss: 0.0465383\tvalid_1's binary_logloss: 0.0712977\n",
            "[170]\ttraining's binary_logloss: 0.0428153\tvalid_1's binary_logloss: 0.0684592\n",
            "[180]\ttraining's binary_logloss: 0.0397705\tvalid_1's binary_logloss: 0.0666724\n",
            "[190]\ttraining's binary_logloss: 0.0367598\tvalid_1's binary_logloss: 0.0648244\n",
            "[200]\ttraining's binary_logloss: 0.0340335\tvalid_1's binary_logloss: 0.0631279\n",
            "[210]\ttraining's binary_logloss: 0.0317282\tvalid_1's binary_logloss: 0.0617002\n",
            "[220]\ttraining's binary_logloss: 0.0293339\tvalid_1's binary_logloss: 0.0599788\n",
            "[230]\ttraining's binary_logloss: 0.0270454\tvalid_1's binary_logloss: 0.0586545\n",
            "[240]\ttraining's binary_logloss: 0.0253696\tvalid_1's binary_logloss: 0.057668\n",
            "[250]\ttraining's binary_logloss: 0.0238435\tvalid_1's binary_logloss: 0.0567694\n",
            "[260]\ttraining's binary_logloss: 0.0220705\tvalid_1's binary_logloss: 0.0555186\n",
            "[270]\ttraining's binary_logloss: 0.0204665\tvalid_1's binary_logloss: 0.0545505\n",
            "[280]\ttraining's binary_logloss: 0.0192794\tvalid_1's binary_logloss: 0.0542769\n",
            "[290]\ttraining's binary_logloss: 0.0178796\tvalid_1's binary_logloss: 0.0533655\n",
            "[300]\ttraining's binary_logloss: 0.0165186\tvalid_1's binary_logloss: 0.0528632\n",
            "[310]\ttraining's binary_logloss: 0.0154606\tvalid_1's binary_logloss: 0.0528602\n",
            "[320]\ttraining's binary_logloss: 0.0140714\tvalid_1's binary_logloss: 0.0518586\n",
            "[330]\ttraining's binary_logloss: 0.0131625\tvalid_1's binary_logloss: 0.0518092\n",
            "Early stopping, best iteration is:\n",
            "[328]\ttraining's binary_logloss: 0.0133224\tvalid_1's binary_logloss: 0.0517608\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-24 12:43:42,902] Trial 25 finished with value: 0.05176077128668289 and parameters: {'max_bin': 382, 'num_leaves': 64}. Best is trial 16 with value: 0.04654357980084098.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.174682\tvalid_1's binary_logloss: 0.16063\n",
            "[20]\ttraining's binary_logloss: 0.140108\tvalid_1's binary_logloss: 0.134155\n",
            "[30]\ttraining's binary_logloss: 0.115063\tvalid_1's binary_logloss: 0.116597\n",
            "[40]\ttraining's binary_logloss: 0.0972323\tvalid_1's binary_logloss: 0.10439\n",
            "[50]\ttraining's binary_logloss: 0.0831931\tvalid_1's binary_logloss: 0.0944932\n",
            "[60]\ttraining's binary_logloss: 0.072278\tvalid_1's binary_logloss: 0.0867989\n",
            "[70]\ttraining's binary_logloss: 0.0631066\tvalid_1's binary_logloss: 0.080576\n",
            "[80]\ttraining's binary_logloss: 0.0561549\tvalid_1's binary_logloss: 0.0761854\n",
            "[90]\ttraining's binary_logloss: 0.0493817\tvalid_1's binary_logloss: 0.0719427\n",
            "[100]\ttraining's binary_logloss: 0.04342\tvalid_1's binary_logloss: 0.0677707\n",
            "[110]\ttraining's binary_logloss: 0.038567\tvalid_1's binary_logloss: 0.0643064\n",
            "[120]\ttraining's binary_logloss: 0.0334806\tvalid_1's binary_logloss: 0.0609968\n",
            "[130]\ttraining's binary_logloss: 0.0293067\tvalid_1's binary_logloss: 0.0588429\n",
            "[140]\ttraining's binary_logloss: 0.0258039\tvalid_1's binary_logloss: 0.0568628\n",
            "[150]\ttraining's binary_logloss: 0.0230126\tvalid_1's binary_logloss: 0.0553808\n",
            "[160]\ttraining's binary_logloss: 0.0200948\tvalid_1's binary_logloss: 0.0539334\n",
            "[170]\ttraining's binary_logloss: 0.0178988\tvalid_1's binary_logloss: 0.0525146\n",
            "[180]\ttraining's binary_logloss: 0.0157685\tvalid_1's binary_logloss: 0.0511025\n",
            "[190]\ttraining's binary_logloss: 0.0137574\tvalid_1's binary_logloss: 0.0502785\n",
            "[200]\ttraining's binary_logloss: 0.0123732\tvalid_1's binary_logloss: 0.0497229\n",
            "[210]\ttraining's binary_logloss: 0.011028\tvalid_1's binary_logloss: 0.0495144\n",
            "[220]\ttraining's binary_logloss: 0.00952027\tvalid_1's binary_logloss: 0.0491297\n",
            "[230]\ttraining's binary_logloss: 0.00836811\tvalid_1's binary_logloss: 0.0485807\n",
            "[240]\ttraining's binary_logloss: 0.00741935\tvalid_1's binary_logloss: 0.0487687\n",
            "Early stopping, best iteration is:\n",
            "[232]\ttraining's binary_logloss: 0.00817703\tvalid_1's binary_logloss: 0.0483583\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-24 12:43:45,736] Trial 26 finished with value: 0.048358344658371785 and parameters: {'max_bin': 286, 'num_leaves': 106}. Best is trial 16 with value: 0.04654357980084098.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.192168\tvalid_1's binary_logloss: 0.172979\n",
            "[20]\ttraining's binary_logloss: 0.167494\tvalid_1's binary_logloss: 0.153158\n",
            "[30]\ttraining's binary_logloss: 0.149279\tvalid_1's binary_logloss: 0.14004\n",
            "[40]\ttraining's binary_logloss: 0.135121\tvalid_1's binary_logloss: 0.12987\n",
            "[50]\ttraining's binary_logloss: 0.123763\tvalid_1's binary_logloss: 0.12142\n",
            "[60]\ttraining's binary_logloss: 0.11423\tvalid_1's binary_logloss: 0.115509\n",
            "[70]\ttraining's binary_logloss: 0.106286\tvalid_1's binary_logloss: 0.109331\n",
            "[80]\ttraining's binary_logloss: 0.0993701\tvalid_1's binary_logloss: 0.105094\n",
            "[90]\ttraining's binary_logloss: 0.0917793\tvalid_1's binary_logloss: 0.0998139\n",
            "[100]\ttraining's binary_logloss: 0.0853251\tvalid_1's binary_logloss: 0.0952929\n",
            "[110]\ttraining's binary_logloss: 0.0802098\tvalid_1's binary_logloss: 0.0914446\n",
            "[120]\ttraining's binary_logloss: 0.0747752\tvalid_1's binary_logloss: 0.0878775\n",
            "[130]\ttraining's binary_logloss: 0.069389\tvalid_1's binary_logloss: 0.0842251\n",
            "[140]\ttraining's binary_logloss: 0.0647617\tvalid_1's binary_logloss: 0.0813533\n",
            "[150]\ttraining's binary_logloss: 0.0605938\tvalid_1's binary_logloss: 0.0782311\n",
            "[160]\ttraining's binary_logloss: 0.0567001\tvalid_1's binary_logloss: 0.0759508\n",
            "[170]\ttraining's binary_logloss: 0.0531931\tvalid_1's binary_logloss: 0.073987\n",
            "[180]\ttraining's binary_logloss: 0.0497585\tvalid_1's binary_logloss: 0.0712206\n",
            "[190]\ttraining's binary_logloss: 0.0459537\tvalid_1's binary_logloss: 0.0685525\n",
            "[200]\ttraining's binary_logloss: 0.0432553\tvalid_1's binary_logloss: 0.0667866\n",
            "[210]\ttraining's binary_logloss: 0.0400171\tvalid_1's binary_logloss: 0.0646525\n",
            "[220]\ttraining's binary_logloss: 0.0377111\tvalid_1's binary_logloss: 0.0633097\n",
            "[230]\ttraining's binary_logloss: 0.0352663\tvalid_1's binary_logloss: 0.0616434\n",
            "[240]\ttraining's binary_logloss: 0.0331908\tvalid_1's binary_logloss: 0.0604424\n",
            "[250]\ttraining's binary_logloss: 0.0309343\tvalid_1's binary_logloss: 0.0592665\n",
            "[260]\ttraining's binary_logloss: 0.0289689\tvalid_1's binary_logloss: 0.05836\n",
            "[270]\ttraining's binary_logloss: 0.0271042\tvalid_1's binary_logloss: 0.0572706\n",
            "[280]\ttraining's binary_logloss: 0.0256131\tvalid_1's binary_logloss: 0.0566135\n",
            "[290]\ttraining's binary_logloss: 0.0237875\tvalid_1's binary_logloss: 0.0552588\n",
            "[300]\ttraining's binary_logloss: 0.0225126\tvalid_1's binary_logloss: 0.0548165\n",
            "[310]\ttraining's binary_logloss: 0.0211757\tvalid_1's binary_logloss: 0.0539755\n",
            "[320]\ttraining's binary_logloss: 0.0196554\tvalid_1's binary_logloss: 0.0530863\n",
            "[330]\ttraining's binary_logloss: 0.0185204\tvalid_1's binary_logloss: 0.0523973\n",
            "[340]\ttraining's binary_logloss: 0.0173303\tvalid_1's binary_logloss: 0.0518153\n",
            "[350]\ttraining's binary_logloss: 0.0161144\tvalid_1's binary_logloss: 0.0510175\n",
            "[360]\ttraining's binary_logloss: 0.0150915\tvalid_1's binary_logloss: 0.0506062\n",
            "[370]\ttraining's binary_logloss: 0.014146\tvalid_1's binary_logloss: 0.0501509\n",
            "[380]\ttraining's binary_logloss: 0.0131497\tvalid_1's binary_logloss: 0.0498325\n",
            "[390]\ttraining's binary_logloss: 0.0122816\tvalid_1's binary_logloss: 0.0496701\n",
            "[400]\ttraining's binary_logloss: 0.0114781\tvalid_1's binary_logloss: 0.0490283\n",
            "[410]\ttraining's binary_logloss: 0.0107252\tvalid_1's binary_logloss: 0.0487873\n",
            "[420]\ttraining's binary_logloss: 0.0101149\tvalid_1's binary_logloss: 0.0486345\n",
            "[430]\ttraining's binary_logloss: 0.00951221\tvalid_1's binary_logloss: 0.0483992\n",
            "[440]\ttraining's binary_logloss: 0.0089918\tvalid_1's binary_logloss: 0.0483738\n",
            "Early stopping, best iteration is:\n",
            "[433]\ttraining's binary_logloss: 0.00935502\tvalid_1's binary_logloss: 0.0482983\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-24 12:43:49,569] Trial 27 finished with value: 0.04829832799621358 and parameters: {'max_bin': 499, 'num_leaves': 55}. Best is trial 16 with value: 0.04654357980084098.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.174269\tvalid_1's binary_logloss: 0.160609\n",
            "[20]\ttraining's binary_logloss: 0.139108\tvalid_1's binary_logloss: 0.132779\n",
            "[30]\ttraining's binary_logloss: 0.114712\tvalid_1's binary_logloss: 0.115772\n",
            "[40]\ttraining's binary_logloss: 0.0964486\tvalid_1's binary_logloss: 0.102485\n",
            "[50]\ttraining's binary_logloss: 0.0828443\tvalid_1's binary_logloss: 0.0934372\n",
            "[60]\ttraining's binary_logloss: 0.0715018\tvalid_1's binary_logloss: 0.0859351\n",
            "[70]\ttraining's binary_logloss: 0.0622762\tvalid_1's binary_logloss: 0.0798645\n",
            "[80]\ttraining's binary_logloss: 0.0546876\tvalid_1's binary_logloss: 0.0751978\n",
            "[90]\ttraining's binary_logloss: 0.0479526\tvalid_1's binary_logloss: 0.0708187\n",
            "[100]\ttraining's binary_logloss: 0.0416363\tvalid_1's binary_logloss: 0.0668695\n",
            "[110]\ttraining's binary_logloss: 0.0366277\tvalid_1's binary_logloss: 0.0638737\n",
            "[120]\ttraining's binary_logloss: 0.0324353\tvalid_1's binary_logloss: 0.0607425\n",
            "[130]\ttraining's binary_logloss: 0.0288234\tvalid_1's binary_logloss: 0.058249\n",
            "[140]\ttraining's binary_logloss: 0.0252126\tvalid_1's binary_logloss: 0.0559948\n",
            "[150]\ttraining's binary_logloss: 0.022438\tvalid_1's binary_logloss: 0.0542555\n",
            "[160]\ttraining's binary_logloss: 0.0197622\tvalid_1's binary_logloss: 0.0528329\n",
            "[170]\ttraining's binary_logloss: 0.0168329\tvalid_1's binary_logloss: 0.0514158\n",
            "[180]\ttraining's binary_logloss: 0.0146725\tvalid_1's binary_logloss: 0.0505318\n",
            "[190]\ttraining's binary_logloss: 0.0129114\tvalid_1's binary_logloss: 0.0500096\n",
            "[200]\ttraining's binary_logloss: 0.0112326\tvalid_1's binary_logloss: 0.0491027\n",
            "[210]\ttraining's binary_logloss: 0.0100348\tvalid_1's binary_logloss: 0.0490656\n",
            "[220]\ttraining's binary_logloss: 0.00880583\tvalid_1's binary_logloss: 0.0488687\n",
            "[230]\ttraining's binary_logloss: 0.00775133\tvalid_1's binary_logloss: 0.0490724\n",
            "Early stopping, best iteration is:\n",
            "[222]\ttraining's binary_logloss: 0.00858884\tvalid_1's binary_logloss: 0.0486925\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-24 12:43:52,482] Trial 28 finished with value: 0.04869251028884313 and parameters: {'max_bin': 418, 'num_leaves': 107}. Best is trial 16 with value: 0.04654357980084098.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.179773\tvalid_1's binary_logloss: 0.164187\n",
            "[20]\ttraining's binary_logloss: 0.148169\tvalid_1's binary_logloss: 0.139654\n",
            "[30]\ttraining's binary_logloss: 0.125695\tvalid_1's binary_logloss: 0.12356\n",
            "[40]\ttraining's binary_logloss: 0.108849\tvalid_1's binary_logloss: 0.111527\n",
            "[50]\ttraining's binary_logloss: 0.0961821\tvalid_1's binary_logloss: 0.103041\n",
            "[60]\ttraining's binary_logloss: 0.0861355\tvalid_1's binary_logloss: 0.0958722\n",
            "[70]\ttraining's binary_logloss: 0.0768487\tvalid_1's binary_logloss: 0.0895626\n",
            "[80]\ttraining's binary_logloss: 0.0697411\tvalid_1's binary_logloss: 0.0849575\n",
            "[90]\ttraining's binary_logloss: 0.0628254\tvalid_1's binary_logloss: 0.0798361\n",
            "[100]\ttraining's binary_logloss: 0.0561203\tvalid_1's binary_logloss: 0.0757668\n",
            "[110]\ttraining's binary_logloss: 0.0508616\tvalid_1's binary_logloss: 0.0728779\n",
            "[120]\ttraining's binary_logloss: 0.046215\tvalid_1's binary_logloss: 0.069845\n",
            "[130]\ttraining's binary_logloss: 0.0415736\tvalid_1's binary_logloss: 0.0669651\n",
            "[140]\ttraining's binary_logloss: 0.0367705\tvalid_1's binary_logloss: 0.0639773\n",
            "[150]\ttraining's binary_logloss: 0.0331117\tvalid_1's binary_logloss: 0.0616023\n",
            "[160]\ttraining's binary_logloss: 0.0291872\tvalid_1's binary_logloss: 0.0592431\n",
            "[170]\ttraining's binary_logloss: 0.0264199\tvalid_1's binary_logloss: 0.0575248\n",
            "[180]\ttraining's binary_logloss: 0.0236946\tvalid_1's binary_logloss: 0.055975\n",
            "[190]\ttraining's binary_logloss: 0.0216328\tvalid_1's binary_logloss: 0.0545121\n",
            "[200]\ttraining's binary_logloss: 0.0198865\tvalid_1's binary_logloss: 0.0539352\n",
            "[210]\ttraining's binary_logloss: 0.018238\tvalid_1's binary_logloss: 0.0535806\n",
            "[220]\ttraining's binary_logloss: 0.0164638\tvalid_1's binary_logloss: 0.0525548\n",
            "[230]\ttraining's binary_logloss: 0.0148498\tvalid_1's binary_logloss: 0.0519048\n",
            "[240]\ttraining's binary_logloss: 0.0129425\tvalid_1's binary_logloss: 0.0511401\n",
            "[250]\ttraining's binary_logloss: 0.0116253\tvalid_1's binary_logloss: 0.0506101\n",
            "[260]\ttraining's binary_logloss: 0.0105313\tvalid_1's binary_logloss: 0.0505058\n",
            "[270]\ttraining's binary_logloss: 0.00938514\tvalid_1's binary_logloss: 0.0499826\n",
            "[280]\ttraining's binary_logloss: 0.00845964\tvalid_1's binary_logloss: 0.0496851\n",
            "[290]\ttraining's binary_logloss: 0.00768615\tvalid_1's binary_logloss: 0.0496326\n",
            "[300]\ttraining's binary_logloss: 0.00695318\tvalid_1's binary_logloss: 0.0496426\n",
            "Early stopping, best iteration is:\n",
            "[294]\ttraining's binary_logloss: 0.00738465\tvalid_1's binary_logloss: 0.0495274\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-24 12:43:55,758] Trial 29 finished with value: 0.04952741524108397 and parameters: {'max_bin': 369, 'num_leaves': 87}. Best is trial 16 with value: 0.04654357980084098.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwZ0MSzwX5fI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lgbm_params = {\n",
        "    'learning_rate': 0.05,\n",
        "    'num_leaves': study.best_params[\"num_leaves\"],\n",
        "    'boosting_type' : 'gbdt',\n",
        "    'objective': 'binary',\n",
        "    'max_bin': study.best_params[\"max_bin\"],\n",
        "    'max_dapth': 7\n",
        "}\n",
        "\n"
      ],
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GPPbOjMO5IQ",
        "colab_type": "text"
      },
      "source": [
        "##Bagging of LGB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uk1tpY_GO5IR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bagging(seed):\n",
        "    positive_count_train = y_train_LGB.sum()\n",
        "    sampler = RandomUnderSampler(sampling_strategy={0:int(positive_count_train), 1:int(positive_count_train)},random_state=seed, replacement=True)\n",
        "    X_resampled, y_resampled = sampler.fit_resample(X_train_LGB, y_train_LGB)\n",
        "    X_train2_LGB, X_valid_LGB, y_train2_LGB, y_valid_LGB = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=seed)\n",
        "    model_bagging = lgbm_train(X_train2_LGB, X_valid_LGB, y_train2_LGB, y_valid_LGB, lgbm_params)\n",
        "    return model_bagging"
      ],
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iT-IUB1O5IV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dcd7b271-b9a9-4220-f092-b22165793bba"
      },
      "source": [
        "%%time\n",
        "models_LGB = []\n",
        "for i in range(10):\n",
        "    models_LGB.append(bagging(i))\n",
        "\n"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's binary_logloss: 0.677199\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's binary_logloss: 0.661076\n",
            "[3]\tvalid_0's binary_logloss: 0.645925\n",
            "[4]\tvalid_0's binary_logloss: 0.633197\n",
            "[5]\tvalid_0's binary_logloss: 0.620732\n",
            "[6]\tvalid_0's binary_logloss: 0.609193\n",
            "[7]\tvalid_0's binary_logloss: 0.598475\n",
            "[8]\tvalid_0's binary_logloss: 0.589049\n",
            "[9]\tvalid_0's binary_logloss: 0.580219\n",
            "[10]\tvalid_0's binary_logloss: 0.570882\n",
            "[11]\tvalid_0's binary_logloss: 0.563916\n",
            "[12]\tvalid_0's binary_logloss: 0.556798\n",
            "[13]\tvalid_0's binary_logloss: 0.550563\n",
            "[14]\tvalid_0's binary_logloss: 0.54511\n",
            "[15]\tvalid_0's binary_logloss: 0.539096\n",
            "[16]\tvalid_0's binary_logloss: 0.534771\n",
            "[17]\tvalid_0's binary_logloss: 0.530005\n",
            "[18]\tvalid_0's binary_logloss: 0.524141\n",
            "[19]\tvalid_0's binary_logloss: 0.519466\n",
            "[20]\tvalid_0's binary_logloss: 0.514915\n",
            "[21]\tvalid_0's binary_logloss: 0.509528\n",
            "[22]\tvalid_0's binary_logloss: 0.504703\n",
            "[23]\tvalid_0's binary_logloss: 0.501275\n",
            "[24]\tvalid_0's binary_logloss: 0.497237\n",
            "[25]\tvalid_0's binary_logloss: 0.492988\n",
            "[26]\tvalid_0's binary_logloss: 0.488084\n",
            "[27]\tvalid_0's binary_logloss: 0.485613\n",
            "[28]\tvalid_0's binary_logloss: 0.481308\n",
            "[29]\tvalid_0's binary_logloss: 0.476996\n",
            "[30]\tvalid_0's binary_logloss: 0.473826\n",
            "[31]\tvalid_0's binary_logloss: 0.471268\n",
            "[32]\tvalid_0's binary_logloss: 0.469051\n",
            "[33]\tvalid_0's binary_logloss: 0.465219\n",
            "[34]\tvalid_0's binary_logloss: 0.462647\n",
            "[35]\tvalid_0's binary_logloss: 0.460078\n",
            "[36]\tvalid_0's binary_logloss: 0.457908\n",
            "[37]\tvalid_0's binary_logloss: 0.455568\n",
            "[38]\tvalid_0's binary_logloss: 0.452516\n",
            "[39]\tvalid_0's binary_logloss: 0.449897\n",
            "[40]\tvalid_0's binary_logloss: 0.448286\n",
            "[41]\tvalid_0's binary_logloss: 0.446367\n",
            "[42]\tvalid_0's binary_logloss: 0.443613\n",
            "[43]\tvalid_0's binary_logloss: 0.441913\n",
            "[44]\tvalid_0's binary_logloss: 0.43923\n",
            "[45]\tvalid_0's binary_logloss: 0.437586\n",
            "[46]\tvalid_0's binary_logloss: 0.435234\n",
            "[47]\tvalid_0's binary_logloss: 0.433718\n",
            "[48]\tvalid_0's binary_logloss: 0.433179\n",
            "[49]\tvalid_0's binary_logloss: 0.430824\n",
            "[50]\tvalid_0's binary_logloss: 0.428153\n",
            "[51]\tvalid_0's binary_logloss: 0.425989\n",
            "[52]\tvalid_0's binary_logloss: 0.424728\n",
            "[53]\tvalid_0's binary_logloss: 0.423738\n",
            "[54]\tvalid_0's binary_logloss: 0.421822\n",
            "[55]\tvalid_0's binary_logloss: 0.42034\n",
            "[56]\tvalid_0's binary_logloss: 0.418961\n",
            "[57]\tvalid_0's binary_logloss: 0.417408\n",
            "[58]\tvalid_0's binary_logloss: 0.416026\n",
            "[59]\tvalid_0's binary_logloss: 0.414069\n",
            "[60]\tvalid_0's binary_logloss: 0.412244\n",
            "[61]\tvalid_0's binary_logloss: 0.411022\n",
            "[62]\tvalid_0's binary_logloss: 0.409242\n",
            "[63]\tvalid_0's binary_logloss: 0.407813\n",
            "[64]\tvalid_0's binary_logloss: 0.407258\n",
            "[65]\tvalid_0's binary_logloss: 0.406186\n",
            "[66]\tvalid_0's binary_logloss: 0.405133\n",
            "[67]\tvalid_0's binary_logloss: 0.404021\n",
            "[68]\tvalid_0's binary_logloss: 0.402578\n",
            "[69]\tvalid_0's binary_logloss: 0.401721\n",
            "[70]\tvalid_0's binary_logloss: 0.400447\n",
            "[71]\tvalid_0's binary_logloss: 0.398922\n",
            "[72]\tvalid_0's binary_logloss: 0.398515\n",
            "[73]\tvalid_0's binary_logloss: 0.398191\n",
            "[74]\tvalid_0's binary_logloss: 0.398072\n",
            "[75]\tvalid_0's binary_logloss: 0.396464\n",
            "[76]\tvalid_0's binary_logloss: 0.396042\n",
            "[77]\tvalid_0's binary_logloss: 0.395427\n",
            "[78]\tvalid_0's binary_logloss: 0.394623\n",
            "[79]\tvalid_0's binary_logloss: 0.393603\n",
            "[80]\tvalid_0's binary_logloss: 0.393105\n",
            "[81]\tvalid_0's binary_logloss: 0.39243\n",
            "[82]\tvalid_0's binary_logloss: 0.391282\n",
            "[83]\tvalid_0's binary_logloss: 0.390291\n",
            "[84]\tvalid_0's binary_logloss: 0.389748\n",
            "[85]\tvalid_0's binary_logloss: 0.388745\n",
            "[86]\tvalid_0's binary_logloss: 0.388827\n",
            "[87]\tvalid_0's binary_logloss: 0.388417\n",
            "[88]\tvalid_0's binary_logloss: 0.38846\n",
            "[89]\tvalid_0's binary_logloss: 0.38723\n",
            "[90]\tvalid_0's binary_logloss: 0.386783\n",
            "[91]\tvalid_0's binary_logloss: 0.386201\n",
            "[92]\tvalid_0's binary_logloss: 0.386284\n",
            "[93]\tvalid_0's binary_logloss: 0.386366\n",
            "[94]\tvalid_0's binary_logloss: 0.386295\n",
            "[95]\tvalid_0's binary_logloss: 0.385644\n",
            "[96]\tvalid_0's binary_logloss: 0.385824\n",
            "[97]\tvalid_0's binary_logloss: 0.385917\n",
            "[98]\tvalid_0's binary_logloss: 0.386023\n",
            "[99]\tvalid_0's binary_logloss: 0.38552\n",
            "[100]\tvalid_0's binary_logloss: 0.385239\n",
            "[101]\tvalid_0's binary_logloss: 0.385119\n",
            "[102]\tvalid_0's binary_logloss: 0.384797\n",
            "[103]\tvalid_0's binary_logloss: 0.383966\n",
            "[104]\tvalid_0's binary_logloss: 0.384222\n",
            "[105]\tvalid_0's binary_logloss: 0.384263\n",
            "[106]\tvalid_0's binary_logloss: 0.384039\n",
            "[107]\tvalid_0's binary_logloss: 0.383496\n",
            "[108]\tvalid_0's binary_logloss: 0.383622\n",
            "[109]\tvalid_0's binary_logloss: 0.383283\n",
            "[110]\tvalid_0's binary_logloss: 0.38276\n",
            "[111]\tvalid_0's binary_logloss: 0.382231\n",
            "[112]\tvalid_0's binary_logloss: 0.38201\n",
            "[113]\tvalid_0's binary_logloss: 0.381286\n",
            "[114]\tvalid_0's binary_logloss: 0.381555\n",
            "[115]\tvalid_0's binary_logloss: 0.380298\n",
            "[116]\tvalid_0's binary_logloss: 0.380056\n",
            "[117]\tvalid_0's binary_logloss: 0.379815\n",
            "[118]\tvalid_0's binary_logloss: 0.379412\n",
            "[119]\tvalid_0's binary_logloss: 0.378353\n",
            "[120]\tvalid_0's binary_logloss: 0.377983\n",
            "[121]\tvalid_0's binary_logloss: 0.377759\n",
            "[122]\tvalid_0's binary_logloss: 0.377849\n",
            "[123]\tvalid_0's binary_logloss: 0.37733\n",
            "[124]\tvalid_0's binary_logloss: 0.377061\n",
            "[125]\tvalid_0's binary_logloss: 0.376838\n",
            "[126]\tvalid_0's binary_logloss: 0.376492\n",
            "[127]\tvalid_0's binary_logloss: 0.376132\n",
            "[128]\tvalid_0's binary_logloss: 0.375424\n",
            "[129]\tvalid_0's binary_logloss: 0.375049\n",
            "[130]\tvalid_0's binary_logloss: 0.375042\n",
            "[131]\tvalid_0's binary_logloss: 0.374959\n",
            "[132]\tvalid_0's binary_logloss: 0.375418\n",
            "[133]\tvalid_0's binary_logloss: 0.37538\n",
            "[134]\tvalid_0's binary_logloss: 0.374937\n",
            "[135]\tvalid_0's binary_logloss: 0.374393\n",
            "[136]\tvalid_0's binary_logloss: 0.374514\n",
            "[137]\tvalid_0's binary_logloss: 0.374693\n",
            "[138]\tvalid_0's binary_logloss: 0.375389\n",
            "[139]\tvalid_0's binary_logloss: 0.374739\n",
            "[140]\tvalid_0's binary_logloss: 0.375034\n",
            "[141]\tvalid_0's binary_logloss: 0.374981\n",
            "[142]\tvalid_0's binary_logloss: 0.374702\n",
            "[143]\tvalid_0's binary_logloss: 0.374751\n",
            "[144]\tvalid_0's binary_logloss: 0.374617\n",
            "[145]\tvalid_0's binary_logloss: 0.374027\n",
            "[146]\tvalid_0's binary_logloss: 0.373761\n",
            "[147]\tvalid_0's binary_logloss: 0.374236\n",
            "[148]\tvalid_0's binary_logloss: 0.373717\n",
            "[149]\tvalid_0's binary_logloss: 0.373384\n",
            "[150]\tvalid_0's binary_logloss: 0.372835\n",
            "[151]\tvalid_0's binary_logloss: 0.373395\n",
            "[152]\tvalid_0's binary_logloss: 0.373001\n",
            "[153]\tvalid_0's binary_logloss: 0.373438\n",
            "[154]\tvalid_0's binary_logloss: 0.373525\n",
            "[155]\tvalid_0's binary_logloss: 0.373525\n",
            "[156]\tvalid_0's binary_logloss: 0.373182\n",
            "[157]\tvalid_0's binary_logloss: 0.373278\n",
            "[158]\tvalid_0's binary_logloss: 0.3731\n",
            "[159]\tvalid_0's binary_logloss: 0.373668\n",
            "[160]\tvalid_0's binary_logloss: 0.373867\n",
            "Early stopping, best iteration is:\n",
            "[150]\tvalid_0's binary_logloss: 0.372835\n",
            "[1]\tvalid_0's binary_logloss: 0.67748\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's binary_logloss: 0.663516\n",
            "[3]\tvalid_0's binary_logloss: 0.649936\n",
            "[4]\tvalid_0's binary_logloss: 0.637449\n",
            "[5]\tvalid_0's binary_logloss: 0.626594\n",
            "[6]\tvalid_0's binary_logloss: 0.61629\n",
            "[7]\tvalid_0's binary_logloss: 0.607347\n",
            "[8]\tvalid_0's binary_logloss: 0.59933\n",
            "[9]\tvalid_0's binary_logloss: 0.591105\n",
            "[10]\tvalid_0's binary_logloss: 0.584631\n",
            "[11]\tvalid_0's binary_logloss: 0.577672\n",
            "[12]\tvalid_0's binary_logloss: 0.571882\n",
            "[13]\tvalid_0's binary_logloss: 0.565984\n",
            "[14]\tvalid_0's binary_logloss: 0.560156\n",
            "[15]\tvalid_0's binary_logloss: 0.554544\n",
            "[16]\tvalid_0's binary_logloss: 0.54928\n",
            "[17]\tvalid_0's binary_logloss: 0.544035\n",
            "[18]\tvalid_0's binary_logloss: 0.539782\n",
            "[19]\tvalid_0's binary_logloss: 0.535878\n",
            "[20]\tvalid_0's binary_logloss: 0.531261\n",
            "[21]\tvalid_0's binary_logloss: 0.52699\n",
            "[22]\tvalid_0's binary_logloss: 0.524249\n",
            "[23]\tvalid_0's binary_logloss: 0.52147\n",
            "[24]\tvalid_0's binary_logloss: 0.518165\n",
            "[25]\tvalid_0's binary_logloss: 0.515824\n",
            "[26]\tvalid_0's binary_logloss: 0.513396\n",
            "[27]\tvalid_0's binary_logloss: 0.510921\n",
            "[28]\tvalid_0's binary_logloss: 0.508997\n",
            "[29]\tvalid_0's binary_logloss: 0.507061\n",
            "[30]\tvalid_0's binary_logloss: 0.505067\n",
            "[31]\tvalid_0's binary_logloss: 0.501673\n",
            "[32]\tvalid_0's binary_logloss: 0.498573\n",
            "[33]\tvalid_0's binary_logloss: 0.496628\n",
            "[34]\tvalid_0's binary_logloss: 0.493873\n",
            "[35]\tvalid_0's binary_logloss: 0.491739\n",
            "[36]\tvalid_0's binary_logloss: 0.489072\n",
            "[37]\tvalid_0's binary_logloss: 0.487757\n",
            "[38]\tvalid_0's binary_logloss: 0.485068\n",
            "[39]\tvalid_0's binary_logloss: 0.483815\n",
            "[40]\tvalid_0's binary_logloss: 0.481665\n",
            "[41]\tvalid_0's binary_logloss: 0.479645\n",
            "[42]\tvalid_0's binary_logloss: 0.475816\n",
            "[43]\tvalid_0's binary_logloss: 0.474761\n",
            "[44]\tvalid_0's binary_logloss: 0.47387\n",
            "[45]\tvalid_0's binary_logloss: 0.470821\n",
            "[46]\tvalid_0's binary_logloss: 0.470207\n",
            "[47]\tvalid_0's binary_logloss: 0.469201\n",
            "[48]\tvalid_0's binary_logloss: 0.466947\n",
            "[49]\tvalid_0's binary_logloss: 0.465163\n",
            "[50]\tvalid_0's binary_logloss: 0.464111\n",
            "[51]\tvalid_0's binary_logloss: 0.462993\n",
            "[52]\tvalid_0's binary_logloss: 0.460765\n",
            "[53]\tvalid_0's binary_logloss: 0.458177\n",
            "[54]\tvalid_0's binary_logloss: 0.457387\n",
            "[55]\tvalid_0's binary_logloss: 0.455694\n",
            "[56]\tvalid_0's binary_logloss: 0.453869\n",
            "[57]\tvalid_0's binary_logloss: 0.4517\n",
            "[58]\tvalid_0's binary_logloss: 0.450669\n",
            "[59]\tvalid_0's binary_logloss: 0.448684\n",
            "[60]\tvalid_0's binary_logloss: 0.446439\n",
            "[61]\tvalid_0's binary_logloss: 0.445267\n",
            "[62]\tvalid_0's binary_logloss: 0.444034\n",
            "[63]\tvalid_0's binary_logloss: 0.443488\n",
            "[64]\tvalid_0's binary_logloss: 0.441306\n",
            "[65]\tvalid_0's binary_logloss: 0.440319\n",
            "[66]\tvalid_0's binary_logloss: 0.439393\n",
            "[67]\tvalid_0's binary_logloss: 0.437685\n",
            "[68]\tvalid_0's binary_logloss: 0.436922\n",
            "[69]\tvalid_0's binary_logloss: 0.435552\n",
            "[70]\tvalid_0's binary_logloss: 0.434505\n",
            "[71]\tvalid_0's binary_logloss: 0.432924\n",
            "[72]\tvalid_0's binary_logloss: 0.430966\n",
            "[73]\tvalid_0's binary_logloss: 0.429744\n",
            "[74]\tvalid_0's binary_logloss: 0.428576\n",
            "[75]\tvalid_0's binary_logloss: 0.427017\n",
            "[76]\tvalid_0's binary_logloss: 0.426369\n",
            "[77]\tvalid_0's binary_logloss: 0.425381\n",
            "[78]\tvalid_0's binary_logloss: 0.424483\n",
            "[79]\tvalid_0's binary_logloss: 0.422962\n",
            "[80]\tvalid_0's binary_logloss: 0.421619\n",
            "[81]\tvalid_0's binary_logloss: 0.42044\n",
            "[82]\tvalid_0's binary_logloss: 0.41961\n",
            "[83]\tvalid_0's binary_logloss: 0.418536\n",
            "[84]\tvalid_0's binary_logloss: 0.417895\n",
            "[85]\tvalid_0's binary_logloss: 0.417799\n",
            "[86]\tvalid_0's binary_logloss: 0.417637\n",
            "[87]\tvalid_0's binary_logloss: 0.416878\n",
            "[88]\tvalid_0's binary_logloss: 0.41567\n",
            "[89]\tvalid_0's binary_logloss: 0.414992\n",
            "[90]\tvalid_0's binary_logloss: 0.414301\n",
            "[91]\tvalid_0's binary_logloss: 0.41454\n",
            "[92]\tvalid_0's binary_logloss: 0.414187\n",
            "[93]\tvalid_0's binary_logloss: 0.413826\n",
            "[94]\tvalid_0's binary_logloss: 0.413316\n",
            "[95]\tvalid_0's binary_logloss: 0.41218\n",
            "[96]\tvalid_0's binary_logloss: 0.412319\n",
            "[97]\tvalid_0's binary_logloss: 0.411724\n",
            "[98]\tvalid_0's binary_logloss: 0.41191\n",
            "[99]\tvalid_0's binary_logloss: 0.41165\n",
            "[100]\tvalid_0's binary_logloss: 0.411797\n",
            "[101]\tvalid_0's binary_logloss: 0.410667\n",
            "[102]\tvalid_0's binary_logloss: 0.410314\n",
            "[103]\tvalid_0's binary_logloss: 0.409138\n",
            "[104]\tvalid_0's binary_logloss: 0.408553\n",
            "[105]\tvalid_0's binary_logloss: 0.408327\n",
            "[106]\tvalid_0's binary_logloss: 0.408023\n",
            "[107]\tvalid_0's binary_logloss: 0.407827\n",
            "[108]\tvalid_0's binary_logloss: 0.407628\n",
            "[109]\tvalid_0's binary_logloss: 0.407622\n",
            "[110]\tvalid_0's binary_logloss: 0.407758\n",
            "[111]\tvalid_0's binary_logloss: 0.407266\n",
            "[112]\tvalid_0's binary_logloss: 0.406384\n",
            "[113]\tvalid_0's binary_logloss: 0.406321\n",
            "[114]\tvalid_0's binary_logloss: 0.406335\n",
            "[115]\tvalid_0's binary_logloss: 0.406435\n",
            "[116]\tvalid_0's binary_logloss: 0.406281\n",
            "[117]\tvalid_0's binary_logloss: 0.406851\n",
            "[118]\tvalid_0's binary_logloss: 0.407135\n",
            "[119]\tvalid_0's binary_logloss: 0.406618\n",
            "[120]\tvalid_0's binary_logloss: 0.406551\n",
            "[121]\tvalid_0's binary_logloss: 0.406528\n",
            "[122]\tvalid_0's binary_logloss: 0.405801\n",
            "[123]\tvalid_0's binary_logloss: 0.406006\n",
            "[124]\tvalid_0's binary_logloss: 0.406011\n",
            "[125]\tvalid_0's binary_logloss: 0.405827\n",
            "[126]\tvalid_0's binary_logloss: 0.406088\n",
            "[127]\tvalid_0's binary_logloss: 0.406126\n",
            "[128]\tvalid_0's binary_logloss: 0.405986\n",
            "[129]\tvalid_0's binary_logloss: 0.406393\n",
            "[130]\tvalid_0's binary_logloss: 0.407283\n",
            "[131]\tvalid_0's binary_logloss: 0.407459\n",
            "[132]\tvalid_0's binary_logloss: 0.40722\n",
            "Early stopping, best iteration is:\n",
            "[122]\tvalid_0's binary_logloss: 0.405801\n",
            "[1]\tvalid_0's binary_logloss: 0.675566\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's binary_logloss: 0.659984\n",
            "[3]\tvalid_0's binary_logloss: 0.646202\n",
            "[4]\tvalid_0's binary_logloss: 0.633239\n",
            "[5]\tvalid_0's binary_logloss: 0.622806\n",
            "[6]\tvalid_0's binary_logloss: 0.612717\n",
            "[7]\tvalid_0's binary_logloss: 0.603683\n",
            "[8]\tvalid_0's binary_logloss: 0.593578\n",
            "[9]\tvalid_0's binary_logloss: 0.586047\n",
            "[10]\tvalid_0's binary_logloss: 0.578248\n",
            "[11]\tvalid_0's binary_logloss: 0.570093\n",
            "[12]\tvalid_0's binary_logloss: 0.563547\n",
            "[13]\tvalid_0's binary_logloss: 0.556487\n",
            "[14]\tvalid_0's binary_logloss: 0.550358\n",
            "[15]\tvalid_0's binary_logloss: 0.544734\n",
            "[16]\tvalid_0's binary_logloss: 0.538405\n",
            "[17]\tvalid_0's binary_logloss: 0.532794\n",
            "[18]\tvalid_0's binary_logloss: 0.527886\n",
            "[19]\tvalid_0's binary_logloss: 0.523787\n",
            "[20]\tvalid_0's binary_logloss: 0.519571\n",
            "[21]\tvalid_0's binary_logloss: 0.516154\n",
            "[22]\tvalid_0's binary_logloss: 0.513345\n",
            "[23]\tvalid_0's binary_logloss: 0.510044\n",
            "[24]\tvalid_0's binary_logloss: 0.507664\n",
            "[25]\tvalid_0's binary_logloss: 0.50305\n",
            "[26]\tvalid_0's binary_logloss: 0.500834\n",
            "[27]\tvalid_0's binary_logloss: 0.498534\n",
            "[28]\tvalid_0's binary_logloss: 0.495425\n",
            "[29]\tvalid_0's binary_logloss: 0.493439\n",
            "[30]\tvalid_0's binary_logloss: 0.492171\n",
            "[31]\tvalid_0's binary_logloss: 0.490839\n",
            "[32]\tvalid_0's binary_logloss: 0.489621\n",
            "[33]\tvalid_0's binary_logloss: 0.488376\n",
            "[34]\tvalid_0's binary_logloss: 0.486533\n",
            "[35]\tvalid_0's binary_logloss: 0.484996\n",
            "[36]\tvalid_0's binary_logloss: 0.48278\n",
            "[37]\tvalid_0's binary_logloss: 0.481676\n",
            "[38]\tvalid_0's binary_logloss: 0.480891\n",
            "[39]\tvalid_0's binary_logloss: 0.480142\n",
            "[40]\tvalid_0's binary_logloss: 0.478803\n",
            "[41]\tvalid_0's binary_logloss: 0.477523\n",
            "[42]\tvalid_0's binary_logloss: 0.475918\n",
            "[43]\tvalid_0's binary_logloss: 0.47442\n",
            "[44]\tvalid_0's binary_logloss: 0.472071\n",
            "[45]\tvalid_0's binary_logloss: 0.470853\n",
            "[46]\tvalid_0's binary_logloss: 0.469515\n",
            "[47]\tvalid_0's binary_logloss: 0.467718\n",
            "[48]\tvalid_0's binary_logloss: 0.46713\n",
            "[49]\tvalid_0's binary_logloss: 0.466263\n",
            "[50]\tvalid_0's binary_logloss: 0.465601\n",
            "[51]\tvalid_0's binary_logloss: 0.46473\n",
            "[52]\tvalid_0's binary_logloss: 0.464546\n",
            "[53]\tvalid_0's binary_logloss: 0.463749\n",
            "[54]\tvalid_0's binary_logloss: 0.462171\n",
            "[55]\tvalid_0's binary_logloss: 0.46169\n",
            "[56]\tvalid_0's binary_logloss: 0.460614\n",
            "[57]\tvalid_0's binary_logloss: 0.459471\n",
            "[58]\tvalid_0's binary_logloss: 0.458101\n",
            "[59]\tvalid_0's binary_logloss: 0.457815\n",
            "[60]\tvalid_0's binary_logloss: 0.457667\n",
            "[61]\tvalid_0's binary_logloss: 0.456622\n",
            "[62]\tvalid_0's binary_logloss: 0.456499\n",
            "[63]\tvalid_0's binary_logloss: 0.455237\n",
            "[64]\tvalid_0's binary_logloss: 0.454845\n",
            "[65]\tvalid_0's binary_logloss: 0.455049\n",
            "[66]\tvalid_0's binary_logloss: 0.454194\n",
            "[67]\tvalid_0's binary_logloss: 0.453027\n",
            "[68]\tvalid_0's binary_logloss: 0.452867\n",
            "[69]\tvalid_0's binary_logloss: 0.452509\n",
            "[70]\tvalid_0's binary_logloss: 0.451185\n",
            "[71]\tvalid_0's binary_logloss: 0.45149\n",
            "[72]\tvalid_0's binary_logloss: 0.451424\n",
            "[73]\tvalid_0's binary_logloss: 0.451415\n",
            "[74]\tvalid_0's binary_logloss: 0.450165\n",
            "[75]\tvalid_0's binary_logloss: 0.451123\n",
            "[76]\tvalid_0's binary_logloss: 0.449971\n",
            "[77]\tvalid_0's binary_logloss: 0.449709\n",
            "[78]\tvalid_0's binary_logloss: 0.448655\n",
            "[79]\tvalid_0's binary_logloss: 0.448141\n",
            "[80]\tvalid_0's binary_logloss: 0.448165\n",
            "[81]\tvalid_0's binary_logloss: 0.449097\n",
            "[82]\tvalid_0's binary_logloss: 0.448748\n",
            "[83]\tvalid_0's binary_logloss: 0.448761\n",
            "[84]\tvalid_0's binary_logloss: 0.44876\n",
            "[85]\tvalid_0's binary_logloss: 0.448707\n",
            "[86]\tvalid_0's binary_logloss: 0.449613\n",
            "[87]\tvalid_0's binary_logloss: 0.449159\n",
            "[88]\tvalid_0's binary_logloss: 0.448911\n",
            "[89]\tvalid_0's binary_logloss: 0.448981\n",
            "Early stopping, best iteration is:\n",
            "[79]\tvalid_0's binary_logloss: 0.448141\n",
            "[1]\tvalid_0's binary_logloss: 0.675151\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's binary_logloss: 0.657032\n",
            "[3]\tvalid_0's binary_logloss: 0.642961\n",
            "[4]\tvalid_0's binary_logloss: 0.629162\n",
            "[5]\tvalid_0's binary_logloss: 0.617572\n",
            "[6]\tvalid_0's binary_logloss: 0.606462\n",
            "[7]\tvalid_0's binary_logloss: 0.595251\n",
            "[8]\tvalid_0's binary_logloss: 0.585396\n",
            "[9]\tvalid_0's binary_logloss: 0.576634\n",
            "[10]\tvalid_0's binary_logloss: 0.568767\n",
            "[11]\tvalid_0's binary_logloss: 0.561058\n",
            "[12]\tvalid_0's binary_logloss: 0.554454\n",
            "[13]\tvalid_0's binary_logloss: 0.547223\n",
            "[14]\tvalid_0's binary_logloss: 0.540162\n",
            "[15]\tvalid_0's binary_logloss: 0.534471\n",
            "[16]\tvalid_0's binary_logloss: 0.528617\n",
            "[17]\tvalid_0's binary_logloss: 0.522732\n",
            "[18]\tvalid_0's binary_logloss: 0.51697\n",
            "[19]\tvalid_0's binary_logloss: 0.512096\n",
            "[20]\tvalid_0's binary_logloss: 0.507756\n",
            "[21]\tvalid_0's binary_logloss: 0.502517\n",
            "[22]\tvalid_0's binary_logloss: 0.498644\n",
            "[23]\tvalid_0's binary_logloss: 0.493933\n",
            "[24]\tvalid_0's binary_logloss: 0.490252\n",
            "[25]\tvalid_0's binary_logloss: 0.485462\n",
            "[26]\tvalid_0's binary_logloss: 0.481742\n",
            "[27]\tvalid_0's binary_logloss: 0.478041\n",
            "[28]\tvalid_0's binary_logloss: 0.475082\n",
            "[29]\tvalid_0's binary_logloss: 0.471616\n",
            "[30]\tvalid_0's binary_logloss: 0.469754\n",
            "[31]\tvalid_0's binary_logloss: 0.466614\n",
            "[32]\tvalid_0's binary_logloss: 0.465089\n",
            "[33]\tvalid_0's binary_logloss: 0.461921\n",
            "[34]\tvalid_0's binary_logloss: 0.459629\n",
            "[35]\tvalid_0's binary_logloss: 0.457612\n",
            "[36]\tvalid_0's binary_logloss: 0.455174\n",
            "[37]\tvalid_0's binary_logloss: 0.452642\n",
            "[38]\tvalid_0's binary_logloss: 0.45107\n",
            "[39]\tvalid_0's binary_logloss: 0.449906\n",
            "[40]\tvalid_0's binary_logloss: 0.448026\n",
            "[41]\tvalid_0's binary_logloss: 0.446275\n",
            "[42]\tvalid_0's binary_logloss: 0.444648\n",
            "[43]\tvalid_0's binary_logloss: 0.442954\n",
            "[44]\tvalid_0's binary_logloss: 0.44117\n",
            "[45]\tvalid_0's binary_logloss: 0.439329\n",
            "[46]\tvalid_0's binary_logloss: 0.438326\n",
            "[47]\tvalid_0's binary_logloss: 0.436866\n",
            "[48]\tvalid_0's binary_logloss: 0.435204\n",
            "[49]\tvalid_0's binary_logloss: 0.433819\n",
            "[50]\tvalid_0's binary_logloss: 0.431801\n",
            "[51]\tvalid_0's binary_logloss: 0.430824\n",
            "[52]\tvalid_0's binary_logloss: 0.428927\n",
            "[53]\tvalid_0's binary_logloss: 0.42797\n",
            "[54]\tvalid_0's binary_logloss: 0.426368\n",
            "[55]\tvalid_0's binary_logloss: 0.425026\n",
            "[56]\tvalid_0's binary_logloss: 0.423457\n",
            "[57]\tvalid_0's binary_logloss: 0.423339\n",
            "[58]\tvalid_0's binary_logloss: 0.422754\n",
            "[59]\tvalid_0's binary_logloss: 0.422452\n",
            "[60]\tvalid_0's binary_logloss: 0.423246\n",
            "[61]\tvalid_0's binary_logloss: 0.422401\n",
            "[62]\tvalid_0's binary_logloss: 0.420433\n",
            "[63]\tvalid_0's binary_logloss: 0.419301\n",
            "[64]\tvalid_0's binary_logloss: 0.418585\n",
            "[65]\tvalid_0's binary_logloss: 0.416905\n",
            "[66]\tvalid_0's binary_logloss: 0.414638\n",
            "[67]\tvalid_0's binary_logloss: 0.413668\n",
            "[68]\tvalid_0's binary_logloss: 0.413079\n",
            "[69]\tvalid_0's binary_logloss: 0.412363\n",
            "[70]\tvalid_0's binary_logloss: 0.411715\n",
            "[71]\tvalid_0's binary_logloss: 0.41019\n",
            "[72]\tvalid_0's binary_logloss: 0.410256\n",
            "[73]\tvalid_0's binary_logloss: 0.409047\n",
            "[74]\tvalid_0's binary_logloss: 0.408348\n",
            "[75]\tvalid_0's binary_logloss: 0.407434\n",
            "[76]\tvalid_0's binary_logloss: 0.407277\n",
            "[77]\tvalid_0's binary_logloss: 0.406804\n",
            "[78]\tvalid_0's binary_logloss: 0.406055\n",
            "[79]\tvalid_0's binary_logloss: 0.405815\n",
            "[80]\tvalid_0's binary_logloss: 0.406151\n",
            "[81]\tvalid_0's binary_logloss: 0.405513\n",
            "[82]\tvalid_0's binary_logloss: 0.405619\n",
            "[83]\tvalid_0's binary_logloss: 0.405353\n",
            "[84]\tvalid_0's binary_logloss: 0.40529\n",
            "[85]\tvalid_0's binary_logloss: 0.40426\n",
            "[86]\tvalid_0's binary_logloss: 0.404596\n",
            "[87]\tvalid_0's binary_logloss: 0.404822\n",
            "[88]\tvalid_0's binary_logloss: 0.404418\n",
            "[89]\tvalid_0's binary_logloss: 0.403774\n",
            "[90]\tvalid_0's binary_logloss: 0.404519\n",
            "[91]\tvalid_0's binary_logloss: 0.404227\n",
            "[92]\tvalid_0's binary_logloss: 0.403647\n",
            "[93]\tvalid_0's binary_logloss: 0.403464\n",
            "[94]\tvalid_0's binary_logloss: 0.403278\n",
            "[95]\tvalid_0's binary_logloss: 0.403152\n",
            "[96]\tvalid_0's binary_logloss: 0.403792\n",
            "[97]\tvalid_0's binary_logloss: 0.404055\n",
            "[98]\tvalid_0's binary_logloss: 0.404187\n",
            "[99]\tvalid_0's binary_logloss: 0.402582\n",
            "[100]\tvalid_0's binary_logloss: 0.402031\n",
            "[101]\tvalid_0's binary_logloss: 0.402491\n",
            "[102]\tvalid_0's binary_logloss: 0.401761\n",
            "[103]\tvalid_0's binary_logloss: 0.402238\n",
            "[104]\tvalid_0's binary_logloss: 0.401824\n",
            "[105]\tvalid_0's binary_logloss: 0.40215\n",
            "[106]\tvalid_0's binary_logloss: 0.402741\n",
            "[107]\tvalid_0's binary_logloss: 0.40338\n",
            "[108]\tvalid_0's binary_logloss: 0.402889\n",
            "[109]\tvalid_0's binary_logloss: 0.402643\n",
            "[110]\tvalid_0's binary_logloss: 0.40298\n",
            "[111]\tvalid_0's binary_logloss: 0.402944\n",
            "[112]\tvalid_0's binary_logloss: 0.403391\n",
            "Early stopping, best iteration is:\n",
            "[102]\tvalid_0's binary_logloss: 0.401761\n",
            "[1]\tvalid_0's binary_logloss: 0.675496\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's binary_logloss: 0.660159\n",
            "[3]\tvalid_0's binary_logloss: 0.646445\n",
            "[4]\tvalid_0's binary_logloss: 0.633963\n",
            "[5]\tvalid_0's binary_logloss: 0.621628\n",
            "[6]\tvalid_0's binary_logloss: 0.610201\n",
            "[7]\tvalid_0's binary_logloss: 0.600784\n",
            "[8]\tvalid_0's binary_logloss: 0.59122\n",
            "[9]\tvalid_0's binary_logloss: 0.581936\n",
            "[10]\tvalid_0's binary_logloss: 0.574796\n",
            "[11]\tvalid_0's binary_logloss: 0.567504\n",
            "[12]\tvalid_0's binary_logloss: 0.561242\n",
            "[13]\tvalid_0's binary_logloss: 0.554532\n",
            "[14]\tvalid_0's binary_logloss: 0.548588\n",
            "[15]\tvalid_0's binary_logloss: 0.544277\n",
            "[16]\tvalid_0's binary_logloss: 0.538628\n",
            "[17]\tvalid_0's binary_logloss: 0.53334\n",
            "[18]\tvalid_0's binary_logloss: 0.52966\n",
            "[19]\tvalid_0's binary_logloss: 0.524776\n",
            "[20]\tvalid_0's binary_logloss: 0.520673\n",
            "[21]\tvalid_0's binary_logloss: 0.515861\n",
            "[22]\tvalid_0's binary_logloss: 0.51302\n",
            "[23]\tvalid_0's binary_logloss: 0.509626\n",
            "[24]\tvalid_0's binary_logloss: 0.506158\n",
            "[25]\tvalid_0's binary_logloss: 0.502642\n",
            "[26]\tvalid_0's binary_logloss: 0.499935\n",
            "[27]\tvalid_0's binary_logloss: 0.497216\n",
            "[28]\tvalid_0's binary_logloss: 0.49399\n",
            "[29]\tvalid_0's binary_logloss: 0.491066\n",
            "[30]\tvalid_0's binary_logloss: 0.488413\n",
            "[31]\tvalid_0's binary_logloss: 0.486803\n",
            "[32]\tvalid_0's binary_logloss: 0.484673\n",
            "[33]\tvalid_0's binary_logloss: 0.482145\n",
            "[34]\tvalid_0's binary_logloss: 0.480599\n",
            "[35]\tvalid_0's binary_logloss: 0.478399\n",
            "[36]\tvalid_0's binary_logloss: 0.476324\n",
            "[37]\tvalid_0's binary_logloss: 0.473717\n",
            "[38]\tvalid_0's binary_logloss: 0.47103\n",
            "[39]\tvalid_0's binary_logloss: 0.468843\n",
            "[40]\tvalid_0's binary_logloss: 0.466298\n",
            "[41]\tvalid_0's binary_logloss: 0.464072\n",
            "[42]\tvalid_0's binary_logloss: 0.46169\n",
            "[43]\tvalid_0's binary_logloss: 0.459597\n",
            "[44]\tvalid_0's binary_logloss: 0.458975\n",
            "[45]\tvalid_0's binary_logloss: 0.456463\n",
            "[46]\tvalid_0's binary_logloss: 0.454851\n",
            "[47]\tvalid_0's binary_logloss: 0.454452\n",
            "[48]\tvalid_0's binary_logloss: 0.452403\n",
            "[49]\tvalid_0's binary_logloss: 0.450556\n",
            "[50]\tvalid_0's binary_logloss: 0.449573\n",
            "[51]\tvalid_0's binary_logloss: 0.447594\n",
            "[52]\tvalid_0's binary_logloss: 0.445616\n",
            "[53]\tvalid_0's binary_logloss: 0.444315\n",
            "[54]\tvalid_0's binary_logloss: 0.442491\n",
            "[55]\tvalid_0's binary_logloss: 0.441775\n",
            "[56]\tvalid_0's binary_logloss: 0.441198\n",
            "[57]\tvalid_0's binary_logloss: 0.439619\n",
            "[58]\tvalid_0's binary_logloss: 0.437826\n",
            "[59]\tvalid_0's binary_logloss: 0.436734\n",
            "[60]\tvalid_0's binary_logloss: 0.435796\n",
            "[61]\tvalid_0's binary_logloss: 0.435324\n",
            "[62]\tvalid_0's binary_logloss: 0.43462\n",
            "[63]\tvalid_0's binary_logloss: 0.434425\n",
            "[64]\tvalid_0's binary_logloss: 0.432525\n",
            "[65]\tvalid_0's binary_logloss: 0.431866\n",
            "[66]\tvalid_0's binary_logloss: 0.431736\n",
            "[67]\tvalid_0's binary_logloss: 0.430152\n",
            "[68]\tvalid_0's binary_logloss: 0.429374\n",
            "[69]\tvalid_0's binary_logloss: 0.428208\n",
            "[70]\tvalid_0's binary_logloss: 0.428108\n",
            "[71]\tvalid_0's binary_logloss: 0.427931\n",
            "[72]\tvalid_0's binary_logloss: 0.426016\n",
            "[73]\tvalid_0's binary_logloss: 0.424199\n",
            "[74]\tvalid_0's binary_logloss: 0.423136\n",
            "[75]\tvalid_0's binary_logloss: 0.422412\n",
            "[76]\tvalid_0's binary_logloss: 0.422484\n",
            "[77]\tvalid_0's binary_logloss: 0.421772\n",
            "[78]\tvalid_0's binary_logloss: 0.420689\n",
            "[79]\tvalid_0's binary_logloss: 0.419075\n",
            "[80]\tvalid_0's binary_logloss: 0.418853\n",
            "[81]\tvalid_0's binary_logloss: 0.417431\n",
            "[82]\tvalid_0's binary_logloss: 0.41606\n",
            "[83]\tvalid_0's binary_logloss: 0.415643\n",
            "[84]\tvalid_0's binary_logloss: 0.415285\n",
            "[85]\tvalid_0's binary_logloss: 0.414131\n",
            "[86]\tvalid_0's binary_logloss: 0.414173\n",
            "[87]\tvalid_0's binary_logloss: 0.413046\n",
            "[88]\tvalid_0's binary_logloss: 0.412306\n",
            "[89]\tvalid_0's binary_logloss: 0.411646\n",
            "[90]\tvalid_0's binary_logloss: 0.41135\n",
            "[91]\tvalid_0's binary_logloss: 0.410418\n",
            "[92]\tvalid_0's binary_logloss: 0.410219\n",
            "[93]\tvalid_0's binary_logloss: 0.409124\n",
            "[94]\tvalid_0's binary_logloss: 0.408563\n",
            "[95]\tvalid_0's binary_logloss: 0.409018\n",
            "[96]\tvalid_0's binary_logloss: 0.408099\n",
            "[97]\tvalid_0's binary_logloss: 0.407741\n",
            "[98]\tvalid_0's binary_logloss: 0.407781\n",
            "[99]\tvalid_0's binary_logloss: 0.407633\n",
            "[100]\tvalid_0's binary_logloss: 0.407418\n",
            "[101]\tvalid_0's binary_logloss: 0.406895\n",
            "[102]\tvalid_0's binary_logloss: 0.406754\n",
            "[103]\tvalid_0's binary_logloss: 0.40669\n",
            "[104]\tvalid_0's binary_logloss: 0.406678\n",
            "[105]\tvalid_0's binary_logloss: 0.406266\n",
            "[106]\tvalid_0's binary_logloss: 0.405407\n",
            "[107]\tvalid_0's binary_logloss: 0.404367\n",
            "[108]\tvalid_0's binary_logloss: 0.404665\n",
            "[109]\tvalid_0's binary_logloss: 0.404289\n",
            "[110]\tvalid_0's binary_logloss: 0.404629\n",
            "[111]\tvalid_0's binary_logloss: 0.404071\n",
            "[112]\tvalid_0's binary_logloss: 0.403977\n",
            "[113]\tvalid_0's binary_logloss: 0.403897\n",
            "[114]\tvalid_0's binary_logloss: 0.404004\n",
            "[115]\tvalid_0's binary_logloss: 0.404052\n",
            "[116]\tvalid_0's binary_logloss: 0.403796\n",
            "[117]\tvalid_0's binary_logloss: 0.403989\n",
            "[118]\tvalid_0's binary_logloss: 0.40377\n",
            "[119]\tvalid_0's binary_logloss: 0.402732\n",
            "[120]\tvalid_0's binary_logloss: 0.403644\n",
            "[121]\tvalid_0's binary_logloss: 0.402991\n",
            "[122]\tvalid_0's binary_logloss: 0.402098\n",
            "[123]\tvalid_0's binary_logloss: 0.403199\n",
            "[124]\tvalid_0's binary_logloss: 0.40291\n",
            "[125]\tvalid_0's binary_logloss: 0.402273\n",
            "[126]\tvalid_0's binary_logloss: 0.401881\n",
            "[127]\tvalid_0's binary_logloss: 0.401433\n",
            "[128]\tvalid_0's binary_logloss: 0.40088\n",
            "[129]\tvalid_0's binary_logloss: 0.401805\n",
            "[130]\tvalid_0's binary_logloss: 0.402645\n",
            "[131]\tvalid_0's binary_logloss: 0.402056\n",
            "[132]\tvalid_0's binary_logloss: 0.401535\n",
            "[133]\tvalid_0's binary_logloss: 0.401721\n",
            "[134]\tvalid_0's binary_logloss: 0.40188\n",
            "[135]\tvalid_0's binary_logloss: 0.401712\n",
            "[136]\tvalid_0's binary_logloss: 0.401333\n",
            "[137]\tvalid_0's binary_logloss: 0.401183\n",
            "[138]\tvalid_0's binary_logloss: 0.400452\n",
            "[139]\tvalid_0's binary_logloss: 0.400918\n",
            "[140]\tvalid_0's binary_logloss: 0.400772\n",
            "[141]\tvalid_0's binary_logloss: 0.400771\n",
            "[142]\tvalid_0's binary_logloss: 0.400699\n",
            "[143]\tvalid_0's binary_logloss: 0.401157\n",
            "[144]\tvalid_0's binary_logloss: 0.401481\n",
            "[145]\tvalid_0's binary_logloss: 0.401607\n",
            "[146]\tvalid_0's binary_logloss: 0.402423\n",
            "[147]\tvalid_0's binary_logloss: 0.402319\n",
            "[148]\tvalid_0's binary_logloss: 0.402225\n",
            "Early stopping, best iteration is:\n",
            "[138]\tvalid_0's binary_logloss: 0.400452\n",
            "[1]\tvalid_0's binary_logloss: 0.675738\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's binary_logloss: 0.659608\n",
            "[3]\tvalid_0's binary_logloss: 0.645362\n",
            "[4]\tvalid_0's binary_logloss: 0.631515\n",
            "[5]\tvalid_0's binary_logloss: 0.619981\n",
            "[6]\tvalid_0's binary_logloss: 0.608785\n",
            "[7]\tvalid_0's binary_logloss: 0.598241\n",
            "[8]\tvalid_0's binary_logloss: 0.588256\n",
            "[9]\tvalid_0's binary_logloss: 0.579463\n",
            "[10]\tvalid_0's binary_logloss: 0.571193\n",
            "[11]\tvalid_0's binary_logloss: 0.564156\n",
            "[12]\tvalid_0's binary_logloss: 0.556229\n",
            "[13]\tvalid_0's binary_logloss: 0.550095\n",
            "[14]\tvalid_0's binary_logloss: 0.54384\n",
            "[15]\tvalid_0's binary_logloss: 0.537177\n",
            "[16]\tvalid_0's binary_logloss: 0.530881\n",
            "[17]\tvalid_0's binary_logloss: 0.525387\n",
            "[18]\tvalid_0's binary_logloss: 0.520555\n",
            "[19]\tvalid_0's binary_logloss: 0.516169\n",
            "[20]\tvalid_0's binary_logloss: 0.511871\n",
            "[21]\tvalid_0's binary_logloss: 0.507749\n",
            "[22]\tvalid_0's binary_logloss: 0.503581\n",
            "[23]\tvalid_0's binary_logloss: 0.499807\n",
            "[24]\tvalid_0's binary_logloss: 0.495788\n",
            "[25]\tvalid_0's binary_logloss: 0.491601\n",
            "[26]\tvalid_0's binary_logloss: 0.487773\n",
            "[27]\tvalid_0's binary_logloss: 0.484937\n",
            "[28]\tvalid_0's binary_logloss: 0.481634\n",
            "[29]\tvalid_0's binary_logloss: 0.478836\n",
            "[30]\tvalid_0's binary_logloss: 0.475467\n",
            "[31]\tvalid_0's binary_logloss: 0.47309\n",
            "[32]\tvalid_0's binary_logloss: 0.470753\n",
            "[33]\tvalid_0's binary_logloss: 0.469206\n",
            "[34]\tvalid_0's binary_logloss: 0.467045\n",
            "[35]\tvalid_0's binary_logloss: 0.465116\n",
            "[36]\tvalid_0's binary_logloss: 0.462589\n",
            "[37]\tvalid_0's binary_logloss: 0.460271\n",
            "[38]\tvalid_0's binary_logloss: 0.45747\n",
            "[39]\tvalid_0's binary_logloss: 0.455344\n",
            "[40]\tvalid_0's binary_logloss: 0.454053\n",
            "[41]\tvalid_0's binary_logloss: 0.451762\n",
            "[42]\tvalid_0's binary_logloss: 0.450757\n",
            "[43]\tvalid_0's binary_logloss: 0.449934\n",
            "[44]\tvalid_0's binary_logloss: 0.448506\n",
            "[45]\tvalid_0's binary_logloss: 0.447218\n",
            "[46]\tvalid_0's binary_logloss: 0.445754\n",
            "[47]\tvalid_0's binary_logloss: 0.443477\n",
            "[48]\tvalid_0's binary_logloss: 0.442379\n",
            "[49]\tvalid_0's binary_logloss: 0.441204\n",
            "[50]\tvalid_0's binary_logloss: 0.439324\n",
            "[51]\tvalid_0's binary_logloss: 0.438077\n",
            "[52]\tvalid_0's binary_logloss: 0.437091\n",
            "[53]\tvalid_0's binary_logloss: 0.435283\n",
            "[54]\tvalid_0's binary_logloss: 0.433921\n",
            "[55]\tvalid_0's binary_logloss: 0.433386\n",
            "[56]\tvalid_0's binary_logloss: 0.431919\n",
            "[57]\tvalid_0's binary_logloss: 0.431167\n",
            "[58]\tvalid_0's binary_logloss: 0.429942\n",
            "[59]\tvalid_0's binary_logloss: 0.429157\n",
            "[60]\tvalid_0's binary_logloss: 0.427726\n",
            "[61]\tvalid_0's binary_logloss: 0.426463\n",
            "[62]\tvalid_0's binary_logloss: 0.425078\n",
            "[63]\tvalid_0's binary_logloss: 0.424036\n",
            "[64]\tvalid_0's binary_logloss: 0.423111\n",
            "[65]\tvalid_0's binary_logloss: 0.42214\n",
            "[66]\tvalid_0's binary_logloss: 0.420975\n",
            "[67]\tvalid_0's binary_logloss: 0.420265\n",
            "[68]\tvalid_0's binary_logloss: 0.41896\n",
            "[69]\tvalid_0's binary_logloss: 0.417732\n",
            "[70]\tvalid_0's binary_logloss: 0.417006\n",
            "[71]\tvalid_0's binary_logloss: 0.415649\n",
            "[72]\tvalid_0's binary_logloss: 0.415013\n",
            "[73]\tvalid_0's binary_logloss: 0.414085\n",
            "[74]\tvalid_0's binary_logloss: 0.413469\n",
            "[75]\tvalid_0's binary_logloss: 0.412758\n",
            "[76]\tvalid_0's binary_logloss: 0.41232\n",
            "[77]\tvalid_0's binary_logloss: 0.412381\n",
            "[78]\tvalid_0's binary_logloss: 0.411881\n",
            "[79]\tvalid_0's binary_logloss: 0.411647\n",
            "[80]\tvalid_0's binary_logloss: 0.410322\n",
            "[81]\tvalid_0's binary_logloss: 0.40951\n",
            "[82]\tvalid_0's binary_logloss: 0.409858\n",
            "[83]\tvalid_0's binary_logloss: 0.409468\n",
            "[84]\tvalid_0's binary_logloss: 0.409024\n",
            "[85]\tvalid_0's binary_logloss: 0.408596\n",
            "[86]\tvalid_0's binary_logloss: 0.40816\n",
            "[87]\tvalid_0's binary_logloss: 0.407766\n",
            "[88]\tvalid_0's binary_logloss: 0.40665\n",
            "[89]\tvalid_0's binary_logloss: 0.406412\n",
            "[90]\tvalid_0's binary_logloss: 0.404929\n",
            "[91]\tvalid_0's binary_logloss: 0.404565\n",
            "[92]\tvalid_0's binary_logloss: 0.404028\n",
            "[93]\tvalid_0's binary_logloss: 0.404111\n",
            "[94]\tvalid_0's binary_logloss: 0.403956\n",
            "[95]\tvalid_0's binary_logloss: 0.404053\n",
            "[96]\tvalid_0's binary_logloss: 0.402482\n",
            "[97]\tvalid_0's binary_logloss: 0.401699\n",
            "[98]\tvalid_0's binary_logloss: 0.401881\n",
            "[99]\tvalid_0's binary_logloss: 0.400848\n",
            "[100]\tvalid_0's binary_logloss: 0.400965\n",
            "[101]\tvalid_0's binary_logloss: 0.401008\n",
            "[102]\tvalid_0's binary_logloss: 0.400778\n",
            "[103]\tvalid_0's binary_logloss: 0.400611\n",
            "[104]\tvalid_0's binary_logloss: 0.400221\n",
            "[105]\tvalid_0's binary_logloss: 0.399333\n",
            "[106]\tvalid_0's binary_logloss: 0.398722\n",
            "[107]\tvalid_0's binary_logloss: 0.398117\n",
            "[108]\tvalid_0's binary_logloss: 0.397572\n",
            "[109]\tvalid_0's binary_logloss: 0.398457\n",
            "[110]\tvalid_0's binary_logloss: 0.397508\n",
            "[111]\tvalid_0's binary_logloss: 0.39723\n",
            "[112]\tvalid_0's binary_logloss: 0.39757\n",
            "[113]\tvalid_0's binary_logloss: 0.397838\n",
            "[114]\tvalid_0's binary_logloss: 0.398245\n",
            "[115]\tvalid_0's binary_logloss: 0.398648\n",
            "[116]\tvalid_0's binary_logloss: 0.398376\n",
            "[117]\tvalid_0's binary_logloss: 0.397724\n",
            "[118]\tvalid_0's binary_logloss: 0.397227\n",
            "[119]\tvalid_0's binary_logloss: 0.397503\n",
            "[120]\tvalid_0's binary_logloss: 0.397025\n",
            "[121]\tvalid_0's binary_logloss: 0.398091\n",
            "[122]\tvalid_0's binary_logloss: 0.397935\n",
            "[123]\tvalid_0's binary_logloss: 0.397941\n",
            "[124]\tvalid_0's binary_logloss: 0.398539\n",
            "[125]\tvalid_0's binary_logloss: 0.399141\n",
            "[126]\tvalid_0's binary_logloss: 0.398196\n",
            "[127]\tvalid_0's binary_logloss: 0.39809\n",
            "[128]\tvalid_0's binary_logloss: 0.397997\n",
            "[129]\tvalid_0's binary_logloss: 0.397959\n",
            "[130]\tvalid_0's binary_logloss: 0.397945\n",
            "Early stopping, best iteration is:\n",
            "[120]\tvalid_0's binary_logloss: 0.397025\n",
            "[1]\tvalid_0's binary_logloss: 0.676797\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's binary_logloss: 0.662624\n",
            "[3]\tvalid_0's binary_logloss: 0.649032\n",
            "[4]\tvalid_0's binary_logloss: 0.637269\n",
            "[5]\tvalid_0's binary_logloss: 0.626663\n",
            "[6]\tvalid_0's binary_logloss: 0.615398\n",
            "[7]\tvalid_0's binary_logloss: 0.603866\n",
            "[8]\tvalid_0's binary_logloss: 0.595055\n",
            "[9]\tvalid_0's binary_logloss: 0.58693\n",
            "[10]\tvalid_0's binary_logloss: 0.578775\n",
            "[11]\tvalid_0's binary_logloss: 0.571881\n",
            "[12]\tvalid_0's binary_logloss: 0.563196\n",
            "[13]\tvalid_0's binary_logloss: 0.557055\n",
            "[14]\tvalid_0's binary_logloss: 0.551471\n",
            "[15]\tvalid_0's binary_logloss: 0.545756\n",
            "[16]\tvalid_0's binary_logloss: 0.541491\n",
            "[17]\tvalid_0's binary_logloss: 0.535611\n",
            "[18]\tvalid_0's binary_logloss: 0.530082\n",
            "[19]\tvalid_0's binary_logloss: 0.525593\n",
            "[20]\tvalid_0's binary_logloss: 0.52127\n",
            "[21]\tvalid_0's binary_logloss: 0.516474\n",
            "[22]\tvalid_0's binary_logloss: 0.511915\n",
            "[23]\tvalid_0's binary_logloss: 0.507792\n",
            "[24]\tvalid_0's binary_logloss: 0.503801\n",
            "[25]\tvalid_0's binary_logloss: 0.500631\n",
            "[26]\tvalid_0's binary_logloss: 0.497516\n",
            "[27]\tvalid_0's binary_logloss: 0.49344\n",
            "[28]\tvalid_0's binary_logloss: 0.490456\n",
            "[29]\tvalid_0's binary_logloss: 0.486942\n",
            "[30]\tvalid_0's binary_logloss: 0.483297\n",
            "[31]\tvalid_0's binary_logloss: 0.48137\n",
            "[32]\tvalid_0's binary_logloss: 0.478951\n",
            "[33]\tvalid_0's binary_logloss: 0.476704\n",
            "[34]\tvalid_0's binary_logloss: 0.474676\n",
            "[35]\tvalid_0's binary_logloss: 0.472469\n",
            "[36]\tvalid_0's binary_logloss: 0.470653\n",
            "[37]\tvalid_0's binary_logloss: 0.468123\n",
            "[38]\tvalid_0's binary_logloss: 0.46728\n",
            "[39]\tvalid_0's binary_logloss: 0.465481\n",
            "[40]\tvalid_0's binary_logloss: 0.464471\n",
            "[41]\tvalid_0's binary_logloss: 0.462569\n",
            "[42]\tvalid_0's binary_logloss: 0.461146\n",
            "[43]\tvalid_0's binary_logloss: 0.459899\n",
            "[44]\tvalid_0's binary_logloss: 0.458605\n",
            "[45]\tvalid_0's binary_logloss: 0.456836\n",
            "[46]\tvalid_0's binary_logloss: 0.455857\n",
            "[47]\tvalid_0's binary_logloss: 0.453812\n",
            "[48]\tvalid_0's binary_logloss: 0.452138\n",
            "[49]\tvalid_0's binary_logloss: 0.450622\n",
            "[50]\tvalid_0's binary_logloss: 0.449077\n",
            "[51]\tvalid_0's binary_logloss: 0.447558\n",
            "[52]\tvalid_0's binary_logloss: 0.446629\n",
            "[53]\tvalid_0's binary_logloss: 0.444723\n",
            "[54]\tvalid_0's binary_logloss: 0.443737\n",
            "[55]\tvalid_0's binary_logloss: 0.442268\n",
            "[56]\tvalid_0's binary_logloss: 0.441185\n",
            "[57]\tvalid_0's binary_logloss: 0.440268\n",
            "[58]\tvalid_0's binary_logloss: 0.438889\n",
            "[59]\tvalid_0's binary_logloss: 0.437399\n",
            "[60]\tvalid_0's binary_logloss: 0.435943\n",
            "[61]\tvalid_0's binary_logloss: 0.43509\n",
            "[62]\tvalid_0's binary_logloss: 0.433815\n",
            "[63]\tvalid_0's binary_logloss: 0.43322\n",
            "[64]\tvalid_0's binary_logloss: 0.432266\n",
            "[65]\tvalid_0's binary_logloss: 0.431671\n",
            "[66]\tvalid_0's binary_logloss: 0.431034\n",
            "[67]\tvalid_0's binary_logloss: 0.430472\n",
            "[68]\tvalid_0's binary_logloss: 0.429583\n",
            "[69]\tvalid_0's binary_logloss: 0.429267\n",
            "[70]\tvalid_0's binary_logloss: 0.428751\n",
            "[71]\tvalid_0's binary_logloss: 0.427878\n",
            "[72]\tvalid_0's binary_logloss: 0.427154\n",
            "[73]\tvalid_0's binary_logloss: 0.425762\n",
            "[74]\tvalid_0's binary_logloss: 0.424895\n",
            "[75]\tvalid_0's binary_logloss: 0.424842\n",
            "[76]\tvalid_0's binary_logloss: 0.423956\n",
            "[77]\tvalid_0's binary_logloss: 0.423585\n",
            "[78]\tvalid_0's binary_logloss: 0.422909\n",
            "[79]\tvalid_0's binary_logloss: 0.422019\n",
            "[80]\tvalid_0's binary_logloss: 0.421781\n",
            "[81]\tvalid_0's binary_logloss: 0.4218\n",
            "[82]\tvalid_0's binary_logloss: 0.421237\n",
            "[83]\tvalid_0's binary_logloss: 0.41991\n",
            "[84]\tvalid_0's binary_logloss: 0.419705\n",
            "[85]\tvalid_0's binary_logloss: 0.419168\n",
            "[86]\tvalid_0's binary_logloss: 0.418149\n",
            "[87]\tvalid_0's binary_logloss: 0.417591\n",
            "[88]\tvalid_0's binary_logloss: 0.417561\n",
            "[89]\tvalid_0's binary_logloss: 0.416677\n",
            "[90]\tvalid_0's binary_logloss: 0.4166\n",
            "[91]\tvalid_0's binary_logloss: 0.416193\n",
            "[92]\tvalid_0's binary_logloss: 0.415884\n",
            "[93]\tvalid_0's binary_logloss: 0.416371\n",
            "[94]\tvalid_0's binary_logloss: 0.416462\n",
            "[95]\tvalid_0's binary_logloss: 0.417168\n",
            "[96]\tvalid_0's binary_logloss: 0.416263\n",
            "[97]\tvalid_0's binary_logloss: 0.415844\n",
            "[98]\tvalid_0's binary_logloss: 0.415471\n",
            "[99]\tvalid_0's binary_logloss: 0.415212\n",
            "[100]\tvalid_0's binary_logloss: 0.414425\n",
            "[101]\tvalid_0's binary_logloss: 0.41445\n",
            "[102]\tvalid_0's binary_logloss: 0.413712\n",
            "[103]\tvalid_0's binary_logloss: 0.412556\n",
            "[104]\tvalid_0's binary_logloss: 0.412766\n",
            "[105]\tvalid_0's binary_logloss: 0.412542\n",
            "[106]\tvalid_0's binary_logloss: 0.412434\n",
            "[107]\tvalid_0's binary_logloss: 0.411646\n",
            "[108]\tvalid_0's binary_logloss: 0.410568\n",
            "[109]\tvalid_0's binary_logloss: 0.410754\n",
            "[110]\tvalid_0's binary_logloss: 0.410804\n",
            "[111]\tvalid_0's binary_logloss: 0.410467\n",
            "[112]\tvalid_0's binary_logloss: 0.410563\n",
            "[113]\tvalid_0's binary_logloss: 0.410026\n",
            "[114]\tvalid_0's binary_logloss: 0.410235\n",
            "[115]\tvalid_0's binary_logloss: 0.410195\n",
            "[116]\tvalid_0's binary_logloss: 0.410032\n",
            "[117]\tvalid_0's binary_logloss: 0.408841\n",
            "[118]\tvalid_0's binary_logloss: 0.408472\n",
            "[119]\tvalid_0's binary_logloss: 0.409014\n",
            "[120]\tvalid_0's binary_logloss: 0.40931\n",
            "[121]\tvalid_0's binary_logloss: 0.408986\n",
            "[122]\tvalid_0's binary_logloss: 0.408549\n",
            "[123]\tvalid_0's binary_logloss: 0.408983\n",
            "[124]\tvalid_0's binary_logloss: 0.408699\n",
            "[125]\tvalid_0's binary_logloss: 0.4085\n",
            "[126]\tvalid_0's binary_logloss: 0.408356\n",
            "[127]\tvalid_0's binary_logloss: 0.408885\n",
            "[128]\tvalid_0's binary_logloss: 0.409131\n",
            "[129]\tvalid_0's binary_logloss: 0.408961\n",
            "[130]\tvalid_0's binary_logloss: 0.409118\n",
            "[131]\tvalid_0's binary_logloss: 0.409196\n",
            "[132]\tvalid_0's binary_logloss: 0.408958\n",
            "[133]\tvalid_0's binary_logloss: 0.409392\n",
            "[134]\tvalid_0's binary_logloss: 0.409171\n",
            "[135]\tvalid_0's binary_logloss: 0.409579\n",
            "[136]\tvalid_0's binary_logloss: 0.409687\n",
            "Early stopping, best iteration is:\n",
            "[126]\tvalid_0's binary_logloss: 0.408356\n",
            "[1]\tvalid_0's binary_logloss: 0.674207\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's binary_logloss: 0.657863\n",
            "[3]\tvalid_0's binary_logloss: 0.642931\n",
            "[4]\tvalid_0's binary_logloss: 0.628861\n",
            "[5]\tvalid_0's binary_logloss: 0.616771\n",
            "[6]\tvalid_0's binary_logloss: 0.605726\n",
            "[7]\tvalid_0's binary_logloss: 0.595201\n",
            "[8]\tvalid_0's binary_logloss: 0.585747\n",
            "[9]\tvalid_0's binary_logloss: 0.577737\n",
            "[10]\tvalid_0's binary_logloss: 0.56961\n",
            "[11]\tvalid_0's binary_logloss: 0.562655\n",
            "[12]\tvalid_0's binary_logloss: 0.554886\n",
            "[13]\tvalid_0's binary_logloss: 0.549817\n",
            "[14]\tvalid_0's binary_logloss: 0.543805\n",
            "[15]\tvalid_0's binary_logloss: 0.537859\n",
            "[16]\tvalid_0's binary_logloss: 0.532613\n",
            "[17]\tvalid_0's binary_logloss: 0.527437\n",
            "[18]\tvalid_0's binary_logloss: 0.522612\n",
            "[19]\tvalid_0's binary_logloss: 0.517724\n",
            "[20]\tvalid_0's binary_logloss: 0.514096\n",
            "[21]\tvalid_0's binary_logloss: 0.508429\n",
            "[22]\tvalid_0's binary_logloss: 0.504432\n",
            "[23]\tvalid_0's binary_logloss: 0.50049\n",
            "[24]\tvalid_0's binary_logloss: 0.497701\n",
            "[25]\tvalid_0's binary_logloss: 0.493701\n",
            "[26]\tvalid_0's binary_logloss: 0.490505\n",
            "[27]\tvalid_0's binary_logloss: 0.48714\n",
            "[28]\tvalid_0's binary_logloss: 0.483975\n",
            "[29]\tvalid_0's binary_logloss: 0.481785\n",
            "[30]\tvalid_0's binary_logloss: 0.47907\n",
            "[31]\tvalid_0's binary_logloss: 0.476139\n",
            "[32]\tvalid_0's binary_logloss: 0.474681\n",
            "[33]\tvalid_0's binary_logloss: 0.472003\n",
            "[34]\tvalid_0's binary_logloss: 0.469994\n",
            "[35]\tvalid_0's binary_logloss: 0.467651\n",
            "[36]\tvalid_0's binary_logloss: 0.464768\n",
            "[37]\tvalid_0's binary_logloss: 0.46291\n",
            "[38]\tvalid_0's binary_logloss: 0.461044\n",
            "[39]\tvalid_0's binary_logloss: 0.459034\n",
            "[40]\tvalid_0's binary_logloss: 0.457984\n",
            "[41]\tvalid_0's binary_logloss: 0.456394\n",
            "[42]\tvalid_0's binary_logloss: 0.454019\n",
            "[43]\tvalid_0's binary_logloss: 0.452938\n",
            "[44]\tvalid_0's binary_logloss: 0.451098\n",
            "[45]\tvalid_0's binary_logloss: 0.449312\n",
            "[46]\tvalid_0's binary_logloss: 0.44795\n",
            "[47]\tvalid_0's binary_logloss: 0.445389\n",
            "[48]\tvalid_0's binary_logloss: 0.44314\n",
            "[49]\tvalid_0's binary_logloss: 0.441481\n",
            "[50]\tvalid_0's binary_logloss: 0.439533\n",
            "[51]\tvalid_0's binary_logloss: 0.438525\n",
            "[52]\tvalid_0's binary_logloss: 0.43703\n",
            "[53]\tvalid_0's binary_logloss: 0.435981\n",
            "[54]\tvalid_0's binary_logloss: 0.435326\n",
            "[55]\tvalid_0's binary_logloss: 0.433808\n",
            "[56]\tvalid_0's binary_logloss: 0.433043\n",
            "[57]\tvalid_0's binary_logloss: 0.431139\n",
            "[58]\tvalid_0's binary_logloss: 0.429778\n",
            "[59]\tvalid_0's binary_logloss: 0.428312\n",
            "[60]\tvalid_0's binary_logloss: 0.427669\n",
            "[61]\tvalid_0's binary_logloss: 0.426055\n",
            "[62]\tvalid_0's binary_logloss: 0.425402\n",
            "[63]\tvalid_0's binary_logloss: 0.424998\n",
            "[64]\tvalid_0's binary_logloss: 0.423707\n",
            "[65]\tvalid_0's binary_logloss: 0.423485\n",
            "[66]\tvalid_0's binary_logloss: 0.423898\n",
            "[67]\tvalid_0's binary_logloss: 0.424223\n",
            "[68]\tvalid_0's binary_logloss: 0.423537\n",
            "[69]\tvalid_0's binary_logloss: 0.422611\n",
            "[70]\tvalid_0's binary_logloss: 0.422027\n",
            "[71]\tvalid_0's binary_logloss: 0.421709\n",
            "[72]\tvalid_0's binary_logloss: 0.421965\n",
            "[73]\tvalid_0's binary_logloss: 0.421469\n",
            "[74]\tvalid_0's binary_logloss: 0.420182\n",
            "[75]\tvalid_0's binary_logloss: 0.419445\n",
            "[76]\tvalid_0's binary_logloss: 0.418391\n",
            "[77]\tvalid_0's binary_logloss: 0.417748\n",
            "[78]\tvalid_0's binary_logloss: 0.417251\n",
            "[79]\tvalid_0's binary_logloss: 0.416082\n",
            "[80]\tvalid_0's binary_logloss: 0.414806\n",
            "[81]\tvalid_0's binary_logloss: 0.414861\n",
            "[82]\tvalid_0's binary_logloss: 0.414081\n",
            "[83]\tvalid_0's binary_logloss: 0.412881\n",
            "[84]\tvalid_0's binary_logloss: 0.411973\n",
            "[85]\tvalid_0's binary_logloss: 0.410703\n",
            "[86]\tvalid_0's binary_logloss: 0.410795\n",
            "[87]\tvalid_0's binary_logloss: 0.411118\n",
            "[88]\tvalid_0's binary_logloss: 0.410181\n",
            "[89]\tvalid_0's binary_logloss: 0.409934\n",
            "[90]\tvalid_0's binary_logloss: 0.409953\n",
            "[91]\tvalid_0's binary_logloss: 0.410045\n",
            "[92]\tvalid_0's binary_logloss: 0.409615\n",
            "[93]\tvalid_0's binary_logloss: 0.409887\n",
            "[94]\tvalid_0's binary_logloss: 0.40915\n",
            "[95]\tvalid_0's binary_logloss: 0.408367\n",
            "[96]\tvalid_0's binary_logloss: 0.407156\n",
            "[97]\tvalid_0's binary_logloss: 0.407179\n",
            "[98]\tvalid_0's binary_logloss: 0.406614\n",
            "[99]\tvalid_0's binary_logloss: 0.406177\n",
            "[100]\tvalid_0's binary_logloss: 0.405581\n",
            "[101]\tvalid_0's binary_logloss: 0.405384\n",
            "[102]\tvalid_0's binary_logloss: 0.406104\n",
            "[103]\tvalid_0's binary_logloss: 0.406146\n",
            "[104]\tvalid_0's binary_logloss: 0.40597\n",
            "[105]\tvalid_0's binary_logloss: 0.406056\n",
            "[106]\tvalid_0's binary_logloss: 0.406349\n",
            "[107]\tvalid_0's binary_logloss: 0.405598\n",
            "[108]\tvalid_0's binary_logloss: 0.405608\n",
            "[109]\tvalid_0's binary_logloss: 0.405302\n",
            "[110]\tvalid_0's binary_logloss: 0.405562\n",
            "[111]\tvalid_0's binary_logloss: 0.404733\n",
            "[112]\tvalid_0's binary_logloss: 0.40456\n",
            "[113]\tvalid_0's binary_logloss: 0.40543\n",
            "[114]\tvalid_0's binary_logloss: 0.405307\n",
            "[115]\tvalid_0's binary_logloss: 0.4051\n",
            "[116]\tvalid_0's binary_logloss: 0.404316\n",
            "[117]\tvalid_0's binary_logloss: 0.403998\n",
            "[118]\tvalid_0's binary_logloss: 0.40442\n",
            "[119]\tvalid_0's binary_logloss: 0.404436\n",
            "[120]\tvalid_0's binary_logloss: 0.404202\n",
            "[121]\tvalid_0's binary_logloss: 0.404162\n",
            "[122]\tvalid_0's binary_logloss: 0.404771\n",
            "[123]\tvalid_0's binary_logloss: 0.404901\n",
            "[124]\tvalid_0's binary_logloss: 0.404938\n",
            "[125]\tvalid_0's binary_logloss: 0.405434\n",
            "[126]\tvalid_0's binary_logloss: 0.405526\n",
            "[127]\tvalid_0's binary_logloss: 0.405722\n",
            "Early stopping, best iteration is:\n",
            "[117]\tvalid_0's binary_logloss: 0.403998\n",
            "[1]\tvalid_0's binary_logloss: 0.674408\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's binary_logloss: 0.657288\n",
            "[3]\tvalid_0's binary_logloss: 0.641801\n",
            "[4]\tvalid_0's binary_logloss: 0.628207\n",
            "[5]\tvalid_0's binary_logloss: 0.616437\n",
            "[6]\tvalid_0's binary_logloss: 0.605701\n",
            "[7]\tvalid_0's binary_logloss: 0.595036\n",
            "[8]\tvalid_0's binary_logloss: 0.585368\n",
            "[9]\tvalid_0's binary_logloss: 0.5767\n",
            "[10]\tvalid_0's binary_logloss: 0.568892\n",
            "[11]\tvalid_0's binary_logloss: 0.561536\n",
            "[12]\tvalid_0's binary_logloss: 0.554221\n",
            "[13]\tvalid_0's binary_logloss: 0.546514\n",
            "[14]\tvalid_0's binary_logloss: 0.541139\n",
            "[15]\tvalid_0's binary_logloss: 0.535836\n",
            "[16]\tvalid_0's binary_logloss: 0.530797\n",
            "[17]\tvalid_0's binary_logloss: 0.524931\n",
            "[18]\tvalid_0's binary_logloss: 0.519367\n",
            "[19]\tvalid_0's binary_logloss: 0.514748\n",
            "[20]\tvalid_0's binary_logloss: 0.510981\n",
            "[21]\tvalid_0's binary_logloss: 0.507318\n",
            "[22]\tvalid_0's binary_logloss: 0.502397\n",
            "[23]\tvalid_0's binary_logloss: 0.497904\n",
            "[24]\tvalid_0's binary_logloss: 0.492648\n",
            "[25]\tvalid_0's binary_logloss: 0.489493\n",
            "[26]\tvalid_0's binary_logloss: 0.485865\n",
            "[27]\tvalid_0's binary_logloss: 0.482188\n",
            "[28]\tvalid_0's binary_logloss: 0.47848\n",
            "[29]\tvalid_0's binary_logloss: 0.475696\n",
            "[30]\tvalid_0's binary_logloss: 0.472595\n",
            "[31]\tvalid_0's binary_logloss: 0.469316\n",
            "[32]\tvalid_0's binary_logloss: 0.467575\n",
            "[33]\tvalid_0's binary_logloss: 0.463509\n",
            "[34]\tvalid_0's binary_logloss: 0.460162\n",
            "[35]\tvalid_0's binary_logloss: 0.458336\n",
            "[36]\tvalid_0's binary_logloss: 0.456356\n",
            "[37]\tvalid_0's binary_logloss: 0.453812\n",
            "[38]\tvalid_0's binary_logloss: 0.450988\n",
            "[39]\tvalid_0's binary_logloss: 0.448144\n",
            "[40]\tvalid_0's binary_logloss: 0.446067\n",
            "[41]\tvalid_0's binary_logloss: 0.444406\n",
            "[42]\tvalid_0's binary_logloss: 0.443338\n",
            "[43]\tvalid_0's binary_logloss: 0.441101\n",
            "[44]\tvalid_0's binary_logloss: 0.439037\n",
            "[45]\tvalid_0's binary_logloss: 0.437315\n",
            "[46]\tvalid_0's binary_logloss: 0.434239\n",
            "[47]\tvalid_0's binary_logloss: 0.430752\n",
            "[48]\tvalid_0's binary_logloss: 0.427553\n",
            "[49]\tvalid_0's binary_logloss: 0.426376\n",
            "[50]\tvalid_0's binary_logloss: 0.424599\n",
            "[51]\tvalid_0's binary_logloss: 0.422271\n",
            "[52]\tvalid_0's binary_logloss: 0.420829\n",
            "[53]\tvalid_0's binary_logloss: 0.419654\n",
            "[54]\tvalid_0's binary_logloss: 0.419024\n",
            "[55]\tvalid_0's binary_logloss: 0.417206\n",
            "[56]\tvalid_0's binary_logloss: 0.415021\n",
            "[57]\tvalid_0's binary_logloss: 0.413975\n",
            "[58]\tvalid_0's binary_logloss: 0.413442\n",
            "[59]\tvalid_0's binary_logloss: 0.412537\n",
            "[60]\tvalid_0's binary_logloss: 0.40968\n",
            "[61]\tvalid_0's binary_logloss: 0.407462\n",
            "[62]\tvalid_0's binary_logloss: 0.406498\n",
            "[63]\tvalid_0's binary_logloss: 0.403721\n",
            "[64]\tvalid_0's binary_logloss: 0.40333\n",
            "[65]\tvalid_0's binary_logloss: 0.403217\n",
            "[66]\tvalid_0's binary_logloss: 0.402343\n",
            "[67]\tvalid_0's binary_logloss: 0.401454\n",
            "[68]\tvalid_0's binary_logloss: 0.400832\n",
            "[69]\tvalid_0's binary_logloss: 0.399684\n",
            "[70]\tvalid_0's binary_logloss: 0.39827\n",
            "[71]\tvalid_0's binary_logloss: 0.397987\n",
            "[72]\tvalid_0's binary_logloss: 0.396981\n",
            "[73]\tvalid_0's binary_logloss: 0.395424\n",
            "[74]\tvalid_0's binary_logloss: 0.394647\n",
            "[75]\tvalid_0's binary_logloss: 0.393877\n",
            "[76]\tvalid_0's binary_logloss: 0.393198\n",
            "[77]\tvalid_0's binary_logloss: 0.392284\n",
            "[78]\tvalid_0's binary_logloss: 0.39154\n",
            "[79]\tvalid_0's binary_logloss: 0.389975\n",
            "[80]\tvalid_0's binary_logloss: 0.389451\n",
            "[81]\tvalid_0's binary_logloss: 0.388537\n",
            "[82]\tvalid_0's binary_logloss: 0.387526\n",
            "[83]\tvalid_0's binary_logloss: 0.38659\n",
            "[84]\tvalid_0's binary_logloss: 0.38637\n",
            "[85]\tvalid_0's binary_logloss: 0.385894\n",
            "[86]\tvalid_0's binary_logloss: 0.385454\n",
            "[87]\tvalid_0's binary_logloss: 0.384495\n",
            "[88]\tvalid_0's binary_logloss: 0.382931\n",
            "[89]\tvalid_0's binary_logloss: 0.383164\n",
            "[90]\tvalid_0's binary_logloss: 0.383051\n",
            "[91]\tvalid_0's binary_logloss: 0.383423\n",
            "[92]\tvalid_0's binary_logloss: 0.382827\n",
            "[93]\tvalid_0's binary_logloss: 0.382856\n",
            "[94]\tvalid_0's binary_logloss: 0.382395\n",
            "[95]\tvalid_0's binary_logloss: 0.3819\n",
            "[96]\tvalid_0's binary_logloss: 0.382195\n",
            "[97]\tvalid_0's binary_logloss: 0.38183\n",
            "[98]\tvalid_0's binary_logloss: 0.382043\n",
            "[99]\tvalid_0's binary_logloss: 0.381109\n",
            "[100]\tvalid_0's binary_logloss: 0.380863\n",
            "[101]\tvalid_0's binary_logloss: 0.380885\n",
            "[102]\tvalid_0's binary_logloss: 0.380811\n",
            "[103]\tvalid_0's binary_logloss: 0.380299\n",
            "[104]\tvalid_0's binary_logloss: 0.380041\n",
            "[105]\tvalid_0's binary_logloss: 0.379546\n",
            "[106]\tvalid_0's binary_logloss: 0.379124\n",
            "[107]\tvalid_0's binary_logloss: 0.378988\n",
            "[108]\tvalid_0's binary_logloss: 0.378601\n",
            "[109]\tvalid_0's binary_logloss: 0.378\n",
            "[110]\tvalid_0's binary_logloss: 0.378337\n",
            "[111]\tvalid_0's binary_logloss: 0.378181\n",
            "[112]\tvalid_0's binary_logloss: 0.377892\n",
            "[113]\tvalid_0's binary_logloss: 0.377665\n",
            "[114]\tvalid_0's binary_logloss: 0.377655\n",
            "[115]\tvalid_0's binary_logloss: 0.377164\n",
            "[116]\tvalid_0's binary_logloss: 0.376914\n",
            "[117]\tvalid_0's binary_logloss: 0.376727\n",
            "[118]\tvalid_0's binary_logloss: 0.376885\n",
            "[119]\tvalid_0's binary_logloss: 0.377659\n",
            "[120]\tvalid_0's binary_logloss: 0.377802\n",
            "[121]\tvalid_0's binary_logloss: 0.377354\n",
            "[122]\tvalid_0's binary_logloss: 0.37719\n",
            "[123]\tvalid_0's binary_logloss: 0.376276\n",
            "[124]\tvalid_0's binary_logloss: 0.375614\n",
            "[125]\tvalid_0's binary_logloss: 0.376058\n",
            "[126]\tvalid_0's binary_logloss: 0.376126\n",
            "[127]\tvalid_0's binary_logloss: 0.375547\n",
            "[128]\tvalid_0's binary_logloss: 0.376074\n",
            "[129]\tvalid_0's binary_logloss: 0.375743\n",
            "[130]\tvalid_0's binary_logloss: 0.37658\n",
            "[131]\tvalid_0's binary_logloss: 0.376493\n",
            "[132]\tvalid_0's binary_logloss: 0.376861\n",
            "[133]\tvalid_0's binary_logloss: 0.376985\n",
            "[134]\tvalid_0's binary_logloss: 0.376594\n",
            "[135]\tvalid_0's binary_logloss: 0.376231\n",
            "[136]\tvalid_0's binary_logloss: 0.376298\n",
            "[137]\tvalid_0's binary_logloss: 0.376842\n",
            "Early stopping, best iteration is:\n",
            "[127]\tvalid_0's binary_logloss: 0.375547\n",
            "[1]\tvalid_0's binary_logloss: 0.676592\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's binary_logloss: 0.661568\n",
            "[3]\tvalid_0's binary_logloss: 0.648082\n",
            "[4]\tvalid_0's binary_logloss: 0.634818\n",
            "[5]\tvalid_0's binary_logloss: 0.623116\n",
            "[6]\tvalid_0's binary_logloss: 0.612358\n",
            "[7]\tvalid_0's binary_logloss: 0.601022\n",
            "[8]\tvalid_0's binary_logloss: 0.59075\n",
            "[9]\tvalid_0's binary_logloss: 0.582167\n",
            "[10]\tvalid_0's binary_logloss: 0.573699\n",
            "[11]\tvalid_0's binary_logloss: 0.565943\n",
            "[12]\tvalid_0's binary_logloss: 0.558275\n",
            "[13]\tvalid_0's binary_logloss: 0.551644\n",
            "[14]\tvalid_0's binary_logloss: 0.546273\n",
            "[15]\tvalid_0's binary_logloss: 0.540446\n",
            "[16]\tvalid_0's binary_logloss: 0.534577\n",
            "[17]\tvalid_0's binary_logloss: 0.529491\n",
            "[18]\tvalid_0's binary_logloss: 0.52447\n",
            "[19]\tvalid_0's binary_logloss: 0.520243\n",
            "[20]\tvalid_0's binary_logloss: 0.515031\n",
            "[21]\tvalid_0's binary_logloss: 0.51161\n",
            "[22]\tvalid_0's binary_logloss: 0.508303\n",
            "[23]\tvalid_0's binary_logloss: 0.504461\n",
            "[24]\tvalid_0's binary_logloss: 0.500237\n",
            "[25]\tvalid_0's binary_logloss: 0.497347\n",
            "[26]\tvalid_0's binary_logloss: 0.493741\n",
            "[27]\tvalid_0's binary_logloss: 0.49046\n",
            "[28]\tvalid_0's binary_logloss: 0.488196\n",
            "[29]\tvalid_0's binary_logloss: 0.485325\n",
            "[30]\tvalid_0's binary_logloss: 0.482942\n",
            "[31]\tvalid_0's binary_logloss: 0.480549\n",
            "[32]\tvalid_0's binary_logloss: 0.477678\n",
            "[33]\tvalid_0's binary_logloss: 0.474921\n",
            "[34]\tvalid_0's binary_logloss: 0.473187\n",
            "[35]\tvalid_0's binary_logloss: 0.471189\n",
            "[36]\tvalid_0's binary_logloss: 0.46944\n",
            "[37]\tvalid_0's binary_logloss: 0.467759\n",
            "[38]\tvalid_0's binary_logloss: 0.465666\n",
            "[39]\tvalid_0's binary_logloss: 0.464371\n",
            "[40]\tvalid_0's binary_logloss: 0.461914\n",
            "[41]\tvalid_0's binary_logloss: 0.460017\n",
            "[42]\tvalid_0's binary_logloss: 0.458868\n",
            "[43]\tvalid_0's binary_logloss: 0.456861\n",
            "[44]\tvalid_0's binary_logloss: 0.45554\n",
            "[45]\tvalid_0's binary_logloss: 0.454556\n",
            "[46]\tvalid_0's binary_logloss: 0.45255\n",
            "[47]\tvalid_0's binary_logloss: 0.450269\n",
            "[48]\tvalid_0's binary_logloss: 0.449263\n",
            "[49]\tvalid_0's binary_logloss: 0.447733\n",
            "[50]\tvalid_0's binary_logloss: 0.445923\n",
            "[51]\tvalid_0's binary_logloss: 0.444886\n",
            "[52]\tvalid_0's binary_logloss: 0.443232\n",
            "[53]\tvalid_0's binary_logloss: 0.441216\n",
            "[54]\tvalid_0's binary_logloss: 0.440432\n",
            "[55]\tvalid_0's binary_logloss: 0.439127\n",
            "[56]\tvalid_0's binary_logloss: 0.437463\n",
            "[57]\tvalid_0's binary_logloss: 0.435927\n",
            "[58]\tvalid_0's binary_logloss: 0.434012\n",
            "[59]\tvalid_0's binary_logloss: 0.432181\n",
            "[60]\tvalid_0's binary_logloss: 0.431701\n",
            "[61]\tvalid_0's binary_logloss: 0.430534\n",
            "[62]\tvalid_0's binary_logloss: 0.429761\n",
            "[63]\tvalid_0's binary_logloss: 0.428789\n",
            "[64]\tvalid_0's binary_logloss: 0.428417\n",
            "[65]\tvalid_0's binary_logloss: 0.426953\n",
            "[66]\tvalid_0's binary_logloss: 0.425401\n",
            "[67]\tvalid_0's binary_logloss: 0.423599\n",
            "[68]\tvalid_0's binary_logloss: 0.422355\n",
            "[69]\tvalid_0's binary_logloss: 0.420481\n",
            "[70]\tvalid_0's binary_logloss: 0.419913\n",
            "[71]\tvalid_0's binary_logloss: 0.418766\n",
            "[72]\tvalid_0's binary_logloss: 0.418062\n",
            "[73]\tvalid_0's binary_logloss: 0.417316\n",
            "[74]\tvalid_0's binary_logloss: 0.416834\n",
            "[75]\tvalid_0's binary_logloss: 0.416315\n",
            "[76]\tvalid_0's binary_logloss: 0.415786\n",
            "[77]\tvalid_0's binary_logloss: 0.414731\n",
            "[78]\tvalid_0's binary_logloss: 0.413941\n",
            "[79]\tvalid_0's binary_logloss: 0.41404\n",
            "[80]\tvalid_0's binary_logloss: 0.41282\n",
            "[81]\tvalid_0's binary_logloss: 0.412092\n",
            "[82]\tvalid_0's binary_logloss: 0.411535\n",
            "[83]\tvalid_0's binary_logloss: 0.411216\n",
            "[84]\tvalid_0's binary_logloss: 0.41086\n",
            "[85]\tvalid_0's binary_logloss: 0.410005\n",
            "[86]\tvalid_0's binary_logloss: 0.409655\n",
            "[87]\tvalid_0's binary_logloss: 0.408851\n",
            "[88]\tvalid_0's binary_logloss: 0.408726\n",
            "[89]\tvalid_0's binary_logloss: 0.407864\n",
            "[90]\tvalid_0's binary_logloss: 0.40743\n",
            "[91]\tvalid_0's binary_logloss: 0.406153\n",
            "[92]\tvalid_0's binary_logloss: 0.405571\n",
            "[93]\tvalid_0's binary_logloss: 0.405329\n",
            "[94]\tvalid_0's binary_logloss: 0.405433\n",
            "[95]\tvalid_0's binary_logloss: 0.405036\n",
            "[96]\tvalid_0's binary_logloss: 0.405247\n",
            "[97]\tvalid_0's binary_logloss: 0.404436\n",
            "[98]\tvalid_0's binary_logloss: 0.403723\n",
            "[99]\tvalid_0's binary_logloss: 0.403076\n",
            "[100]\tvalid_0's binary_logloss: 0.402471\n",
            "[101]\tvalid_0's binary_logloss: 0.401396\n",
            "[102]\tvalid_0's binary_logloss: 0.400357\n",
            "[103]\tvalid_0's binary_logloss: 0.400028\n",
            "[104]\tvalid_0's binary_logloss: 0.400059\n",
            "[105]\tvalid_0's binary_logloss: 0.39967\n",
            "[106]\tvalid_0's binary_logloss: 0.399023\n",
            "[107]\tvalid_0's binary_logloss: 0.398593\n",
            "[108]\tvalid_0's binary_logloss: 0.398889\n",
            "[109]\tvalid_0's binary_logloss: 0.398279\n",
            "[110]\tvalid_0's binary_logloss: 0.39803\n",
            "[111]\tvalid_0's binary_logloss: 0.397559\n",
            "[112]\tvalid_0's binary_logloss: 0.397575\n",
            "[113]\tvalid_0's binary_logloss: 0.397985\n",
            "[114]\tvalid_0's binary_logloss: 0.397526\n",
            "[115]\tvalid_0's binary_logloss: 0.397789\n",
            "[116]\tvalid_0's binary_logloss: 0.398157\n",
            "[117]\tvalid_0's binary_logloss: 0.398175\n",
            "[118]\tvalid_0's binary_logloss: 0.397079\n",
            "[119]\tvalid_0's binary_logloss: 0.396989\n",
            "[120]\tvalid_0's binary_logloss: 0.396343\n",
            "[121]\tvalid_0's binary_logloss: 0.396043\n",
            "[122]\tvalid_0's binary_logloss: 0.396357\n",
            "[123]\tvalid_0's binary_logloss: 0.396947\n",
            "[124]\tvalid_0's binary_logloss: 0.39733\n",
            "[125]\tvalid_0's binary_logloss: 0.397227\n",
            "[126]\tvalid_0's binary_logloss: 0.396821\n",
            "[127]\tvalid_0's binary_logloss: 0.396643\n",
            "[128]\tvalid_0's binary_logloss: 0.395705\n",
            "[129]\tvalid_0's binary_logloss: 0.396225\n",
            "[130]\tvalid_0's binary_logloss: 0.396704\n",
            "[131]\tvalid_0's binary_logloss: 0.396501\n",
            "[132]\tvalid_0's binary_logloss: 0.396375\n",
            "[133]\tvalid_0's binary_logloss: 0.396255\n",
            "[134]\tvalid_0's binary_logloss: 0.395317\n",
            "[135]\tvalid_0's binary_logloss: 0.395262\n",
            "[136]\tvalid_0's binary_logloss: 0.395697\n",
            "[137]\tvalid_0's binary_logloss: 0.395489\n",
            "[138]\tvalid_0's binary_logloss: 0.395431\n",
            "[139]\tvalid_0's binary_logloss: 0.395029\n",
            "[140]\tvalid_0's binary_logloss: 0.395578\n",
            "[141]\tvalid_0's binary_logloss: 0.395768\n",
            "[142]\tvalid_0's binary_logloss: 0.395758\n",
            "[143]\tvalid_0's binary_logloss: 0.395305\n",
            "[144]\tvalid_0's binary_logloss: 0.396153\n",
            "[145]\tvalid_0's binary_logloss: 0.396074\n",
            "[146]\tvalid_0's binary_logloss: 0.395724\n",
            "[147]\tvalid_0's binary_logloss: 0.395505\n",
            "[148]\tvalid_0's binary_logloss: 0.395316\n",
            "[149]\tvalid_0's binary_logloss: 0.395313\n",
            "Early stopping, best iteration is:\n",
            "[139]\tvalid_0's binary_logloss: 0.395029\n",
            "CPU times: user 22 s, sys: 1.16 s, total: 23.1 s\n",
            "Wall time: 17.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "i1R856gNO5Ib",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "51296eb4-2e83-4842-830d-85267fdae3c5"
      },
      "source": [
        "y_preds_LGB = []\n",
        "\n",
        "for m in models_LGB:\n",
        "    y_preds_LGB.append(m.predict(X_test_LGB, num_iteration=m.best_iteration))\n",
        "\n",
        "y_preds_bagging_LGB = sum(y_preds_LGB)/len(y_preds_LGB)\n",
        "# auc を計算する\n",
        "auc = roc_auc_score(y_test_LGB, y_preds_bagging_LGB)\n",
        "print(auc)\n",
        "\n",
        "y_subs_LGB = []\n",
        "for m in models_LGB:\n",
        "    y_subs_LGB.append(m.predict(X_sub, num_iteration=m.best_iteration))\n",
        "\n",
        "y_subs_bagging_LGB = sum(y_subs_LGB)/len(y_subs_LGB)\n",
        "# auc を計算する\n",
        "y_subs_bagging_LGB"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8655835675261715\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.97434199, 0.31304721, 0.1020039 , ..., 0.23753478, 0.01384158,\n",
              "       0.53885567])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "746B_92sc2W4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ac1c7893-3765-4b05-b11f-bbb8ca2cfb0a"
      },
      "source": [
        "percentage_LGB=0.23\n",
        "y_sub_LGB = (y_subs_bagging_LGB > percentage_LGB).astype(int)\n",
        "\n",
        "# sub['B'] = y_sub_LGB\n",
        "# sub.to_csv('submission_lightgbm_bagging.csv', index=False, header=False)\n",
        "\n",
        "sum(y_sub_LGB),len(y_sub_LGB)"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9058, 18050)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liLEHD8vPObL",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dGu_Bxh8Jie0"
      },
      "source": [
        "##Holdout of LGB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sA7ycCWYSfUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LightGBM_Hのデータ分割\n",
        "X_train_LGB, X_test_LGB, y_train_LGB, y_test_LGB = train_test_split(X, y, test_size=0.3, random_state=7)\n",
        "X_train2_LGB, X_valid_LGB, y_train2_LGB, y_valid_LGB = train_test_split(X, y, test_size=0.3, random_state=8)"
      ],
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lHSu8P1KJifA",
        "colab": {}
      },
      "source": [
        "def holdout(seed):\n",
        "    positive_count_train = y_train_LGB.sum()\n",
        "    sampler = RandomUnderSampler(sampling_strategy={0:int(positive_count_train)*2, 1:int(positive_count_train)},random_state=seed+20, replacement=True)\n",
        "    X_resampled, y_resampled = sampler.fit_resample(X_train_LGB, y_train_LGB)\n",
        "    X_train2_LGB, X_valid_LGB, y_train2_LGB, y_valid_LGB = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=seed)\n",
        "    model_holdout = lgbm_train(X_train2_LGB, X_valid_LGB, y_train2_LGB, y_valid_LGB, lgbm_params)\n",
        "    return model_holdout"
      ],
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-JTeTAa9JifG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5576a5fe-d2eb-46c8-ae49-f730d82b1e5c"
      },
      "source": [
        "\n",
        "y_pred_H = holdout(18).predict(X_test_LGB, num_iteration=holdout(18).best_iteration)\n",
        "y_preds_bagging_LGB = sum(y_pred_H)/len(y_pred_H)\n",
        "# auc を計算する\n",
        "auc = roc_auc_score(y_test_LGB, y_pred_H)\n",
        "\n",
        "\n",
        "y_subs_H_LGB = holdout(18).predict(X_sub, num_iteration=holdout(18).best_iteration)\n",
        "\n",
        "y_subs_H_LGB2 = sum(y_subs_H_LGB)/len(y_subs_H_LGB)\n",
        "# auc を計算する\n",
        "y_subs_H_LGB2"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's binary_logloss: 0.619005\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's binary_logloss: 0.602224\n",
            "[3]\tvalid_0's binary_logloss: 0.587648\n",
            "[4]\tvalid_0's binary_logloss: 0.573756\n",
            "[5]\tvalid_0's binary_logloss: 0.561234\n",
            "[6]\tvalid_0's binary_logloss: 0.550234\n",
            "[7]\tvalid_0's binary_logloss: 0.539704\n",
            "[8]\tvalid_0's binary_logloss: 0.52993\n",
            "[9]\tvalid_0's binary_logloss: 0.52216\n",
            "[10]\tvalid_0's binary_logloss: 0.51332\n",
            "[11]\tvalid_0's binary_logloss: 0.505759\n",
            "[12]\tvalid_0's binary_logloss: 0.498712\n",
            "[13]\tvalid_0's binary_logloss: 0.4919\n",
            "[14]\tvalid_0's binary_logloss: 0.485855\n",
            "[15]\tvalid_0's binary_logloss: 0.479855\n",
            "[16]\tvalid_0's binary_logloss: 0.475015\n",
            "[17]\tvalid_0's binary_logloss: 0.470394\n",
            "[18]\tvalid_0's binary_logloss: 0.465196\n",
            "[19]\tvalid_0's binary_logloss: 0.459927\n",
            "[20]\tvalid_0's binary_logloss: 0.455397\n",
            "[21]\tvalid_0's binary_logloss: 0.450699\n",
            "[22]\tvalid_0's binary_logloss: 0.445916\n",
            "[23]\tvalid_0's binary_logloss: 0.442506\n",
            "[24]\tvalid_0's binary_logloss: 0.439073\n",
            "[25]\tvalid_0's binary_logloss: 0.43523\n",
            "[26]\tvalid_0's binary_logloss: 0.432442\n",
            "[27]\tvalid_0's binary_logloss: 0.429223\n",
            "[28]\tvalid_0's binary_logloss: 0.42559\n",
            "[29]\tvalid_0's binary_logloss: 0.423194\n",
            "[30]\tvalid_0's binary_logloss: 0.420366\n",
            "[31]\tvalid_0's binary_logloss: 0.417424\n",
            "[32]\tvalid_0's binary_logloss: 0.415889\n",
            "[33]\tvalid_0's binary_logloss: 0.412711\n",
            "[34]\tvalid_0's binary_logloss: 0.410511\n",
            "[35]\tvalid_0's binary_logloss: 0.408259\n",
            "[36]\tvalid_0's binary_logloss: 0.406102\n",
            "[37]\tvalid_0's binary_logloss: 0.403872\n",
            "[38]\tvalid_0's binary_logloss: 0.402221\n",
            "[39]\tvalid_0's binary_logloss: 0.400871\n",
            "[40]\tvalid_0's binary_logloss: 0.39916\n",
            "[41]\tvalid_0's binary_logloss: 0.39708\n",
            "[42]\tvalid_0's binary_logloss: 0.395391\n",
            "[43]\tvalid_0's binary_logloss: 0.393289\n",
            "[44]\tvalid_0's binary_logloss: 0.391803\n",
            "[45]\tvalid_0's binary_logloss: 0.389986\n",
            "[46]\tvalid_0's binary_logloss: 0.388517\n",
            "[47]\tvalid_0's binary_logloss: 0.387243\n",
            "[48]\tvalid_0's binary_logloss: 0.386393\n",
            "[49]\tvalid_0's binary_logloss: 0.385127\n",
            "[50]\tvalid_0's binary_logloss: 0.383618\n",
            "[51]\tvalid_0's binary_logloss: 0.382379\n",
            "[52]\tvalid_0's binary_logloss: 0.380632\n",
            "[53]\tvalid_0's binary_logloss: 0.379678\n",
            "[54]\tvalid_0's binary_logloss: 0.378469\n",
            "[55]\tvalid_0's binary_logloss: 0.37719\n",
            "[56]\tvalid_0's binary_logloss: 0.375813\n",
            "[57]\tvalid_0's binary_logloss: 0.374645\n",
            "[58]\tvalid_0's binary_logloss: 0.373264\n",
            "[59]\tvalid_0's binary_logloss: 0.372029\n",
            "[60]\tvalid_0's binary_logloss: 0.371807\n",
            "[61]\tvalid_0's binary_logloss: 0.370357\n",
            "[62]\tvalid_0's binary_logloss: 0.369364\n",
            "[63]\tvalid_0's binary_logloss: 0.367654\n",
            "[64]\tvalid_0's binary_logloss: 0.3665\n",
            "[65]\tvalid_0's binary_logloss: 0.36594\n",
            "[66]\tvalid_0's binary_logloss: 0.364752\n",
            "[67]\tvalid_0's binary_logloss: 0.36419\n",
            "[68]\tvalid_0's binary_logloss: 0.363507\n",
            "[69]\tvalid_0's binary_logloss: 0.362918\n",
            "[70]\tvalid_0's binary_logloss: 0.362168\n",
            "[71]\tvalid_0's binary_logloss: 0.361662\n",
            "[72]\tvalid_0's binary_logloss: 0.361633\n",
            "[73]\tvalid_0's binary_logloss: 0.360396\n",
            "[74]\tvalid_0's binary_logloss: 0.359554\n",
            "[75]\tvalid_0's binary_logloss: 0.359421\n",
            "[76]\tvalid_0's binary_logloss: 0.358817\n",
            "[77]\tvalid_0's binary_logloss: 0.358466\n",
            "[78]\tvalid_0's binary_logloss: 0.357187\n",
            "[79]\tvalid_0's binary_logloss: 0.356449\n",
            "[80]\tvalid_0's binary_logloss: 0.355971\n",
            "[81]\tvalid_0's binary_logloss: 0.355607\n",
            "[82]\tvalid_0's binary_logloss: 0.354559\n",
            "[83]\tvalid_0's binary_logloss: 0.353887\n",
            "[84]\tvalid_0's binary_logloss: 0.352957\n",
            "[85]\tvalid_0's binary_logloss: 0.352882\n",
            "[86]\tvalid_0's binary_logloss: 0.3524\n",
            "[87]\tvalid_0's binary_logloss: 0.352167\n",
            "[88]\tvalid_0's binary_logloss: 0.351929\n",
            "[89]\tvalid_0's binary_logloss: 0.351964\n",
            "[90]\tvalid_0's binary_logloss: 0.351355\n",
            "[91]\tvalid_0's binary_logloss: 0.351205\n",
            "[92]\tvalid_0's binary_logloss: 0.350608\n",
            "[93]\tvalid_0's binary_logloss: 0.350165\n",
            "[94]\tvalid_0's binary_logloss: 0.350078\n",
            "[95]\tvalid_0's binary_logloss: 0.349073\n",
            "[96]\tvalid_0's binary_logloss: 0.347844\n",
            "[97]\tvalid_0's binary_logloss: 0.347737\n",
            "[98]\tvalid_0's binary_logloss: 0.348194\n",
            "[99]\tvalid_0's binary_logloss: 0.347802\n",
            "[100]\tvalid_0's binary_logloss: 0.347741\n",
            "[101]\tvalid_0's binary_logloss: 0.347544\n",
            "[102]\tvalid_0's binary_logloss: 0.347203\n",
            "[103]\tvalid_0's binary_logloss: 0.347118\n",
            "[104]\tvalid_0's binary_logloss: 0.347131\n",
            "[105]\tvalid_0's binary_logloss: 0.346929\n",
            "[106]\tvalid_0's binary_logloss: 0.346675\n",
            "[107]\tvalid_0's binary_logloss: 0.346593\n",
            "[108]\tvalid_0's binary_logloss: 0.346652\n",
            "[109]\tvalid_0's binary_logloss: 0.346198\n",
            "[110]\tvalid_0's binary_logloss: 0.345499\n",
            "[111]\tvalid_0's binary_logloss: 0.345243\n",
            "[112]\tvalid_0's binary_logloss: 0.345215\n",
            "[113]\tvalid_0's binary_logloss: 0.345529\n",
            "[114]\tvalid_0's binary_logloss: 0.346005\n",
            "[115]\tvalid_0's binary_logloss: 0.346168\n",
            "[116]\tvalid_0's binary_logloss: 0.346419\n",
            "[117]\tvalid_0's binary_logloss: 0.346695\n",
            "[118]\tvalid_0's binary_logloss: 0.346332\n",
            "[119]\tvalid_0's binary_logloss: 0.346625\n",
            "[120]\tvalid_0's binary_logloss: 0.346919\n",
            "[121]\tvalid_0's binary_logloss: 0.347002\n",
            "[122]\tvalid_0's binary_logloss: 0.346889\n",
            "Early stopping, best iteration is:\n",
            "[112]\tvalid_0's binary_logloss: 0.345215\n",
            "[1]\tvalid_0's binary_logloss: 0.619005\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's binary_logloss: 0.602224\n",
            "[3]\tvalid_0's binary_logloss: 0.587648\n",
            "[4]\tvalid_0's binary_logloss: 0.573756\n",
            "[5]\tvalid_0's binary_logloss: 0.561234\n",
            "[6]\tvalid_0's binary_logloss: 0.550234\n",
            "[7]\tvalid_0's binary_logloss: 0.539704\n",
            "[8]\tvalid_0's binary_logloss: 0.52993\n",
            "[9]\tvalid_0's binary_logloss: 0.52216\n",
            "[10]\tvalid_0's binary_logloss: 0.51332\n",
            "[11]\tvalid_0's binary_logloss: 0.505759\n",
            "[12]\tvalid_0's binary_logloss: 0.498712\n",
            "[13]\tvalid_0's binary_logloss: 0.4919\n",
            "[14]\tvalid_0's binary_logloss: 0.485855\n",
            "[15]\tvalid_0's binary_logloss: 0.479855\n",
            "[16]\tvalid_0's binary_logloss: 0.475015\n",
            "[17]\tvalid_0's binary_logloss: 0.470394\n",
            "[18]\tvalid_0's binary_logloss: 0.465196\n",
            "[19]\tvalid_0's binary_logloss: 0.459927\n",
            "[20]\tvalid_0's binary_logloss: 0.455397\n",
            "[21]\tvalid_0's binary_logloss: 0.450699\n",
            "[22]\tvalid_0's binary_logloss: 0.445916\n",
            "[23]\tvalid_0's binary_logloss: 0.442506\n",
            "[24]\tvalid_0's binary_logloss: 0.439073\n",
            "[25]\tvalid_0's binary_logloss: 0.43523\n",
            "[26]\tvalid_0's binary_logloss: 0.432442\n",
            "[27]\tvalid_0's binary_logloss: 0.429223\n",
            "[28]\tvalid_0's binary_logloss: 0.42559\n",
            "[29]\tvalid_0's binary_logloss: 0.423194\n",
            "[30]\tvalid_0's binary_logloss: 0.420366\n",
            "[31]\tvalid_0's binary_logloss: 0.417424\n",
            "[32]\tvalid_0's binary_logloss: 0.415889\n",
            "[33]\tvalid_0's binary_logloss: 0.412711\n",
            "[34]\tvalid_0's binary_logloss: 0.410511\n",
            "[35]\tvalid_0's binary_logloss: 0.408259\n",
            "[36]\tvalid_0's binary_logloss: 0.406102\n",
            "[37]\tvalid_0's binary_logloss: 0.403872\n",
            "[38]\tvalid_0's binary_logloss: 0.402221\n",
            "[39]\tvalid_0's binary_logloss: 0.400871\n",
            "[40]\tvalid_0's binary_logloss: 0.39916\n",
            "[41]\tvalid_0's binary_logloss: 0.39708\n",
            "[42]\tvalid_0's binary_logloss: 0.395391\n",
            "[43]\tvalid_0's binary_logloss: 0.393289\n",
            "[44]\tvalid_0's binary_logloss: 0.391803\n",
            "[45]\tvalid_0's binary_logloss: 0.389986\n",
            "[46]\tvalid_0's binary_logloss: 0.388517\n",
            "[47]\tvalid_0's binary_logloss: 0.387243\n",
            "[48]\tvalid_0's binary_logloss: 0.386393\n",
            "[49]\tvalid_0's binary_logloss: 0.385127\n",
            "[50]\tvalid_0's binary_logloss: 0.383618\n",
            "[51]\tvalid_0's binary_logloss: 0.382379\n",
            "[52]\tvalid_0's binary_logloss: 0.380632\n",
            "[53]\tvalid_0's binary_logloss: 0.379678\n",
            "[54]\tvalid_0's binary_logloss: 0.378469\n",
            "[55]\tvalid_0's binary_logloss: 0.37719\n",
            "[56]\tvalid_0's binary_logloss: 0.375813\n",
            "[57]\tvalid_0's binary_logloss: 0.374645\n",
            "[58]\tvalid_0's binary_logloss: 0.373264\n",
            "[59]\tvalid_0's binary_logloss: 0.372029\n",
            "[60]\tvalid_0's binary_logloss: 0.371807\n",
            "[61]\tvalid_0's binary_logloss: 0.370357\n",
            "[62]\tvalid_0's binary_logloss: 0.369364\n",
            "[63]\tvalid_0's binary_logloss: 0.367654\n",
            "[64]\tvalid_0's binary_logloss: 0.3665\n",
            "[65]\tvalid_0's binary_logloss: 0.36594\n",
            "[66]\tvalid_0's binary_logloss: 0.364752\n",
            "[67]\tvalid_0's binary_logloss: 0.36419\n",
            "[68]\tvalid_0's binary_logloss: 0.363507\n",
            "[69]\tvalid_0's binary_logloss: 0.362918\n",
            "[70]\tvalid_0's binary_logloss: 0.362168\n",
            "[71]\tvalid_0's binary_logloss: 0.361662\n",
            "[72]\tvalid_0's binary_logloss: 0.361633\n",
            "[73]\tvalid_0's binary_logloss: 0.360396\n",
            "[74]\tvalid_0's binary_logloss: 0.359554\n",
            "[75]\tvalid_0's binary_logloss: 0.359421\n",
            "[76]\tvalid_0's binary_logloss: 0.358817\n",
            "[77]\tvalid_0's binary_logloss: 0.358466\n",
            "[78]\tvalid_0's binary_logloss: 0.357187\n",
            "[79]\tvalid_0's binary_logloss: 0.356449\n",
            "[80]\tvalid_0's binary_logloss: 0.355971\n",
            "[81]\tvalid_0's binary_logloss: 0.355607\n",
            "[82]\tvalid_0's binary_logloss: 0.354559\n",
            "[83]\tvalid_0's binary_logloss: 0.353887\n",
            "[84]\tvalid_0's binary_logloss: 0.352957\n",
            "[85]\tvalid_0's binary_logloss: 0.352882\n",
            "[86]\tvalid_0's binary_logloss: 0.3524\n",
            "[87]\tvalid_0's binary_logloss: 0.352167\n",
            "[88]\tvalid_0's binary_logloss: 0.351929\n",
            "[89]\tvalid_0's binary_logloss: 0.351964\n",
            "[90]\tvalid_0's binary_logloss: 0.351355\n",
            "[91]\tvalid_0's binary_logloss: 0.351205\n",
            "[92]\tvalid_0's binary_logloss: 0.350608\n",
            "[93]\tvalid_0's binary_logloss: 0.350165\n",
            "[94]\tvalid_0's binary_logloss: 0.350078\n",
            "[95]\tvalid_0's binary_logloss: 0.349073\n",
            "[96]\tvalid_0's binary_logloss: 0.347844\n",
            "[97]\tvalid_0's binary_logloss: 0.347737\n",
            "[98]\tvalid_0's binary_logloss: 0.348194\n",
            "[99]\tvalid_0's binary_logloss: 0.347802\n",
            "[100]\tvalid_0's binary_logloss: 0.347741\n",
            "[101]\tvalid_0's binary_logloss: 0.347544\n",
            "[102]\tvalid_0's binary_logloss: 0.347203\n",
            "[103]\tvalid_0's binary_logloss: 0.347118\n",
            "[104]\tvalid_0's binary_logloss: 0.347131\n",
            "[105]\tvalid_0's binary_logloss: 0.346929\n",
            "[106]\tvalid_0's binary_logloss: 0.346675\n",
            "[107]\tvalid_0's binary_logloss: 0.346593\n",
            "[108]\tvalid_0's binary_logloss: 0.346652\n",
            "[109]\tvalid_0's binary_logloss: 0.346198\n",
            "[110]\tvalid_0's binary_logloss: 0.345499\n",
            "[111]\tvalid_0's binary_logloss: 0.345243\n",
            "[112]\tvalid_0's binary_logloss: 0.345215\n",
            "[113]\tvalid_0's binary_logloss: 0.345529\n",
            "[114]\tvalid_0's binary_logloss: 0.346005\n",
            "[115]\tvalid_0's binary_logloss: 0.346168\n",
            "[116]\tvalid_0's binary_logloss: 0.346419\n",
            "[117]\tvalid_0's binary_logloss: 0.346695\n",
            "[118]\tvalid_0's binary_logloss: 0.346332\n",
            "[119]\tvalid_0's binary_logloss: 0.346625\n",
            "[120]\tvalid_0's binary_logloss: 0.346919\n",
            "[121]\tvalid_0's binary_logloss: 0.347002\n",
            "[122]\tvalid_0's binary_logloss: 0.346889\n",
            "Early stopping, best iteration is:\n",
            "[112]\tvalid_0's binary_logloss: 0.345215\n",
            "[1]\tvalid_0's binary_logloss: 0.619005\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's binary_logloss: 0.602224\n",
            "[3]\tvalid_0's binary_logloss: 0.587648\n",
            "[4]\tvalid_0's binary_logloss: 0.573756\n",
            "[5]\tvalid_0's binary_logloss: 0.561234\n",
            "[6]\tvalid_0's binary_logloss: 0.550234\n",
            "[7]\tvalid_0's binary_logloss: 0.539704\n",
            "[8]\tvalid_0's binary_logloss: 0.52993\n",
            "[9]\tvalid_0's binary_logloss: 0.52216\n",
            "[10]\tvalid_0's binary_logloss: 0.51332\n",
            "[11]\tvalid_0's binary_logloss: 0.505759\n",
            "[12]\tvalid_0's binary_logloss: 0.498712\n",
            "[13]\tvalid_0's binary_logloss: 0.4919\n",
            "[14]\tvalid_0's binary_logloss: 0.485855\n",
            "[15]\tvalid_0's binary_logloss: 0.479855\n",
            "[16]\tvalid_0's binary_logloss: 0.475015\n",
            "[17]\tvalid_0's binary_logloss: 0.470394\n",
            "[18]\tvalid_0's binary_logloss: 0.465196\n",
            "[19]\tvalid_0's binary_logloss: 0.459927\n",
            "[20]\tvalid_0's binary_logloss: 0.455397\n",
            "[21]\tvalid_0's binary_logloss: 0.450699\n",
            "[22]\tvalid_0's binary_logloss: 0.445916\n",
            "[23]\tvalid_0's binary_logloss: 0.442506\n",
            "[24]\tvalid_0's binary_logloss: 0.439073\n",
            "[25]\tvalid_0's binary_logloss: 0.43523\n",
            "[26]\tvalid_0's binary_logloss: 0.432442\n",
            "[27]\tvalid_0's binary_logloss: 0.429223\n",
            "[28]\tvalid_0's binary_logloss: 0.42559\n",
            "[29]\tvalid_0's binary_logloss: 0.423194\n",
            "[30]\tvalid_0's binary_logloss: 0.420366\n",
            "[31]\tvalid_0's binary_logloss: 0.417424\n",
            "[32]\tvalid_0's binary_logloss: 0.415889\n",
            "[33]\tvalid_0's binary_logloss: 0.412711\n",
            "[34]\tvalid_0's binary_logloss: 0.410511\n",
            "[35]\tvalid_0's binary_logloss: 0.408259\n",
            "[36]\tvalid_0's binary_logloss: 0.406102\n",
            "[37]\tvalid_0's binary_logloss: 0.403872\n",
            "[38]\tvalid_0's binary_logloss: 0.402221\n",
            "[39]\tvalid_0's binary_logloss: 0.400871\n",
            "[40]\tvalid_0's binary_logloss: 0.39916\n",
            "[41]\tvalid_0's binary_logloss: 0.39708\n",
            "[42]\tvalid_0's binary_logloss: 0.395391\n",
            "[43]\tvalid_0's binary_logloss: 0.393289\n",
            "[44]\tvalid_0's binary_logloss: 0.391803\n",
            "[45]\tvalid_0's binary_logloss: 0.389986\n",
            "[46]\tvalid_0's binary_logloss: 0.388517\n",
            "[47]\tvalid_0's binary_logloss: 0.387243\n",
            "[48]\tvalid_0's binary_logloss: 0.386393\n",
            "[49]\tvalid_0's binary_logloss: 0.385127\n",
            "[50]\tvalid_0's binary_logloss: 0.383618\n",
            "[51]\tvalid_0's binary_logloss: 0.382379\n",
            "[52]\tvalid_0's binary_logloss: 0.380632\n",
            "[53]\tvalid_0's binary_logloss: 0.379678\n",
            "[54]\tvalid_0's binary_logloss: 0.378469\n",
            "[55]\tvalid_0's binary_logloss: 0.37719\n",
            "[56]\tvalid_0's binary_logloss: 0.375813\n",
            "[57]\tvalid_0's binary_logloss: 0.374645\n",
            "[58]\tvalid_0's binary_logloss: 0.373264\n",
            "[59]\tvalid_0's binary_logloss: 0.372029\n",
            "[60]\tvalid_0's binary_logloss: 0.371807\n",
            "[61]\tvalid_0's binary_logloss: 0.370357\n",
            "[62]\tvalid_0's binary_logloss: 0.369364\n",
            "[63]\tvalid_0's binary_logloss: 0.367654\n",
            "[64]\tvalid_0's binary_logloss: 0.3665\n",
            "[65]\tvalid_0's binary_logloss: 0.36594\n",
            "[66]\tvalid_0's binary_logloss: 0.364752\n",
            "[67]\tvalid_0's binary_logloss: 0.36419\n",
            "[68]\tvalid_0's binary_logloss: 0.363507\n",
            "[69]\tvalid_0's binary_logloss: 0.362918\n",
            "[70]\tvalid_0's binary_logloss: 0.362168\n",
            "[71]\tvalid_0's binary_logloss: 0.361662\n",
            "[72]\tvalid_0's binary_logloss: 0.361633\n",
            "[73]\tvalid_0's binary_logloss: 0.360396\n",
            "[74]\tvalid_0's binary_logloss: 0.359554\n",
            "[75]\tvalid_0's binary_logloss: 0.359421\n",
            "[76]\tvalid_0's binary_logloss: 0.358817\n",
            "[77]\tvalid_0's binary_logloss: 0.358466\n",
            "[78]\tvalid_0's binary_logloss: 0.357187\n",
            "[79]\tvalid_0's binary_logloss: 0.356449\n",
            "[80]\tvalid_0's binary_logloss: 0.355971\n",
            "[81]\tvalid_0's binary_logloss: 0.355607\n",
            "[82]\tvalid_0's binary_logloss: 0.354559\n",
            "[83]\tvalid_0's binary_logloss: 0.353887\n",
            "[84]\tvalid_0's binary_logloss: 0.352957\n",
            "[85]\tvalid_0's binary_logloss: 0.352882\n",
            "[86]\tvalid_0's binary_logloss: 0.3524\n",
            "[87]\tvalid_0's binary_logloss: 0.352167\n",
            "[88]\tvalid_0's binary_logloss: 0.351929\n",
            "[89]\tvalid_0's binary_logloss: 0.351964\n",
            "[90]\tvalid_0's binary_logloss: 0.351355\n",
            "[91]\tvalid_0's binary_logloss: 0.351205\n",
            "[92]\tvalid_0's binary_logloss: 0.350608\n",
            "[93]\tvalid_0's binary_logloss: 0.350165\n",
            "[94]\tvalid_0's binary_logloss: 0.350078\n",
            "[95]\tvalid_0's binary_logloss: 0.349073\n",
            "[96]\tvalid_0's binary_logloss: 0.347844\n",
            "[97]\tvalid_0's binary_logloss: 0.347737\n",
            "[98]\tvalid_0's binary_logloss: 0.348194\n",
            "[99]\tvalid_0's binary_logloss: 0.347802\n",
            "[100]\tvalid_0's binary_logloss: 0.347741\n",
            "[101]\tvalid_0's binary_logloss: 0.347544\n",
            "[102]\tvalid_0's binary_logloss: 0.347203\n",
            "[103]\tvalid_0's binary_logloss: 0.347118\n",
            "[104]\tvalid_0's binary_logloss: 0.347131\n",
            "[105]\tvalid_0's binary_logloss: 0.346929\n",
            "[106]\tvalid_0's binary_logloss: 0.346675\n",
            "[107]\tvalid_0's binary_logloss: 0.346593\n",
            "[108]\tvalid_0's binary_logloss: 0.346652\n",
            "[109]\tvalid_0's binary_logloss: 0.346198\n",
            "[110]\tvalid_0's binary_logloss: 0.345499\n",
            "[111]\tvalid_0's binary_logloss: 0.345243\n",
            "[112]\tvalid_0's binary_logloss: 0.345215\n",
            "[113]\tvalid_0's binary_logloss: 0.345529\n",
            "[114]\tvalid_0's binary_logloss: 0.346005\n",
            "[115]\tvalid_0's binary_logloss: 0.346168\n",
            "[116]\tvalid_0's binary_logloss: 0.346419\n",
            "[117]\tvalid_0's binary_logloss: 0.346695\n",
            "[118]\tvalid_0's binary_logloss: 0.346332\n",
            "[119]\tvalid_0's binary_logloss: 0.346625\n",
            "[120]\tvalid_0's binary_logloss: 0.346919\n",
            "[121]\tvalid_0's binary_logloss: 0.347002\n",
            "[122]\tvalid_0's binary_logloss: 0.346889\n",
            "Early stopping, best iteration is:\n",
            "[112]\tvalid_0's binary_logloss: 0.345215\n",
            "[1]\tvalid_0's binary_logloss: 0.619005\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's binary_logloss: 0.602224\n",
            "[3]\tvalid_0's binary_logloss: 0.587648\n",
            "[4]\tvalid_0's binary_logloss: 0.573756\n",
            "[5]\tvalid_0's binary_logloss: 0.561234\n",
            "[6]\tvalid_0's binary_logloss: 0.550234\n",
            "[7]\tvalid_0's binary_logloss: 0.539704\n",
            "[8]\tvalid_0's binary_logloss: 0.52993\n",
            "[9]\tvalid_0's binary_logloss: 0.52216\n",
            "[10]\tvalid_0's binary_logloss: 0.51332\n",
            "[11]\tvalid_0's binary_logloss: 0.505759\n",
            "[12]\tvalid_0's binary_logloss: 0.498712\n",
            "[13]\tvalid_0's binary_logloss: 0.4919\n",
            "[14]\tvalid_0's binary_logloss: 0.485855\n",
            "[15]\tvalid_0's binary_logloss: 0.479855\n",
            "[16]\tvalid_0's binary_logloss: 0.475015\n",
            "[17]\tvalid_0's binary_logloss: 0.470394\n",
            "[18]\tvalid_0's binary_logloss: 0.465196\n",
            "[19]\tvalid_0's binary_logloss: 0.459927\n",
            "[20]\tvalid_0's binary_logloss: 0.455397\n",
            "[21]\tvalid_0's binary_logloss: 0.450699\n",
            "[22]\tvalid_0's binary_logloss: 0.445916\n",
            "[23]\tvalid_0's binary_logloss: 0.442506\n",
            "[24]\tvalid_0's binary_logloss: 0.439073\n",
            "[25]\tvalid_0's binary_logloss: 0.43523\n",
            "[26]\tvalid_0's binary_logloss: 0.432442\n",
            "[27]\tvalid_0's binary_logloss: 0.429223\n",
            "[28]\tvalid_0's binary_logloss: 0.42559\n",
            "[29]\tvalid_0's binary_logloss: 0.423194\n",
            "[30]\tvalid_0's binary_logloss: 0.420366\n",
            "[31]\tvalid_0's binary_logloss: 0.417424\n",
            "[32]\tvalid_0's binary_logloss: 0.415889\n",
            "[33]\tvalid_0's binary_logloss: 0.412711\n",
            "[34]\tvalid_0's binary_logloss: 0.410511\n",
            "[35]\tvalid_0's binary_logloss: 0.408259\n",
            "[36]\tvalid_0's binary_logloss: 0.406102\n",
            "[37]\tvalid_0's binary_logloss: 0.403872\n",
            "[38]\tvalid_0's binary_logloss: 0.402221\n",
            "[39]\tvalid_0's binary_logloss: 0.400871\n",
            "[40]\tvalid_0's binary_logloss: 0.39916\n",
            "[41]\tvalid_0's binary_logloss: 0.39708\n",
            "[42]\tvalid_0's binary_logloss: 0.395391\n",
            "[43]\tvalid_0's binary_logloss: 0.393289\n",
            "[44]\tvalid_0's binary_logloss: 0.391803\n",
            "[45]\tvalid_0's binary_logloss: 0.389986\n",
            "[46]\tvalid_0's binary_logloss: 0.388517\n",
            "[47]\tvalid_0's binary_logloss: 0.387243\n",
            "[48]\tvalid_0's binary_logloss: 0.386393\n",
            "[49]\tvalid_0's binary_logloss: 0.385127\n",
            "[50]\tvalid_0's binary_logloss: 0.383618\n",
            "[51]\tvalid_0's binary_logloss: 0.382379\n",
            "[52]\tvalid_0's binary_logloss: 0.380632\n",
            "[53]\tvalid_0's binary_logloss: 0.379678\n",
            "[54]\tvalid_0's binary_logloss: 0.378469\n",
            "[55]\tvalid_0's binary_logloss: 0.37719\n",
            "[56]\tvalid_0's binary_logloss: 0.375813\n",
            "[57]\tvalid_0's binary_logloss: 0.374645\n",
            "[58]\tvalid_0's binary_logloss: 0.373264\n",
            "[59]\tvalid_0's binary_logloss: 0.372029\n",
            "[60]\tvalid_0's binary_logloss: 0.371807\n",
            "[61]\tvalid_0's binary_logloss: 0.370357\n",
            "[62]\tvalid_0's binary_logloss: 0.369364\n",
            "[63]\tvalid_0's binary_logloss: 0.367654\n",
            "[64]\tvalid_0's binary_logloss: 0.3665\n",
            "[65]\tvalid_0's binary_logloss: 0.36594\n",
            "[66]\tvalid_0's binary_logloss: 0.364752\n",
            "[67]\tvalid_0's binary_logloss: 0.36419\n",
            "[68]\tvalid_0's binary_logloss: 0.363507\n",
            "[69]\tvalid_0's binary_logloss: 0.362918\n",
            "[70]\tvalid_0's binary_logloss: 0.362168\n",
            "[71]\tvalid_0's binary_logloss: 0.361662\n",
            "[72]\tvalid_0's binary_logloss: 0.361633\n",
            "[73]\tvalid_0's binary_logloss: 0.360396\n",
            "[74]\tvalid_0's binary_logloss: 0.359554\n",
            "[75]\tvalid_0's binary_logloss: 0.359421\n",
            "[76]\tvalid_0's binary_logloss: 0.358817\n",
            "[77]\tvalid_0's binary_logloss: 0.358466\n",
            "[78]\tvalid_0's binary_logloss: 0.357187\n",
            "[79]\tvalid_0's binary_logloss: 0.356449\n",
            "[80]\tvalid_0's binary_logloss: 0.355971\n",
            "[81]\tvalid_0's binary_logloss: 0.355607\n",
            "[82]\tvalid_0's binary_logloss: 0.354559\n",
            "[83]\tvalid_0's binary_logloss: 0.353887\n",
            "[84]\tvalid_0's binary_logloss: 0.352957\n",
            "[85]\tvalid_0's binary_logloss: 0.352882\n",
            "[86]\tvalid_0's binary_logloss: 0.3524\n",
            "[87]\tvalid_0's binary_logloss: 0.352167\n",
            "[88]\tvalid_0's binary_logloss: 0.351929\n",
            "[89]\tvalid_0's binary_logloss: 0.351964\n",
            "[90]\tvalid_0's binary_logloss: 0.351355\n",
            "[91]\tvalid_0's binary_logloss: 0.351205\n",
            "[92]\tvalid_0's binary_logloss: 0.350608\n",
            "[93]\tvalid_0's binary_logloss: 0.350165\n",
            "[94]\tvalid_0's binary_logloss: 0.350078\n",
            "[95]\tvalid_0's binary_logloss: 0.349073\n",
            "[96]\tvalid_0's binary_logloss: 0.347844\n",
            "[97]\tvalid_0's binary_logloss: 0.347737\n",
            "[98]\tvalid_0's binary_logloss: 0.348194\n",
            "[99]\tvalid_0's binary_logloss: 0.347802\n",
            "[100]\tvalid_0's binary_logloss: 0.347741\n",
            "[101]\tvalid_0's binary_logloss: 0.347544\n",
            "[102]\tvalid_0's binary_logloss: 0.347203\n",
            "[103]\tvalid_0's binary_logloss: 0.347118\n",
            "[104]\tvalid_0's binary_logloss: 0.347131\n",
            "[105]\tvalid_0's binary_logloss: 0.346929\n",
            "[106]\tvalid_0's binary_logloss: 0.346675\n",
            "[107]\tvalid_0's binary_logloss: 0.346593\n",
            "[108]\tvalid_0's binary_logloss: 0.346652\n",
            "[109]\tvalid_0's binary_logloss: 0.346198\n",
            "[110]\tvalid_0's binary_logloss: 0.345499\n",
            "[111]\tvalid_0's binary_logloss: 0.345243\n",
            "[112]\tvalid_0's binary_logloss: 0.345215\n",
            "[113]\tvalid_0's binary_logloss: 0.345529\n",
            "[114]\tvalid_0's binary_logloss: 0.346005\n",
            "[115]\tvalid_0's binary_logloss: 0.346168\n",
            "[116]\tvalid_0's binary_logloss: 0.346419\n",
            "[117]\tvalid_0's binary_logloss: 0.346695\n",
            "[118]\tvalid_0's binary_logloss: 0.346332\n",
            "[119]\tvalid_0's binary_logloss: 0.346625\n",
            "[120]\tvalid_0's binary_logloss: 0.346919\n",
            "[121]\tvalid_0's binary_logloss: 0.347002\n",
            "[122]\tvalid_0's binary_logloss: 0.346889\n",
            "Early stopping, best iteration is:\n",
            "[112]\tvalid_0's binary_logloss: 0.345215\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1954011334540482"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PwKBVSWAJifQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ef79159e-8d19-459f-ed86-1bb61f1181b5"
      },
      "source": [
        "percentage_H=0.1\n",
        "y_sub_H = (y_subs_H_LGB > percentage_H).astype(int)\n",
        "\n",
        "# sub['B'] = y_sub_LGB\n",
        "# sub.to_csv('submission_lightgbm_bagging.csv', index=False, header=False)\n",
        "\n",
        "sum(y_sub_H),len(y_sub_H)"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8341, 18050)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WtzPSEXi7KJE"
      },
      "source": [
        "# RandomForest\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a_2RfUrS7KJF"
      },
      "source": [
        "## def RF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HeIpnKkW7KJG",
        "colab": {}
      },
      "source": [
        "#RandomForestのデータ分割\n",
        "X_train_RF, X_test_RF, y_train_RF, y_test_RF = train_test_split(X, y, test_size=0.2, random_state=12)\n",
        "#X_train2, X_valid, y_train2, y_valid = train_test_split(X, y, test_size=0.2, random_state=1)"
      ],
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9TQBWt8Y7KJI",
        "colab": {}
      },
      "source": [
        "def RF(seed):\n",
        "    positive_count_train = y_train_RF.sum()\n",
        "    sampler_RF = RandomUnderSampler(sampling_strategy={0:int(positive_count_train), 1:int(positive_count_train)},random_state=seed+10, replacement=True)\n",
        "    X_resampled_RF, y_resampled_RF = sampler_RF.fit_resample(X_train_RF, y_train_RF)\n",
        "    clf = RandomForestClassifier(n_estimators=100,max_depth=4, random_state=seed)\n",
        "    clf.fit(X_resampled_RF, y_resampled_RF)\n",
        "\n",
        "    return clf"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrtGW4o08rM3",
        "colab_type": "text"
      },
      "source": [
        "## Bagging of RF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NkZuEZXq7KJM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e287906f-f748-4f1d-e454-6bf1b606dc02"
      },
      "source": [
        "%%time\n",
        "models_RF = []\n",
        "\n",
        "for i in range(10):\n",
        "    models_RF.append(RF(i))"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3.09 s, sys: 22.3 ms, total: 3.11 s\n",
            "Wall time: 3.12 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab_type": "code",
        "id": "Y8zoDavG7KJQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "260bbe45-97ff-4e00-a5f8-ea4c7ebfc5a1"
      },
      "source": [
        "y_preds_RF = []\n",
        "percentage_RF=0.004\n",
        "\n",
        "for clf in models_RF:\n",
        "    y_preds_RF.append(clf.predict(X_sub))\n",
        "y_subs_bagging_RF = sum(y_preds_RF)/len(y_preds_RF)\n",
        "y_sub_RF = (y_subs_bagging_RF > percentage_RF).astype(int)\n",
        "\n",
        "sum(y_sub_RF),len(y_sub_RF)"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7879, 18050)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2w5EAyW7Tvg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "464e197a-16b0-48a9-c906-d992bbc5213f"
      },
      "source": [
        "y_sub_LGB"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, ..., 1, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iJlUmtgQ8GW4"
      },
      "source": [
        "## 全部　RF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jz211tf38GW6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "894fb384-99ca-4b03-b791-4d36f3afc6f2"
      },
      "source": [
        "\"\"\"\n",
        "RF_clf = RandomForestClassifier(n_estimators=100,max_depth=30, random_state=13)\n",
        "RF_clf.fit(X, y)\n",
        "y_pred_RF=RF_clf.predict(X_sub)\n",
        "percentage_RF=0.004\n",
        "y_sub_RF = (y_pred_RF > percentage_RF).astype(int)\n",
        "\n",
        "sum(y_sub_RF),len(y_sub_RF)\n",
        "\"\"\""
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nRF_clf = RandomForestClassifier(n_estimators=100,max_depth=30, random_state=13)\\nRF_clf.fit(X, y)\\ny_pred_RF=RF_clf.predict(X_sub)\\npercentage_RF=0.004\\ny_sub_RF = (y_pred_RF > percentage_RF).astype(int)\\n\\nsum(y_sub_RF),len(y_sub_RF)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "695Ag1t-YDma",
        "colab_type": "text"
      },
      "source": [
        "# Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2zz5CB0_lL4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "ef8c8194-66b2-4c3f-c815-8f983bf2827f"
      },
      "source": [
        "sub2 = pd.DataFrame({'y_sub_LGB': y_sub_LGB,\n",
        "                     'y_sub_LR': y_sub_LR,\n",
        "                     'y_sub_RF': y_sub_RF,\n",
        "                     'y_sub_H': y_sub_H\n",
        "                     })\n",
        "sub2.corr()"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_sub_LGB</th>\n",
              "      <th>y_sub_LR</th>\n",
              "      <th>y_sub_RF</th>\n",
              "      <th>y_sub_H</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>y_sub_LGB</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.133561</td>\n",
              "      <td>0.659100</td>\n",
              "      <td>0.667687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>y_sub_LR</th>\n",
              "      <td>0.133561</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.153279</td>\n",
              "      <td>0.149122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>y_sub_RF</th>\n",
              "      <td>0.659100</td>\n",
              "      <td>0.153279</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.605649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>y_sub_H</th>\n",
              "      <td>0.667687</td>\n",
              "      <td>0.149122</td>\n",
              "      <td>0.605649</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           y_sub_LGB  y_sub_LR  y_sub_RF   y_sub_H\n",
              "y_sub_LGB   1.000000  0.133561  0.659100  0.667687\n",
              "y_sub_LR    0.133561  1.000000  0.153279  0.149122\n",
              "y_sub_RF    0.659100  0.153279  1.000000  0.605649\n",
              "y_sub_H     0.667687  0.149122  0.605649  1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-QBmIylTt3O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "636323c8-5a65-4949-a71b-205cbc4c11b7"
      },
      "source": [
        "sum(y_sub_LGB),sum(y_sub_LR),sum(y_sub_RF),sum(y_sub_H)"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9058, 9769, 7879, 8341)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOE7TSa1__L2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "6684daf1-6869-4012-d934-a458c28c5db7"
      },
      "source": [
        "sum_subs = y_sub_LGB + y_sub_H + y_sub_RF\n",
        "#sub['B'] = (sum_subs >= 2).astype(int)\n",
        "sub['B'] = y_sub_LGB\n",
        "\n",
        "sub.to_csv('submission_LGB_H_RF_ensemble.csv', index=False, header=False)\n",
        "sub.head()"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   A  B\n",
              "0  0  1\n",
              "1  1  1\n",
              "2  2  0\n",
              "3  3  0\n",
              "4  4  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLzVgCck73ED",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "66b5a4cd-c76d-4237-fd9f-b9bd44541ad7"
      },
      "source": [
        "sum(sub[\"B\"])"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9058"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGkTtqTFLjmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFYBKMQJrXac",
        "colab_type": "text"
      },
      "source": [
        "# Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bombv9qqVda2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "3d8ff2e9-8134-40df-ccbb-8314ae0c8e5d"
      },
      "source": [
        "files.download('submission_LGB_H_RF_ensemble.csv')"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_360da425-8305-496f-84b1-daff150d8383\", \"submission_LGB_H_RF_ensemble.csv\", 133290)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B49_UEjwoGQ1",
        "colab_type": "text"
      },
      "source": [
        "# LogisticRegression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcMTGP7YX2DF",
        "colab_type": "text"
      },
      "source": [
        "## def LogiReg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwUuRqTWTgfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LogisticRegressionのデータ分割\n",
        "X_train_LR, X_test_LR, y_train_LR, y_test_LR = train_test_split(X, y, test_size=0.2, random_state=11)\n",
        "#X_train2, X_valid, y_train2, y_valid = train_test_split(X, y, test_size=0.2, random_state=1)"
      ],
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rXu1Pj9uSex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LogiReg(seed):\n",
        "    positive_count_train = y_train_LR.sum()\n",
        "    sampler_LR = RandomUnderSampler(sampling_strategy={0:int(positive_count_train), 1:int(positive_count_train)},random_state=seed, replacement=True)\n",
        "    X_resampled_LR, y_resampled_LR = sampler_LR.fit_resample(X_train_LR, y_train_LR)\n",
        "    clf = LogisticRegression(penalty='l2', solver=\"sag\", random_state=seed)\n",
        "    clf.fit(X_resampled_LR, y_resampled_LR)\n",
        "\n",
        "    return clf"
      ],
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe960kd-v2Dw",
        "colab_type": "text"
      },
      "source": [
        "## Bagging of LogiReg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V0h0L3uhzd03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "ca15053b-fa28-4c69-e572-11ee41cda2a0"
      },
      "source": [
        "%%time\n",
        "models_LR = []\n",
        "\n",
        "for i in range(10,20):\n",
        "    models_LR.append(LogiReg(i))"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.31 s, sys: 9.13 ms, total: 1.31 s\n",
            "Wall time: 1.32 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab_type": "code",
        "id": "jIj9dbNjzd1J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "76ed8686-329e-409e-cde6-166ce5274dd3"
      },
      "source": [
        "y_preds_LR = []\n",
        "percentage_LR=0.2\n",
        "\n",
        "for clf in models_LR:\n",
        "    y_preds_LR.append(clf.predict(X_sub))\n",
        "y_subs_bagging_LR = sum(y_preds_LR)/len(y_preds_LR)\n",
        "y_sub_LR = (y_subs_bagging_LR > percentage_LR).astype(int)\n",
        "\n",
        "sum(y_sub_LR),len(y_sub_LR)"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9769, 18050)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jWVjOw8n99hx"
      },
      "source": [
        "## 全部　LR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MEssqTxI99hz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d7ede8b2-742c-4266-ad07-8e7db777b17e"
      },
      "source": [
        "\"\"\"\n",
        "LR_clf = LogisticRegression(penalty='l2', solver=\"sag\", random_state=15)\n",
        "LR_clf.fit(X, y)\n",
        "y_pred_LR=LR_clf.predict(X_sub)\n",
        "percentage_LR=0.4\n",
        "y_sub_LR = (y_pred_LR > percentage_LR).astype(int)\n",
        "\n",
        "sum(y_sub_LR),len(y_sub_LR)\n",
        "\"\"\""
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nLR_clf = LogisticRegression(penalty=\\'l2\\', solver=\"sag\", random_state=15)\\nLR_clf.fit(X, y)\\ny_pred_LR=LR_clf.predict(X_sub)\\npercentage_LR=0.4\\ny_sub_LR = (y_pred_LR > percentage_LR).astype(int)\\n\\nsum(y_sub_LR),len(y_sub_LR)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QwzruIxc2cK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 223,
      "outputs": []
    }
  ]
}