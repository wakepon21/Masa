{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "downsamplinh*bagging0823",
      "provenance": [],
      "collapsed_sections": [
        "k24AZlklO5Hl",
        "BhcmtmI8O5IB",
        "1GPPbOjMO5IQ"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wakepon21/Masa/blob/master/signate-23%E5%9B%9E%E7%9B%AE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF8YmhdLO5HG",
        "colab_type": "text"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1lgD7CtO5G-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LightGBM\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Imbalanced-learn\n",
        "from imblearn.under_sampling import RandomUnderSampler\n"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KI1Zd3haLl8a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7d801ec9-a519-48ef-d9dc-1719c9ff5296"
      },
      "source": [
        "#control\n",
        "!pip install git+https://github.com/pandas-profiling/pandas-profiling.git\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import pandas_profiling\n",
        "import seaborn as sns\n",
        "from pandas_profiling.utils.cache import cache_file\n",
        "\n",
        "#Optuna\n",
        "!pip install optuna\n",
        "import optuna\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "#何で必要なのか分かってない\n",
        "%matplotlib inline\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/pandas-profiling/pandas-profiling.git\n",
            "  Cloning https://github.com/pandas-profiling/pandas-profiling.git to /tmp/pip-req-build-2jrywfoy\n",
            "  Running command git clone -q https://github.com/pandas-profiling/pandas-profiling.git /tmp/pip-req-build-2jrywfoy\n",
            "Requirement already satisfied (use --upgrade to upgrade): pandas-profiling==2.9.0rc1 from git+https://github.com/pandas-profiling/pandas-profiling.git in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.9.0rc1) (0.16.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.9.0rc1) (1.4.1)\n",
            "Requirement already satisfied: pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.9.0rc1) (1.0.5)\n",
            "Requirement already satisfied: matplotlib>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.9.0rc1) (3.2.2)\n",
            "Requirement already satisfied: confuse>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.9.0rc1) (1.3.0)\n",
            "Requirement already satisfied: jinja2>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.9.0rc1) (2.11.2)\n",
            "Requirement already satisfied: visions[type_image_path]==0.4.4 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.9.0rc1) (0.4.4)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.9.0rc1) (1.18.5)\n",
            "Requirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.9.0rc1) (19.3.0)\n",
            "Requirement already satisfied: htmlmin>=0.1.12 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.9.0rc1) (0.1.12)\n",
            "Requirement already satisfied: missingno>=0.4.2 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.9.0rc1) (0.4.2)\n",
            "Requirement already satisfied: phik>=0.9.10 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.9.0rc1) (0.10.0)\n",
            "Requirement already satisfied: tangled-up-in-unicode>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.9.0rc1) (0.0.6)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.9.0rc1) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.43.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.9.0rc1) (4.48.2)\n",
            "Requirement already satisfied: ipywidgets>=7.5.1 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.9.0rc1) (7.5.1)\n",
            "Requirement already satisfied: seaborn>=0.10.1 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.9.0rc1) (0.10.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3->pandas-profiling==2.9.0rc1) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3->pandas-profiling==2.9.0rc1) (2018.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.2.0->pandas-profiling==2.9.0rc1) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.2.0->pandas-profiling==2.9.0rc1) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.2.0->pandas-profiling==2.9.0rc1) (2.4.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from confuse>=1.0.0->pandas-profiling==2.9.0rc1) (3.13)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.11.1->pandas-profiling==2.9.0rc1) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.6/dist-packages (from visions[type_image_path]==0.4.4->pandas-profiling==2.9.0rc1) (2.4)\n",
            "Requirement already satisfied: imagehash; extra == \"type_image_path\" in /usr/local/lib/python3.6/dist-packages (from visions[type_image_path]==0.4.4->pandas-profiling==2.9.0rc1) (4.1.0)\n",
            "Requirement already satisfied: Pillow; extra == \"type_image_path\" in /usr/local/lib/python3.6/dist-packages (from visions[type_image_path]==0.4.4->pandas-profiling==2.9.0rc1) (7.0.0)\n",
            "Requirement already satisfied: numba>=0.38.1 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.10->pandas-profiling==2.9.0rc1) (0.48.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.23.0->pandas-profiling==2.9.0rc1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.23.0->pandas-profiling==2.9.0rc1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.23.0->pandas-profiling==2.9.0rc1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.23.0->pandas-profiling==2.9.0rc1) (2020.6.20)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.5.1->pandas-profiling==2.9.0rc1) (5.5.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.5.1->pandas-profiling==2.9.0rc1) (5.0.7)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.5.1->pandas-profiling==2.9.0rc1) (4.10.1)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.5.1->pandas-profiling==2.9.0rc1) (4.3.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.5.1->pandas-profiling==2.9.0rc1) (3.5.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3->pandas-profiling==2.9.0rc1) (1.15.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.4->visions[type_image_path]==0.4.4->pandas-profiling==2.9.0rc1) (4.4.2)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.6/dist-packages (from imagehash; extra == \"type_image_path\"->visions[type_image_path]==0.4.4->pandas-profiling==2.9.0rc1) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.1->phik>=0.9.10->pandas-profiling==2.9.0rc1) (49.2.0)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.1->phik>=0.9.10->pandas-profiling==2.9.0rc1) (0.31.0)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.1->pandas-profiling==2.9.0rc1) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.1->pandas-profiling==2.9.0rc1) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.1->pandas-profiling==2.9.0rc1) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.1->pandas-profiling==2.9.0rc1) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.1->pandas-profiling==2.9.0rc1) (2.1.3)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0rc1) (0.2.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0rc1) (4.6.3)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0rc1) (2.6.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1->pandas-profiling==2.9.0rc1) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1->pandas-profiling==2.9.0rc1) (5.1.1)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0rc1) (5.3.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.1->pandas-profiling==2.9.0rc1) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.1->pandas-profiling==2.9.0rc1) (0.2.5)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.5.1->pandas-profiling==2.9.0rc1) (19.0.2)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0rc1) (1.5.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0rc1) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0rc1) (0.8.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0rc1) (0.6.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0rc1) (0.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0rc1) (0.4.4)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0rc1) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0rc1) (3.1.5)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0rc1) (1.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0rc1) (20.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->pandas-profiling==2.9.0rc1) (0.5.1)\n",
            "Building wheels for collected packages: pandas-profiling\n",
            "  Building wheel for pandas-profiling (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandas-profiling: filename=pandas_profiling-2.9.0rc1-py2.py3-none-any.whl size=258106 sha256=7894e0b671b90e2b014e2f198bdf8d12327516108dc4f2a6afb74b5e1d290c70\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bhtyh683/wheels/cd/13/75/8fcecd52c706914e90d916ede57f8c74de60e4c9ebc6c2f3b7\n",
            "Successfully built pandas-profiling\n",
            "Collecting optuna\n",
            "  Using cached https://files.pythonhosted.org/packages/06/b0/9a6313c78bca92abfacc08a2ad8b27bfe845256f615786ee2b6452ae1978/optuna-2.0.0.tar.gz\n",
            "Collecting alembic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/1e/cabc75a189de0fbb2841d0975243e59bde8b7822bacbb95008ac6fe9ad47/alembic-1.4.2.tar.gz (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 2.8MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cliff\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/06/03b1f92d46546a18eabf33ff7f37ef422c18c93d5a926bf590fee32ebe75/cliff-3.4.0-py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.1MB/s \n",
            "\u001b[?25hCollecting cmaes>=0.5.1\n",
            "  Downloading https://files.pythonhosted.org/packages/63/88/d5e9b78151dce671d7e78ee4cc8905d83208254caa2a386b163ae0ab0027/cmaes-0.6.0-py3-none-any.whl\n",
            "Collecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/2a/81/12d77537c82c5d46aa2721dfee25a0e873ef5920ebd0827152f411effb57/colorlog-4.2.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from optuna) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from optuna) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from optuna) (20.4)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.3.18)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from optuna) (4.48.2)\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from alembic->optuna) (2.8.1)\n",
            "Collecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Requirement already satisfied: PrettyTable<0.8,>=0.7.2 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (0.7.2)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/ba/aa953a11ec014b23df057ecdbc922fdb40ca8463466b1193f3367d2711a6/pbr-5.4.5-py2.py3-none-any.whl (110kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 18.0MB/s \n",
            "\u001b[?25hCollecting cmd2!=0.8.3,>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/f3/c1ebff567b8dba74eaa26f52bceda3242200ef092fafb56fcc4e105d5953/cmd2-1.3.4-py3-none-any.whl (130kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 15.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (3.13)\n",
            "Collecting stevedore>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/f4/041afc90e684f2b7d00a7f49abcbaf0b8c03e916bbc398ce49dce2a3c408/stevedore-3.2.0-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (2.4.7)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (1.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->optuna) (1.1.1)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (0.2.5)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/f6/5b/55866e1cde0f86f5eec59dab5de8a66628cb0d53da74b8dbc15ad8dabda3/pyperclip-1.8.0.tar.gz\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (19.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=1.6.0; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (1.7.0)\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: setuptools>=34.4 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (49.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=1.6.0; python_version < \"3.8\"->cmd2!=0.8.3,>=0.8.0->cliff->optuna) (3.1.0)\n",
            "Building wheels for collected packages: alembic\n",
            "  Building wheel for alembic (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alembic: filename=alembic-1.4.2-cp36-none-any.whl size=159543 sha256=19d4babcea3d07a23a97383a2c8ee5c2da8cee14a50efb12a64990a1fccfec05\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/04/83/76023f7a4c14688c0b5c2682a96392cfdd3ee4449eaaa287ef\n",
            "Successfully built alembic\n",
            "Building wheels for collected packages: optuna, pyperclip\n",
            "  Building wheel for optuna (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for optuna: filename=optuna-2.0.0-cp36-none-any.whl size=312964 sha256=df89813006667c44f8eac8591a2471ca4473202b8b9fd0bf5cafe77dd38a56da\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/c9/03/c45484454bf657ffed0ed6af153bd3d213928df115eb2a56eb\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.0-cp36-none-any.whl size=8693 sha256=6f2c93eece37635aa91639d0e4c07ba7f42b4be628b4f2022c5ede1957dc14eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/ac/0a/b784f0afe26eaf52e88a7e15c7369090deea0354fa1c6fc689\n",
            "Successfully built optuna pyperclip\n",
            "Installing collected packages: Mako, python-editor, alembic, pbr, pyperclip, colorama, cmd2, stevedore, cliff, cmaes, colorlog, optuna\n",
            "Successfully installed Mako-1.1.3 alembic-1.4.2 cliff-3.4.0 cmaes-0.6.0 cmd2-1.3.4 colorama-0.4.3 colorlog-4.2.1 optuna-2.0.0 pbr-5.4.5 pyperclip-1.8.0 python-editor-1.0.4 stevedore-3.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jw4TmFfKx2SL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f73a0dec-46c8-473c-ca7f-819ca6f6a2e5"
      },
      "source": [
        "#train,test,submit_sampleのみっつがそろっているか確認\n",
        "!ls"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\t\t       submit_sample.csv  train.csv\n",
            "submission_lightgbm_kfold.csv  test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHdnUDx0ufsI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "outputId": "6ce5b9b2-4300-4f2f-d85f-12fb8cc808a6"
      },
      "source": [
        "#そろっていなかったら選択\n",
        "from google.colab import files\n",
        "train_up = files.upload()"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ed6a0806-8933-4782-9af5-fbc8e244bf59\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ed6a0806-8933-4782-9af5-fbc8e244bf59\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-121-37c1010706dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#そろっていなかったら選択\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_up\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m   result = _output.eval_js(\n\u001b[1;32m     63\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[0;32m---> 64\u001b[0;31m           input_id=input_id, output_id=output_id))\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: TypeError: Cannot read property '_uploadFiles' of undefined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWkc1BR0EfDx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub = pd.read_csv(\"submit_sample.csv\",names=(\"A\",\"B\"))\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "train = pd.read_csv(\"train.csv\")\n"
      ],
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pN5JFRzPLz7N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "data = pd.concat([train,test], sort=False)\n",
        "\n",
        "#特徴量をエンジニアリング\n",
        "data[\"income\"]=data[\"job\"].copy()\n",
        "data[\"goodincome\"]=data[\"job\"].copy()\n",
        "data[\"job\"].replace(['blue-collar','management','technician','admin.','services',\\\n",
        "                     'unknown','self-employed','entrepreneur','student','retired',\\\n",
        "                     'unemployed','housemaid'],[0,1,2,3,4,5,6,7,8,9,10,11],inplace=True)\n",
        "data[\"loan\"].replace(['yes','no'],[1,0],inplace=True)\n",
        "data[\"married\"]=data[\"marital\"]\n",
        "data[\"single\"]=data[\"marital\"]\n",
        "data['education'].replace(['secondary','tertiary','primary','unknown'],[3,1,0,2],inplace=True)\n",
        "data[\"housing\"].replace(['yes','no'],[1,0],inplace=True)\n",
        "data[\"contact\"].replace(['cellular','telephone','unknown'],[2,1,0],inplace=True)\n",
        "data[\"poutcome\"].replace(['success','failure','unknown','other'],[3,1,2,0],inplace=True)\n",
        "#data[\"job\"] = data[\"job\"].astype(np.int64)\n",
        "\n",
        "data[\"month\"].replace(['jan','feb','mar','apr','may','jun','jul','aug','sep','oct','nov','des'],\\\n",
        "                      [3,4,5,6,7,8,9,10,11,0,1,2],inplace=True)\n",
        "#data[\"y\"].astype(np.int64)\n",
        "#ここから追加\n",
        "data[\"year\"]=data[\"month\"]*30+data[\"day\"]\n",
        "data[\"campaign+previous\"]=data[\"campaign\"] + data[\"previous\"]\n",
        "data[\"poutcome/pdays\"]=data[\"poutcome\"] / (data[\"pdays\"]+10) * 10000\n",
        "data[\"poutcome/pdays\"] = data[\"poutcome/pdays\"].astype(np.int64)\n",
        "data[\"income\"].replace(['blue-collar','management','technician',\\\n",
        "                                         'admin.','services','unknown','self-employed',\\\n",
        "                                         'entrepreneur','student','retired','unemployed','housemaid'],\\\n",
        "                                        [0,0,0,0,0,0,0,0,1,1,1,0],inplace=True)\n",
        "data[\"goodincome\"].replace(['blue-collar','management','technician','admin.','services','unknown','self-employed','entrepreneur','student','retired','unemployed','housemaid'],\\\n",
        "                                                [0,1,0,1,0,0,1,1,0,0,0,0],inplace=True)\n",
        "data[\"housing+loan\"] = data[\"housing\"] + data[\"loan\"]\n",
        "data[\"duration*campaign\"] = data[\"duration\"] * data[\"campaign\"] \n",
        "data[\"married\"].replace(['married','single','divorced'],[1,0,1],inplace=True)\n",
        "data[\"single\"].replace(['married','single','divorced'],[1,0,0],inplace=True)\n",
        "train[\"y\"]=train[\"y\"].astype(np.int64)\n",
        "\n",
        "#全体のうち、残したいモノだけ選ぶ\n",
        "all_columns = list(train.columns)\n",
        "remain_columns = ['age','job','education','balance','housing','loan',\n",
        "                  'contact','day','month','duration','campaign','pdays','previous',\n",
        "                  'poutcome','y','income','goodincome',\"married\",\"single\",\"year\",\n",
        "                  'campaign+previous'\t,'poutcome/pdays'\t,'housing+loan','duration*campaign']\n",
        "                  \n",
        "delete_columns = list(set(all_columns)-set(remain_columns))\n",
        "data.drop(delete_columns, axis=1, inplace=True)\n",
        "\n",
        "#trainとtestを再度切り分け\n",
        "train = data[:len(train)]\n",
        "test = data[len(train):]\n",
        "\n",
        "#train,testを、さらに説明変数Xと、予測変数yに切り分け。y_testは与えられていないのでなし。三種類がでる\n",
        "y = train['y']\n",
        "X = train.drop('y', axis = 1)\n",
        "X_sub = test.drop('y', axis = 1)\n",
        "#Xcolumns=X_train.columns"
      ],
      "execution_count": 253,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsajDLmyO5HN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8da018c1-d379-4332-d89b-286702ab8722"
      },
      "source": [
        "len(y[y == 0]), len(y[y == 1])"
      ],
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24988, 2112)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "TFO1MejzO5HV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5dfe8b1b-efb7-46da-c84c-491d8a057315"
      },
      "source": [
        "len(y[y == 1])/len(y)"
      ],
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07793357933579335"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxjvhsIDKKE0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "eb4f4dc2-999b-4eb5-b01d-db0b85af236d"
      },
      "source": [
        "X"
      ],
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>job</th>\n",
              "      <th>education</th>\n",
              "      <th>balance</th>\n",
              "      <th>housing</th>\n",
              "      <th>loan</th>\n",
              "      <th>contact</th>\n",
              "      <th>day</th>\n",
              "      <th>month</th>\n",
              "      <th>duration</th>\n",
              "      <th>campaign</th>\n",
              "      <th>pdays</th>\n",
              "      <th>previous</th>\n",
              "      <th>poutcome</th>\n",
              "      <th>income</th>\n",
              "      <th>goodincome</th>\n",
              "      <th>married</th>\n",
              "      <th>single</th>\n",
              "      <th>year</th>\n",
              "      <th>campaign+previous</th>\n",
              "      <th>poutcome/pdays</th>\n",
              "      <th>housing+loan</th>\n",
              "      <th>duration*campaign</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>12294</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>101</td>\n",
              "      <td>3</td>\n",
              "      <td>498</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>51</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>29</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>43027</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>22</td>\n",
              "      <td>10</td>\n",
              "      <td>158</td>\n",
              "      <td>2</td>\n",
              "      <td>702</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>322</td>\n",
              "      <td>2</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>12252</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>351</td>\n",
              "      <td>1</td>\n",
              "      <td>826</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>99121</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>7</td>\n",
              "      <td>658</td>\n",
              "      <td>2</td>\n",
              "      <td>120</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>226</td>\n",
              "      <td>2</td>\n",
              "      <td>76</td>\n",
              "      <td>2</td>\n",
              "      <td>1316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>48</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>42005</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>177</td>\n",
              "      <td>1</td>\n",
              "      <td>273</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>183</td>\n",
              "      <td>1</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27095</th>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>26661</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>27</td>\n",
              "      <td>7</td>\n",
              "      <td>345</td>\n",
              "      <td>4</td>\n",
              "      <td>425</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>237</td>\n",
              "      <td>4</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>1380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27096</th>\n",
              "      <td>35</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>42150</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>27</td>\n",
              "      <td>7</td>\n",
              "      <td>121</td>\n",
              "      <td>1</td>\n",
              "      <td>719</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>237</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27097</th>\n",
              "      <td>35</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>34531</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>28</td>\n",
              "      <td>8</td>\n",
              "      <td>177</td>\n",
              "      <td>2</td>\n",
              "      <td>121</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>268</td>\n",
              "      <td>2</td>\n",
              "      <td>152</td>\n",
              "      <td>0</td>\n",
              "      <td>354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27098</th>\n",
              "      <td>30</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>99621</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>27</td>\n",
              "      <td>7</td>\n",
              "      <td>121</td>\n",
              "      <td>1</td>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>237</td>\n",
              "      <td>1</td>\n",
              "      <td>181</td>\n",
              "      <td>1</td>\n",
              "      <td>121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27099</th>\n",
              "      <td>34</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8657</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>27</td>\n",
              "      <td>7</td>\n",
              "      <td>345</td>\n",
              "      <td>2</td>\n",
              "      <td>321</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>237</td>\n",
              "      <td>2</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>690</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>27100 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       age  job  education  ...  poutcome/pdays  housing+loan  duration*campaign\n",
              "0       31    4          3  ...               0             1                303\n",
              "1       29    7          1  ...              28             0                316\n",
              "2       35    1          1  ...              11             1                351\n",
              "3       31    2          3  ...              76             2               1316\n",
              "4       48   10          0  ...              70             1                177\n",
              "...    ...  ...        ...  ...             ...           ...                ...\n",
              "27095   37    0          3  ...              45             1               1380\n",
              "27096   35    4          3  ...              27             1                121\n",
              "27097   35    4          2  ...             152             0                354\n",
              "27098   30    3          3  ...             181             1                121\n",
              "27099   34    1          1  ...              60             1                690\n",
              "\n",
              "[27100 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YudCwI-lKU3Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "732e51ea-c0c4-4106-88fd-c9317a9ad181"
      },
      "source": [
        "len(X)"
      ],
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 257
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emTTZbQIKWPq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e1370665-588c-4a9b-cd65-48f4b3e42d73"
      },
      "source": [
        "len(y)"
      ],
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGLtDD-IKNXS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "89c6ba13-1957-4440-ffb9-e39d9b2c660d"
      },
      "source": [
        "y"
      ],
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        0.0\n",
              "1        1.0\n",
              "2        0.0\n",
              "3        0.0\n",
              "4        0.0\n",
              "        ... \n",
              "27095    0.0\n",
              "27096    0.0\n",
              "27097    0.0\n",
              "27098    0.0\n",
              "27099    0.0\n",
              "Name: y, Length: 27100, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pg5blmY4KP2i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9d3eb00e-e07e-4446-a81e-eb4092224077"
      },
      "source": [
        "sum(y)"
      ],
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2112.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 260
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdh9uPAfO5Hb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imbalanced_data_split(X, y, test_size=0.2):\n",
        "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
        "    for train_index, test_index in sss.split(X, y):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "        return X_train, X_test, y_train, y_test"
      ],
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8r5hXuIO5Hg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = imbalanced_data_split(X.values, y.values, test_size=0.2)\n",
        "X_train2, X_valid, y_train2, y_valid = imbalanced_data_split(X_train, y_train, test_size=0.2)"
      ],
      "execution_count": 262,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQkATlfOKR96",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "04d4f2d1-8c09-411e-88a0-aed7d8e9cec3"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 30,   7,   1, ...,  56,   0, 152],\n",
              "       [ 60,   9,   3, ...,  83,   1, 303],\n",
              "       [ 31,   2,   0, ...,  25,   1, 121],\n",
              "       ...,\n",
              "       [ 29,   7,   2, ...,  43,   0, 826],\n",
              "       [ 30,   0,   3, ...,  27,   1, 363],\n",
              "       [ 31,   0,   3, ...,  58,   1, 304]], dtype=int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2Hj_ka5KTXZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "218aa2c0-b27b-4a35-ff9b-52fceb982fde"
      },
      "source": [
        "len(X_train)"
      ],
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21680"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pDzhNWBKb4N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a01c57ac-56a7-4a15-d0b8-bea5ae0ec4ef"
      },
      "source": [
        "len(y_train)"
      ],
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21680"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 265
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mbD8kqdZDNy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b5db285c-10c7-44a0-a3fd-c969b701a1be"
      },
      "source": [
        "y_test"
      ],
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 266
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWakFvp4ZE25",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "947b5dbd-45c3-46b4-8a58-6ee5c7b38561"
      },
      "source": [
        "len(y_test)"
      ],
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5420"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 267
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k24AZlklO5Hl",
        "colab_type": "text"
      },
      "source": [
        "# LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdomFxgIO5Hm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lgbm_params = {\n",
        "    'learning_rate': 0.05,\n",
        "    'num_leaves': 40,\n",
        "    'boosting_type' : 'gbdt',\n",
        "    'reg_alpha' : 1,\n",
        "    'reg_lambda' : 1,\n",
        "    'objective': 'binary',\n",
        "    'max_bin': 300,\n",
        "    'metric': 'auc',\n",
        "}\n",
        "\n",
        "#categorical_features = ['job','education','housing','loan','contact','poutcome',\"income\",'goodincome','married',\"single\",'housing+loan']\n",
        "#X_train[categorical_features]=X_train[categorical_features].astype('category')"
      ],
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lja5ioHeO5Ht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lgbm_train(X_train_df, X_valid_df, y_train_df, y_valid_df, lgbm_params):\n",
        "    lgb_train = lgb.Dataset(X_train_df, y_train_df)\n",
        "    lgb_eval = lgb.Dataset(X_valid_df, y_valid_df, reference=lgb_train)\n",
        "\n",
        "    # 上記のパラメータでモデルを学習する\n",
        "    model = lgb.train(lgbm_params, lgb_train,\n",
        "                      # モデルの評価用データを渡す\n",
        "                      valid_sets=lgb_eval,\n",
        "                      # 最大で 1000 ラウンドまで学習する\n",
        "                      num_boost_round=1000,\n",
        "                      # 10 ラウンド経過しても性能が向上しないときは学習を打ち切る\n",
        "                      early_stopping_rounds=10)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElqnNPbLO5Hy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "77f2cc24-c0f4-4b4f-ba21-58f446a6fece"
      },
      "source": [
        "%%time\n",
        "model_normal = lgbm_train(X_train2, X_valid, y_train2, y_valid, lgbm_params)"
      ],
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's auc: 0.805251\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's auc: 0.815825\n",
            "[3]\tvalid_0's auc: 0.817747\n",
            "[4]\tvalid_0's auc: 0.8218\n",
            "[5]\tvalid_0's auc: 0.825149\n",
            "[6]\tvalid_0's auc: 0.827336\n",
            "[7]\tvalid_0's auc: 0.830136\n",
            "[8]\tvalid_0's auc: 0.830165\n",
            "[9]\tvalid_0's auc: 0.831059\n",
            "[10]\tvalid_0's auc: 0.831259\n",
            "[11]\tvalid_0's auc: 0.833037\n",
            "[12]\tvalid_0's auc: 0.833967\n",
            "[13]\tvalid_0's auc: 0.83466\n",
            "[14]\tvalid_0's auc: 0.835408\n",
            "[15]\tvalid_0's auc: 0.837015\n",
            "[16]\tvalid_0's auc: 0.837062\n",
            "[17]\tvalid_0's auc: 0.837236\n",
            "[18]\tvalid_0's auc: 0.839483\n",
            "[19]\tvalid_0's auc: 0.839535\n",
            "[20]\tvalid_0's auc: 0.840581\n",
            "[21]\tvalid_0's auc: 0.841271\n",
            "[22]\tvalid_0's auc: 0.841602\n",
            "[23]\tvalid_0's auc: 0.84293\n",
            "[24]\tvalid_0's auc: 0.844172\n",
            "[25]\tvalid_0's auc: 0.845816\n",
            "[26]\tvalid_0's auc: 0.845874\n",
            "[27]\tvalid_0's auc: 0.847107\n",
            "[28]\tvalid_0's auc: 0.848084\n",
            "[29]\tvalid_0's auc: 0.848422\n",
            "[30]\tvalid_0's auc: 0.848841\n",
            "[31]\tvalid_0's auc: 0.849253\n",
            "[32]\tvalid_0's auc: 0.849786\n",
            "[33]\tvalid_0's auc: 0.850122\n",
            "[34]\tvalid_0's auc: 0.851136\n",
            "[35]\tvalid_0's auc: 0.851558\n",
            "[36]\tvalid_0's auc: 0.851759\n",
            "[37]\tvalid_0's auc: 0.852529\n",
            "[38]\tvalid_0's auc: 0.852704\n",
            "[39]\tvalid_0's auc: 0.852815\n",
            "[40]\tvalid_0's auc: 0.853509\n",
            "[41]\tvalid_0's auc: 0.853772\n",
            "[42]\tvalid_0's auc: 0.854039\n",
            "[43]\tvalid_0's auc: 0.854079\n",
            "[44]\tvalid_0's auc: 0.854596\n",
            "[45]\tvalid_0's auc: 0.855041\n",
            "[46]\tvalid_0's auc: 0.855512\n",
            "[47]\tvalid_0's auc: 0.855336\n",
            "[48]\tvalid_0's auc: 0.855549\n",
            "[49]\tvalid_0's auc: 0.856055\n",
            "[50]\tvalid_0's auc: 0.856632\n",
            "[51]\tvalid_0's auc: 0.857681\n",
            "[52]\tvalid_0's auc: 0.858242\n",
            "[53]\tvalid_0's auc: 0.858533\n",
            "[54]\tvalid_0's auc: 0.858737\n",
            "[55]\tvalid_0's auc: 0.859225\n",
            "[56]\tvalid_0's auc: 0.859205\n",
            "[57]\tvalid_0's auc: 0.859785\n",
            "[58]\tvalid_0's auc: 0.859552\n",
            "[59]\tvalid_0's auc: 0.860014\n",
            "[60]\tvalid_0's auc: 0.860079\n",
            "[61]\tvalid_0's auc: 0.861036\n",
            "[62]\tvalid_0's auc: 0.861589\n",
            "[63]\tvalid_0's auc: 0.861788\n",
            "[64]\tvalid_0's auc: 0.861873\n",
            "[65]\tvalid_0's auc: 0.862388\n",
            "[66]\tvalid_0's auc: 0.862517\n",
            "[67]\tvalid_0's auc: 0.862735\n",
            "[68]\tvalid_0's auc: 0.863154\n",
            "[69]\tvalid_0's auc: 0.863524\n",
            "[70]\tvalid_0's auc: 0.863419\n",
            "[71]\tvalid_0's auc: 0.863609\n",
            "[72]\tvalid_0's auc: 0.863902\n",
            "[73]\tvalid_0's auc: 0.864275\n",
            "[74]\tvalid_0's auc: 0.864409\n",
            "[75]\tvalid_0's auc: 0.864451\n",
            "[76]\tvalid_0's auc: 0.864434\n",
            "[77]\tvalid_0's auc: 0.864947\n",
            "[78]\tvalid_0's auc: 0.865235\n",
            "[79]\tvalid_0's auc: 0.865706\n",
            "[80]\tvalid_0's auc: 0.865795\n",
            "[81]\tvalid_0's auc: 0.865934\n",
            "[82]\tvalid_0's auc: 0.865932\n",
            "[83]\tvalid_0's auc: 0.865941\n",
            "[84]\tvalid_0's auc: 0.866159\n",
            "[85]\tvalid_0's auc: 0.866199\n",
            "[86]\tvalid_0's auc: 0.866236\n",
            "[87]\tvalid_0's auc: 0.86605\n",
            "[88]\tvalid_0's auc: 0.866079\n",
            "[89]\tvalid_0's auc: 0.866339\n",
            "[90]\tvalid_0's auc: 0.866532\n",
            "[91]\tvalid_0's auc: 0.866541\n",
            "[92]\tvalid_0's auc: 0.866405\n",
            "[93]\tvalid_0's auc: 0.866576\n",
            "[94]\tvalid_0's auc: 0.866667\n",
            "[95]\tvalid_0's auc: 0.866718\n",
            "[96]\tvalid_0's auc: 0.86654\n",
            "[97]\tvalid_0's auc: 0.866581\n",
            "[98]\tvalid_0's auc: 0.866568\n",
            "[99]\tvalid_0's auc: 0.866451\n",
            "[100]\tvalid_0's auc: 0.86646\n",
            "[101]\tvalid_0's auc: 0.866456\n",
            "[102]\tvalid_0's auc: 0.866464\n",
            "[103]\tvalid_0's auc: 0.866327\n",
            "[104]\tvalid_0's auc: 0.86628\n",
            "[105]\tvalid_0's auc: 0.866395\n",
            "Early stopping, best iteration is:\n",
            "[95]\tvalid_0's auc: 0.866718\n",
            "CPU times: user 2.14 s, sys: 81.1 ms, total: 2.22 s\n",
            "Wall time: 1.53 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4qkOGVbO5H4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0f7cd30f-3bba-4d0c-b017-5c117e6746e4"
      },
      "source": [
        "# テストデータを予測する\n",
        "y_pred_normal = model_normal.predict(X_test, num_iteration=model_normal.best_iteration)\n",
        "\n",
        "# auc を計算する\n",
        "auc = roc_auc_score(y_test, y_pred_normal)\n",
        "print(auc)"
      ],
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.850349618520394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9HHgeANXVn2",
        "colab_type": "text"
      },
      "source": [
        "# Optuna\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhcmtmI8O5IB",
        "colab_type": "text"
      },
      "source": [
        "# Imbalanced-learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6DewnICO5IC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sampler = RandomUnderSampler(random_state=42)\n",
        "X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
        "X_train2, X_valid, y_train2, y_valid = imbalanced_data_split(X_resampled, y_resampled, test_size=0.2)"
      ],
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZorKeACO5IG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d94f14b8-1169-4cd8-fec7-5df79bd93698"
      },
      "source": [
        "%%time\n",
        "model_under_sample = lgbm_train(X_train2, X_valid, y_train2, y_valid, lgbm_params)"
      ],
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's auc: 0.782838\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's auc: 0.783844\n",
            "[3]\tvalid_0's auc: 0.787057\n",
            "[4]\tvalid_0's auc: 0.790619\n",
            "[5]\tvalid_0's auc: 0.793744\n",
            "[6]\tvalid_0's auc: 0.79669\n",
            "[7]\tvalid_0's auc: 0.798335\n",
            "[8]\tvalid_0's auc: 0.799784\n",
            "[9]\tvalid_0's auc: 0.800313\n",
            "[10]\tvalid_0's auc: 0.801469\n",
            "[11]\tvalid_0's auc: 0.802383\n",
            "[12]\tvalid_0's auc: 0.802952\n",
            "[13]\tvalid_0's auc: 0.801346\n",
            "[14]\tvalid_0's auc: 0.800939\n",
            "[15]\tvalid_0's auc: 0.802423\n",
            "[16]\tvalid_0's auc: 0.802283\n",
            "[17]\tvalid_0's auc: 0.803136\n",
            "[18]\tvalid_0's auc: 0.803788\n",
            "[19]\tvalid_0's auc: 0.80385\n",
            "[20]\tvalid_0's auc: 0.804099\n",
            "[21]\tvalid_0's auc: 0.804742\n",
            "[22]\tvalid_0's auc: 0.804598\n",
            "[23]\tvalid_0's auc: 0.805136\n",
            "[24]\tvalid_0's auc: 0.80581\n",
            "[25]\tvalid_0's auc: 0.806038\n",
            "[26]\tvalid_0's auc: 0.806388\n",
            "[27]\tvalid_0's auc: 0.806169\n",
            "[28]\tvalid_0's auc: 0.807373\n",
            "[29]\tvalid_0's auc: 0.808428\n",
            "[30]\tvalid_0's auc: 0.808664\n",
            "[31]\tvalid_0's auc: 0.809369\n",
            "[32]\tvalid_0's auc: 0.809193\n",
            "[33]\tvalid_0's auc: 0.807968\n",
            "[34]\tvalid_0's auc: 0.80876\n",
            "[35]\tvalid_0's auc: 0.809172\n",
            "[36]\tvalid_0's auc: 0.809347\n",
            "[37]\tvalid_0's auc: 0.809942\n",
            "[38]\tvalid_0's auc: 0.809758\n",
            "[39]\tvalid_0's auc: 0.809312\n",
            "[40]\tvalid_0's auc: 0.808883\n",
            "[41]\tvalid_0's auc: 0.809316\n",
            "[42]\tvalid_0's auc: 0.809237\n",
            "[43]\tvalid_0's auc: 0.80908\n",
            "[44]\tvalid_0's auc: 0.809097\n",
            "[45]\tvalid_0's auc: 0.809609\n",
            "[46]\tvalid_0's auc: 0.809653\n",
            "[47]\tvalid_0's auc: 0.810152\n",
            "[48]\tvalid_0's auc: 0.810406\n",
            "[49]\tvalid_0's auc: 0.810651\n",
            "[50]\tvalid_0's auc: 0.810808\n",
            "[51]\tvalid_0's auc: 0.811185\n",
            "[52]\tvalid_0's auc: 0.811544\n",
            "[53]\tvalid_0's auc: 0.811876\n",
            "[54]\tvalid_0's auc: 0.811999\n",
            "[55]\tvalid_0's auc: 0.812402\n",
            "[56]\tvalid_0's auc: 0.812795\n",
            "[57]\tvalid_0's auc: 0.812997\n",
            "[58]\tvalid_0's auc: 0.813356\n",
            "[59]\tvalid_0's auc: 0.814047\n",
            "[60]\tvalid_0's auc: 0.81375\n",
            "[61]\tvalid_0's auc: 0.814038\n",
            "[62]\tvalid_0's auc: 0.814424\n",
            "[63]\tvalid_0's auc: 0.814459\n",
            "[64]\tvalid_0's auc: 0.814485\n",
            "[65]\tvalid_0's auc: 0.814712\n",
            "[66]\tvalid_0's auc: 0.81438\n",
            "[67]\tvalid_0's auc: 0.814642\n",
            "[68]\tvalid_0's auc: 0.814791\n",
            "[69]\tvalid_0's auc: 0.814695\n",
            "[70]\tvalid_0's auc: 0.814984\n",
            "[71]\tvalid_0's auc: 0.815203\n",
            "[72]\tvalid_0's auc: 0.814914\n",
            "[73]\tvalid_0's auc: 0.814984\n",
            "[74]\tvalid_0's auc: 0.81508\n",
            "[75]\tvalid_0's auc: 0.814826\n",
            "[76]\tvalid_0's auc: 0.814222\n",
            "[77]\tvalid_0's auc: 0.814196\n",
            "[78]\tvalid_0's auc: 0.814424\n",
            "[79]\tvalid_0's auc: 0.813907\n",
            "[80]\tvalid_0's auc: 0.814038\n",
            "[81]\tvalid_0's auc: 0.81452\n",
            "Early stopping, best iteration is:\n",
            "[71]\tvalid_0's auc: 0.815203\n",
            "CPU times: user 879 ms, sys: 52 ms, total: 931 ms\n",
            "Wall time: 756 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ma7tzD0O5IK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1e316e45-3234-4de0-a0c1-d10cb0727f5d"
      },
      "source": [
        "# テストデータを予測する\n",
        "y_pred_under_sample = model_under_sample.predict(X_test, num_iteration=model_under_sample.best_iteration)\n",
        "\n",
        "# auc を計算する\n",
        "auc = roc_auc_score(y_test, y_pred_under_sample)\n",
        "print(auc)"
      ],
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8430898425721\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GPPbOjMO5IQ",
        "colab_type": "text"
      },
      "source": [
        "# Bagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uk1tpY_GO5IR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bagging(seed):\n",
        "    sampler = RandomUnderSampler(random_state=seed, replacement=True)\n",
        "    X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
        "    X_train2, X_valid, y_train2, y_valid = imbalanced_data_split(X_resampled, y_resampled, test_size=0.2)\n",
        "    model_bagging = lgbm_train(X_train2, X_valid, y_train2, y_valid, lgbm_params)\n",
        "    return model_bagging"
      ],
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iT-IUB1O5IV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "daf37916-cd55-4cf8-8fad-182bfd20a9f9"
      },
      "source": [
        "%%time\n",
        "models = []\n",
        "\n",
        "for i in range(10):\n",
        "    models.append(bagging(i))"
      ],
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's auc: 0.800335\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's auc: 0.798519\n",
            "[3]\tvalid_0's auc: 0.799272\n",
            "[4]\tvalid_0's auc: 0.798983\n",
            "[5]\tvalid_0's auc: 0.798217\n",
            "[6]\tvalid_0's auc: 0.805683\n",
            "[7]\tvalid_0's auc: 0.805727\n",
            "[8]\tvalid_0's auc: 0.810156\n",
            "[9]\tvalid_0's auc: 0.812143\n",
            "[10]\tvalid_0's auc: 0.811465\n",
            "[11]\tvalid_0's auc: 0.812218\n",
            "[12]\tvalid_0's auc: 0.812668\n",
            "[13]\tvalid_0's auc: 0.812787\n",
            "[14]\tvalid_0's auc: 0.812524\n",
            "[15]\tvalid_0's auc: 0.812546\n",
            "[16]\tvalid_0's auc: 0.814533\n",
            "[17]\tvalid_0's auc: 0.815767\n",
            "[18]\tvalid_0's auc: 0.816783\n",
            "[19]\tvalid_0's auc: 0.817684\n",
            "[20]\tvalid_0's auc: 0.816577\n",
            "[21]\tvalid_0's auc: 0.817124\n",
            "[22]\tvalid_0's auc: 0.817216\n",
            "[23]\tvalid_0's auc: 0.817531\n",
            "[24]\tvalid_0's auc: 0.818113\n",
            "[25]\tvalid_0's auc: 0.818376\n",
            "[26]\tvalid_0's auc: 0.818726\n",
            "[27]\tvalid_0's auc: 0.819443\n",
            "[28]\tvalid_0's auc: 0.81912\n",
            "[29]\tvalid_0's auc: 0.819146\n",
            "[30]\tvalid_0's auc: 0.819452\n",
            "[31]\tvalid_0's auc: 0.820061\n",
            "[32]\tvalid_0's auc: 0.819842\n",
            "[33]\tvalid_0's auc: 0.820818\n",
            "[34]\tvalid_0's auc: 0.820665\n",
            "[35]\tvalid_0's auc: 0.820971\n",
            "[36]\tvalid_0's auc: 0.820787\n",
            "[37]\tvalid_0's auc: 0.82112\n",
            "[38]\tvalid_0's auc: 0.821943\n",
            "[39]\tvalid_0's auc: 0.822647\n",
            "[40]\tvalid_0's auc: 0.822166\n",
            "[41]\tvalid_0's auc: 0.822297\n",
            "[42]\tvalid_0's auc: 0.823575\n",
            "[43]\tvalid_0's auc: 0.823807\n",
            "[44]\tvalid_0's auc: 0.824446\n",
            "[45]\tvalid_0's auc: 0.825172\n",
            "[46]\tvalid_0's auc: 0.825934\n",
            "[47]\tvalid_0's auc: 0.826564\n",
            "[48]\tvalid_0's auc: 0.826814\n",
            "[49]\tvalid_0's auc: 0.827155\n",
            "[50]\tvalid_0's auc: 0.827636\n",
            "[51]\tvalid_0's auc: 0.828078\n",
            "[52]\tvalid_0's auc: 0.82849\n",
            "[53]\tvalid_0's auc: 0.829164\n",
            "[54]\tvalid_0's auc: 0.829523\n",
            "[55]\tvalid_0's auc: 0.829803\n",
            "[56]\tvalid_0's auc: 0.830118\n",
            "[57]\tvalid_0's auc: 0.830661\n",
            "[58]\tvalid_0's auc: 0.830985\n",
            "[59]\tvalid_0's auc: 0.831422\n",
            "[60]\tvalid_0's auc: 0.831834\n",
            "[61]\tvalid_0's auc: 0.832122\n",
            "[62]\tvalid_0's auc: 0.831895\n",
            "[63]\tvalid_0's auc: 0.832184\n",
            "[64]\tvalid_0's auc: 0.83298\n",
            "[65]\tvalid_0's auc: 0.833987\n",
            "[66]\tvalid_0's auc: 0.833934\n",
            "[67]\tvalid_0's auc: 0.834188\n",
            "[68]\tvalid_0's auc: 0.834757\n",
            "[69]\tvalid_0's auc: 0.834775\n",
            "[70]\tvalid_0's auc: 0.834643\n",
            "[71]\tvalid_0's auc: 0.835335\n",
            "[72]\tvalid_0's auc: 0.83495\n",
            "[73]\tvalid_0's auc: 0.835431\n",
            "[74]\tvalid_0's auc: 0.835492\n",
            "[75]\tvalid_0's auc: 0.835668\n",
            "[76]\tvalid_0's auc: 0.835808\n",
            "[77]\tvalid_0's auc: 0.836088\n",
            "[78]\tvalid_0's auc: 0.83635\n",
            "[79]\tvalid_0's auc: 0.835326\n",
            "[80]\tvalid_0's auc: 0.835212\n",
            "[81]\tvalid_0's auc: 0.835239\n",
            "[82]\tvalid_0's auc: 0.835055\n",
            "[83]\tvalid_0's auc: 0.835239\n",
            "[84]\tvalid_0's auc: 0.835536\n",
            "[85]\tvalid_0's auc: 0.836166\n",
            "[86]\tvalid_0's auc: 0.836035\n",
            "[87]\tvalid_0's auc: 0.835886\n",
            "[88]\tvalid_0's auc: 0.835247\n",
            "Early stopping, best iteration is:\n",
            "[78]\tvalid_0's auc: 0.83635\n",
            "[1]\tvalid_0's auc: 0.806003\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's auc: 0.808795\n",
            "[3]\tvalid_0's auc: 0.804152\n",
            "[4]\tvalid_0's auc: 0.808629\n",
            "[5]\tvalid_0's auc: 0.809513\n",
            "[6]\tvalid_0's auc: 0.813229\n",
            "[7]\tvalid_0's auc: 0.816231\n",
            "[8]\tvalid_0's auc: 0.815828\n",
            "[9]\tvalid_0's auc: 0.817492\n",
            "[10]\tvalid_0's auc: 0.818065\n",
            "[11]\tvalid_0's auc: 0.820883\n",
            "[12]\tvalid_0's auc: 0.820354\n",
            "[13]\tvalid_0's auc: 0.821724\n",
            "[14]\tvalid_0's auc: 0.823601\n",
            "[15]\tvalid_0's auc: 0.824385\n",
            "[16]\tvalid_0's auc: 0.825531\n",
            "[17]\tvalid_0's auc: 0.82568\n",
            "[18]\tvalid_0's auc: 0.826726\n",
            "[19]\tvalid_0's auc: 0.827387\n",
            "[20]\tvalid_0's auc: 0.828166\n",
            "[21]\tvalid_0's auc: 0.828429\n",
            "[22]\tvalid_0's auc: 0.828604\n",
            "[23]\tvalid_0's auc: 0.828831\n",
            "[24]\tvalid_0's auc: 0.829286\n",
            "[25]\tvalid_0's auc: 0.829676\n",
            "[26]\tvalid_0's auc: 0.830437\n",
            "[27]\tvalid_0's auc: 0.83042\n",
            "[28]\tvalid_0's auc: 0.830122\n",
            "[29]\tvalid_0's auc: 0.830389\n",
            "[30]\tvalid_0's auc: 0.830219\n",
            "[31]\tvalid_0's auc: 0.830866\n",
            "[32]\tvalid_0's auc: 0.830652\n",
            "[33]\tvalid_0's auc: 0.830634\n",
            "[34]\tvalid_0's auc: 0.830845\n",
            "[35]\tvalid_0's auc: 0.830284\n",
            "[36]\tvalid_0's auc: 0.830538\n",
            "[37]\tvalid_0's auc: 0.830748\n",
            "[38]\tvalid_0's auc: 0.831326\n",
            "[39]\tvalid_0's auc: 0.831991\n",
            "[40]\tvalid_0's auc: 0.831597\n",
            "[41]\tvalid_0's auc: 0.831886\n",
            "[42]\tvalid_0's auc: 0.832674\n",
            "[43]\tvalid_0's auc: 0.833886\n",
            "[44]\tvalid_0's auc: 0.834201\n",
            "[45]\tvalid_0's auc: 0.834613\n",
            "[46]\tvalid_0's auc: 0.835348\n",
            "[47]\tvalid_0's auc: 0.836127\n",
            "[48]\tvalid_0's auc: 0.836118\n",
            "[49]\tvalid_0's auc: 0.836617\n",
            "[50]\tvalid_0's auc: 0.836267\n",
            "[51]\tvalid_0's auc: 0.836661\n",
            "[52]\tvalid_0's auc: 0.836775\n",
            "[53]\tvalid_0's auc: 0.837851\n",
            "[54]\tvalid_0's auc: 0.837764\n",
            "[55]\tvalid_0's auc: 0.838407\n",
            "[56]\tvalid_0's auc: 0.839055\n",
            "[57]\tvalid_0's auc: 0.839571\n",
            "[58]\tvalid_0's auc: 0.839983\n",
            "[59]\tvalid_0's auc: 0.840132\n",
            "[60]\tvalid_0's auc: 0.840298\n",
            "[61]\tvalid_0's auc: 0.840447\n",
            "[62]\tvalid_0's auc: 0.84035\n",
            "[63]\tvalid_0's auc: 0.84074\n",
            "[64]\tvalid_0's auc: 0.840968\n",
            "[65]\tvalid_0's auc: 0.841335\n",
            "[66]\tvalid_0's auc: 0.841309\n",
            "[67]\tvalid_0's auc: 0.841029\n",
            "[68]\tvalid_0's auc: 0.840687\n",
            "[69]\tvalid_0's auc: 0.840399\n",
            "[70]\tvalid_0's auc: 0.841125\n",
            "[71]\tvalid_0's auc: 0.840709\n",
            "[72]\tvalid_0's auc: 0.840385\n",
            "[73]\tvalid_0's auc: 0.840652\n",
            "[74]\tvalid_0's auc: 0.840609\n",
            "[75]\tvalid_0's auc: 0.840863\n",
            "Early stopping, best iteration is:\n",
            "[65]\tvalid_0's auc: 0.841335\n",
            "[1]\tvalid_0's auc: 0.781175\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's auc: 0.786956\n",
            "[3]\tvalid_0's auc: 0.785822\n",
            "[4]\tvalid_0's auc: 0.793061\n",
            "[5]\tvalid_0's auc: 0.79609\n",
            "[6]\tvalid_0's auc: 0.800108\n",
            "[7]\tvalid_0's auc: 0.799906\n",
            "[8]\tvalid_0's auc: 0.802668\n",
            "[9]\tvalid_0's auc: 0.805447\n",
            "[10]\tvalid_0's auc: 0.805618\n",
            "[11]\tvalid_0's auc: 0.807666\n",
            "[12]\tvalid_0's auc: 0.807522\n",
            "[13]\tvalid_0's auc: 0.807618\n",
            "[14]\tvalid_0's auc: 0.809832\n",
            "[15]\tvalid_0's auc: 0.812892\n",
            "[16]\tvalid_0's auc: 0.812935\n",
            "[17]\tvalid_0's auc: 0.812458\n",
            "[18]\tvalid_0's auc: 0.813032\n",
            "[19]\tvalid_0's auc: 0.81364\n",
            "[20]\tvalid_0's auc: 0.814953\n",
            "[21]\tvalid_0's auc: 0.815329\n",
            "[22]\tvalid_0's auc: 0.815238\n",
            "[23]\tvalid_0's auc: 0.815623\n",
            "[24]\tvalid_0's auc: 0.815973\n",
            "[25]\tvalid_0's auc: 0.815763\n",
            "[26]\tvalid_0's auc: 0.816691\n",
            "[27]\tvalid_0's auc: 0.817601\n",
            "[28]\tvalid_0's auc: 0.81733\n",
            "[29]\tvalid_0's auc: 0.817338\n",
            "[30]\tvalid_0's auc: 0.817807\n",
            "[31]\tvalid_0's auc: 0.818117\n",
            "[32]\tvalid_0's auc: 0.818577\n",
            "[33]\tvalid_0's auc: 0.819155\n",
            "[34]\tvalid_0's auc: 0.819058\n",
            "[35]\tvalid_0's auc: 0.820096\n",
            "[36]\tvalid_0's auc: 0.82056\n",
            "[37]\tvalid_0's auc: 0.820336\n",
            "[38]\tvalid_0's auc: 0.821203\n",
            "[39]\tvalid_0's auc: 0.821553\n",
            "[40]\tvalid_0's auc: 0.821474\n",
            "[41]\tvalid_0's auc: 0.821986\n",
            "[42]\tvalid_0's auc: 0.822599\n",
            "[43]\tvalid_0's auc: 0.823947\n",
            "[44]\tvalid_0's auc: 0.824192\n",
            "[45]\tvalid_0's auc: 0.82519\n",
            "[46]\tvalid_0's auc: 0.825111\n",
            "[47]\tvalid_0's auc: 0.825733\n",
            "[48]\tvalid_0's auc: 0.825794\n",
            "[49]\tvalid_0's auc: 0.826433\n",
            "[50]\tvalid_0's auc: 0.826906\n",
            "[51]\tvalid_0's auc: 0.826188\n",
            "[52]\tvalid_0's auc: 0.827019\n",
            "[53]\tvalid_0's auc: 0.826547\n",
            "[54]\tvalid_0's auc: 0.827343\n",
            "[55]\tvalid_0's auc: 0.827912\n",
            "[56]\tvalid_0's auc: 0.828131\n",
            "[57]\tvalid_0's auc: 0.827702\n",
            "[58]\tvalid_0's auc: 0.828569\n",
            "[59]\tvalid_0's auc: 0.828061\n",
            "[60]\tvalid_0's auc: 0.828227\n",
            "[61]\tvalid_0's auc: 0.828604\n",
            "[62]\tvalid_0's auc: 0.828481\n",
            "[63]\tvalid_0's auc: 0.828691\n",
            "[64]\tvalid_0's auc: 0.828402\n",
            "[65]\tvalid_0's auc: 0.828823\n",
            "[66]\tvalid_0's auc: 0.828534\n",
            "[67]\tvalid_0's auc: 0.828367\n",
            "[68]\tvalid_0's auc: 0.828919\n",
            "[69]\tvalid_0's auc: 0.828394\n",
            "[70]\tvalid_0's auc: 0.828236\n",
            "[71]\tvalid_0's auc: 0.828114\n",
            "[72]\tvalid_0's auc: 0.827965\n",
            "[73]\tvalid_0's auc: 0.82786\n",
            "[74]\tvalid_0's auc: 0.82835\n",
            "[75]\tvalid_0's auc: 0.82793\n",
            "[76]\tvalid_0's auc: 0.827807\n",
            "[77]\tvalid_0's auc: 0.828043\n",
            "[78]\tvalid_0's auc: 0.827536\n",
            "Early stopping, best iteration is:\n",
            "[68]\tvalid_0's auc: 0.828919\n",
            "[1]\tvalid_0's auc: 0.761931\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's auc: 0.782168\n",
            "[3]\tvalid_0's auc: 0.784492\n",
            "[4]\tvalid_0's auc: 0.78373\n",
            "[5]\tvalid_0's auc: 0.786348\n",
            "[6]\tvalid_0's auc: 0.786033\n",
            "[7]\tvalid_0's auc: 0.787385\n",
            "[8]\tvalid_0's auc: 0.78756\n",
            "[9]\tvalid_0's auc: 0.788869\n",
            "[10]\tvalid_0's auc: 0.786995\n",
            "[11]\tvalid_0's auc: 0.790567\n",
            "[12]\tvalid_0's auc: 0.79212\n",
            "[13]\tvalid_0's auc: 0.792103\n",
            "[14]\tvalid_0's auc: 0.793442\n",
            "[15]\tvalid_0's auc: 0.794173\n",
            "[16]\tvalid_0's auc: 0.794151\n",
            "[17]\tvalid_0's auc: 0.79549\n",
            "[18]\tvalid_0's auc: 0.796659\n",
            "[19]\tvalid_0's auc: 0.79707\n",
            "[20]\tvalid_0's auc: 0.798077\n",
            "[21]\tvalid_0's auc: 0.7989\n",
            "[22]\tvalid_0's auc: 0.798751\n",
            "[23]\tvalid_0's auc: 0.799933\n",
            "[24]\tvalid_0's auc: 0.7996\n",
            "[25]\tvalid_0's auc: 0.800256\n",
            "[26]\tvalid_0's auc: 0.800917\n",
            "[27]\tvalid_0's auc: 0.801289\n",
            "[28]\tvalid_0's auc: 0.801092\n",
            "[29]\tvalid_0's auc: 0.802454\n",
            "[30]\tvalid_0's auc: 0.802729\n",
            "[31]\tvalid_0's auc: 0.801793\n",
            "[32]\tvalid_0's auc: 0.800992\n",
            "[33]\tvalid_0's auc: 0.801106\n",
            "[34]\tvalid_0's auc: 0.801049\n",
            "[35]\tvalid_0's auc: 0.801355\n",
            "[36]\tvalid_0's auc: 0.801373\n",
            "[37]\tvalid_0's auc: 0.800042\n",
            "[38]\tvalid_0's auc: 0.800077\n",
            "[39]\tvalid_0's auc: 0.800366\n",
            "[40]\tvalid_0's auc: 0.800331\n",
            "Early stopping, best iteration is:\n",
            "[30]\tvalid_0's auc: 0.802729\n",
            "[1]\tvalid_0's auc: 0.785442\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's auc: 0.790046\n",
            "[3]\tvalid_0's auc: 0.793578\n",
            "[4]\tvalid_0's auc: 0.793604\n",
            "[5]\tvalid_0's auc: 0.795433\n",
            "[6]\tvalid_0's auc: 0.795679\n",
            "[7]\tvalid_0's auc: 0.795486\n",
            "[8]\tvalid_0's auc: 0.793245\n",
            "[9]\tvalid_0's auc: 0.793394\n",
            "[10]\tvalid_0's auc: 0.794689\n",
            "[11]\tvalid_0's auc: 0.795031\n",
            "[12]\tvalid_0's auc: 0.795967\n",
            "[13]\tvalid_0's auc: 0.795823\n",
            "[14]\tvalid_0's auc: 0.796002\n",
            "[15]\tvalid_0's auc: 0.795298\n",
            "[16]\tvalid_0's auc: 0.796169\n",
            "[17]\tvalid_0's auc: 0.795381\n",
            "[18]\tvalid_0's auc: 0.795849\n",
            "[19]\tvalid_0's auc: 0.795932\n",
            "[20]\tvalid_0's auc: 0.796322\n",
            "[21]\tvalid_0's auc: 0.795762\n",
            "[22]\tvalid_0's auc: 0.79595\n",
            "[23]\tvalid_0's auc: 0.796248\n",
            "[24]\tvalid_0's auc: 0.79662\n",
            "[25]\tvalid_0's auc: 0.797329\n",
            "[26]\tvalid_0's auc: 0.797981\n",
            "[27]\tvalid_0's auc: 0.798143\n",
            "[28]\tvalid_0's auc: 0.799779\n",
            "[29]\tvalid_0's auc: 0.800217\n",
            "[30]\tvalid_0's auc: 0.799609\n",
            "[31]\tvalid_0's auc: 0.800926\n",
            "[32]\tvalid_0's auc: 0.800917\n",
            "[33]\tvalid_0's auc: 0.799902\n",
            "[34]\tvalid_0's auc: 0.800598\n",
            "[35]\tvalid_0's auc: 0.801482\n",
            "[36]\tvalid_0's auc: 0.801631\n",
            "[37]\tvalid_0's auc: 0.802878\n",
            "[38]\tvalid_0's auc: 0.803421\n",
            "[39]\tvalid_0's auc: 0.803193\n",
            "[40]\tvalid_0's auc: 0.804226\n",
            "[41]\tvalid_0's auc: 0.804042\n",
            "[42]\tvalid_0's auc: 0.803937\n",
            "[43]\tvalid_0's auc: 0.803963\n",
            "[44]\tvalid_0's auc: 0.804209\n",
            "[45]\tvalid_0's auc: 0.804244\n",
            "[46]\tvalid_0's auc: 0.805303\n",
            "[47]\tvalid_0's auc: 0.805495\n",
            "[48]\tvalid_0's auc: 0.806213\n",
            "[49]\tvalid_0's auc: 0.807163\n",
            "[50]\tvalid_0's auc: 0.807789\n",
            "[51]\tvalid_0's auc: 0.8082\n",
            "[52]\tvalid_0's auc: 0.809303\n",
            "[53]\tvalid_0's auc: 0.809259\n",
            "[54]\tvalid_0's auc: 0.809697\n",
            "[55]\tvalid_0's auc: 0.810021\n",
            "[56]\tvalid_0's auc: 0.810187\n",
            "[57]\tvalid_0's auc: 0.81115\n",
            "[58]\tvalid_0's auc: 0.810607\n",
            "[59]\tvalid_0's auc: 0.81115\n",
            "[60]\tvalid_0's auc: 0.810791\n",
            "[61]\tvalid_0's auc: 0.811229\n",
            "[62]\tvalid_0's auc: 0.812095\n",
            "[63]\tvalid_0's auc: 0.812323\n",
            "[64]\tvalid_0's auc: 0.81227\n",
            "[65]\tvalid_0's auc: 0.812577\n",
            "[66]\tvalid_0's auc: 0.81297\n",
            "[67]\tvalid_0's auc: 0.813601\n",
            "[68]\tvalid_0's auc: 0.813496\n",
            "[69]\tvalid_0's auc: 0.813531\n",
            "[70]\tvalid_0's auc: 0.813679\n",
            "[71]\tvalid_0's auc: 0.814826\n",
            "[72]\tvalid_0's auc: 0.815159\n",
            "[73]\tvalid_0's auc: 0.814669\n",
            "[74]\tvalid_0's auc: 0.814931\n",
            "[75]\tvalid_0's auc: 0.815535\n",
            "[76]\tvalid_0's auc: 0.815736\n",
            "[77]\tvalid_0's auc: 0.815675\n",
            "[78]\tvalid_0's auc: 0.81571\n",
            "[79]\tvalid_0's auc: 0.816393\n",
            "[80]\tvalid_0's auc: 0.816551\n",
            "[81]\tvalid_0's auc: 0.816752\n",
            "[82]\tvalid_0's auc: 0.816997\n",
            "[83]\tvalid_0's auc: 0.8174\n",
            "[84]\tvalid_0's auc: 0.817356\n",
            "[85]\tvalid_0's auc: 0.818004\n",
            "[86]\tvalid_0's auc: 0.818179\n",
            "[87]\tvalid_0's auc: 0.818432\n",
            "[88]\tvalid_0's auc: 0.818345\n",
            "[89]\tvalid_0's auc: 0.818275\n",
            "[90]\tvalid_0's auc: 0.818074\n",
            "[91]\tvalid_0's auc: 0.818494\n",
            "[92]\tvalid_0's auc: 0.81845\n",
            "[93]\tvalid_0's auc: 0.818231\n",
            "[94]\tvalid_0's auc: 0.818179\n",
            "[95]\tvalid_0's auc: 0.81845\n",
            "[96]\tvalid_0's auc: 0.819159\n",
            "[97]\tvalid_0's auc: 0.819754\n",
            "[98]\tvalid_0's auc: 0.820069\n",
            "[99]\tvalid_0's auc: 0.820087\n",
            "[100]\tvalid_0's auc: 0.820104\n",
            "[101]\tvalid_0's auc: 0.820665\n",
            "[102]\tvalid_0's auc: 0.820332\n",
            "[103]\tvalid_0's auc: 0.820279\n",
            "[104]\tvalid_0's auc: 0.820507\n",
            "[105]\tvalid_0's auc: 0.82063\n",
            "[106]\tvalid_0's auc: 0.820568\n",
            "[107]\tvalid_0's auc: 0.820402\n",
            "[108]\tvalid_0's auc: 0.820446\n",
            "[109]\tvalid_0's auc: 0.819868\n",
            "[110]\tvalid_0's auc: 0.820201\n",
            "[111]\tvalid_0's auc: 0.820446\n",
            "Early stopping, best iteration is:\n",
            "[101]\tvalid_0's auc: 0.820665\n",
            "[1]\tvalid_0's auc: 0.807749\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's auc: 0.806244\n",
            "[3]\tvalid_0's auc: 0.805832\n",
            "[4]\tvalid_0's auc: 0.806887\n",
            "[5]\tvalid_0's auc: 0.807775\n",
            "[6]\tvalid_0's auc: 0.809102\n",
            "[7]\tvalid_0's auc: 0.807544\n",
            "[8]\tvalid_0's auc: 0.806808\n",
            "[9]\tvalid_0's auc: 0.808099\n",
            "[10]\tvalid_0's auc: 0.807955\n",
            "[11]\tvalid_0's auc: 0.813058\n",
            "[12]\tvalid_0's auc: 0.815645\n",
            "[13]\tvalid_0's auc: 0.815824\n",
            "[14]\tvalid_0's auc: 0.817058\n",
            "[15]\tvalid_0's auc: 0.816914\n",
            "[16]\tvalid_0's auc: 0.818201\n",
            "[17]\tvalid_0's auc: 0.819286\n",
            "[18]\tvalid_0's auc: 0.820328\n",
            "[19]\tvalid_0's auc: 0.821483\n",
            "[20]\tvalid_0's auc: 0.82249\n",
            "[21]\tvalid_0's auc: 0.822393\n",
            "[22]\tvalid_0's auc: 0.823032\n",
            "[23]\tvalid_0's auc: 0.824761\n",
            "[24]\tvalid_0's auc: 0.824665\n",
            "[25]\tvalid_0's auc: 0.825207\n",
            "[26]\tvalid_0's auc: 0.827011\n",
            "[27]\tvalid_0's auc: 0.82782\n",
            "[28]\tvalid_0's auc: 0.828998\n",
            "[29]\tvalid_0's auc: 0.828573\n",
            "[30]\tvalid_0's auc: 0.829939\n",
            "[31]\tvalid_0's auc: 0.829855\n",
            "[32]\tvalid_0's auc: 0.831055\n",
            "[33]\tvalid_0's auc: 0.830503\n",
            "[34]\tvalid_0's auc: 0.830092\n",
            "[35]\tvalid_0's auc: 0.829847\n",
            "[36]\tvalid_0's auc: 0.830683\n",
            "[37]\tvalid_0's auc: 0.830718\n",
            "[38]\tvalid_0's auc: 0.830613\n",
            "[39]\tvalid_0's auc: 0.830971\n",
            "[40]\tvalid_0's auc: 0.831939\n",
            "[41]\tvalid_0's auc: 0.832709\n",
            "[42]\tvalid_0's auc: 0.832761\n",
            "[43]\tvalid_0's auc: 0.833422\n",
            "[44]\tvalid_0's auc: 0.833956\n",
            "[45]\tvalid_0's auc: 0.835002\n",
            "[46]\tvalid_0's auc: 0.835077\n",
            "[47]\tvalid_0's auc: 0.835786\n",
            "[48]\tvalid_0's auc: 0.836582\n",
            "[49]\tvalid_0's auc: 0.836766\n",
            "[50]\tvalid_0's auc: 0.837729\n",
            "[51]\tvalid_0's auc: 0.838464\n",
            "[52]\tvalid_0's auc: 0.838403\n",
            "[53]\tvalid_0's auc: 0.838473\n",
            "[54]\tvalid_0's auc: 0.839182\n",
            "[55]\tvalid_0's auc: 0.839742\n",
            "[56]\tvalid_0's auc: 0.840162\n",
            "[57]\tvalid_0's auc: 0.840539\n",
            "[58]\tvalid_0's auc: 0.84081\n",
            "[59]\tvalid_0's auc: 0.841151\n",
            "[60]\tvalid_0's auc: 0.84172\n",
            "[61]\tvalid_0's auc: 0.842473\n",
            "[62]\tvalid_0's auc: 0.84292\n",
            "[63]\tvalid_0's auc: 0.842955\n",
            "[64]\tvalid_0's auc: 0.843532\n",
            "[65]\tvalid_0's auc: 0.843961\n",
            "[66]\tvalid_0's auc: 0.844434\n",
            "[67]\tvalid_0's auc: 0.844863\n",
            "[68]\tvalid_0's auc: 0.844565\n",
            "[69]\tvalid_0's auc: 0.844416\n",
            "[70]\tvalid_0's auc: 0.8439\n",
            "[71]\tvalid_0's auc: 0.844276\n",
            "[72]\tvalid_0's auc: 0.844075\n",
            "[73]\tvalid_0's auc: 0.844338\n",
            "[74]\tvalid_0's auc: 0.844451\n",
            "[75]\tvalid_0's auc: 0.844408\n",
            "[76]\tvalid_0's auc: 0.84411\n",
            "[77]\tvalid_0's auc: 0.844268\n",
            "Early stopping, best iteration is:\n",
            "[67]\tvalid_0's auc: 0.844863\n",
            "[1]\tvalid_0's auc: 0.763581\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's auc: 0.763935\n",
            "[3]\tvalid_0's auc: 0.769703\n",
            "[4]\tvalid_0's auc: 0.778977\n",
            "[5]\tvalid_0's auc: 0.783739\n",
            "[6]\tvalid_0's auc: 0.787984\n",
            "[7]\tvalid_0's auc: 0.786755\n",
            "[8]\tvalid_0's auc: 0.786308\n",
            "[9]\tvalid_0's auc: 0.786658\n",
            "[10]\tvalid_0's auc: 0.786461\n",
            "[11]\tvalid_0's auc: 0.78721\n",
            "[12]\tvalid_0's auc: 0.790273\n",
            "[13]\tvalid_0's auc: 0.790615\n",
            "[14]\tvalid_0's auc: 0.791214\n",
            "[15]\tvalid_0's auc: 0.792536\n",
            "[16]\tvalid_0's auc: 0.794173\n",
            "[17]\tvalid_0's auc: 0.796318\n",
            "[18]\tvalid_0's auc: 0.797018\n",
            "[19]\tvalid_0's auc: 0.797714\n",
            "[20]\tvalid_0's auc: 0.797482\n",
            "[21]\tvalid_0's auc: 0.797788\n",
            "[22]\tvalid_0's auc: 0.797486\n",
            "[23]\tvalid_0's auc: 0.797547\n",
            "[24]\tvalid_0's auc: 0.796965\n",
            "[25]\tvalid_0's auc: 0.797674\n",
            "[26]\tvalid_0's auc: 0.798038\n",
            "[27]\tvalid_0's auc: 0.79911\n",
            "[28]\tvalid_0's auc: 0.799552\n",
            "[29]\tvalid_0's auc: 0.800506\n",
            "[30]\tvalid_0's auc: 0.80069\n",
            "[31]\tvalid_0's auc: 0.800685\n",
            "[32]\tvalid_0's auc: 0.800817\n",
            "[33]\tvalid_0's auc: 0.800926\n",
            "[34]\tvalid_0's auc: 0.801845\n",
            "[35]\tvalid_0's auc: 0.80227\n",
            "[36]\tvalid_0's auc: 0.802707\n",
            "[37]\tvalid_0's auc: 0.803513\n",
            "[38]\tvalid_0's auc: 0.804935\n",
            "[39]\tvalid_0's auc: 0.806099\n",
            "[40]\tvalid_0's auc: 0.807115\n",
            "[41]\tvalid_0's auc: 0.80753\n",
            "[42]\tvalid_0's auc: 0.807942\n",
            "[43]\tvalid_0's auc: 0.808861\n",
            "[44]\tvalid_0's auc: 0.809141\n",
            "[45]\tvalid_0's auc: 0.80957\n",
            "[46]\tvalid_0's auc: 0.808992\n",
            "[47]\tvalid_0's auc: 0.808686\n",
            "[48]\tvalid_0's auc: 0.809649\n",
            "[49]\tvalid_0's auc: 0.810261\n",
            "[50]\tvalid_0's auc: 0.810611\n",
            "[51]\tvalid_0's auc: 0.811005\n",
            "[52]\tvalid_0's auc: 0.810822\n",
            "[53]\tvalid_0's auc: 0.81122\n",
            "[54]\tvalid_0's auc: 0.811903\n",
            "[55]\tvalid_0's auc: 0.810686\n",
            "[56]\tvalid_0's auc: 0.811307\n",
            "[57]\tvalid_0's auc: 0.811675\n",
            "[58]\tvalid_0's auc: 0.811552\n",
            "[59]\tvalid_0's auc: 0.81171\n",
            "[60]\tvalid_0's auc: 0.812078\n",
            "[61]\tvalid_0's auc: 0.812095\n",
            "[62]\tvalid_0's auc: 0.812025\n",
            "[63]\tvalid_0's auc: 0.811763\n",
            "[64]\tvalid_0's auc: 0.812244\n",
            "[65]\tvalid_0's auc: 0.812594\n",
            "[66]\tvalid_0's auc: 0.81276\n",
            "[67]\tvalid_0's auc: 0.812839\n",
            "[68]\tvalid_0's auc: 0.812279\n",
            "[69]\tvalid_0's auc: 0.811246\n",
            "[70]\tvalid_0's auc: 0.810668\n",
            "[71]\tvalid_0's auc: 0.810817\n",
            "[72]\tvalid_0's auc: 0.81094\n",
            "[73]\tvalid_0's auc: 0.811342\n",
            "[74]\tvalid_0's auc: 0.811132\n",
            "[75]\tvalid_0's auc: 0.811412\n",
            "[76]\tvalid_0's auc: 0.81136\n",
            "[77]\tvalid_0's auc: 0.811491\n",
            "Early stopping, best iteration is:\n",
            "[67]\tvalid_0's auc: 0.812839\n",
            "[1]\tvalid_0's auc: 0.779275\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's auc: 0.779021\n",
            "[3]\tvalid_0's auc: 0.779126\n",
            "[4]\tvalid_0's auc: 0.785542\n",
            "[5]\tvalid_0's auc: 0.78475\n",
            "[6]\tvalid_0's auc: 0.787967\n",
            "[7]\tvalid_0's auc: 0.786794\n",
            "[8]\tvalid_0's auc: 0.789306\n",
            "[9]\tvalid_0's auc: 0.788895\n",
            "[10]\tvalid_0's auc: 0.788085\n",
            "[11]\tvalid_0's auc: 0.789144\n",
            "[12]\tvalid_0's auc: 0.790168\n",
            "[13]\tvalid_0's auc: 0.790361\n",
            "[14]\tvalid_0's auc: 0.792221\n",
            "[15]\tvalid_0's auc: 0.794252\n",
            "[16]\tvalid_0's auc: 0.79651\n",
            "[17]\tvalid_0's auc: 0.796545\n",
            "[18]\tvalid_0's auc: 0.798576\n",
            "[19]\tvalid_0's auc: 0.799027\n",
            "[20]\tvalid_0's auc: 0.798996\n",
            "[21]\tvalid_0's auc: 0.799119\n",
            "[22]\tvalid_0's auc: 0.799337\n",
            "[23]\tvalid_0's auc: 0.799683\n",
            "[24]\tvalid_0's auc: 0.801106\n",
            "[25]\tvalid_0's auc: 0.801526\n",
            "[26]\tvalid_0's auc: 0.802777\n",
            "[27]\tvalid_0's auc: 0.803443\n",
            "[28]\tvalid_0's auc: 0.803294\n",
            "[29]\tvalid_0's auc: 0.804191\n",
            "[30]\tvalid_0's auc: 0.803675\n",
            "[31]\tvalid_0's auc: 0.803517\n",
            "[32]\tvalid_0's auc: 0.80385\n",
            "[33]\tvalid_0's auc: 0.804419\n",
            "[34]\tvalid_0's auc: 0.804427\n",
            "[35]\tvalid_0's auc: 0.805079\n",
            "[36]\tvalid_0's auc: 0.806283\n",
            "[37]\tvalid_0's auc: 0.80778\n",
            "[38]\tvalid_0's auc: 0.807727\n",
            "[39]\tvalid_0's auc: 0.808896\n",
            "[40]\tvalid_0's auc: 0.808734\n",
            "[41]\tvalid_0's auc: 0.808646\n",
            "[42]\tvalid_0's auc: 0.809058\n",
            "[43]\tvalid_0's auc: 0.808533\n",
            "[44]\tvalid_0's auc: 0.808323\n",
            "[45]\tvalid_0's auc: 0.809058\n",
            "[46]\tvalid_0's auc: 0.80925\n",
            "[47]\tvalid_0's auc: 0.809005\n",
            "[48]\tvalid_0's auc: 0.809233\n",
            "[49]\tvalid_0's auc: 0.809478\n",
            "[50]\tvalid_0's auc: 0.810021\n",
            "[51]\tvalid_0's auc: 0.810178\n",
            "[52]\tvalid_0's auc: 0.810143\n",
            "[53]\tvalid_0's auc: 0.810966\n",
            "[54]\tvalid_0's auc: 0.811544\n",
            "[55]\tvalid_0's auc: 0.812235\n",
            "[56]\tvalid_0's auc: 0.811325\n",
            "[57]\tvalid_0's auc: 0.812253\n",
            "[58]\tvalid_0's auc: 0.812244\n",
            "[59]\tvalid_0's auc: 0.811552\n",
            "[60]\tvalid_0's auc: 0.81241\n",
            "[61]\tvalid_0's auc: 0.812612\n",
            "[62]\tvalid_0's auc: 0.812314\n",
            "[63]\tvalid_0's auc: 0.81255\n",
            "[64]\tvalid_0's auc: 0.812445\n",
            "[65]\tvalid_0's auc: 0.81283\n",
            "[66]\tvalid_0's auc: 0.812857\n",
            "[67]\tvalid_0's auc: 0.81382\n",
            "[68]\tvalid_0's auc: 0.813128\n",
            "[69]\tvalid_0's auc: 0.813618\n",
            "[70]\tvalid_0's auc: 0.81431\n",
            "[71]\tvalid_0's auc: 0.814704\n",
            "[72]\tvalid_0's auc: 0.814345\n",
            "[73]\tvalid_0's auc: 0.814599\n",
            "[74]\tvalid_0's auc: 0.814791\n",
            "[75]\tvalid_0's auc: 0.814826\n",
            "[76]\tvalid_0's auc: 0.815334\n",
            "[77]\tvalid_0's auc: 0.815439\n",
            "[78]\tvalid_0's auc: 0.815526\n",
            "[79]\tvalid_0's auc: 0.815605\n",
            "[80]\tvalid_0's auc: 0.815929\n",
            "[81]\tvalid_0's auc: 0.816384\n",
            "[82]\tvalid_0's auc: 0.815763\n",
            "[83]\tvalid_0's auc: 0.81564\n",
            "[84]\tvalid_0's auc: 0.815054\n",
            "[85]\tvalid_0's auc: 0.815456\n",
            "[86]\tvalid_0's auc: 0.815859\n",
            "[87]\tvalid_0's auc: 0.815903\n",
            "[88]\tvalid_0's auc: 0.815281\n",
            "[89]\tvalid_0's auc: 0.815526\n",
            "[90]\tvalid_0's auc: 0.815395\n",
            "[91]\tvalid_0's auc: 0.815614\n",
            "Early stopping, best iteration is:\n",
            "[81]\tvalid_0's auc: 0.816384\n",
            "[1]\tvalid_0's auc: 0.800291\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's auc: 0.79921\n",
            "[3]\tvalid_0's auc: 0.798309\n",
            "[4]\tvalid_0's auc: 0.802108\n",
            "[5]\tvalid_0's auc: 0.801534\n",
            "[6]\tvalid_0's auc: 0.806541\n",
            "[7]\tvalid_0's auc: 0.804292\n",
            "[8]\tvalid_0's auc: 0.806279\n",
            "[9]\tvalid_0's auc: 0.806537\n",
            "[10]\tvalid_0's auc: 0.807972\n",
            "[11]\tvalid_0's auc: 0.807473\n",
            "[12]\tvalid_0's auc: 0.807968\n",
            "[13]\tvalid_0's auc: 0.808161\n",
            "[14]\tvalid_0's auc: 0.809999\n",
            "[15]\tvalid_0's auc: 0.809706\n",
            "[16]\tvalid_0's auc: 0.811145\n",
            "[17]\tvalid_0's auc: 0.811465\n",
            "[18]\tvalid_0's auc: 0.811137\n",
            "[19]\tvalid_0's auc: 0.812043\n",
            "[20]\tvalid_0's auc: 0.813194\n",
            "[21]\tvalid_0's auc: 0.812318\n",
            "[22]\tvalid_0's auc: 0.812752\n",
            "[23]\tvalid_0's auc: 0.812191\n",
            "[24]\tvalid_0's auc: 0.812305\n",
            "[25]\tvalid_0's auc: 0.811942\n",
            "[26]\tvalid_0's auc: 0.812152\n",
            "[27]\tvalid_0's auc: 0.812288\n",
            "[28]\tvalid_0's auc: 0.812445\n",
            "[29]\tvalid_0's auc: 0.812244\n",
            "[30]\tvalid_0's auc: 0.811981\n",
            "Early stopping, best iteration is:\n",
            "[20]\tvalid_0's auc: 0.813194\n",
            "[1]\tvalid_0's auc: 0.796444\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's auc: 0.799674\n",
            "[3]\tvalid_0's auc: 0.802725\n",
            "[4]\tvalid_0's auc: 0.804147\n",
            "[5]\tvalid_0's auc: 0.808603\n",
            "[6]\tvalid_0's auc: 0.807789\n",
            "[7]\tvalid_0's auc: 0.810388\n",
            "[8]\tvalid_0's auc: 0.809202\n",
            "[9]\tvalid_0's auc: 0.81069\n",
            "[10]\tvalid_0's auc: 0.810511\n",
            "[11]\tvalid_0's auc: 0.810782\n",
            "[12]\tvalid_0's auc: 0.813399\n",
            "[13]\tvalid_0's auc: 0.813119\n",
            "[14]\tvalid_0's auc: 0.81227\n",
            "[15]\tvalid_0's auc: 0.814108\n",
            "[16]\tvalid_0's auc: 0.814927\n",
            "[17]\tvalid_0's auc: 0.814231\n",
            "[18]\tvalid_0's auc: 0.815548\n",
            "[19]\tvalid_0's auc: 0.816336\n",
            "[20]\tvalid_0's auc: 0.818651\n",
            "[21]\tvalid_0's auc: 0.819321\n",
            "[22]\tvalid_0's auc: 0.819846\n",
            "[23]\tvalid_0's auc: 0.8201\n",
            "[24]\tvalid_0's auc: 0.820726\n",
            "[25]\tvalid_0's auc: 0.821299\n",
            "[26]\tvalid_0's auc: 0.820546\n",
            "[27]\tvalid_0's auc: 0.820551\n",
            "[28]\tvalid_0's auc: 0.821404\n",
            "[29]\tvalid_0's auc: 0.822196\n",
            "[30]\tvalid_0's auc: 0.822735\n",
            "[31]\tvalid_0's auc: 0.823269\n",
            "[32]\tvalid_0's auc: 0.823868\n",
            "[33]\tvalid_0's auc: 0.823833\n",
            "[34]\tvalid_0's auc: 0.823776\n",
            "[35]\tvalid_0's auc: 0.823269\n",
            "[36]\tvalid_0's auc: 0.82312\n",
            "[37]\tvalid_0's auc: 0.823505\n",
            "[38]\tvalid_0's auc: 0.823457\n",
            "[39]\tvalid_0's auc: 0.823842\n",
            "[40]\tvalid_0's auc: 0.824166\n",
            "[41]\tvalid_0's auc: 0.824074\n",
            "[42]\tvalid_0's auc: 0.824551\n",
            "[43]\tvalid_0's auc: 0.824516\n",
            "[44]\tvalid_0's auc: 0.824227\n",
            "[45]\tvalid_0's auc: 0.824398\n",
            "[46]\tvalid_0's auc: 0.824818\n",
            "[47]\tvalid_0's auc: 0.825194\n",
            "[48]\tvalid_0's auc: 0.825527\n",
            "[49]\tvalid_0's auc: 0.825938\n",
            "[50]\tvalid_0's auc: 0.826573\n",
            "[51]\tvalid_0's auc: 0.826871\n",
            "[52]\tvalid_0's auc: 0.82652\n",
            "[53]\tvalid_0's auc: 0.827422\n",
            "[54]\tvalid_0's auc: 0.827514\n",
            "[55]\tvalid_0's auc: 0.82849\n",
            "[56]\tvalid_0's auc: 0.829129\n",
            "[57]\tvalid_0's auc: 0.829098\n",
            "[58]\tvalid_0's auc: 0.829352\n",
            "[59]\tvalid_0's auc: 0.829689\n",
            "[60]\tvalid_0's auc: 0.829637\n",
            "[61]\tvalid_0's auc: 0.829225\n",
            "[62]\tvalid_0's auc: 0.829724\n",
            "[63]\tvalid_0's auc: 0.82954\n",
            "[64]\tvalid_0's auc: 0.82968\n",
            "[65]\tvalid_0's auc: 0.82933\n",
            "[66]\tvalid_0's auc: 0.82877\n",
            "[67]\tvalid_0's auc: 0.82919\n",
            "[68]\tvalid_0's auc: 0.828831\n",
            "[69]\tvalid_0's auc: 0.829024\n",
            "[70]\tvalid_0's auc: 0.829225\n",
            "[71]\tvalid_0's auc: 0.829523\n",
            "[72]\tvalid_0's auc: 0.830109\n",
            "[73]\tvalid_0's auc: 0.829987\n",
            "[74]\tvalid_0's auc: 0.830232\n",
            "[75]\tvalid_0's auc: 0.830258\n",
            "[76]\tvalid_0's auc: 0.829995\n",
            "[77]\tvalid_0's auc: 0.830171\n",
            "[78]\tvalid_0's auc: 0.8301\n",
            "[79]\tvalid_0's auc: 0.830188\n",
            "[80]\tvalid_0's auc: 0.830424\n",
            "[81]\tvalid_0's auc: 0.830521\n",
            "[82]\tvalid_0's auc: 0.830582\n",
            "[83]\tvalid_0's auc: 0.82996\n",
            "[84]\tvalid_0's auc: 0.830048\n",
            "[85]\tvalid_0's auc: 0.829785\n",
            "[86]\tvalid_0's auc: 0.830302\n",
            "[87]\tvalid_0's auc: 0.830433\n",
            "[88]\tvalid_0's auc: 0.830433\n",
            "[89]\tvalid_0's auc: 0.829934\n",
            "[90]\tvalid_0's auc: 0.830249\n",
            "[91]\tvalid_0's auc: 0.830022\n",
            "[92]\tvalid_0's auc: 0.830389\n",
            "Early stopping, best iteration is:\n",
            "[82]\tvalid_0's auc: 0.830582\n",
            "CPU times: user 8.46 s, sys: 507 ms, total: 8.96 s\n",
            "Wall time: 7.19 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "i1R856gNO5Ib",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0176747d-cda2-429f-86ff-ac0c4f0d2865"
      },
      "source": [
        "y_preds = []\n",
        "\n",
        "for m in models:\n",
        "    y_preds.append(m.predict(X_test, num_iteration=m.best_iteration))\n",
        "\n",
        "y_preds_bagging = sum(y_preds)/len(y_preds)\n",
        "# auc を計算する\n",
        "auc = roc_auc_score(y_test, y_preds_bagging)\n",
        "print(auc)"
      ],
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8476618135405821\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQSA_C3YRp46",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8b6e2f91-36d7-4573-a61c-bbb5445ddf8e"
      },
      "source": [
        "y_test"
      ],
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 278
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yud6bs8iRrh4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8b413848-6bf6-4f4a-f1fd-8dbf7237c580"
      },
      "source": [
        "sum(y_test)"
      ],
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "422.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 279
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pi1Zu7-5RvZg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "08863df6-5485-45d7-922a-27ad017e7ae4"
      },
      "source": [
        "len(y_test)"
      ],
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5420"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 280
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHK8ztofZk8W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "734a228c-098e-4d2c-d739-26dbc71250fa"
      },
      "source": [
        "models"
      ],
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<lightgbm.basic.Booster at 0x7fa9747ff4e0>,\n",
              " <lightgbm.basic.Booster at 0x7fa9748b6cf8>,\n",
              " <lightgbm.basic.Booster at 0x7fa9747ff470>,\n",
              " <lightgbm.basic.Booster at 0x7fa974816ac8>,\n",
              " <lightgbm.basic.Booster at 0x7fa974816240>,\n",
              " <lightgbm.basic.Booster at 0x7fa9748169b0>,\n",
              " <lightgbm.basic.Booster at 0x7fa9747ff0b8>,\n",
              " <lightgbm.basic.Booster at 0x7fa9748164a8>,\n",
              " <lightgbm.basic.Booster at 0x7fa97480d048>,\n",
              " <lightgbm.basic.Booster at 0x7fa974816198>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 281
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q4qjMJpZYpu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2d52fbfe-3967-4398-c0e8-49f2aaf0b8a2"
      },
      "source": [
        "y_preds_bagging"
      ],
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.40682771, 0.47081367, 0.63580271, ..., 0.27380271, 0.31215199,\n",
              "       0.47963997])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 282
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M6KHxkZZZoI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9f53520c-59c2-4741-eacc-4f772d0c7e0f"
      },
      "source": [
        "len(y_preds_bagging)"
      ],
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5420"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 283
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMO1zM5NPCiu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "954b980e-7169-43d2-cbfc-851198a58ac3"
      },
      "source": [
        "y_test"
      ],
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 284
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8r_nEfPPGpJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f3ace76a-eb50-4490-e2ca-0b29bae58dc4"
      },
      "source": [
        "len(y_test)"
      ],
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5420"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 285
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Phwh8R1FO5Ii",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "a034c4a4-7935-499b-908e-53f46792c469"
      },
      "source": [
        "for y_pred in y_preds:\n",
        "    print(roc_auc_score(y_test, y_pred))"
      ],
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8351283641418653\n",
            "0.8422176927643095\n",
            "0.8341926818120613\n",
            "0.8220371086823356\n",
            "0.8392314271680235\n",
            "0.8371068806669588\n",
            "0.837431181003207\n",
            "0.8379342258230306\n",
            "0.8193692168810652\n",
            "0.8358305407471045\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5iMtJ1rSb1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 286,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haOYdZJlO5In",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "531df519-877a-40a4-e16e-9cb23c63927c"
      },
      "source": [
        "y_subs = []\n",
        "\n",
        "for m in models:\n",
        "    y_subs.append(m.predict(X_sub, num_iteration=m.best_iteration))\n",
        "\n",
        "y_subs_bagging = sum(y_subs)/len(y_subs)\n",
        "# auc を計算する\n",
        "y_subs_bagging"
      ],
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.93260942, 0.28383637, 0.20715047, ..., 0.50886412, 0.07996322,\n",
              "       0.6520975 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 287
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gssJpf6ATSD0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5303c989-6241-4157-9c32-acf38367b86f"
      },
      "source": [
        "percentage=0.32\n",
        "y_sub = (y_subs_bagging > percentage).astype(int)\n",
        "\n",
        "sub['B'] = y_sub\n",
        "sub.to_csv('submission_lightgbm_kfold.csv', index=False, header=False)\n",
        "\n",
        "sum(sub[\"B\"]),len(sub[\"B\"])"
      ],
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9611, 18050)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 290
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9Z9-c6xTDgO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d08fb03b-8a13-4615-d8f0-3e0a3238c625"
      },
      "source": [
        "sum(y_sub)"
      ],
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9611"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 291
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLncMw7ITZbP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "34a6cd22-c4e2-4f3f-a65d-439f4df16320"
      },
      "source": [
        "files.download('submission_lightgbm_kfold.csv')"
      ],
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_4462d287-3bac-4129-afb7-566b155593ae\", \"submission_lightgbm_kfold.csv\", 133290)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpLXQfdmO5H8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def objective(trial):\n",
        "    params = {\n",
        "        'objective': 'binary',\n",
        "        'max_bin': trial.suggest_int('max_bin', 255, 500),\n",
        "        'learning_rate': 0.05,\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 32, 128),\n",
        "    }\n",
        "\n",
        "    lgb_train = lgb.Dataset(X_train, y_train)\n",
        "    lgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n",
        "\n",
        "    model = lgb.train(params, lgb_train,\n",
        "                                   valid_sets=[lgb_train, lgb_eval],\n",
        "                                   verbose_eval=10,\n",
        "                                   num_boost_round=1000,\n",
        "                                   early_stopping_rounds=10)\n",
        "\n",
        "    y_pred_valid = model.predict(X_valid, num_iteration=model.best_iteration)\n",
        "    score = log_loss(y_valid, y_pred_valid)\n",
        "    return score"
      ],
      "execution_count": 293,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZP6cLcCvX5bi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "393e3110-f3d2-42d1-fd85-f9aaae3a4778"
      },
      "source": [
        "study = optuna.create_study(sampler=optuna.samplers.RandomSampler(seed=0))\n",
        "study.optimize(objective, n_trials=40)"
      ],
      "execution_count": 294,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.217688\tvalid_1's binary_logloss: 1.00872\n",
            "[20]\ttraining's binary_logloss: 0.195256\tvalid_1's binary_logloss: 0.895166\n",
            "[30]\ttraining's binary_logloss: 0.180891\tvalid_1's binary_logloss: 0.822762\n",
            "[40]\ttraining's binary_logloss: 0.169985\tvalid_1's binary_logloss: 0.762963\n",
            "[50]\ttraining's binary_logloss: 0.15986\tvalid_1's binary_logloss: 0.708496\n",
            "[60]\ttraining's binary_logloss: 0.151197\tvalid_1's binary_logloss: 0.666988\n",
            "[70]\ttraining's binary_logloss: 0.143329\tvalid_1's binary_logloss: 0.626358\n",
            "[80]\ttraining's binary_logloss: 0.136186\tvalid_1's binary_logloss: 0.590633\n",
            "[90]\ttraining's binary_logloss: 0.129867\tvalid_1's binary_logloss: 0.560449\n",
            "[100]\ttraining's binary_logloss: 0.124222\tvalid_1's binary_logloss: 0.532001\n",
            "[110]\ttraining's binary_logloss: 0.118826\tvalid_1's binary_logloss: 0.502306\n",
            "[120]\ttraining's binary_logloss: 0.114102\tvalid_1's binary_logloss: 0.4803\n",
            "[130]\ttraining's binary_logloss: 0.109799\tvalid_1's binary_logloss: 0.459645\n",
            "[140]\ttraining's binary_logloss: 0.105477\tvalid_1's binary_logloss: 0.437487\n",
            "[150]\ttraining's binary_logloss: 0.10197\tvalid_1's binary_logloss: 0.4206\n",
            "[160]\ttraining's binary_logloss: 0.0985467\tvalid_1's binary_logloss: 0.405818\n",
            "[170]\ttraining's binary_logloss: 0.0952972\tvalid_1's binary_logloss: 0.390249\n",
            "[180]\ttraining's binary_logloss: 0.0919294\tvalid_1's binary_logloss: 0.375312\n",
            "[190]\ttraining's binary_logloss: 0.0889653\tvalid_1's binary_logloss: 0.361577\n",
            "[200]\ttraining's binary_logloss: 0.0861246\tvalid_1's binary_logloss: 0.349303\n",
            "[210]\ttraining's binary_logloss: 0.0830099\tvalid_1's binary_logloss: 0.334437\n",
            "[220]\ttraining's binary_logloss: 0.0802001\tvalid_1's binary_logloss: 0.323039\n",
            "[230]\ttraining's binary_logloss: 0.0775726\tvalid_1's binary_logloss: 0.312206\n",
            "[240]\ttraining's binary_logloss: 0.0748825\tvalid_1's binary_logloss: 0.300706\n",
            "[250]\ttraining's binary_logloss: 0.0727717\tvalid_1's binary_logloss: 0.292195\n",
            "[260]\ttraining's binary_logloss: 0.0701895\tvalid_1's binary_logloss: 0.280389\n",
            "[270]\ttraining's binary_logloss: 0.0682201\tvalid_1's binary_logloss: 0.272497\n",
            "[280]\ttraining's binary_logloss: 0.0661261\tvalid_1's binary_logloss: 0.26377\n",
            "[290]\ttraining's binary_logloss: 0.0638277\tvalid_1's binary_logloss: 0.251907\n",
            "[300]\ttraining's binary_logloss: 0.0619598\tvalid_1's binary_logloss: 0.244543\n",
            "[310]\ttraining's binary_logloss: 0.0600125\tvalid_1's binary_logloss: 0.235942\n",
            "[320]\ttraining's binary_logloss: 0.0581424\tvalid_1's binary_logloss: 0.227718\n",
            "[330]\ttraining's binary_logloss: 0.0562387\tvalid_1's binary_logloss: 0.219401\n",
            "[340]\ttraining's binary_logloss: 0.0546384\tvalid_1's binary_logloss: 0.213429\n",
            "[350]\ttraining's binary_logloss: 0.0531353\tvalid_1's binary_logloss: 0.207548\n",
            "[360]\ttraining's binary_logloss: 0.0517896\tvalid_1's binary_logloss: 0.202371\n",
            "[370]\ttraining's binary_logloss: 0.0504853\tvalid_1's binary_logloss: 0.197476\n",
            "[380]\ttraining's binary_logloss: 0.0489872\tvalid_1's binary_logloss: 0.191055\n",
            "[390]\ttraining's binary_logloss: 0.0475767\tvalid_1's binary_logloss: 0.185369\n",
            "[400]\ttraining's binary_logloss: 0.0459271\tvalid_1's binary_logloss: 0.178554\n",
            "[410]\ttraining's binary_logloss: 0.0446173\tvalid_1's binary_logloss: 0.173669\n",
            "[420]\ttraining's binary_logloss: 0.0434602\tvalid_1's binary_logloss: 0.168898\n",
            "[430]\ttraining's binary_logloss: 0.042292\tvalid_1's binary_logloss: 0.163567\n",
            "[440]\ttraining's binary_logloss: 0.0410859\tvalid_1's binary_logloss: 0.158723\n",
            "[450]\ttraining's binary_logloss: 0.0398678\tvalid_1's binary_logloss: 0.153368\n",
            "[460]\ttraining's binary_logloss: 0.0387439\tvalid_1's binary_logloss: 0.148636\n",
            "[470]\ttraining's binary_logloss: 0.0374222\tvalid_1's binary_logloss: 0.143481\n",
            "[480]\ttraining's binary_logloss: 0.0362018\tvalid_1's binary_logloss: 0.138124\n",
            "[490]\ttraining's binary_logloss: 0.0351497\tvalid_1's binary_logloss: 0.133814\n",
            "[500]\ttraining's binary_logloss: 0.0339481\tvalid_1's binary_logloss: 0.128913\n",
            "[510]\ttraining's binary_logloss: 0.0329058\tvalid_1's binary_logloss: 0.125047\n",
            "[520]\ttraining's binary_logloss: 0.0318913\tvalid_1's binary_logloss: 0.120887\n",
            "[530]\ttraining's binary_logloss: 0.0309126\tvalid_1's binary_logloss: 0.116711\n",
            "[540]\ttraining's binary_logloss: 0.0299501\tvalid_1's binary_logloss: 0.113075\n",
            "[550]\ttraining's binary_logloss: 0.0289283\tvalid_1's binary_logloss: 0.108781\n",
            "[560]\ttraining's binary_logloss: 0.0279376\tvalid_1's binary_logloss: 0.104369\n",
            "[570]\ttraining's binary_logloss: 0.0271146\tvalid_1's binary_logloss: 0.101427\n",
            "[580]\ttraining's binary_logloss: 0.0261895\tvalid_1's binary_logloss: 0.0977024\n",
            "[590]\ttraining's binary_logloss: 0.0254543\tvalid_1's binary_logloss: 0.0947931\n",
            "[600]\ttraining's binary_logloss: 0.024697\tvalid_1's binary_logloss: 0.0917277\n",
            "[610]\ttraining's binary_logloss: 0.0240765\tvalid_1's binary_logloss: 0.0895123\n",
            "[620]\ttraining's binary_logloss: 0.0234782\tvalid_1's binary_logloss: 0.0874182\n",
            "[630]\ttraining's binary_logloss: 0.0228019\tvalid_1's binary_logloss: 0.0849296\n",
            "[640]\ttraining's binary_logloss: 0.0219931\tvalid_1's binary_logloss: 0.0818024\n",
            "[650]\ttraining's binary_logloss: 0.0212335\tvalid_1's binary_logloss: 0.0787494\n",
            "[660]\ttraining's binary_logloss: 0.0205849\tvalid_1's binary_logloss: 0.0762182\n",
            "[670]\ttraining's binary_logloss: 0.0199674\tvalid_1's binary_logloss: 0.0735025\n",
            "[680]\ttraining's binary_logloss: 0.0193996\tvalid_1's binary_logloss: 0.0713812\n",
            "[690]\ttraining's binary_logloss: 0.0188179\tvalid_1's binary_logloss: 0.069226\n",
            "[700]\ttraining's binary_logloss: 0.0183242\tvalid_1's binary_logloss: 0.0674527\n",
            "[710]\ttraining's binary_logloss: 0.0177663\tvalid_1's binary_logloss: 0.0654168\n",
            "[720]\ttraining's binary_logloss: 0.0172911\tvalid_1's binary_logloss: 0.063768\n",
            "[730]\ttraining's binary_logloss: 0.0167892\tvalid_1's binary_logloss: 0.0619448\n",
            "[740]\ttraining's binary_logloss: 0.0163913\tvalid_1's binary_logloss: 0.0604835\n",
            "[750]\ttraining's binary_logloss: 0.0157935\tvalid_1's binary_logloss: 0.0581082\n",
            "[760]\ttraining's binary_logloss: 0.0152855\tvalid_1's binary_logloss: 0.0563265\n",
            "[770]\ttraining's binary_logloss: 0.0147636\tvalid_1's binary_logloss: 0.0539991\n",
            "[780]\ttraining's binary_logloss: 0.0143453\tvalid_1's binary_logloss: 0.0524462\n",
            "[790]\ttraining's binary_logloss: 0.0139606\tvalid_1's binary_logloss: 0.0510698\n",
            "[800]\ttraining's binary_logloss: 0.0134694\tvalid_1's binary_logloss: 0.0493517\n",
            "[810]\ttraining's binary_logloss: 0.013092\tvalid_1's binary_logloss: 0.0480338\n",
            "[820]\ttraining's binary_logloss: 0.0126984\tvalid_1's binary_logloss: 0.0467146\n",
            "[830]\ttraining's binary_logloss: 0.0122952\tvalid_1's binary_logloss: 0.0452261\n",
            "[840]\ttraining's binary_logloss: 0.0119111\tvalid_1's binary_logloss: 0.0437925\n",
            "[850]\ttraining's binary_logloss: 0.0115444\tvalid_1's binary_logloss: 0.0425173\n",
            "[860]\ttraining's binary_logloss: 0.0111925\tvalid_1's binary_logloss: 0.0411524\n",
            "[870]\ttraining's binary_logloss: 0.0109072\tvalid_1's binary_logloss: 0.0401605\n",
            "[880]\ttraining's binary_logloss: 0.0106035\tvalid_1's binary_logloss: 0.038936\n",
            "[890]\ttraining's binary_logloss: 0.0102957\tvalid_1's binary_logloss: 0.0377827\n",
            "[900]\ttraining's binary_logloss: 0.0100588\tvalid_1's binary_logloss: 0.0369146\n",
            "[910]\ttraining's binary_logloss: 0.00976849\tvalid_1's binary_logloss: 0.0356884\n",
            "[920]\ttraining's binary_logloss: 0.00943296\tvalid_1's binary_logloss: 0.0344142\n",
            "[930]\ttraining's binary_logloss: 0.00914903\tvalid_1's binary_logloss: 0.0333803\n",
            "[940]\ttraining's binary_logloss: 0.00882754\tvalid_1's binary_logloss: 0.0322211\n",
            "[950]\ttraining's binary_logloss: 0.00856799\tvalid_1's binary_logloss: 0.0311883\n",
            "[960]\ttraining's binary_logloss: 0.00830047\tvalid_1's binary_logloss: 0.0301429\n",
            "[970]\ttraining's binary_logloss: 0.0080617\tvalid_1's binary_logloss: 0.0292593\n",
            "[980]\ttraining's binary_logloss: 0.00784778\tvalid_1's binary_logloss: 0.0284386\n",
            "[990]\ttraining's binary_logloss: 0.00763578\tvalid_1's binary_logloss: 0.02764\n",
            "[1000]\ttraining's binary_logloss: 0.00740752\tvalid_1's binary_logloss: 0.0267811\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.00740752\tvalid_1's binary_logloss: 0.0267811\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:44:17,172] Trial 0 finished with value: 0.026781051256995352 and parameters: {'max_bin': 427, 'num_leaves': 79}. Best is trial 0 with value: 0.026781051256995352.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.215271\tvalid_1's binary_logloss: 0.991995\n",
            "[20]\ttraining's binary_logloss: 0.191506\tvalid_1's binary_logloss: 0.871958\n",
            "[30]\ttraining's binary_logloss: 0.175745\tvalid_1's binary_logloss: 0.795478\n",
            "[40]\ttraining's binary_logloss: 0.163522\tvalid_1's binary_logloss: 0.731207\n",
            "[50]\ttraining's binary_logloss: 0.152547\tvalid_1's binary_logloss: 0.671328\n",
            "[60]\ttraining's binary_logloss: 0.142932\tvalid_1's binary_logloss: 0.623255\n",
            "[70]\ttraining's binary_logloss: 0.134295\tvalid_1's binary_logloss: 0.578039\n",
            "[80]\ttraining's binary_logloss: 0.126637\tvalid_1's binary_logloss: 0.539438\n",
            "[90]\ttraining's binary_logloss: 0.120034\tvalid_1's binary_logloss: 0.509078\n",
            "[100]\ttraining's binary_logloss: 0.114275\tvalid_1's binary_logloss: 0.480163\n",
            "[110]\ttraining's binary_logloss: 0.109095\tvalid_1's binary_logloss: 0.455164\n",
            "[120]\ttraining's binary_logloss: 0.104391\tvalid_1's binary_logloss: 0.43097\n",
            "[130]\ttraining's binary_logloss: 0.0997373\tvalid_1's binary_logloss: 0.408685\n",
            "[140]\ttraining's binary_logloss: 0.095191\tvalid_1's binary_logloss: 0.38671\n",
            "[150]\ttraining's binary_logloss: 0.0913882\tvalid_1's binary_logloss: 0.369168\n",
            "[160]\ttraining's binary_logloss: 0.0879424\tvalid_1's binary_logloss: 0.353807\n",
            "[170]\ttraining's binary_logloss: 0.0844193\tvalid_1's binary_logloss: 0.337739\n",
            "[180]\ttraining's binary_logloss: 0.0806966\tvalid_1's binary_logloss: 0.321532\n",
            "[190]\ttraining's binary_logloss: 0.0770374\tvalid_1's binary_logloss: 0.30571\n",
            "[200]\ttraining's binary_logloss: 0.073947\tvalid_1's binary_logloss: 0.292773\n",
            "[210]\ttraining's binary_logloss: 0.0707533\tvalid_1's binary_logloss: 0.277954\n",
            "[220]\ttraining's binary_logloss: 0.0677746\tvalid_1's binary_logloss: 0.265576\n",
            "[230]\ttraining's binary_logloss: 0.0650011\tvalid_1's binary_logloss: 0.253276\n",
            "[240]\ttraining's binary_logloss: 0.0622155\tvalid_1's binary_logloss: 0.241703\n",
            "[250]\ttraining's binary_logloss: 0.0597732\tvalid_1's binary_logloss: 0.23229\n",
            "[260]\ttraining's binary_logloss: 0.0576233\tvalid_1's binary_logloss: 0.223063\n",
            "[270]\ttraining's binary_logloss: 0.0553955\tvalid_1's binary_logloss: 0.213608\n",
            "[280]\ttraining's binary_logloss: 0.0534216\tvalid_1's binary_logloss: 0.206483\n",
            "[290]\ttraining's binary_logloss: 0.0515815\tvalid_1's binary_logloss: 0.199069\n",
            "[300]\ttraining's binary_logloss: 0.0498053\tvalid_1's binary_logloss: 0.191858\n",
            "[310]\ttraining's binary_logloss: 0.047998\tvalid_1's binary_logloss: 0.184293\n",
            "[320]\ttraining's binary_logloss: 0.0463306\tvalid_1's binary_logloss: 0.177613\n",
            "[330]\ttraining's binary_logloss: 0.0446935\tvalid_1's binary_logloss: 0.170121\n",
            "[340]\ttraining's binary_logloss: 0.0431248\tvalid_1's binary_logloss: 0.163376\n",
            "[350]\ttraining's binary_logloss: 0.0418096\tvalid_1's binary_logloss: 0.158516\n",
            "[360]\ttraining's binary_logloss: 0.0405117\tvalid_1's binary_logloss: 0.153117\n",
            "[370]\ttraining's binary_logloss: 0.0388358\tvalid_1's binary_logloss: 0.146102\n",
            "[380]\ttraining's binary_logloss: 0.0375157\tvalid_1's binary_logloss: 0.141306\n",
            "[390]\ttraining's binary_logloss: 0.0360534\tvalid_1's binary_logloss: 0.13551\n",
            "[400]\ttraining's binary_logloss: 0.0348491\tvalid_1's binary_logloss: 0.130887\n",
            "[410]\ttraining's binary_logloss: 0.0334911\tvalid_1's binary_logloss: 0.125947\n",
            "[420]\ttraining's binary_logloss: 0.0322672\tvalid_1's binary_logloss: 0.121305\n",
            "[430]\ttraining's binary_logloss: 0.0309679\tvalid_1's binary_logloss: 0.116178\n",
            "[440]\ttraining's binary_logloss: 0.0299569\tvalid_1's binary_logloss: 0.111894\n",
            "[450]\ttraining's binary_logloss: 0.0288071\tvalid_1's binary_logloss: 0.107339\n",
            "[460]\ttraining's binary_logloss: 0.0277599\tvalid_1's binary_logloss: 0.103233\n",
            "[470]\ttraining's binary_logloss: 0.0266719\tvalid_1's binary_logloss: 0.0990465\n",
            "[480]\ttraining's binary_logloss: 0.0256559\tvalid_1's binary_logloss: 0.0949203\n",
            "[490]\ttraining's binary_logloss: 0.0246401\tvalid_1's binary_logloss: 0.0908277\n",
            "[500]\ttraining's binary_logloss: 0.0238101\tvalid_1's binary_logloss: 0.0873819\n",
            "[510]\ttraining's binary_logloss: 0.0228715\tvalid_1's binary_logloss: 0.0836565\n",
            "[520]\ttraining's binary_logloss: 0.0220147\tvalid_1's binary_logloss: 0.0804344\n",
            "[530]\ttraining's binary_logloss: 0.0211143\tvalid_1's binary_logloss: 0.0771912\n",
            "[540]\ttraining's binary_logloss: 0.020288\tvalid_1's binary_logloss: 0.0739549\n",
            "[550]\ttraining's binary_logloss: 0.0195204\tvalid_1's binary_logloss: 0.0712758\n",
            "[560]\ttraining's binary_logloss: 0.0188571\tvalid_1's binary_logloss: 0.0689077\n",
            "[570]\ttraining's binary_logloss: 0.0181822\tvalid_1's binary_logloss: 0.0663232\n",
            "[580]\ttraining's binary_logloss: 0.0174965\tvalid_1's binary_logloss: 0.0637647\n",
            "[590]\ttraining's binary_logloss: 0.016756\tvalid_1's binary_logloss: 0.0608723\n",
            "[600]\ttraining's binary_logloss: 0.0161367\tvalid_1's binary_logloss: 0.0584517\n",
            "[610]\ttraining's binary_logloss: 0.0156071\tvalid_1's binary_logloss: 0.0568051\n",
            "[620]\ttraining's binary_logloss: 0.0149665\tvalid_1's binary_logloss: 0.0544543\n",
            "[630]\ttraining's binary_logloss: 0.0144268\tvalid_1's binary_logloss: 0.0524475\n",
            "[640]\ttraining's binary_logloss: 0.0138793\tvalid_1's binary_logloss: 0.0506029\n",
            "[650]\ttraining's binary_logloss: 0.0133495\tvalid_1's binary_logloss: 0.0486467\n",
            "[660]\ttraining's binary_logloss: 0.0128217\tvalid_1's binary_logloss: 0.0464496\n",
            "[670]\ttraining's binary_logloss: 0.0123864\tvalid_1's binary_logloss: 0.0449306\n",
            "[680]\ttraining's binary_logloss: 0.0119467\tvalid_1's binary_logloss: 0.0434043\n",
            "[690]\ttraining's binary_logloss: 0.0115178\tvalid_1's binary_logloss: 0.0417665\n",
            "[700]\ttraining's binary_logloss: 0.0111203\tvalid_1's binary_logloss: 0.0402743\n",
            "[710]\ttraining's binary_logloss: 0.010679\tvalid_1's binary_logloss: 0.0386086\n",
            "[720]\ttraining's binary_logloss: 0.0102455\tvalid_1's binary_logloss: 0.0370482\n",
            "[730]\ttraining's binary_logloss: 0.0098878\tvalid_1's binary_logloss: 0.0356883\n",
            "[740]\ttraining's binary_logloss: 0.00954043\tvalid_1's binary_logloss: 0.0344179\n",
            "[750]\ttraining's binary_logloss: 0.00914022\tvalid_1's binary_logloss: 0.032986\n",
            "[760]\ttraining's binary_logloss: 0.0087672\tvalid_1's binary_logloss: 0.0315972\n",
            "[770]\ttraining's binary_logloss: 0.00837971\tvalid_1's binary_logloss: 0.0302172\n",
            "[780]\ttraining's binary_logloss: 0.00803774\tvalid_1's binary_logloss: 0.0288994\n",
            "[790]\ttraining's binary_logloss: 0.00770121\tvalid_1's binary_logloss: 0.0276623\n",
            "[800]\ttraining's binary_logloss: 0.00739906\tvalid_1's binary_logloss: 0.026655\n",
            "[810]\ttraining's binary_logloss: 0.00715311\tvalid_1's binary_logloss: 0.0257781\n",
            "[820]\ttraining's binary_logloss: 0.00689802\tvalid_1's binary_logloss: 0.0249298\n",
            "[830]\ttraining's binary_logloss: 0.00665512\tvalid_1's binary_logloss: 0.0240213\n",
            "[840]\ttraining's binary_logloss: 0.00642892\tvalid_1's binary_logloss: 0.023171\n",
            "[850]\ttraining's binary_logloss: 0.00618958\tvalid_1's binary_logloss: 0.0223219\n",
            "[860]\ttraining's binary_logloss: 0.00594916\tvalid_1's binary_logloss: 0.0213274\n",
            "[870]\ttraining's binary_logloss: 0.00573069\tvalid_1's binary_logloss: 0.0205685\n",
            "[880]\ttraining's binary_logloss: 0.00553972\tvalid_1's binary_logloss: 0.0199032\n",
            "[890]\ttraining's binary_logloss: 0.00535473\tvalid_1's binary_logloss: 0.0191835\n",
            "[900]\ttraining's binary_logloss: 0.0051667\tvalid_1's binary_logloss: 0.0185164\n",
            "[910]\ttraining's binary_logloss: 0.0049837\tvalid_1's binary_logloss: 0.0178425\n",
            "[920]\ttraining's binary_logloss: 0.00480837\tvalid_1's binary_logloss: 0.0172153\n",
            "[930]\ttraining's binary_logloss: 0.00463242\tvalid_1's binary_logloss: 0.0165212\n",
            "[940]\ttraining's binary_logloss: 0.00447996\tvalid_1's binary_logloss: 0.0160411\n",
            "[950]\ttraining's binary_logloss: 0.00432879\tvalid_1's binary_logloss: 0.015487\n",
            "[960]\ttraining's binary_logloss: 0.00416618\tvalid_1's binary_logloss: 0.0149202\n",
            "[970]\ttraining's binary_logloss: 0.00402941\tvalid_1's binary_logloss: 0.0144091\n",
            "[980]\ttraining's binary_logloss: 0.00390187\tvalid_1's binary_logloss: 0.0139272\n",
            "[990]\ttraining's binary_logloss: 0.00376377\tvalid_1's binary_logloss: 0.0134732\n",
            "[1000]\ttraining's binary_logloss: 0.00362318\tvalid_1's binary_logloss: 0.0129209\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.00362318\tvalid_1's binary_logloss: 0.0129209\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:44:27,085] Trial 1 finished with value: 0.012920924217732561 and parameters: {'max_bin': 372, 'num_leaves': 96}. Best is trial 1 with value: 0.012920924217732561.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.214776\tvalid_1's binary_logloss: 0.989285\n",
            "[20]\ttraining's binary_logloss: 0.190662\tvalid_1's binary_logloss: 0.865635\n",
            "[30]\ttraining's binary_logloss: 0.174693\tvalid_1's binary_logloss: 0.785841\n",
            "[40]\ttraining's binary_logloss: 0.162235\tvalid_1's binary_logloss: 0.720306\n",
            "[50]\ttraining's binary_logloss: 0.15082\tvalid_1's binary_logloss: 0.658601\n",
            "[60]\ttraining's binary_logloss: 0.14071\tvalid_1's binary_logloss: 0.604612\n",
            "[70]\ttraining's binary_logloss: 0.132381\tvalid_1's binary_logloss: 0.565581\n",
            "[80]\ttraining's binary_logloss: 0.124551\tvalid_1's binary_logloss: 0.523822\n",
            "[90]\ttraining's binary_logloss: 0.117553\tvalid_1's binary_logloss: 0.487456\n",
            "[100]\ttraining's binary_logloss: 0.111832\tvalid_1's binary_logloss: 0.46197\n",
            "[110]\ttraining's binary_logloss: 0.106748\tvalid_1's binary_logloss: 0.438357\n",
            "[120]\ttraining's binary_logloss: 0.101631\tvalid_1's binary_logloss: 0.415059\n",
            "[130]\ttraining's binary_logloss: 0.0970207\tvalid_1's binary_logloss: 0.393202\n",
            "[140]\ttraining's binary_logloss: 0.0928017\tvalid_1's binary_logloss: 0.373865\n",
            "[150]\ttraining's binary_logloss: 0.0886555\tvalid_1's binary_logloss: 0.352695\n",
            "[160]\ttraining's binary_logloss: 0.0846982\tvalid_1's binary_logloss: 0.334919\n",
            "[170]\ttraining's binary_logloss: 0.0813151\tvalid_1's binary_logloss: 0.320046\n",
            "[180]\ttraining's binary_logloss: 0.077938\tvalid_1's binary_logloss: 0.304636\n",
            "[190]\ttraining's binary_logloss: 0.0748191\tvalid_1's binary_logloss: 0.291874\n",
            "[200]\ttraining's binary_logloss: 0.0717469\tvalid_1's binary_logloss: 0.278284\n",
            "[210]\ttraining's binary_logloss: 0.0689549\tvalid_1's binary_logloss: 0.26566\n",
            "[220]\ttraining's binary_logloss: 0.0663941\tvalid_1's binary_logloss: 0.254925\n",
            "[230]\ttraining's binary_logloss: 0.0635451\tvalid_1's binary_logloss: 0.242989\n",
            "[240]\ttraining's binary_logloss: 0.0609357\tvalid_1's binary_logloss: 0.232571\n",
            "[250]\ttraining's binary_logloss: 0.0584063\tvalid_1's binary_logloss: 0.222214\n",
            "[260]\ttraining's binary_logloss: 0.0565413\tvalid_1's binary_logloss: 0.21521\n",
            "[270]\ttraining's binary_logloss: 0.0545209\tvalid_1's binary_logloss: 0.206752\n",
            "[280]\ttraining's binary_logloss: 0.0523963\tvalid_1's binary_logloss: 0.19842\n",
            "[290]\ttraining's binary_logloss: 0.0502564\tvalid_1's binary_logloss: 0.190069\n",
            "[300]\ttraining's binary_logloss: 0.0482335\tvalid_1's binary_logloss: 0.182501\n",
            "[310]\ttraining's binary_logloss: 0.0463052\tvalid_1's binary_logloss: 0.175099\n",
            "[320]\ttraining's binary_logloss: 0.0443085\tvalid_1's binary_logloss: 0.166185\n",
            "[330]\ttraining's binary_logloss: 0.0425381\tvalid_1's binary_logloss: 0.158664\n",
            "[340]\ttraining's binary_logloss: 0.0409371\tvalid_1's binary_logloss: 0.152548\n",
            "[350]\ttraining's binary_logloss: 0.0392479\tvalid_1's binary_logloss: 0.145658\n",
            "[360]\ttraining's binary_logloss: 0.0378076\tvalid_1's binary_logloss: 0.139863\n",
            "[370]\ttraining's binary_logloss: 0.0363047\tvalid_1's binary_logloss: 0.133886\n",
            "[380]\ttraining's binary_logloss: 0.034974\tvalid_1's binary_logloss: 0.129204\n",
            "[390]\ttraining's binary_logloss: 0.0335993\tvalid_1's binary_logloss: 0.1242\n",
            "[400]\ttraining's binary_logloss: 0.0324383\tvalid_1's binary_logloss: 0.119756\n",
            "[410]\ttraining's binary_logloss: 0.0310092\tvalid_1's binary_logloss: 0.113949\n",
            "[420]\ttraining's binary_logloss: 0.0297321\tvalid_1's binary_logloss: 0.109001\n",
            "[430]\ttraining's binary_logloss: 0.0286388\tvalid_1's binary_logloss: 0.104765\n",
            "[440]\ttraining's binary_logloss: 0.0276778\tvalid_1's binary_logloss: 0.101301\n",
            "[450]\ttraining's binary_logloss: 0.0266988\tvalid_1's binary_logloss: 0.0977836\n",
            "[460]\ttraining's binary_logloss: 0.0258323\tvalid_1's binary_logloss: 0.0944724\n",
            "[470]\ttraining's binary_logloss: 0.0249356\tvalid_1's binary_logloss: 0.0913527\n",
            "[480]\ttraining's binary_logloss: 0.024089\tvalid_1's binary_logloss: 0.0883543\n",
            "[490]\ttraining's binary_logloss: 0.0232251\tvalid_1's binary_logloss: 0.0852542\n",
            "[500]\ttraining's binary_logloss: 0.0222354\tvalid_1's binary_logloss: 0.0815427\n",
            "[510]\ttraining's binary_logloss: 0.0214102\tvalid_1's binary_logloss: 0.0782135\n",
            "[520]\ttraining's binary_logloss: 0.0205984\tvalid_1's binary_logloss: 0.0751258\n",
            "[530]\ttraining's binary_logloss: 0.019757\tvalid_1's binary_logloss: 0.0716717\n",
            "[540]\ttraining's binary_logloss: 0.0190258\tvalid_1's binary_logloss: 0.0686835\n",
            "[550]\ttraining's binary_logloss: 0.0183439\tvalid_1's binary_logloss: 0.0659139\n",
            "[560]\ttraining's binary_logloss: 0.0176678\tvalid_1's binary_logloss: 0.0633487\n",
            "[570]\ttraining's binary_logloss: 0.017019\tvalid_1's binary_logloss: 0.060917\n",
            "[580]\ttraining's binary_logloss: 0.0163995\tvalid_1's binary_logloss: 0.0586517\n",
            "[590]\ttraining's binary_logloss: 0.0157466\tvalid_1's binary_logloss: 0.0564267\n",
            "[600]\ttraining's binary_logloss: 0.0152163\tvalid_1's binary_logloss: 0.0543701\n",
            "[610]\ttraining's binary_logloss: 0.0145661\tvalid_1's binary_logloss: 0.0519977\n",
            "[620]\ttraining's binary_logloss: 0.0140287\tvalid_1's binary_logloss: 0.0499824\n",
            "[630]\ttraining's binary_logloss: 0.0134784\tvalid_1's binary_logloss: 0.0482312\n",
            "[640]\ttraining's binary_logloss: 0.0130585\tvalid_1's binary_logloss: 0.046744\n",
            "[650]\ttraining's binary_logloss: 0.0125752\tvalid_1's binary_logloss: 0.0450268\n",
            "[660]\ttraining's binary_logloss: 0.0121114\tvalid_1's binary_logloss: 0.0433511\n",
            "[670]\ttraining's binary_logloss: 0.0116901\tvalid_1's binary_logloss: 0.0418573\n",
            "[680]\ttraining's binary_logloss: 0.0112513\tvalid_1's binary_logloss: 0.0402732\n",
            "[690]\ttraining's binary_logloss: 0.0108808\tvalid_1's binary_logloss: 0.0390188\n",
            "[700]\ttraining's binary_logloss: 0.0104791\tvalid_1's binary_logloss: 0.0375101\n",
            "[710]\ttraining's binary_logloss: 0.0100711\tvalid_1's binary_logloss: 0.0360485\n",
            "[720]\ttraining's binary_logloss: 0.00972219\tvalid_1's binary_logloss: 0.0347261\n",
            "[730]\ttraining's binary_logloss: 0.00935102\tvalid_1's binary_logloss: 0.0335351\n",
            "[740]\ttraining's binary_logloss: 0.00899859\tvalid_1's binary_logloss: 0.0322871\n",
            "[750]\ttraining's binary_logloss: 0.00868619\tvalid_1's binary_logloss: 0.0312215\n",
            "[760]\ttraining's binary_logloss: 0.00834321\tvalid_1's binary_logloss: 0.0300563\n",
            "[770]\ttraining's binary_logloss: 0.00801973\tvalid_1's binary_logloss: 0.0287971\n",
            "[780]\ttraining's binary_logloss: 0.00770563\tvalid_1's binary_logloss: 0.0276586\n",
            "[790]\ttraining's binary_logloss: 0.00742018\tvalid_1's binary_logloss: 0.0266277\n",
            "[800]\ttraining's binary_logloss: 0.00707162\tvalid_1's binary_logloss: 0.0253774\n",
            "[810]\ttraining's binary_logloss: 0.00678632\tvalid_1's binary_logloss: 0.0242891\n",
            "[820]\ttraining's binary_logloss: 0.00651374\tvalid_1's binary_logloss: 0.0232513\n",
            "[830]\ttraining's binary_logloss: 0.00625023\tvalid_1's binary_logloss: 0.0223363\n",
            "[840]\ttraining's binary_logloss: 0.00603481\tvalid_1's binary_logloss: 0.0215353\n",
            "[850]\ttraining's binary_logloss: 0.00578478\tvalid_1's binary_logloss: 0.0207098\n",
            "[860]\ttraining's binary_logloss: 0.00556551\tvalid_1's binary_logloss: 0.0199678\n",
            "[870]\ttraining's binary_logloss: 0.0053719\tvalid_1's binary_logloss: 0.0193008\n",
            "[880]\ttraining's binary_logloss: 0.0051875\tvalid_1's binary_logloss: 0.0186023\n",
            "[890]\ttraining's binary_logloss: 0.00500095\tvalid_1's binary_logloss: 0.01792\n",
            "[900]\ttraining's binary_logloss: 0.00479776\tvalid_1's binary_logloss: 0.0171947\n",
            "[910]\ttraining's binary_logloss: 0.00461084\tvalid_1's binary_logloss: 0.0165551\n",
            "[920]\ttraining's binary_logloss: 0.00444325\tvalid_1's binary_logloss: 0.0159495\n",
            "[930]\ttraining's binary_logloss: 0.00426726\tvalid_1's binary_logloss: 0.015254\n",
            "[940]\ttraining's binary_logloss: 0.00409511\tvalid_1's binary_logloss: 0.014617\n",
            "[950]\ttraining's binary_logloss: 0.00394111\tvalid_1's binary_logloss: 0.0140654\n",
            "[960]\ttraining's binary_logloss: 0.00379943\tvalid_1's binary_logloss: 0.0135463\n",
            "[970]\ttraining's binary_logloss: 0.00365573\tvalid_1's binary_logloss: 0.0130261\n",
            "[980]\ttraining's binary_logloss: 0.00352987\tvalid_1's binary_logloss: 0.0125846\n",
            "[990]\ttraining's binary_logloss: 0.00337488\tvalid_1's binary_logloss: 0.0119633\n",
            "[1000]\ttraining's binary_logloss: 0.00323164\tvalid_1's binary_logloss: 0.0114776\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.00323164\tvalid_1's binary_logloss: 0.0114776\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:44:36,791] Trial 2 finished with value: 0.011477592522205557 and parameters: {'max_bin': 322, 'num_leaves': 99}. Best is trial 2 with value: 0.011477592522205557.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.22501\tvalid_1's binary_logloss: 1.04882\n",
            "[20]\ttraining's binary_logloss: 0.207364\tvalid_1's binary_logloss: 0.961143\n",
            "[30]\ttraining's binary_logloss: 0.195994\tvalid_1's binary_logloss: 0.90664\n",
            "[40]\ttraining's binary_logloss: 0.187514\tvalid_1's binary_logloss: 0.866625\n",
            "[50]\ttraining's binary_logloss: 0.180688\tvalid_1's binary_logloss: 0.830488\n",
            "[60]\ttraining's binary_logloss: 0.174205\tvalid_1's binary_logloss: 0.793211\n",
            "[70]\ttraining's binary_logloss: 0.168705\tvalid_1's binary_logloss: 0.763356\n",
            "[80]\ttraining's binary_logloss: 0.163894\tvalid_1's binary_logloss: 0.738227\n",
            "[90]\ttraining's binary_logloss: 0.159488\tvalid_1's binary_logloss: 0.7159\n",
            "[100]\ttraining's binary_logloss: 0.15548\tvalid_1's binary_logloss: 0.696995\n",
            "[110]\ttraining's binary_logloss: 0.151707\tvalid_1's binary_logloss: 0.677357\n",
            "[120]\ttraining's binary_logloss: 0.148397\tvalid_1's binary_logloss: 0.661217\n",
            "[130]\ttraining's binary_logloss: 0.144972\tvalid_1's binary_logloss: 0.644354\n",
            "[140]\ttraining's binary_logloss: 0.141776\tvalid_1's binary_logloss: 0.625161\n",
            "[150]\ttraining's binary_logloss: 0.138632\tvalid_1's binary_logloss: 0.606769\n",
            "[160]\ttraining's binary_logloss: 0.135581\tvalid_1's binary_logloss: 0.593292\n",
            "[170]\ttraining's binary_logloss: 0.132844\tvalid_1's binary_logloss: 0.579443\n",
            "[180]\ttraining's binary_logloss: 0.130034\tvalid_1's binary_logloss: 0.563569\n",
            "[190]\ttraining's binary_logloss: 0.127472\tvalid_1's binary_logloss: 0.551179\n",
            "[200]\ttraining's binary_logloss: 0.124847\tvalid_1's binary_logloss: 0.536185\n",
            "[210]\ttraining's binary_logloss: 0.122681\tvalid_1's binary_logloss: 0.524953\n",
            "[220]\ttraining's binary_logloss: 0.120449\tvalid_1's binary_logloss: 0.51337\n",
            "[230]\ttraining's binary_logloss: 0.118204\tvalid_1's binary_logloss: 0.502354\n",
            "[240]\ttraining's binary_logloss: 0.116009\tvalid_1's binary_logloss: 0.490504\n",
            "[250]\ttraining's binary_logloss: 0.11377\tvalid_1's binary_logloss: 0.479905\n",
            "[260]\ttraining's binary_logloss: 0.111829\tvalid_1's binary_logloss: 0.469816\n",
            "[270]\ttraining's binary_logloss: 0.109826\tvalid_1's binary_logloss: 0.459854\n",
            "[280]\ttraining's binary_logloss: 0.107714\tvalid_1's binary_logloss: 0.450846\n",
            "[290]\ttraining's binary_logloss: 0.105527\tvalid_1's binary_logloss: 0.439835\n",
            "[300]\ttraining's binary_logloss: 0.103514\tvalid_1's binary_logloss: 0.42986\n",
            "[310]\ttraining's binary_logloss: 0.101718\tvalid_1's binary_logloss: 0.421342\n",
            "[320]\ttraining's binary_logloss: 0.0998745\tvalid_1's binary_logloss: 0.413067\n",
            "[330]\ttraining's binary_logloss: 0.0980756\tvalid_1's binary_logloss: 0.40407\n",
            "[340]\ttraining's binary_logloss: 0.0963572\tvalid_1's binary_logloss: 0.396268\n",
            "[350]\ttraining's binary_logloss: 0.0946382\tvalid_1's binary_logloss: 0.388699\n",
            "[360]\ttraining's binary_logloss: 0.0930272\tvalid_1's binary_logloss: 0.381234\n",
            "[370]\ttraining's binary_logloss: 0.0913896\tvalid_1's binary_logloss: 0.374051\n",
            "[380]\ttraining's binary_logloss: 0.0899817\tvalid_1's binary_logloss: 0.368408\n",
            "[390]\ttraining's binary_logloss: 0.0884799\tvalid_1's binary_logloss: 0.361682\n",
            "[400]\ttraining's binary_logloss: 0.0868544\tvalid_1's binary_logloss: 0.354612\n",
            "[410]\ttraining's binary_logloss: 0.0852831\tvalid_1's binary_logloss: 0.347189\n",
            "[420]\ttraining's binary_logloss: 0.0838675\tvalid_1's binary_logloss: 0.340103\n",
            "[430]\ttraining's binary_logloss: 0.0823258\tvalid_1's binary_logloss: 0.33284\n",
            "[440]\ttraining's binary_logloss: 0.0809224\tvalid_1's binary_logloss: 0.325352\n",
            "[450]\ttraining's binary_logloss: 0.0795383\tvalid_1's binary_logloss: 0.319635\n",
            "[460]\ttraining's binary_logloss: 0.0783895\tvalid_1's binary_logloss: 0.314541\n",
            "[470]\ttraining's binary_logloss: 0.0771399\tvalid_1's binary_logloss: 0.309471\n",
            "[480]\ttraining's binary_logloss: 0.0757487\tvalid_1's binary_logloss: 0.303816\n",
            "[490]\ttraining's binary_logloss: 0.0744791\tvalid_1's binary_logloss: 0.29871\n",
            "[500]\ttraining's binary_logloss: 0.0730549\tvalid_1's binary_logloss: 0.291503\n",
            "[510]\ttraining's binary_logloss: 0.0715745\tvalid_1's binary_logloss: 0.284672\n",
            "[520]\ttraining's binary_logloss: 0.0702763\tvalid_1's binary_logloss: 0.278498\n",
            "[530]\ttraining's binary_logloss: 0.0690872\tvalid_1's binary_logloss: 0.273187\n",
            "[540]\ttraining's binary_logloss: 0.0678513\tvalid_1's binary_logloss: 0.267235\n",
            "[550]\ttraining's binary_logloss: 0.0665934\tvalid_1's binary_logloss: 0.262151\n",
            "[560]\ttraining's binary_logloss: 0.0654387\tvalid_1's binary_logloss: 0.25749\n",
            "[570]\ttraining's binary_logloss: 0.0644844\tvalid_1's binary_logloss: 0.253447\n",
            "[580]\ttraining's binary_logloss: 0.0634655\tvalid_1's binary_logloss: 0.249651\n",
            "[590]\ttraining's binary_logloss: 0.0626141\tvalid_1's binary_logloss: 0.245485\n",
            "[600]\ttraining's binary_logloss: 0.0615321\tvalid_1's binary_logloss: 0.241285\n",
            "[610]\ttraining's binary_logloss: 0.0604461\tvalid_1's binary_logloss: 0.23626\n",
            "[620]\ttraining's binary_logloss: 0.0593478\tvalid_1's binary_logloss: 0.231268\n",
            "[630]\ttraining's binary_logloss: 0.0582928\tvalid_1's binary_logloss: 0.22671\n",
            "[640]\ttraining's binary_logloss: 0.0573827\tvalid_1's binary_logloss: 0.223108\n",
            "[650]\ttraining's binary_logloss: 0.0563107\tvalid_1's binary_logloss: 0.218594\n",
            "[660]\ttraining's binary_logloss: 0.0554109\tvalid_1's binary_logloss: 0.214555\n",
            "[670]\ttraining's binary_logloss: 0.0544733\tvalid_1's binary_logloss: 0.210619\n",
            "[680]\ttraining's binary_logloss: 0.0535886\tvalid_1's binary_logloss: 0.20696\n",
            "[690]\ttraining's binary_logloss: 0.0526668\tvalid_1's binary_logloss: 0.203739\n",
            "[700]\ttraining's binary_logloss: 0.0518452\tvalid_1's binary_logloss: 0.200198\n",
            "[710]\ttraining's binary_logloss: 0.0509908\tvalid_1's binary_logloss: 0.196982\n",
            "[720]\ttraining's binary_logloss: 0.050189\tvalid_1's binary_logloss: 0.193431\n",
            "[730]\ttraining's binary_logloss: 0.0494215\tvalid_1's binary_logloss: 0.190444\n",
            "[740]\ttraining's binary_logloss: 0.0486294\tvalid_1's binary_logloss: 0.186868\n",
            "[750]\ttraining's binary_logloss: 0.0477003\tvalid_1's binary_logloss: 0.182755\n",
            "[760]\ttraining's binary_logloss: 0.0468312\tvalid_1's binary_logloss: 0.179019\n",
            "[770]\ttraining's binary_logloss: 0.0461125\tvalid_1's binary_logloss: 0.176034\n",
            "[780]\ttraining's binary_logloss: 0.0454383\tvalid_1's binary_logloss: 0.173298\n",
            "[790]\ttraining's binary_logloss: 0.0447698\tvalid_1's binary_logloss: 0.170638\n",
            "[800]\ttraining's binary_logloss: 0.0440747\tvalid_1's binary_logloss: 0.167831\n",
            "[810]\ttraining's binary_logloss: 0.0434171\tvalid_1's binary_logloss: 0.165125\n",
            "[820]\ttraining's binary_logloss: 0.0428289\tvalid_1's binary_logloss: 0.162739\n",
            "[830]\ttraining's binary_logloss: 0.0421845\tvalid_1's binary_logloss: 0.160227\n",
            "[840]\ttraining's binary_logloss: 0.0415541\tvalid_1's binary_logloss: 0.157864\n",
            "[850]\ttraining's binary_logloss: 0.0407568\tvalid_1's binary_logloss: 0.154397\n",
            "[860]\ttraining's binary_logloss: 0.0400859\tvalid_1's binary_logloss: 0.151695\n",
            "[870]\ttraining's binary_logloss: 0.0394015\tvalid_1's binary_logloss: 0.14903\n",
            "[880]\ttraining's binary_logloss: 0.0386932\tvalid_1's binary_logloss: 0.145785\n",
            "[890]\ttraining's binary_logloss: 0.0381822\tvalid_1's binary_logloss: 0.143741\n",
            "[900]\ttraining's binary_logloss: 0.0376546\tvalid_1's binary_logloss: 0.141643\n",
            "[910]\ttraining's binary_logloss: 0.0370233\tvalid_1's binary_logloss: 0.139389\n",
            "[920]\ttraining's binary_logloss: 0.0364837\tvalid_1's binary_logloss: 0.137111\n",
            "[930]\ttraining's binary_logloss: 0.035956\tvalid_1's binary_logloss: 0.135111\n",
            "[940]\ttraining's binary_logloss: 0.0353952\tvalid_1's binary_logloss: 0.132947\n",
            "[950]\ttraining's binary_logloss: 0.0349006\tvalid_1's binary_logloss: 0.130973\n",
            "[960]\ttraining's binary_logloss: 0.034391\tvalid_1's binary_logloss: 0.128945\n",
            "[970]\ttraining's binary_logloss: 0.0339249\tvalid_1's binary_logloss: 0.127196\n",
            "[980]\ttraining's binary_logloss: 0.0334261\tvalid_1's binary_logloss: 0.125069\n",
            "[990]\ttraining's binary_logloss: 0.0328934\tvalid_1's binary_logloss: 0.122695\n",
            "[1000]\ttraining's binary_logloss: 0.0323633\tvalid_1's binary_logloss: 0.120522\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.0323633\tvalid_1's binary_logloss: 0.120522\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:44:43,247] Trial 3 finished with value: 0.12052193479135524 and parameters: {'max_bin': 358, 'num_leaves': 41}. Best is trial 2 with value: 0.011477592522205557.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.222501\tvalid_1's binary_logloss: 1.03438\n",
            "[20]\ttraining's binary_logloss: 0.20318\tvalid_1's binary_logloss: 0.939627\n",
            "[30]\ttraining's binary_logloss: 0.190859\tvalid_1's binary_logloss: 0.881371\n",
            "[40]\ttraining's binary_logloss: 0.181339\tvalid_1's binary_logloss: 0.832985\n",
            "[50]\ttraining's binary_logloss: 0.173689\tvalid_1's binary_logloss: 0.792591\n",
            "[60]\ttraining's binary_logloss: 0.166579\tvalid_1's binary_logloss: 0.756743\n",
            "[70]\ttraining's binary_logloss: 0.160075\tvalid_1's binary_logloss: 0.721779\n",
            "[80]\ttraining's binary_logloss: 0.15446\tvalid_1's binary_logloss: 0.690852\n",
            "[90]\ttraining's binary_logloss: 0.14893\tvalid_1's binary_logloss: 0.661265\n",
            "[100]\ttraining's binary_logloss: 0.144291\tvalid_1's binary_logloss: 0.637539\n",
            "[110]\ttraining's binary_logloss: 0.140398\tvalid_1's binary_logloss: 0.617439\n",
            "[120]\ttraining's binary_logloss: 0.136581\tvalid_1's binary_logloss: 0.596837\n",
            "[130]\ttraining's binary_logloss: 0.132752\tvalid_1's binary_logloss: 0.575837\n",
            "[140]\ttraining's binary_logloss: 0.129185\tvalid_1's binary_logloss: 0.558339\n",
            "[150]\ttraining's binary_logloss: 0.125897\tvalid_1's binary_logloss: 0.541737\n",
            "[160]\ttraining's binary_logloss: 0.12302\tvalid_1's binary_logloss: 0.525718\n",
            "[170]\ttraining's binary_logloss: 0.119989\tvalid_1's binary_logloss: 0.510998\n",
            "[180]\ttraining's binary_logloss: 0.117105\tvalid_1's binary_logloss: 0.495935\n",
            "[190]\ttraining's binary_logloss: 0.114406\tvalid_1's binary_logloss: 0.483101\n",
            "[200]\ttraining's binary_logloss: 0.112083\tvalid_1's binary_logloss: 0.472261\n",
            "[210]\ttraining's binary_logloss: 0.109402\tvalid_1's binary_logloss: 0.458554\n",
            "[220]\ttraining's binary_logloss: 0.10689\tvalid_1's binary_logloss: 0.445525\n",
            "[230]\ttraining's binary_logloss: 0.104523\tvalid_1's binary_logloss: 0.435635\n",
            "[240]\ttraining's binary_logloss: 0.102149\tvalid_1's binary_logloss: 0.424242\n",
            "[250]\ttraining's binary_logloss: 0.0996691\tvalid_1's binary_logloss: 0.40931\n",
            "[260]\ttraining's binary_logloss: 0.0975217\tvalid_1's binary_logloss: 0.396917\n",
            "[270]\ttraining's binary_logloss: 0.095365\tvalid_1's binary_logloss: 0.386654\n",
            "[280]\ttraining's binary_logloss: 0.0932714\tvalid_1's binary_logloss: 0.375569\n",
            "[290]\ttraining's binary_logloss: 0.091283\tvalid_1's binary_logloss: 0.365935\n",
            "[300]\ttraining's binary_logloss: 0.0891175\tvalid_1's binary_logloss: 0.356053\n",
            "[310]\ttraining's binary_logloss: 0.0870924\tvalid_1's binary_logloss: 0.346686\n",
            "[320]\ttraining's binary_logloss: 0.0850918\tvalid_1's binary_logloss: 0.338719\n",
            "[330]\ttraining's binary_logloss: 0.083194\tvalid_1's binary_logloss: 0.329894\n",
            "[340]\ttraining's binary_logloss: 0.0811123\tvalid_1's binary_logloss: 0.320322\n",
            "[350]\ttraining's binary_logloss: 0.0791744\tvalid_1's binary_logloss: 0.311741\n",
            "[360]\ttraining's binary_logloss: 0.0773537\tvalid_1's binary_logloss: 0.303396\n",
            "[370]\ttraining's binary_logloss: 0.0754681\tvalid_1's binary_logloss: 0.295388\n",
            "[380]\ttraining's binary_logloss: 0.07382\tvalid_1's binary_logloss: 0.288654\n",
            "[390]\ttraining's binary_logloss: 0.0721717\tvalid_1's binary_logloss: 0.281949\n",
            "[400]\ttraining's binary_logloss: 0.0708813\tvalid_1's binary_logloss: 0.276582\n",
            "[410]\ttraining's binary_logloss: 0.0691139\tvalid_1's binary_logloss: 0.269615\n",
            "[420]\ttraining's binary_logloss: 0.0676136\tvalid_1's binary_logloss: 0.262882\n",
            "[430]\ttraining's binary_logloss: 0.0660359\tvalid_1's binary_logloss: 0.257202\n",
            "[440]\ttraining's binary_logloss: 0.0644527\tvalid_1's binary_logloss: 0.250584\n",
            "[450]\ttraining's binary_logloss: 0.0632163\tvalid_1's binary_logloss: 0.245848\n",
            "[460]\ttraining's binary_logloss: 0.0618382\tvalid_1's binary_logloss: 0.239048\n",
            "[470]\ttraining's binary_logloss: 0.0605596\tvalid_1's binary_logloss: 0.233237\n",
            "[480]\ttraining's binary_logloss: 0.0592598\tvalid_1's binary_logloss: 0.227529\n",
            "[490]\ttraining's binary_logloss: 0.0580901\tvalid_1's binary_logloss: 0.223215\n",
            "[500]\ttraining's binary_logloss: 0.0567473\tvalid_1's binary_logloss: 0.217862\n",
            "[510]\ttraining's binary_logloss: 0.0554572\tvalid_1's binary_logloss: 0.212989\n",
            "[520]\ttraining's binary_logloss: 0.0542185\tvalid_1's binary_logloss: 0.208124\n",
            "[530]\ttraining's binary_logloss: 0.0530848\tvalid_1's binary_logloss: 0.20412\n",
            "[540]\ttraining's binary_logloss: 0.051955\tvalid_1's binary_logloss: 0.199857\n",
            "[550]\ttraining's binary_logloss: 0.0509044\tvalid_1's binary_logloss: 0.19569\n",
            "[560]\ttraining's binary_logloss: 0.0497157\tvalid_1's binary_logloss: 0.189883\n",
            "[570]\ttraining's binary_logloss: 0.0487148\tvalid_1's binary_logloss: 0.186349\n",
            "[580]\ttraining's binary_logloss: 0.0476703\tvalid_1's binary_logloss: 0.181874\n",
            "[590]\ttraining's binary_logloss: 0.0466504\tvalid_1's binary_logloss: 0.177391\n",
            "[600]\ttraining's binary_logloss: 0.0456415\tvalid_1's binary_logloss: 0.173372\n",
            "[610]\ttraining's binary_logloss: 0.0445195\tvalid_1's binary_logloss: 0.169175\n",
            "[620]\ttraining's binary_logloss: 0.0435189\tvalid_1's binary_logloss: 0.165397\n",
            "[630]\ttraining's binary_logloss: 0.042649\tvalid_1's binary_logloss: 0.162143\n",
            "[640]\ttraining's binary_logloss: 0.0417636\tvalid_1's binary_logloss: 0.158873\n",
            "[650]\ttraining's binary_logloss: 0.0409941\tvalid_1's binary_logloss: 0.155718\n",
            "[660]\ttraining's binary_logloss: 0.0401571\tvalid_1's binary_logloss: 0.152451\n",
            "[670]\ttraining's binary_logloss: 0.0394144\tvalid_1's binary_logloss: 0.149966\n",
            "[680]\ttraining's binary_logloss: 0.0386172\tvalid_1's binary_logloss: 0.146665\n",
            "[690]\ttraining's binary_logloss: 0.0378764\tvalid_1's binary_logloss: 0.143685\n",
            "[700]\ttraining's binary_logloss: 0.037168\tvalid_1's binary_logloss: 0.14096\n",
            "[710]\ttraining's binary_logloss: 0.0363615\tvalid_1's binary_logloss: 0.138026\n",
            "[720]\ttraining's binary_logloss: 0.0356078\tvalid_1's binary_logloss: 0.134838\n",
            "[730]\ttraining's binary_logloss: 0.0348299\tvalid_1's binary_logloss: 0.131948\n",
            "[740]\ttraining's binary_logloss: 0.0340067\tvalid_1's binary_logloss: 0.128559\n",
            "[750]\ttraining's binary_logloss: 0.0333182\tvalid_1's binary_logloss: 0.125748\n",
            "[760]\ttraining's binary_logloss: 0.0326816\tvalid_1's binary_logloss: 0.123448\n",
            "[770]\ttraining's binary_logloss: 0.0320606\tvalid_1's binary_logloss: 0.120946\n",
            "[780]\ttraining's binary_logloss: 0.031507\tvalid_1's binary_logloss: 0.118878\n",
            "[790]\ttraining's binary_logloss: 0.0309225\tvalid_1's binary_logloss: 0.116683\n",
            "[800]\ttraining's binary_logloss: 0.0303274\tvalid_1's binary_logloss: 0.114753\n",
            "[810]\ttraining's binary_logloss: 0.029754\tvalid_1's binary_logloss: 0.112504\n",
            "[820]\ttraining's binary_logloss: 0.0291685\tvalid_1's binary_logloss: 0.110266\n",
            "[830]\ttraining's binary_logloss: 0.0286786\tvalid_1's binary_logloss: 0.108292\n",
            "[840]\ttraining's binary_logloss: 0.0280853\tvalid_1's binary_logloss: 0.106186\n",
            "[850]\ttraining's binary_logloss: 0.0275342\tvalid_1's binary_logloss: 0.104295\n",
            "[860]\ttraining's binary_logloss: 0.0270163\tvalid_1's binary_logloss: 0.102395\n",
            "[870]\ttraining's binary_logloss: 0.0264144\tvalid_1's binary_logloss: 0.0996904\n",
            "[880]\ttraining's binary_logloss: 0.0259261\tvalid_1's binary_logloss: 0.0980542\n",
            "[890]\ttraining's binary_logloss: 0.0254492\tvalid_1's binary_logloss: 0.096327\n",
            "[900]\ttraining's binary_logloss: 0.0249544\tvalid_1's binary_logloss: 0.0942716\n",
            "[910]\ttraining's binary_logloss: 0.0244014\tvalid_1's binary_logloss: 0.0924674\n",
            "[920]\ttraining's binary_logloss: 0.0239494\tvalid_1's binary_logloss: 0.0906798\n",
            "[930]\ttraining's binary_logloss: 0.0234491\tvalid_1's binary_logloss: 0.0887118\n",
            "[940]\ttraining's binary_logloss: 0.022983\tvalid_1's binary_logloss: 0.0865932\n",
            "[950]\ttraining's binary_logloss: 0.0224846\tvalid_1's binary_logloss: 0.0849022\n",
            "[960]\ttraining's binary_logloss: 0.0220133\tvalid_1's binary_logloss: 0.0830528\n",
            "[970]\ttraining's binary_logloss: 0.021587\tvalid_1's binary_logloss: 0.0811245\n",
            "[980]\ttraining's binary_logloss: 0.0211517\tvalid_1's binary_logloss: 0.0796752\n",
            "[990]\ttraining's binary_logloss: 0.0207535\tvalid_1's binary_logloss: 0.0781687\n",
            "[1000]\ttraining's binary_logloss: 0.0203976\tvalid_1's binary_logloss: 0.0768434\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.0203976\tvalid_1's binary_logloss: 0.0768434\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:44:50,469] Trial 4 finished with value: 0.07684342044843524 and parameters: {'max_bin': 466, 'num_leaves': 53}. Best is trial 2 with value: 0.011477592522205557.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.219586\tvalid_1's binary_logloss: 1.01797\n",
            "[20]\ttraining's binary_logloss: 0.198527\tvalid_1's binary_logloss: 0.91286\n",
            "[30]\ttraining's binary_logloss: 0.184984\tvalid_1's binary_logloss: 0.847966\n",
            "[40]\ttraining's binary_logloss: 0.174237\tvalid_1's binary_logloss: 0.795034\n",
            "[50]\ttraining's binary_logloss: 0.16519\tvalid_1's binary_logloss: 0.747782\n",
            "[60]\ttraining's binary_logloss: 0.156995\tvalid_1's binary_logloss: 0.703364\n",
            "[70]\ttraining's binary_logloss: 0.149719\tvalid_1's binary_logloss: 0.667135\n",
            "[80]\ttraining's binary_logloss: 0.143358\tvalid_1's binary_logloss: 0.635119\n",
            "[90]\ttraining's binary_logloss: 0.137064\tvalid_1's binary_logloss: 0.602245\n",
            "[100]\ttraining's binary_logloss: 0.131804\tvalid_1's binary_logloss: 0.579926\n",
            "[110]\ttraining's binary_logloss: 0.12732\tvalid_1's binary_logloss: 0.557033\n",
            "[120]\ttraining's binary_logloss: 0.122889\tvalid_1's binary_logloss: 0.533137\n",
            "[130]\ttraining's binary_logloss: 0.118742\tvalid_1's binary_logloss: 0.511935\n",
            "[140]\ttraining's binary_logloss: 0.114804\tvalid_1's binary_logloss: 0.49175\n",
            "[150]\ttraining's binary_logloss: 0.111243\tvalid_1's binary_logloss: 0.473778\n",
            "[160]\ttraining's binary_logloss: 0.107862\tvalid_1's binary_logloss: 0.456306\n",
            "[170]\ttraining's binary_logloss: 0.104669\tvalid_1's binary_logloss: 0.440086\n",
            "[180]\ttraining's binary_logloss: 0.10167\tvalid_1's binary_logloss: 0.422778\n",
            "[190]\ttraining's binary_logloss: 0.098604\tvalid_1's binary_logloss: 0.409142\n",
            "[200]\ttraining's binary_logloss: 0.0955013\tvalid_1's binary_logloss: 0.393649\n",
            "[210]\ttraining's binary_logloss: 0.0930228\tvalid_1's binary_logloss: 0.380804\n",
            "[220]\ttraining's binary_logloss: 0.090444\tvalid_1's binary_logloss: 0.368705\n",
            "[230]\ttraining's binary_logloss: 0.0876232\tvalid_1's binary_logloss: 0.356296\n",
            "[240]\ttraining's binary_logloss: 0.0850251\tvalid_1's binary_logloss: 0.344234\n",
            "[250]\ttraining's binary_logloss: 0.0827205\tvalid_1's binary_logloss: 0.334044\n",
            "[260]\ttraining's binary_logloss: 0.0802498\tvalid_1's binary_logloss: 0.323331\n",
            "[270]\ttraining's binary_logloss: 0.0780232\tvalid_1's binary_logloss: 0.31404\n",
            "[280]\ttraining's binary_logloss: 0.076005\tvalid_1's binary_logloss: 0.305123\n",
            "[290]\ttraining's binary_logloss: 0.074072\tvalid_1's binary_logloss: 0.296879\n",
            "[300]\ttraining's binary_logloss: 0.0720044\tvalid_1's binary_logloss: 0.287715\n",
            "[310]\ttraining's binary_logloss: 0.0699353\tvalid_1's binary_logloss: 0.279045\n",
            "[320]\ttraining's binary_logloss: 0.0681493\tvalid_1's binary_logloss: 0.270861\n",
            "[330]\ttraining's binary_logloss: 0.0662201\tvalid_1's binary_logloss: 0.261493\n",
            "[340]\ttraining's binary_logloss: 0.0644331\tvalid_1's binary_logloss: 0.25328\n",
            "[350]\ttraining's binary_logloss: 0.06269\tvalid_1's binary_logloss: 0.245405\n",
            "[360]\ttraining's binary_logloss: 0.0610112\tvalid_1's binary_logloss: 0.237399\n",
            "[370]\ttraining's binary_logloss: 0.0593356\tvalid_1's binary_logloss: 0.230678\n",
            "[380]\ttraining's binary_logloss: 0.0577965\tvalid_1's binary_logloss: 0.224088\n",
            "[390]\ttraining's binary_logloss: 0.0560631\tvalid_1's binary_logloss: 0.216768\n",
            "[400]\ttraining's binary_logloss: 0.0545144\tvalid_1's binary_logloss: 0.21118\n",
            "[410]\ttraining's binary_logloss: 0.0531614\tvalid_1's binary_logloss: 0.205937\n",
            "[420]\ttraining's binary_logloss: 0.0517653\tvalid_1's binary_logloss: 0.199875\n",
            "[430]\ttraining's binary_logloss: 0.0505684\tvalid_1's binary_logloss: 0.194783\n",
            "[440]\ttraining's binary_logloss: 0.0491235\tvalid_1's binary_logloss: 0.188418\n",
            "[450]\ttraining's binary_logloss: 0.047827\tvalid_1's binary_logloss: 0.18346\n",
            "[460]\ttraining's binary_logloss: 0.0465123\tvalid_1's binary_logloss: 0.17841\n",
            "[470]\ttraining's binary_logloss: 0.0451508\tvalid_1's binary_logloss: 0.173039\n",
            "[480]\ttraining's binary_logloss: 0.0441144\tvalid_1's binary_logloss: 0.169179\n",
            "[490]\ttraining's binary_logloss: 0.0432494\tvalid_1's binary_logloss: 0.166089\n",
            "[500]\ttraining's binary_logloss: 0.0420258\tvalid_1's binary_logloss: 0.161086\n",
            "[510]\ttraining's binary_logloss: 0.0408753\tvalid_1's binary_logloss: 0.156583\n",
            "[520]\ttraining's binary_logloss: 0.0397691\tvalid_1's binary_logloss: 0.15283\n",
            "[530]\ttraining's binary_logloss: 0.0389133\tvalid_1's binary_logloss: 0.150014\n",
            "[540]\ttraining's binary_logloss: 0.0379343\tvalid_1's binary_logloss: 0.145949\n",
            "[550]\ttraining's binary_logloss: 0.0366936\tvalid_1's binary_logloss: 0.140485\n",
            "[560]\ttraining's binary_logloss: 0.0356674\tvalid_1's binary_logloss: 0.136223\n",
            "[570]\ttraining's binary_logloss: 0.0346616\tvalid_1's binary_logloss: 0.131879\n",
            "[580]\ttraining's binary_logloss: 0.0337435\tvalid_1's binary_logloss: 0.128586\n",
            "[590]\ttraining's binary_logloss: 0.0329126\tvalid_1's binary_logloss: 0.125466\n",
            "[600]\ttraining's binary_logloss: 0.0319341\tvalid_1's binary_logloss: 0.12159\n",
            "[610]\ttraining's binary_logloss: 0.030966\tvalid_1's binary_logloss: 0.117234\n",
            "[620]\ttraining's binary_logloss: 0.0300155\tvalid_1's binary_logloss: 0.113402\n",
            "[630]\ttraining's binary_logloss: 0.0291337\tvalid_1's binary_logloss: 0.109769\n",
            "[640]\ttraining's binary_logloss: 0.0283219\tvalid_1's binary_logloss: 0.106455\n",
            "[650]\ttraining's binary_logloss: 0.0276108\tvalid_1's binary_logloss: 0.103578\n",
            "[660]\ttraining's binary_logloss: 0.0268414\tvalid_1's binary_logloss: 0.100793\n",
            "[670]\ttraining's binary_logloss: 0.0261085\tvalid_1's binary_logloss: 0.0980468\n",
            "[680]\ttraining's binary_logloss: 0.0253619\tvalid_1's binary_logloss: 0.0947648\n",
            "[690]\ttraining's binary_logloss: 0.0247223\tvalid_1's binary_logloss: 0.0924669\n",
            "[700]\ttraining's binary_logloss: 0.0241276\tvalid_1's binary_logloss: 0.0903879\n",
            "[710]\ttraining's binary_logloss: 0.0235065\tvalid_1's binary_logloss: 0.0880418\n",
            "[720]\ttraining's binary_logloss: 0.0229103\tvalid_1's binary_logloss: 0.0855894\n",
            "[730]\ttraining's binary_logloss: 0.0221908\tvalid_1's binary_logloss: 0.0826212\n",
            "[740]\ttraining's binary_logloss: 0.0216323\tvalid_1's binary_logloss: 0.0804697\n",
            "[750]\ttraining's binary_logloss: 0.0211092\tvalid_1's binary_logloss: 0.0783603\n",
            "[760]\ttraining's binary_logloss: 0.020604\tvalid_1's binary_logloss: 0.0765493\n",
            "[770]\ttraining's binary_logloss: 0.0200687\tvalid_1's binary_logloss: 0.0745346\n",
            "[780]\ttraining's binary_logloss: 0.0195852\tvalid_1's binary_logloss: 0.0729538\n",
            "[790]\ttraining's binary_logloss: 0.0191621\tvalid_1's binary_logloss: 0.0714705\n",
            "[800]\ttraining's binary_logloss: 0.0186791\tvalid_1's binary_logloss: 0.0697495\n",
            "[810]\ttraining's binary_logloss: 0.0182761\tvalid_1's binary_logloss: 0.0682677\n",
            "[820]\ttraining's binary_logloss: 0.0178239\tvalid_1's binary_logloss: 0.066451\n",
            "[830]\ttraining's binary_logloss: 0.0173212\tvalid_1's binary_logloss: 0.0644915\n",
            "[840]\ttraining's binary_logloss: 0.0169212\tvalid_1's binary_logloss: 0.0629071\n",
            "[850]\ttraining's binary_logloss: 0.0164671\tvalid_1's binary_logloss: 0.0611089\n",
            "[860]\ttraining's binary_logloss: 0.0160426\tvalid_1's binary_logloss: 0.0594813\n",
            "[870]\ttraining's binary_logloss: 0.0155982\tvalid_1's binary_logloss: 0.0578182\n",
            "[880]\ttraining's binary_logloss: 0.0151953\tvalid_1's binary_logloss: 0.0564598\n",
            "[890]\ttraining's binary_logloss: 0.0148422\tvalid_1's binary_logloss: 0.0551213\n",
            "[900]\ttraining's binary_logloss: 0.0145098\tvalid_1's binary_logloss: 0.0539012\n",
            "[910]\ttraining's binary_logloss: 0.0141028\tvalid_1's binary_logloss: 0.0522421\n",
            "[920]\ttraining's binary_logloss: 0.0138168\tvalid_1's binary_logloss: 0.051181\n",
            "[930]\ttraining's binary_logloss: 0.0134899\tvalid_1's binary_logloss: 0.0498893\n",
            "[940]\ttraining's binary_logloss: 0.0131685\tvalid_1's binary_logloss: 0.0487432\n",
            "[950]\ttraining's binary_logloss: 0.0128153\tvalid_1's binary_logloss: 0.0472726\n",
            "[960]\ttraining's binary_logloss: 0.0124483\tvalid_1's binary_logloss: 0.0457966\n",
            "[970]\ttraining's binary_logloss: 0.0120981\tvalid_1's binary_logloss: 0.0445351\n",
            "[980]\ttraining's binary_logloss: 0.0117466\tvalid_1's binary_logloss: 0.0432055\n",
            "[990]\ttraining's binary_logloss: 0.0114698\tvalid_1's binary_logloss: 0.0423623\n",
            "[1000]\ttraining's binary_logloss: 0.0111415\tvalid_1's binary_logloss: 0.0410735\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.0111415\tvalid_1's binary_logloss: 0.0410735\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:44:58,698] Trial 5 finished with value: 0.041073470306809745 and parameters: {'max_bin': 497, 'num_leaves': 68}. Best is trial 2 with value: 0.011477592522205557.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.214168\tvalid_1's binary_logloss: 0.986922\n",
            "[20]\ttraining's binary_logloss: 0.189615\tvalid_1's binary_logloss: 0.864736\n",
            "[30]\ttraining's binary_logloss: 0.173362\tvalid_1's binary_logloss: 0.780751\n",
            "[40]\ttraining's binary_logloss: 0.160719\tvalid_1's binary_logloss: 0.715023\n",
            "[50]\ttraining's binary_logloss: 0.149565\tvalid_1's binary_logloss: 0.653407\n",
            "[60]\ttraining's binary_logloss: 0.139772\tvalid_1's binary_logloss: 0.603468\n",
            "[70]\ttraining's binary_logloss: 0.130821\tvalid_1's binary_logloss: 0.558807\n",
            "[80]\ttraining's binary_logloss: 0.122709\tvalid_1's binary_logloss: 0.516374\n",
            "[90]\ttraining's binary_logloss: 0.115759\tvalid_1's binary_logloss: 0.482325\n",
            "[100]\ttraining's binary_logloss: 0.109599\tvalid_1's binary_logloss: 0.453257\n",
            "[110]\ttraining's binary_logloss: 0.103884\tvalid_1's binary_logloss: 0.428068\n",
            "[120]\ttraining's binary_logloss: 0.0989748\tvalid_1's binary_logloss: 0.403994\n",
            "[130]\ttraining's binary_logloss: 0.0943214\tvalid_1's binary_logloss: 0.381559\n",
            "[140]\ttraining's binary_logloss: 0.0901332\tvalid_1's binary_logloss: 0.361918\n",
            "[150]\ttraining's binary_logloss: 0.0860629\tvalid_1's binary_logloss: 0.344908\n",
            "[160]\ttraining's binary_logloss: 0.0822268\tvalid_1's binary_logloss: 0.32654\n",
            "[170]\ttraining's binary_logloss: 0.0786147\tvalid_1's binary_logloss: 0.311069\n",
            "[180]\ttraining's binary_logloss: 0.075373\tvalid_1's binary_logloss: 0.296751\n",
            "[190]\ttraining's binary_logloss: 0.0719588\tvalid_1's binary_logloss: 0.282114\n",
            "[200]\ttraining's binary_logloss: 0.0691606\tvalid_1's binary_logloss: 0.270391\n",
            "[210]\ttraining's binary_logloss: 0.0663959\tvalid_1's binary_logloss: 0.257765\n",
            "[220]\ttraining's binary_logloss: 0.063867\tvalid_1's binary_logloss: 0.246669\n",
            "[230]\ttraining's binary_logloss: 0.0614706\tvalid_1's binary_logloss: 0.237387\n",
            "[240]\ttraining's binary_logloss: 0.0588405\tvalid_1's binary_logloss: 0.225451\n",
            "[250]\ttraining's binary_logloss: 0.0564465\tvalid_1's binary_logloss: 0.215579\n",
            "[260]\ttraining's binary_logloss: 0.0541742\tvalid_1's binary_logloss: 0.206571\n",
            "[270]\ttraining's binary_logloss: 0.0520239\tvalid_1's binary_logloss: 0.1982\n",
            "[280]\ttraining's binary_logloss: 0.0498703\tvalid_1's binary_logloss: 0.189574\n",
            "[290]\ttraining's binary_logloss: 0.0480561\tvalid_1's binary_logloss: 0.182407\n",
            "[300]\ttraining's binary_logloss: 0.0463382\tvalid_1's binary_logloss: 0.17514\n",
            "[310]\ttraining's binary_logloss: 0.0445266\tvalid_1's binary_logloss: 0.16774\n",
            "[320]\ttraining's binary_logloss: 0.0427178\tvalid_1's binary_logloss: 0.161102\n",
            "[330]\ttraining's binary_logloss: 0.0411465\tvalid_1's binary_logloss: 0.154938\n",
            "[340]\ttraining's binary_logloss: 0.0393787\tvalid_1's binary_logloss: 0.14815\n",
            "[350]\ttraining's binary_logloss: 0.0378847\tvalid_1's binary_logloss: 0.142252\n",
            "[360]\ttraining's binary_logloss: 0.0365292\tvalid_1's binary_logloss: 0.136845\n",
            "[370]\ttraining's binary_logloss: 0.0350495\tvalid_1's binary_logloss: 0.130751\n",
            "[380]\ttraining's binary_logloss: 0.0337424\tvalid_1's binary_logloss: 0.125553\n",
            "[390]\ttraining's binary_logloss: 0.0324561\tvalid_1's binary_logloss: 0.120444\n",
            "[400]\ttraining's binary_logloss: 0.0313172\tvalid_1's binary_logloss: 0.116279\n",
            "[410]\ttraining's binary_logloss: 0.0302333\tvalid_1's binary_logloss: 0.112461\n",
            "[420]\ttraining's binary_logloss: 0.029172\tvalid_1's binary_logloss: 0.10843\n",
            "[430]\ttraining's binary_logloss: 0.0278838\tvalid_1's binary_logloss: 0.103358\n",
            "[440]\ttraining's binary_logloss: 0.0266369\tvalid_1's binary_logloss: 0.0989094\n",
            "[450]\ttraining's binary_logloss: 0.0255496\tvalid_1's binary_logloss: 0.0946618\n",
            "[460]\ttraining's binary_logloss: 0.0244597\tvalid_1's binary_logloss: 0.0904961\n",
            "[470]\ttraining's binary_logloss: 0.0233995\tvalid_1's binary_logloss: 0.0867626\n",
            "[480]\ttraining's binary_logloss: 0.0224382\tvalid_1's binary_logloss: 0.0830248\n",
            "[490]\ttraining's binary_logloss: 0.0215404\tvalid_1's binary_logloss: 0.0792913\n",
            "[500]\ttraining's binary_logloss: 0.0205695\tvalid_1's binary_logloss: 0.0756147\n",
            "[510]\ttraining's binary_logloss: 0.0197133\tvalid_1's binary_logloss: 0.072448\n",
            "[520]\ttraining's binary_logloss: 0.0188836\tvalid_1's binary_logloss: 0.069462\n",
            "[530]\ttraining's binary_logloss: 0.0180352\tvalid_1's binary_logloss: 0.066526\n",
            "[540]\ttraining's binary_logloss: 0.017353\tvalid_1's binary_logloss: 0.0639741\n",
            "[550]\ttraining's binary_logloss: 0.0166781\tvalid_1's binary_logloss: 0.0615748\n",
            "[560]\ttraining's binary_logloss: 0.0160191\tvalid_1's binary_logloss: 0.0592946\n",
            "[570]\ttraining's binary_logloss: 0.0153931\tvalid_1's binary_logloss: 0.0567632\n",
            "[580]\ttraining's binary_logloss: 0.0148241\tvalid_1's binary_logloss: 0.0546887\n",
            "[590]\ttraining's binary_logloss: 0.0142985\tvalid_1's binary_logloss: 0.0526294\n",
            "[600]\ttraining's binary_logloss: 0.0136334\tvalid_1's binary_logloss: 0.0501202\n",
            "[610]\ttraining's binary_logloss: 0.0131472\tvalid_1's binary_logloss: 0.048161\n",
            "[620]\ttraining's binary_logloss: 0.0127433\tvalid_1's binary_logloss: 0.0466637\n",
            "[630]\ttraining's binary_logloss: 0.0122031\tvalid_1's binary_logloss: 0.0444022\n",
            "[640]\ttraining's binary_logloss: 0.0117429\tvalid_1's binary_logloss: 0.0426579\n",
            "[650]\ttraining's binary_logloss: 0.0112894\tvalid_1's binary_logloss: 0.040917\n",
            "[660]\ttraining's binary_logloss: 0.0108192\tvalid_1's binary_logloss: 0.038987\n",
            "[670]\ttraining's binary_logloss: 0.0103772\tvalid_1's binary_logloss: 0.0373518\n",
            "[680]\ttraining's binary_logloss: 0.0100235\tvalid_1's binary_logloss: 0.0360272\n",
            "[690]\ttraining's binary_logloss: 0.00961388\tvalid_1's binary_logloss: 0.0345994\n",
            "[700]\ttraining's binary_logloss: 0.00923141\tvalid_1's binary_logloss: 0.0332909\n",
            "[710]\ttraining's binary_logloss: 0.00888571\tvalid_1's binary_logloss: 0.0319967\n",
            "[720]\ttraining's binary_logloss: 0.00856235\tvalid_1's binary_logloss: 0.0308628\n",
            "[730]\ttraining's binary_logloss: 0.00826725\tvalid_1's binary_logloss: 0.0298107\n",
            "[740]\ttraining's binary_logloss: 0.00799145\tvalid_1's binary_logloss: 0.0288495\n",
            "[750]\ttraining's binary_logloss: 0.007687\tvalid_1's binary_logloss: 0.0279048\n",
            "[760]\ttraining's binary_logloss: 0.00738098\tvalid_1's binary_logloss: 0.0267649\n",
            "[770]\ttraining's binary_logloss: 0.00711972\tvalid_1's binary_logloss: 0.0258326\n",
            "[780]\ttraining's binary_logloss: 0.0068093\tvalid_1's binary_logloss: 0.0247645\n",
            "[790]\ttraining's binary_logloss: 0.00654828\tvalid_1's binary_logloss: 0.0238598\n",
            "[800]\ttraining's binary_logloss: 0.00629688\tvalid_1's binary_logloss: 0.0229195\n",
            "[810]\ttraining's binary_logloss: 0.00605459\tvalid_1's binary_logloss: 0.0220909\n",
            "[820]\ttraining's binary_logloss: 0.00578704\tvalid_1's binary_logloss: 0.0211118\n",
            "[830]\ttraining's binary_logloss: 0.00553948\tvalid_1's binary_logloss: 0.0201991\n",
            "[840]\ttraining's binary_logloss: 0.00531003\tvalid_1's binary_logloss: 0.0193496\n",
            "[850]\ttraining's binary_logloss: 0.00508825\tvalid_1's binary_logloss: 0.0185378\n",
            "[860]\ttraining's binary_logloss: 0.00489085\tvalid_1's binary_logloss: 0.0178821\n",
            "[870]\ttraining's binary_logloss: 0.00470462\tvalid_1's binary_logloss: 0.0172067\n",
            "[880]\ttraining's binary_logloss: 0.00452944\tvalid_1's binary_logloss: 0.0165685\n",
            "[890]\ttraining's binary_logloss: 0.00434332\tvalid_1's binary_logloss: 0.0158899\n",
            "[900]\ttraining's binary_logloss: 0.00418758\tvalid_1's binary_logloss: 0.015311\n",
            "[910]\ttraining's binary_logloss: 0.00402208\tvalid_1's binary_logloss: 0.0147118\n",
            "[920]\ttraining's binary_logloss: 0.00385785\tvalid_1's binary_logloss: 0.014064\n",
            "[930]\ttraining's binary_logloss: 0.0036887\tvalid_1's binary_logloss: 0.0133498\n",
            "[940]\ttraining's binary_logloss: 0.00354351\tvalid_1's binary_logloss: 0.0128129\n",
            "[950]\ttraining's binary_logloss: 0.00341259\tvalid_1's binary_logloss: 0.0123657\n",
            "[960]\ttraining's binary_logloss: 0.00327254\tvalid_1's binary_logloss: 0.0118348\n",
            "[970]\ttraining's binary_logloss: 0.00312658\tvalid_1's binary_logloss: 0.0112962\n",
            "[980]\ttraining's binary_logloss: 0.00298267\tvalid_1's binary_logloss: 0.0107747\n",
            "[990]\ttraining's binary_logloss: 0.00287052\tvalid_1's binary_logloss: 0.0103466\n",
            "[1000]\ttraining's binary_logloss: 0.00275296\tvalid_1's binary_logloss: 0.00994236\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.00275296\tvalid_1's binary_logloss: 0.00994236\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:45:08,562] Trial 6 finished with value: 0.009942362035527114 and parameters: {'max_bin': 342, 'num_leaves': 102}. Best is trial 6 with value: 0.009942362035527114.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.21167\tvalid_1's binary_logloss: 0.970818\n",
            "[20]\ttraining's binary_logloss: 0.185948\tvalid_1's binary_logloss: 0.842649\n",
            "[30]\ttraining's binary_logloss: 0.168598\tvalid_1's binary_logloss: 0.756554\n",
            "[40]\ttraining's binary_logloss: 0.154934\tvalid_1's binary_logloss: 0.684327\n",
            "[50]\ttraining's binary_logloss: 0.142824\tvalid_1's binary_logloss: 0.619687\n",
            "[60]\ttraining's binary_logloss: 0.13216\tvalid_1's binary_logloss: 0.563897\n",
            "[70]\ttraining's binary_logloss: 0.122502\tvalid_1's binary_logloss: 0.51787\n",
            "[80]\ttraining's binary_logloss: 0.114176\tvalid_1's binary_logloss: 0.480978\n",
            "[90]\ttraining's binary_logloss: 0.106804\tvalid_1's binary_logloss: 0.441257\n",
            "[100]\ttraining's binary_logloss: 0.100386\tvalid_1's binary_logloss: 0.412525\n",
            "[110]\ttraining's binary_logloss: 0.0946379\tvalid_1's binary_logloss: 0.386441\n",
            "[120]\ttraining's binary_logloss: 0.0894377\tvalid_1's binary_logloss: 0.361145\n",
            "[130]\ttraining's binary_logloss: 0.0844818\tvalid_1's binary_logloss: 0.339255\n",
            "[140]\ttraining's binary_logloss: 0.0799681\tvalid_1's binary_logloss: 0.319942\n",
            "[150]\ttraining's binary_logloss: 0.0757886\tvalid_1's binary_logloss: 0.301079\n",
            "[160]\ttraining's binary_logloss: 0.0719471\tvalid_1's binary_logloss: 0.286138\n",
            "[170]\ttraining's binary_logloss: 0.0685136\tvalid_1's binary_logloss: 0.271706\n",
            "[180]\ttraining's binary_logloss: 0.065132\tvalid_1's binary_logloss: 0.257644\n",
            "[190]\ttraining's binary_logloss: 0.0622262\tvalid_1's binary_logloss: 0.245262\n",
            "[200]\ttraining's binary_logloss: 0.0590042\tvalid_1's binary_logloss: 0.232017\n",
            "[210]\ttraining's binary_logloss: 0.0561298\tvalid_1's binary_logloss: 0.220118\n",
            "[220]\ttraining's binary_logloss: 0.0537388\tvalid_1's binary_logloss: 0.210388\n",
            "[230]\ttraining's binary_logloss: 0.0512233\tvalid_1's binary_logloss: 0.200327\n",
            "[240]\ttraining's binary_logloss: 0.048717\tvalid_1's binary_logloss: 0.189753\n",
            "[250]\ttraining's binary_logloss: 0.046435\tvalid_1's binary_logloss: 0.179812\n",
            "[260]\ttraining's binary_logloss: 0.0441603\tvalid_1's binary_logloss: 0.170147\n",
            "[270]\ttraining's binary_logloss: 0.0422483\tvalid_1's binary_logloss: 0.162716\n",
            "[280]\ttraining's binary_logloss: 0.0403589\tvalid_1's binary_logloss: 0.155026\n",
            "[290]\ttraining's binary_logloss: 0.03841\tvalid_1's binary_logloss: 0.14694\n",
            "[300]\ttraining's binary_logloss: 0.0365479\tvalid_1's binary_logloss: 0.138919\n",
            "[310]\ttraining's binary_logloss: 0.0348861\tvalid_1's binary_logloss: 0.132567\n",
            "[320]\ttraining's binary_logloss: 0.0334671\tvalid_1's binary_logloss: 0.127216\n",
            "[330]\ttraining's binary_logloss: 0.0319211\tvalid_1's binary_logloss: 0.120632\n",
            "[340]\ttraining's binary_logloss: 0.03059\tvalid_1's binary_logloss: 0.115525\n",
            "[350]\ttraining's binary_logloss: 0.0291176\tvalid_1's binary_logloss: 0.109423\n",
            "[360]\ttraining's binary_logloss: 0.0278528\tvalid_1's binary_logloss: 0.104255\n",
            "[370]\ttraining's binary_logloss: 0.0265463\tvalid_1's binary_logloss: 0.0993102\n",
            "[380]\ttraining's binary_logloss: 0.025287\tvalid_1's binary_logloss: 0.0941242\n",
            "[390]\ttraining's binary_logloss: 0.0241306\tvalid_1's binary_logloss: 0.0899388\n",
            "[400]\ttraining's binary_logloss: 0.0230035\tvalid_1's binary_logloss: 0.0854944\n",
            "[410]\ttraining's binary_logloss: 0.0218526\tvalid_1's binary_logloss: 0.0812524\n",
            "[420]\ttraining's binary_logloss: 0.0207158\tvalid_1's binary_logloss: 0.0766208\n",
            "[430]\ttraining's binary_logloss: 0.019801\tvalid_1's binary_logloss: 0.073157\n",
            "[440]\ttraining's binary_logloss: 0.0188986\tvalid_1's binary_logloss: 0.0696179\n",
            "[450]\ttraining's binary_logloss: 0.0180828\tvalid_1's binary_logloss: 0.0663828\n",
            "[460]\ttraining's binary_logloss: 0.0172428\tvalid_1's binary_logloss: 0.0630158\n",
            "[470]\ttraining's binary_logloss: 0.0164569\tvalid_1's binary_logloss: 0.0597355\n",
            "[480]\ttraining's binary_logloss: 0.0157452\tvalid_1's binary_logloss: 0.0571403\n",
            "[490]\ttraining's binary_logloss: 0.0150305\tvalid_1's binary_logloss: 0.0543248\n",
            "[500]\ttraining's binary_logloss: 0.0143505\tvalid_1's binary_logloss: 0.0519056\n",
            "[510]\ttraining's binary_logloss: 0.013626\tvalid_1's binary_logloss: 0.0492296\n",
            "[520]\ttraining's binary_logloss: 0.0129203\tvalid_1's binary_logloss: 0.0465978\n",
            "[530]\ttraining's binary_logloss: 0.0123494\tvalid_1's binary_logloss: 0.0445468\n",
            "[540]\ttraining's binary_logloss: 0.0118099\tvalid_1's binary_logloss: 0.0426034\n",
            "[550]\ttraining's binary_logloss: 0.0113387\tvalid_1's binary_logloss: 0.0409299\n",
            "[560]\ttraining's binary_logloss: 0.0107568\tvalid_1's binary_logloss: 0.0386306\n",
            "[570]\ttraining's binary_logloss: 0.0102851\tvalid_1's binary_logloss: 0.0368747\n",
            "[580]\ttraining's binary_logloss: 0.009877\tvalid_1's binary_logloss: 0.0354094\n",
            "[590]\ttraining's binary_logloss: 0.00942205\tvalid_1's binary_logloss: 0.0338116\n",
            "[600]\ttraining's binary_logloss: 0.00897557\tvalid_1's binary_logloss: 0.0321368\n",
            "[610]\ttraining's binary_logloss: 0.00857643\tvalid_1's binary_logloss: 0.0306801\n",
            "[620]\ttraining's binary_logloss: 0.00818993\tvalid_1's binary_logloss: 0.0293074\n",
            "[630]\ttraining's binary_logloss: 0.0077997\tvalid_1's binary_logloss: 0.0278636\n",
            "[640]\ttraining's binary_logloss: 0.00739956\tvalid_1's binary_logloss: 0.0263228\n",
            "[650]\ttraining's binary_logloss: 0.00707169\tvalid_1's binary_logloss: 0.0251266\n",
            "[660]\ttraining's binary_logloss: 0.00674797\tvalid_1's binary_logloss: 0.0239342\n",
            "[670]\ttraining's binary_logloss: 0.00644607\tvalid_1's binary_logloss: 0.0229521\n",
            "[680]\ttraining's binary_logloss: 0.00613812\tvalid_1's binary_logloss: 0.0218281\n",
            "[690]\ttraining's binary_logloss: 0.0058564\tvalid_1's binary_logloss: 0.0208295\n",
            "[700]\ttraining's binary_logloss: 0.00560177\tvalid_1's binary_logloss: 0.0198706\n",
            "[710]\ttraining's binary_logloss: 0.00531028\tvalid_1's binary_logloss: 0.0188446\n",
            "[720]\ttraining's binary_logloss: 0.00504575\tvalid_1's binary_logloss: 0.0179313\n",
            "[730]\ttraining's binary_logloss: 0.00478873\tvalid_1's binary_logloss: 0.0171171\n",
            "[740]\ttraining's binary_logloss: 0.00457045\tvalid_1's binary_logloss: 0.0163675\n",
            "[750]\ttraining's binary_logloss: 0.00435743\tvalid_1's binary_logloss: 0.0155403\n",
            "[760]\ttraining's binary_logloss: 0.00417726\tvalid_1's binary_logloss: 0.0149382\n",
            "[770]\ttraining's binary_logloss: 0.00399104\tvalid_1's binary_logloss: 0.0142417\n",
            "[780]\ttraining's binary_logloss: 0.00379121\tvalid_1's binary_logloss: 0.0135567\n",
            "[790]\ttraining's binary_logloss: 0.00360404\tvalid_1's binary_logloss: 0.0129033\n",
            "[800]\ttraining's binary_logloss: 0.00342598\tvalid_1's binary_logloss: 0.0123036\n",
            "[810]\ttraining's binary_logloss: 0.00329056\tvalid_1's binary_logloss: 0.0117657\n",
            "[820]\ttraining's binary_logloss: 0.00314622\tvalid_1's binary_logloss: 0.0112104\n",
            "[830]\ttraining's binary_logloss: 0.00300483\tvalid_1's binary_logloss: 0.0107113\n",
            "[840]\ttraining's binary_logloss: 0.00288135\tvalid_1's binary_logloss: 0.0102426\n",
            "[850]\ttraining's binary_logloss: 0.00275598\tvalid_1's binary_logloss: 0.0097582\n",
            "[860]\ttraining's binary_logloss: 0.0026473\tvalid_1's binary_logloss: 0.00935361\n",
            "[870]\ttraining's binary_logloss: 0.00252159\tvalid_1's binary_logloss: 0.00889423\n",
            "[880]\ttraining's binary_logloss: 0.0024014\tvalid_1's binary_logloss: 0.00846882\n",
            "[890]\ttraining's binary_logloss: 0.00227391\tvalid_1's binary_logloss: 0.00797414\n",
            "[900]\ttraining's binary_logloss: 0.00216308\tvalid_1's binary_logloss: 0.00758986\n",
            "[910]\ttraining's binary_logloss: 0.00205668\tvalid_1's binary_logloss: 0.00723691\n",
            "[920]\ttraining's binary_logloss: 0.00196727\tvalid_1's binary_logloss: 0.00693699\n",
            "[930]\ttraining's binary_logloss: 0.00187806\tvalid_1's binary_logloss: 0.00661943\n",
            "[940]\ttraining's binary_logloss: 0.00179493\tvalid_1's binary_logloss: 0.00634098\n",
            "[950]\ttraining's binary_logloss: 0.00171817\tvalid_1's binary_logloss: 0.00605964\n",
            "[960]\ttraining's binary_logloss: 0.0016277\tvalid_1's binary_logloss: 0.00576858\n",
            "[970]\ttraining's binary_logloss: 0.00155119\tvalid_1's binary_logloss: 0.00547213\n",
            "[980]\ttraining's binary_logloss: 0.00147745\tvalid_1's binary_logloss: 0.00522082\n",
            "[990]\ttraining's binary_logloss: 0.00141959\tvalid_1's binary_logloss: 0.00503573\n",
            "[1000]\ttraining's binary_logloss: 0.00135194\tvalid_1's binary_logloss: 0.00479557\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.00135194\tvalid_1's binary_logloss: 0.00479557\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:45:20,515] Trial 7 finished with value: 0.004795566388927853 and parameters: {'max_bin': 471, 'num_leaves': 120}. Best is trial 7 with value: 0.004795566388927853.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.216016\tvalid_1's binary_logloss: 0.997804\n",
            "[20]\ttraining's binary_logloss: 0.192777\tvalid_1's binary_logloss: 0.881287\n",
            "[30]\ttraining's binary_logloss: 0.177685\tvalid_1's binary_logloss: 0.807865\n",
            "[40]\ttraining's binary_logloss: 0.165816\tvalid_1's binary_logloss: 0.744673\n",
            "[50]\ttraining's binary_logloss: 0.154752\tvalid_1's binary_logloss: 0.684817\n",
            "[60]\ttraining's binary_logloss: 0.145793\tvalid_1's binary_logloss: 0.639078\n",
            "[70]\ttraining's binary_logloss: 0.137402\tvalid_1's binary_logloss: 0.596939\n",
            "[80]\ttraining's binary_logloss: 0.129508\tvalid_1's binary_logloss: 0.555031\n",
            "[90]\ttraining's binary_logloss: 0.122996\tvalid_1's binary_logloss: 0.522138\n",
            "[100]\ttraining's binary_logloss: 0.117213\tvalid_1's binary_logloss: 0.494301\n",
            "[110]\ttraining's binary_logloss: 0.111798\tvalid_1's binary_logloss: 0.470143\n",
            "[120]\ttraining's binary_logloss: 0.106664\tvalid_1's binary_logloss: 0.44753\n",
            "[130]\ttraining's binary_logloss: 0.102239\tvalid_1's binary_logloss: 0.426256\n",
            "[140]\ttraining's binary_logloss: 0.0978677\tvalid_1's binary_logloss: 0.404899\n",
            "[150]\ttraining's binary_logloss: 0.0937041\tvalid_1's binary_logloss: 0.385553\n",
            "[160]\ttraining's binary_logloss: 0.0899769\tvalid_1's binary_logloss: 0.36676\n",
            "[170]\ttraining's binary_logloss: 0.0864762\tvalid_1's binary_logloss: 0.350642\n",
            "[180]\ttraining's binary_logloss: 0.0828821\tvalid_1's binary_logloss: 0.334237\n",
            "[190]\ttraining's binary_logloss: 0.0794174\tvalid_1's binary_logloss: 0.319141\n",
            "[200]\ttraining's binary_logloss: 0.0766041\tvalid_1's binary_logloss: 0.307094\n",
            "[210]\ttraining's binary_logloss: 0.0739225\tvalid_1's binary_logloss: 0.29568\n",
            "[220]\ttraining's binary_logloss: 0.0712084\tvalid_1's binary_logloss: 0.283925\n",
            "[230]\ttraining's binary_logloss: 0.0687636\tvalid_1's binary_logloss: 0.272932\n",
            "[240]\ttraining's binary_logloss: 0.0663885\tvalid_1's binary_logloss: 0.263435\n",
            "[250]\ttraining's binary_logloss: 0.063994\tvalid_1's binary_logloss: 0.253843\n",
            "[260]\ttraining's binary_logloss: 0.0616546\tvalid_1's binary_logloss: 0.243717\n",
            "[270]\ttraining's binary_logloss: 0.0596075\tvalid_1's binary_logloss: 0.235562\n",
            "[280]\ttraining's binary_logloss: 0.057662\tvalid_1's binary_logloss: 0.227184\n",
            "[290]\ttraining's binary_logloss: 0.0557106\tvalid_1's binary_logloss: 0.219732\n",
            "[300]\ttraining's binary_logloss: 0.0540404\tvalid_1's binary_logloss: 0.212375\n",
            "[310]\ttraining's binary_logloss: 0.0520356\tvalid_1's binary_logloss: 0.204102\n",
            "[320]\ttraining's binary_logloss: 0.0502946\tvalid_1's binary_logloss: 0.197197\n",
            "[330]\ttraining's binary_logloss: 0.048627\tvalid_1's binary_logloss: 0.19044\n",
            "[340]\ttraining's binary_logloss: 0.0468117\tvalid_1's binary_logloss: 0.182556\n",
            "[350]\ttraining's binary_logloss: 0.0452159\tvalid_1's binary_logloss: 0.176035\n",
            "[360]\ttraining's binary_logloss: 0.043502\tvalid_1's binary_logloss: 0.168782\n",
            "[370]\ttraining's binary_logloss: 0.0419649\tvalid_1's binary_logloss: 0.162542\n",
            "[380]\ttraining's binary_logloss: 0.0404127\tvalid_1's binary_logloss: 0.156049\n",
            "[390]\ttraining's binary_logloss: 0.0388164\tvalid_1's binary_logloss: 0.148413\n",
            "[400]\ttraining's binary_logloss: 0.0374539\tvalid_1's binary_logloss: 0.142883\n",
            "[410]\ttraining's binary_logloss: 0.036013\tvalid_1's binary_logloss: 0.136714\n",
            "[420]\ttraining's binary_logloss: 0.0347392\tvalid_1's binary_logloss: 0.131538\n",
            "[430]\ttraining's binary_logloss: 0.0334491\tvalid_1's binary_logloss: 0.126392\n",
            "[440]\ttraining's binary_logloss: 0.0323403\tvalid_1's binary_logloss: 0.122223\n",
            "[450]\ttraining's binary_logloss: 0.0312509\tvalid_1's binary_logloss: 0.117662\n",
            "[460]\ttraining's binary_logloss: 0.0302249\tvalid_1's binary_logloss: 0.113564\n",
            "[470]\ttraining's binary_logloss: 0.0293461\tvalid_1's binary_logloss: 0.11012\n",
            "[480]\ttraining's binary_logloss: 0.0284483\tvalid_1's binary_logloss: 0.106399\n",
            "[490]\ttraining's binary_logloss: 0.0276717\tvalid_1's binary_logloss: 0.103636\n",
            "[500]\ttraining's binary_logloss: 0.0268295\tvalid_1's binary_logloss: 0.100398\n",
            "[510]\ttraining's binary_logloss: 0.0258679\tvalid_1's binary_logloss: 0.0964102\n",
            "[520]\ttraining's binary_logloss: 0.025009\tvalid_1's binary_logloss: 0.0929707\n",
            "[530]\ttraining's binary_logloss: 0.0241528\tvalid_1's binary_logloss: 0.0895466\n",
            "[540]\ttraining's binary_logloss: 0.0233564\tvalid_1's binary_logloss: 0.0865189\n",
            "[550]\ttraining's binary_logloss: 0.0225492\tvalid_1's binary_logloss: 0.0835046\n",
            "[560]\ttraining's binary_logloss: 0.0217752\tvalid_1's binary_logloss: 0.0807324\n",
            "[570]\ttraining's binary_logloss: 0.0210111\tvalid_1's binary_logloss: 0.0777711\n",
            "[580]\ttraining's binary_logloss: 0.0203575\tvalid_1's binary_logloss: 0.0752946\n",
            "[590]\ttraining's binary_logloss: 0.01961\tvalid_1's binary_logloss: 0.0723066\n",
            "[600]\ttraining's binary_logloss: 0.01894\tvalid_1's binary_logloss: 0.0698433\n",
            "[610]\ttraining's binary_logloss: 0.0182274\tvalid_1's binary_logloss: 0.066724\n",
            "[620]\ttraining's binary_logloss: 0.017626\tvalid_1's binary_logloss: 0.0642269\n",
            "[630]\ttraining's binary_logloss: 0.0170345\tvalid_1's binary_logloss: 0.0620993\n",
            "[640]\ttraining's binary_logloss: 0.016458\tvalid_1's binary_logloss: 0.0597989\n",
            "[650]\ttraining's binary_logloss: 0.0159534\tvalid_1's binary_logloss: 0.0579757\n",
            "[660]\ttraining's binary_logloss: 0.0154201\tvalid_1's binary_logloss: 0.055871\n",
            "[670]\ttraining's binary_logloss: 0.0148646\tvalid_1's binary_logloss: 0.0538416\n",
            "[680]\ttraining's binary_logloss: 0.0142681\tvalid_1's binary_logloss: 0.0517732\n",
            "[690]\ttraining's binary_logloss: 0.0137439\tvalid_1's binary_logloss: 0.049776\n",
            "[700]\ttraining's binary_logloss: 0.013332\tvalid_1's binary_logloss: 0.0482296\n",
            "[710]\ttraining's binary_logloss: 0.0128986\tvalid_1's binary_logloss: 0.0465603\n",
            "[720]\ttraining's binary_logloss: 0.0124674\tvalid_1's binary_logloss: 0.0449276\n",
            "[730]\ttraining's binary_logloss: 0.0120749\tvalid_1's binary_logloss: 0.043495\n",
            "[740]\ttraining's binary_logloss: 0.0116404\tvalid_1's binary_logloss: 0.0417893\n",
            "[750]\ttraining's binary_logloss: 0.0112052\tvalid_1's binary_logloss: 0.0399479\n",
            "[760]\ttraining's binary_logloss: 0.0108005\tvalid_1's binary_logloss: 0.0384033\n",
            "[770]\ttraining's binary_logloss: 0.010436\tvalid_1's binary_logloss: 0.0370611\n",
            "[780]\ttraining's binary_logloss: 0.0100875\tvalid_1's binary_logloss: 0.0359553\n",
            "[790]\ttraining's binary_logloss: 0.00976533\tvalid_1's binary_logloss: 0.0348037\n",
            "[800]\ttraining's binary_logloss: 0.00946087\tvalid_1's binary_logloss: 0.0336773\n",
            "[810]\ttraining's binary_logloss: 0.00910647\tvalid_1's binary_logloss: 0.0323213\n",
            "[820]\ttraining's binary_logloss: 0.008798\tvalid_1's binary_logloss: 0.0312534\n",
            "[830]\ttraining's binary_logloss: 0.00846249\tvalid_1's binary_logloss: 0.0300743\n",
            "[840]\ttraining's binary_logloss: 0.00821991\tvalid_1's binary_logloss: 0.029264\n",
            "[850]\ttraining's binary_logloss: 0.00795449\tvalid_1's binary_logloss: 0.0282488\n",
            "[860]\ttraining's binary_logloss: 0.00769756\tvalid_1's binary_logloss: 0.0272999\n",
            "[870]\ttraining's binary_logloss: 0.00747251\tvalid_1's binary_logloss: 0.0264084\n",
            "[880]\ttraining's binary_logloss: 0.00722317\tvalid_1's binary_logloss: 0.02554\n",
            "[890]\ttraining's binary_logloss: 0.00697639\tvalid_1's binary_logloss: 0.0246856\n",
            "[900]\ttraining's binary_logloss: 0.0067166\tvalid_1's binary_logloss: 0.0237267\n",
            "[910]\ttraining's binary_logloss: 0.00650542\tvalid_1's binary_logloss: 0.0230402\n",
            "[920]\ttraining's binary_logloss: 0.00627472\tvalid_1's binary_logloss: 0.0222739\n",
            "[930]\ttraining's binary_logloss: 0.00604704\tvalid_1's binary_logloss: 0.0214634\n",
            "[940]\ttraining's binary_logloss: 0.00582845\tvalid_1's binary_logloss: 0.0206731\n",
            "[950]\ttraining's binary_logloss: 0.00559988\tvalid_1's binary_logloss: 0.019916\n",
            "[960]\ttraining's binary_logloss: 0.00540329\tvalid_1's binary_logloss: 0.0191945\n",
            "[970]\ttraining's binary_logloss: 0.00522902\tvalid_1's binary_logloss: 0.0185951\n",
            "[980]\ttraining's binary_logloss: 0.00504997\tvalid_1's binary_logloss: 0.0180024\n",
            "[990]\ttraining's binary_logloss: 0.00490564\tvalid_1's binary_logloss: 0.0175021\n",
            "[1000]\ttraining's binary_logloss: 0.00475938\tvalid_1's binary_logloss: 0.0170241\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.00475938\tvalid_1's binary_logloss: 0.0170241\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:45:29,823] Trial 8 finished with value: 0.01702411342371729 and parameters: {'max_bin': 395, 'num_leaves': 90}. Best is trial 7 with value: 0.004795566388927853.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.219177\tvalid_1's binary_logloss: 1.01517\n",
            "[20]\ttraining's binary_logloss: 0.197664\tvalid_1's binary_logloss: 0.909232\n",
            "[30]\ttraining's binary_logloss: 0.184052\tvalid_1's binary_logloss: 0.84363\n",
            "[40]\ttraining's binary_logloss: 0.173091\tvalid_1's binary_logloss: 0.783181\n",
            "[50]\ttraining's binary_logloss: 0.16368\tvalid_1's binary_logloss: 0.731696\n",
            "[60]\ttraining's binary_logloss: 0.155372\tvalid_1's binary_logloss: 0.690489\n",
            "[70]\ttraining's binary_logloss: 0.147594\tvalid_1's binary_logloss: 0.648689\n",
            "[80]\ttraining's binary_logloss: 0.141025\tvalid_1's binary_logloss: 0.6206\n",
            "[90]\ttraining's binary_logloss: 0.135441\tvalid_1's binary_logloss: 0.594073\n",
            "[100]\ttraining's binary_logloss: 0.13023\tvalid_1's binary_logloss: 0.568489\n",
            "[110]\ttraining's binary_logloss: 0.125542\tvalid_1's binary_logloss: 0.544167\n",
            "[120]\ttraining's binary_logloss: 0.12079\tvalid_1's binary_logloss: 0.520146\n",
            "[130]\ttraining's binary_logloss: 0.116592\tvalid_1's binary_logloss: 0.501311\n",
            "[140]\ttraining's binary_logloss: 0.113007\tvalid_1's binary_logloss: 0.484246\n",
            "[150]\ttraining's binary_logloss: 0.10911\tvalid_1's binary_logloss: 0.463732\n",
            "[160]\ttraining's binary_logloss: 0.105379\tvalid_1's binary_logloss: 0.442457\n",
            "[170]\ttraining's binary_logloss: 0.102063\tvalid_1's binary_logloss: 0.424478\n",
            "[180]\ttraining's binary_logloss: 0.0990233\tvalid_1's binary_logloss: 0.409506\n",
            "[190]\ttraining's binary_logloss: 0.0961076\tvalid_1's binary_logloss: 0.39577\n",
            "[200]\ttraining's binary_logloss: 0.0928792\tvalid_1's binary_logloss: 0.381879\n",
            "[210]\ttraining's binary_logloss: 0.0902654\tvalid_1's binary_logloss: 0.369799\n",
            "[220]\ttraining's binary_logloss: 0.0874586\tvalid_1's binary_logloss: 0.357296\n",
            "[230]\ttraining's binary_logloss: 0.0847593\tvalid_1's binary_logloss: 0.344463\n",
            "[240]\ttraining's binary_logloss: 0.0820697\tvalid_1's binary_logloss: 0.332279\n",
            "[250]\ttraining's binary_logloss: 0.0795981\tvalid_1's binary_logloss: 0.321167\n",
            "[260]\ttraining's binary_logloss: 0.0771081\tvalid_1's binary_logloss: 0.309869\n",
            "[270]\ttraining's binary_logloss: 0.0748287\tvalid_1's binary_logloss: 0.299498\n",
            "[280]\ttraining's binary_logloss: 0.0728148\tvalid_1's binary_logloss: 0.289965\n",
            "[290]\ttraining's binary_logloss: 0.070896\tvalid_1's binary_logloss: 0.282408\n",
            "[300]\ttraining's binary_logloss: 0.0688308\tvalid_1's binary_logloss: 0.274227\n",
            "[310]\ttraining's binary_logloss: 0.0669566\tvalid_1's binary_logloss: 0.26612\n",
            "[320]\ttraining's binary_logloss: 0.064987\tvalid_1's binary_logloss: 0.257939\n",
            "[330]\ttraining's binary_logloss: 0.0631868\tvalid_1's binary_logloss: 0.250294\n",
            "[340]\ttraining's binary_logloss: 0.0615102\tvalid_1's binary_logloss: 0.243056\n",
            "[350]\ttraining's binary_logloss: 0.0598284\tvalid_1's binary_logloss: 0.235731\n",
            "[360]\ttraining's binary_logloss: 0.0582443\tvalid_1's binary_logloss: 0.229219\n",
            "[370]\ttraining's binary_logloss: 0.0568249\tvalid_1's binary_logloss: 0.223299\n",
            "[380]\ttraining's binary_logloss: 0.0553496\tvalid_1's binary_logloss: 0.217406\n",
            "[390]\ttraining's binary_logloss: 0.0537706\tvalid_1's binary_logloss: 0.210798\n",
            "[400]\ttraining's binary_logloss: 0.0524048\tvalid_1's binary_logloss: 0.205524\n",
            "[410]\ttraining's binary_logloss: 0.0508963\tvalid_1's binary_logloss: 0.200595\n",
            "[420]\ttraining's binary_logloss: 0.0496568\tvalid_1's binary_logloss: 0.196267\n",
            "[430]\ttraining's binary_logloss: 0.0483037\tvalid_1's binary_logloss: 0.190902\n",
            "[440]\ttraining's binary_logloss: 0.0470616\tvalid_1's binary_logloss: 0.186248\n",
            "[450]\ttraining's binary_logloss: 0.0458678\tvalid_1's binary_logloss: 0.18157\n",
            "[460]\ttraining's binary_logloss: 0.044455\tvalid_1's binary_logloss: 0.175025\n",
            "[470]\ttraining's binary_logloss: 0.0433454\tvalid_1's binary_logloss: 0.170554\n",
            "[480]\ttraining's binary_logloss: 0.0422322\tvalid_1's binary_logloss: 0.165907\n",
            "[490]\ttraining's binary_logloss: 0.04119\tvalid_1's binary_logloss: 0.161722\n",
            "[500]\ttraining's binary_logloss: 0.0400763\tvalid_1's binary_logloss: 0.156816\n",
            "[510]\ttraining's binary_logloss: 0.0390014\tvalid_1's binary_logloss: 0.152217\n",
            "[520]\ttraining's binary_logloss: 0.0379186\tvalid_1's binary_logloss: 0.147907\n",
            "[530]\ttraining's binary_logloss: 0.0367415\tvalid_1's binary_logloss: 0.142944\n",
            "[540]\ttraining's binary_logloss: 0.0356096\tvalid_1's binary_logloss: 0.138391\n",
            "[550]\ttraining's binary_logloss: 0.0347384\tvalid_1's binary_logloss: 0.135092\n",
            "[560]\ttraining's binary_logloss: 0.0337447\tvalid_1's binary_logloss: 0.131017\n",
            "[570]\ttraining's binary_logloss: 0.0328185\tvalid_1's binary_logloss: 0.127209\n",
            "[580]\ttraining's binary_logloss: 0.0320031\tvalid_1's binary_logloss: 0.123969\n",
            "[590]\ttraining's binary_logloss: 0.0311337\tvalid_1's binary_logloss: 0.120488\n",
            "[600]\ttraining's binary_logloss: 0.0302928\tvalid_1's binary_logloss: 0.117236\n",
            "[610]\ttraining's binary_logloss: 0.0295014\tvalid_1's binary_logloss: 0.113941\n",
            "[620]\ttraining's binary_logloss: 0.0287756\tvalid_1's binary_logloss: 0.111311\n",
            "[630]\ttraining's binary_logloss: 0.0279148\tvalid_1's binary_logloss: 0.107628\n",
            "[640]\ttraining's binary_logloss: 0.0272266\tvalid_1's binary_logloss: 0.104616\n",
            "[650]\ttraining's binary_logloss: 0.0264762\tvalid_1's binary_logloss: 0.101655\n",
            "[660]\ttraining's binary_logloss: 0.0257081\tvalid_1's binary_logloss: 0.0986334\n",
            "[670]\ttraining's binary_logloss: 0.0249151\tvalid_1's binary_logloss: 0.0948226\n",
            "[680]\ttraining's binary_logloss: 0.0241127\tvalid_1's binary_logloss: 0.0914402\n",
            "[690]\ttraining's binary_logloss: 0.0234456\tvalid_1's binary_logloss: 0.0888053\n",
            "[700]\ttraining's binary_logloss: 0.0227792\tvalid_1's binary_logloss: 0.0862108\n",
            "[710]\ttraining's binary_logloss: 0.0221702\tvalid_1's binary_logloss: 0.08391\n",
            "[720]\ttraining's binary_logloss: 0.021681\tvalid_1's binary_logloss: 0.0823088\n",
            "[730]\ttraining's binary_logloss: 0.0211502\tvalid_1's binary_logloss: 0.0804751\n",
            "[740]\ttraining's binary_logloss: 0.0206149\tvalid_1's binary_logloss: 0.07834\n",
            "[750]\ttraining's binary_logloss: 0.0200704\tvalid_1's binary_logloss: 0.0762714\n",
            "[760]\ttraining's binary_logloss: 0.0195141\tvalid_1's binary_logloss: 0.0741043\n",
            "[770]\ttraining's binary_logloss: 0.0189871\tvalid_1's binary_logloss: 0.072024\n",
            "[780]\ttraining's binary_logloss: 0.0183763\tvalid_1's binary_logloss: 0.0695085\n",
            "[790]\ttraining's binary_logloss: 0.0178456\tvalid_1's binary_logloss: 0.0674045\n",
            "[800]\ttraining's binary_logloss: 0.0172534\tvalid_1's binary_logloss: 0.0648664\n",
            "[810]\ttraining's binary_logloss: 0.0167679\tvalid_1's binary_logloss: 0.0631331\n",
            "[820]\ttraining's binary_logloss: 0.0162932\tvalid_1's binary_logloss: 0.0612305\n",
            "[830]\ttraining's binary_logloss: 0.015858\tvalid_1's binary_logloss: 0.0596872\n",
            "[840]\ttraining's binary_logloss: 0.0153495\tvalid_1's binary_logloss: 0.057626\n",
            "[850]\ttraining's binary_logloss: 0.0149751\tvalid_1's binary_logloss: 0.0562412\n",
            "[860]\ttraining's binary_logloss: 0.0145607\tvalid_1's binary_logloss: 0.0547092\n",
            "[870]\ttraining's binary_logloss: 0.014186\tvalid_1's binary_logloss: 0.0530904\n",
            "[880]\ttraining's binary_logloss: 0.0138014\tvalid_1's binary_logloss: 0.051443\n",
            "[890]\ttraining's binary_logloss: 0.013421\tvalid_1's binary_logloss: 0.0499346\n",
            "[900]\ttraining's binary_logloss: 0.013098\tvalid_1's binary_logloss: 0.0486807\n",
            "[910]\ttraining's binary_logloss: 0.0127964\tvalid_1's binary_logloss: 0.0476109\n",
            "[920]\ttraining's binary_logloss: 0.0124875\tvalid_1's binary_logloss: 0.0464764\n",
            "[930]\ttraining's binary_logloss: 0.0121529\tvalid_1's binary_logloss: 0.0452083\n",
            "[940]\ttraining's binary_logloss: 0.0118267\tvalid_1's binary_logloss: 0.0440095\n",
            "[950]\ttraining's binary_logloss: 0.0115208\tvalid_1's binary_logloss: 0.0428432\n",
            "[960]\ttraining's binary_logloss: 0.0112345\tvalid_1's binary_logloss: 0.0417881\n",
            "[970]\ttraining's binary_logloss: 0.01092\tvalid_1's binary_logloss: 0.0406126\n",
            "[980]\ttraining's binary_logloss: 0.010653\tvalid_1's binary_logloss: 0.0396443\n",
            "[990]\ttraining's binary_logloss: 0.0104293\tvalid_1's binary_logloss: 0.0388745\n",
            "[1000]\ttraining's binary_logloss: 0.0101309\tvalid_1's binary_logloss: 0.0377764\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.0101309\tvalid_1's binary_logloss: 0.0377764\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:45:38,238] Trial 9 finished with value: 0.03777637404757999 and parameters: {'max_bin': 448, 'num_leaves': 71}. Best is trial 7 with value: 0.004795566388927853.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.217881\tvalid_1's binary_logloss: 1.00921\n",
            "[20]\ttraining's binary_logloss: 0.195578\tvalid_1's binary_logloss: 0.895235\n",
            "[30]\ttraining's binary_logloss: 0.181005\tvalid_1's binary_logloss: 0.824904\n",
            "[40]\ttraining's binary_logloss: 0.170046\tvalid_1's binary_logloss: 0.765414\n",
            "[50]\ttraining's binary_logloss: 0.159926\tvalid_1's binary_logloss: 0.709158\n",
            "[60]\ttraining's binary_logloss: 0.151125\tvalid_1's binary_logloss: 0.663204\n",
            "[70]\ttraining's binary_logloss: 0.143306\tvalid_1's binary_logloss: 0.622015\n",
            "[80]\ttraining's binary_logloss: 0.136263\tvalid_1's binary_logloss: 0.586729\n",
            "[90]\ttraining's binary_logloss: 0.130093\tvalid_1's binary_logloss: 0.558398\n",
            "[100]\ttraining's binary_logloss: 0.124605\tvalid_1's binary_logloss: 0.526688\n",
            "[110]\ttraining's binary_logloss: 0.119198\tvalid_1's binary_logloss: 0.500259\n",
            "[120]\ttraining's binary_logloss: 0.114298\tvalid_1's binary_logloss: 0.474616\n",
            "[130]\ttraining's binary_logloss: 0.109925\tvalid_1's binary_logloss: 0.453652\n",
            "[140]\ttraining's binary_logloss: 0.106025\tvalid_1's binary_logloss: 0.433024\n",
            "[150]\ttraining's binary_logloss: 0.102146\tvalid_1's binary_logloss: 0.415125\n",
            "[160]\ttraining's binary_logloss: 0.0988334\tvalid_1's binary_logloss: 0.400584\n",
            "[170]\ttraining's binary_logloss: 0.0952344\tvalid_1's binary_logloss: 0.385313\n",
            "[180]\ttraining's binary_logloss: 0.0922286\tvalid_1's binary_logloss: 0.370844\n",
            "[190]\ttraining's binary_logloss: 0.0895476\tvalid_1's binary_logloss: 0.358606\n",
            "[200]\ttraining's binary_logloss: 0.0866112\tvalid_1's binary_logloss: 0.344945\n",
            "[210]\ttraining's binary_logloss: 0.0839244\tvalid_1's binary_logloss: 0.332926\n",
            "[220]\ttraining's binary_logloss: 0.0814069\tvalid_1's binary_logloss: 0.321405\n",
            "[230]\ttraining's binary_logloss: 0.0788313\tvalid_1's binary_logloss: 0.310595\n",
            "[240]\ttraining's binary_logloss: 0.0762032\tvalid_1's binary_logloss: 0.299458\n",
            "[250]\ttraining's binary_logloss: 0.0742005\tvalid_1's binary_logloss: 0.289862\n",
            "[260]\ttraining's binary_logloss: 0.0713909\tvalid_1's binary_logloss: 0.278353\n",
            "[270]\ttraining's binary_logloss: 0.0689231\tvalid_1's binary_logloss: 0.267774\n",
            "[280]\ttraining's binary_logloss: 0.0666054\tvalid_1's binary_logloss: 0.258477\n",
            "[290]\ttraining's binary_logloss: 0.0643208\tvalid_1's binary_logloss: 0.249441\n",
            "[300]\ttraining's binary_logloss: 0.061971\tvalid_1's binary_logloss: 0.238995\n",
            "[310]\ttraining's binary_logloss: 0.0599462\tvalid_1's binary_logloss: 0.230497\n",
            "[320]\ttraining's binary_logloss: 0.0580568\tvalid_1's binary_logloss: 0.223497\n",
            "[330]\ttraining's binary_logloss: 0.056351\tvalid_1's binary_logloss: 0.217713\n",
            "[340]\ttraining's binary_logloss: 0.0545842\tvalid_1's binary_logloss: 0.210035\n",
            "[350]\ttraining's binary_logloss: 0.0529112\tvalid_1's binary_logloss: 0.202329\n",
            "[360]\ttraining's binary_logloss: 0.051332\tvalid_1's binary_logloss: 0.195539\n",
            "[370]\ttraining's binary_logloss: 0.0496176\tvalid_1's binary_logloss: 0.187985\n",
            "[380]\ttraining's binary_logloss: 0.048121\tvalid_1's binary_logloss: 0.182106\n",
            "[390]\ttraining's binary_logloss: 0.0466811\tvalid_1's binary_logloss: 0.176476\n",
            "[400]\ttraining's binary_logloss: 0.0451204\tvalid_1's binary_logloss: 0.16974\n",
            "[410]\ttraining's binary_logloss: 0.0438782\tvalid_1's binary_logloss: 0.165107\n",
            "[420]\ttraining's binary_logloss: 0.0426762\tvalid_1's binary_logloss: 0.160633\n",
            "[430]\ttraining's binary_logloss: 0.0412481\tvalid_1's binary_logloss: 0.155098\n",
            "[440]\ttraining's binary_logloss: 0.0400233\tvalid_1's binary_logloss: 0.150089\n",
            "[450]\ttraining's binary_logloss: 0.0388576\tvalid_1's binary_logloss: 0.145685\n",
            "[460]\ttraining's binary_logloss: 0.0376624\tvalid_1's binary_logloss: 0.140943\n",
            "[470]\ttraining's binary_logloss: 0.0365154\tvalid_1's binary_logloss: 0.136555\n",
            "[480]\ttraining's binary_logloss: 0.0353534\tvalid_1's binary_logloss: 0.132118\n",
            "[490]\ttraining's binary_logloss: 0.0343887\tvalid_1's binary_logloss: 0.128644\n",
            "[500]\ttraining's binary_logloss: 0.0333308\tvalid_1's binary_logloss: 0.124525\n",
            "[510]\ttraining's binary_logloss: 0.0323841\tvalid_1's binary_logloss: 0.120819\n",
            "[520]\ttraining's binary_logloss: 0.0314616\tvalid_1's binary_logloss: 0.117257\n",
            "[530]\ttraining's binary_logloss: 0.030581\tvalid_1's binary_logloss: 0.114182\n",
            "[540]\ttraining's binary_logloss: 0.0296181\tvalid_1's binary_logloss: 0.110173\n",
            "[550]\ttraining's binary_logloss: 0.0286333\tvalid_1's binary_logloss: 0.106342\n",
            "[560]\ttraining's binary_logloss: 0.0276391\tvalid_1's binary_logloss: 0.102244\n",
            "[570]\ttraining's binary_logloss: 0.0267778\tvalid_1's binary_logloss: 0.0989557\n",
            "[580]\ttraining's binary_logloss: 0.0258936\tvalid_1's binary_logloss: 0.0954736\n",
            "[590]\ttraining's binary_logloss: 0.0250394\tvalid_1's binary_logloss: 0.0920726\n",
            "[600]\ttraining's binary_logloss: 0.024356\tvalid_1's binary_logloss: 0.0894969\n",
            "[610]\ttraining's binary_logloss: 0.0235188\tvalid_1's binary_logloss: 0.0863195\n",
            "[620]\ttraining's binary_logloss: 0.0228403\tvalid_1's binary_logloss: 0.0840154\n",
            "[630]\ttraining's binary_logloss: 0.0221566\tvalid_1's binary_logloss: 0.0814772\n",
            "[640]\ttraining's binary_logloss: 0.0215077\tvalid_1's binary_logloss: 0.0791345\n",
            "[650]\ttraining's binary_logloss: 0.0208911\tvalid_1's binary_logloss: 0.0770076\n",
            "[660]\ttraining's binary_logloss: 0.0202843\tvalid_1's binary_logloss: 0.0749559\n",
            "[670]\ttraining's binary_logloss: 0.0196934\tvalid_1's binary_logloss: 0.0728358\n",
            "[680]\ttraining's binary_logloss: 0.0191318\tvalid_1's binary_logloss: 0.0708817\n",
            "[690]\ttraining's binary_logloss: 0.0185175\tvalid_1's binary_logloss: 0.068265\n",
            "[700]\ttraining's binary_logloss: 0.0179674\tvalid_1's binary_logloss: 0.0665865\n",
            "[710]\ttraining's binary_logloss: 0.0174581\tvalid_1's binary_logloss: 0.0644911\n",
            "[720]\ttraining's binary_logloss: 0.0169774\tvalid_1's binary_logloss: 0.0626514\n",
            "[730]\ttraining's binary_logloss: 0.0164335\tvalid_1's binary_logloss: 0.0604787\n",
            "[740]\ttraining's binary_logloss: 0.0159787\tvalid_1's binary_logloss: 0.058935\n",
            "[750]\ttraining's binary_logloss: 0.0155115\tvalid_1's binary_logloss: 0.0570612\n",
            "[760]\ttraining's binary_logloss: 0.0150868\tvalid_1's binary_logloss: 0.0556915\n",
            "[770]\ttraining's binary_logloss: 0.0146941\tvalid_1's binary_logloss: 0.0542017\n",
            "[780]\ttraining's binary_logloss: 0.0143362\tvalid_1's binary_logloss: 0.0527763\n",
            "[790]\ttraining's binary_logloss: 0.0139066\tvalid_1's binary_logloss: 0.0512452\n",
            "[800]\ttraining's binary_logloss: 0.0135271\tvalid_1's binary_logloss: 0.0499173\n",
            "[810]\ttraining's binary_logloss: 0.0131815\tvalid_1's binary_logloss: 0.0487007\n",
            "[820]\ttraining's binary_logloss: 0.0128337\tvalid_1's binary_logloss: 0.0474377\n",
            "[830]\ttraining's binary_logloss: 0.0125066\tvalid_1's binary_logloss: 0.0462942\n",
            "[840]\ttraining's binary_logloss: 0.0121398\tvalid_1's binary_logloss: 0.0448961\n",
            "[850]\ttraining's binary_logloss: 0.0118144\tvalid_1's binary_logloss: 0.0436682\n",
            "[860]\ttraining's binary_logloss: 0.0114977\tvalid_1's binary_logloss: 0.0425524\n",
            "[870]\ttraining's binary_logloss: 0.0111949\tvalid_1's binary_logloss: 0.0414436\n",
            "[880]\ttraining's binary_logloss: 0.0108909\tvalid_1's binary_logloss: 0.0404314\n",
            "[890]\ttraining's binary_logloss: 0.0106217\tvalid_1's binary_logloss: 0.0394209\n",
            "[900]\ttraining's binary_logloss: 0.0102945\tvalid_1's binary_logloss: 0.0382087\n",
            "[910]\ttraining's binary_logloss: 0.0100303\tvalid_1's binary_logloss: 0.0372003\n",
            "[920]\ttraining's binary_logloss: 0.00978941\tvalid_1's binary_logloss: 0.0362881\n",
            "[930]\ttraining's binary_logloss: 0.00950839\tvalid_1's binary_logloss: 0.0352442\n",
            "[940]\ttraining's binary_logloss: 0.00927198\tvalid_1's binary_logloss: 0.0343705\n",
            "[950]\ttraining's binary_logloss: 0.00901495\tvalid_1's binary_logloss: 0.033501\n",
            "[960]\ttraining's binary_logloss: 0.00876452\tvalid_1's binary_logloss: 0.0326115\n",
            "[970]\ttraining's binary_logloss: 0.00854251\tvalid_1's binary_logloss: 0.0317839\n",
            "[980]\ttraining's binary_logloss: 0.00831632\tvalid_1's binary_logloss: 0.0309576\n",
            "[990]\ttraining's binary_logloss: 0.0081021\tvalid_1's binary_logloss: 0.0301906\n",
            "[1000]\ttraining's binary_logloss: 0.00789385\tvalid_1's binary_logloss: 0.0293904\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.00789385\tvalid_1's binary_logloss: 0.0293904\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:45:46,786] Trial 10 finished with value: 0.02939044649281032 and parameters: {'max_bin': 342, 'num_leaves': 78}. Best is trial 7 with value: 0.004795566388927853.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.212632\tvalid_1's binary_logloss: 0.976531\n",
            "[20]\ttraining's binary_logloss: 0.187389\tvalid_1's binary_logloss: 0.849685\n",
            "[30]\ttraining's binary_logloss: 0.17036\tvalid_1's binary_logloss: 0.766487\n",
            "[40]\ttraining's binary_logloss: 0.156945\tvalid_1's binary_logloss: 0.697048\n",
            "[50]\ttraining's binary_logloss: 0.145181\tvalid_1's binary_logloss: 0.637163\n",
            "[60]\ttraining's binary_logloss: 0.135024\tvalid_1's binary_logloss: 0.584158\n",
            "[70]\ttraining's binary_logloss: 0.125688\tvalid_1's binary_logloss: 0.538817\n",
            "[80]\ttraining's binary_logloss: 0.11752\tvalid_1's binary_logloss: 0.499645\n",
            "[90]\ttraining's binary_logloss: 0.110362\tvalid_1's binary_logloss: 0.46597\n",
            "[100]\ttraining's binary_logloss: 0.104175\tvalid_1's binary_logloss: 0.435509\n",
            "[110]\ttraining's binary_logloss: 0.0988082\tvalid_1's binary_logloss: 0.409835\n",
            "[120]\ttraining's binary_logloss: 0.0934614\tvalid_1's binary_logloss: 0.382878\n",
            "[130]\ttraining's binary_logloss: 0.088925\tvalid_1's binary_logloss: 0.361875\n",
            "[140]\ttraining's binary_logloss: 0.0846347\tvalid_1's binary_logloss: 0.342944\n",
            "[150]\ttraining's binary_logloss: 0.0802613\tvalid_1's binary_logloss: 0.323487\n",
            "[160]\ttraining's binary_logloss: 0.0763792\tvalid_1's binary_logloss: 0.305472\n",
            "[170]\ttraining's binary_logloss: 0.0727365\tvalid_1's binary_logloss: 0.288055\n",
            "[180]\ttraining's binary_logloss: 0.0693114\tvalid_1's binary_logloss: 0.273646\n",
            "[190]\ttraining's binary_logloss: 0.0659229\tvalid_1's binary_logloss: 0.259478\n",
            "[200]\ttraining's binary_logloss: 0.0628326\tvalid_1's binary_logloss: 0.245866\n",
            "[210]\ttraining's binary_logloss: 0.0601036\tvalid_1's binary_logloss: 0.23368\n",
            "[220]\ttraining's binary_logloss: 0.0572323\tvalid_1's binary_logloss: 0.222232\n",
            "[230]\ttraining's binary_logloss: 0.0548045\tvalid_1's binary_logloss: 0.212911\n",
            "[240]\ttraining's binary_logloss: 0.0523686\tvalid_1's binary_logloss: 0.202878\n",
            "[250]\ttraining's binary_logloss: 0.0502333\tvalid_1's binary_logloss: 0.193447\n",
            "[260]\ttraining's binary_logloss: 0.0477348\tvalid_1's binary_logloss: 0.182688\n",
            "[270]\ttraining's binary_logloss: 0.0454747\tvalid_1's binary_logloss: 0.172966\n",
            "[280]\ttraining's binary_logloss: 0.0431677\tvalid_1's binary_logloss: 0.163523\n",
            "[290]\ttraining's binary_logloss: 0.0412332\tvalid_1's binary_logloss: 0.156332\n",
            "[300]\ttraining's binary_logloss: 0.0394937\tvalid_1's binary_logloss: 0.148979\n",
            "[310]\ttraining's binary_logloss: 0.0378002\tvalid_1's binary_logloss: 0.142389\n",
            "[320]\ttraining's binary_logloss: 0.0360756\tvalid_1's binary_logloss: 0.135392\n",
            "[330]\ttraining's binary_logloss: 0.0345348\tvalid_1's binary_logloss: 0.129395\n",
            "[340]\ttraining's binary_logloss: 0.0329484\tvalid_1's binary_logloss: 0.123242\n",
            "[350]\ttraining's binary_logloss: 0.0316958\tvalid_1's binary_logloss: 0.118583\n",
            "[360]\ttraining's binary_logloss: 0.0303105\tvalid_1's binary_logloss: 0.112886\n",
            "[370]\ttraining's binary_logloss: 0.0290108\tvalid_1's binary_logloss: 0.107895\n",
            "[380]\ttraining's binary_logloss: 0.0278052\tvalid_1's binary_logloss: 0.102786\n",
            "[390]\ttraining's binary_logloss: 0.0267056\tvalid_1's binary_logloss: 0.0987624\n",
            "[400]\ttraining's binary_logloss: 0.0255656\tvalid_1's binary_logloss: 0.094394\n",
            "[410]\ttraining's binary_logloss: 0.024557\tvalid_1's binary_logloss: 0.0904236\n",
            "[420]\ttraining's binary_logloss: 0.0235594\tvalid_1's binary_logloss: 0.0867486\n",
            "[430]\ttraining's binary_logloss: 0.0225672\tvalid_1's binary_logloss: 0.0831603\n",
            "[440]\ttraining's binary_logloss: 0.0215923\tvalid_1's binary_logloss: 0.0793172\n",
            "[450]\ttraining's binary_logloss: 0.0206739\tvalid_1's binary_logloss: 0.075739\n",
            "[460]\ttraining's binary_logloss: 0.0197646\tvalid_1's binary_logloss: 0.0724604\n",
            "[470]\ttraining's binary_logloss: 0.0189439\tvalid_1's binary_logloss: 0.0692862\n",
            "[480]\ttraining's binary_logloss: 0.0179814\tvalid_1's binary_logloss: 0.0657018\n",
            "[490]\ttraining's binary_logloss: 0.0172644\tvalid_1's binary_logloss: 0.0630684\n",
            "[500]\ttraining's binary_logloss: 0.016573\tvalid_1's binary_logloss: 0.0603137\n",
            "[510]\ttraining's binary_logloss: 0.0157814\tvalid_1's binary_logloss: 0.0573789\n",
            "[520]\ttraining's binary_logloss: 0.0151073\tvalid_1's binary_logloss: 0.0549734\n",
            "[530]\ttraining's binary_logloss: 0.0143661\tvalid_1's binary_logloss: 0.0521354\n",
            "[540]\ttraining's binary_logloss: 0.0137389\tvalid_1's binary_logloss: 0.0499144\n",
            "[550]\ttraining's binary_logloss: 0.0130852\tvalid_1's binary_logloss: 0.0471851\n",
            "[560]\ttraining's binary_logloss: 0.0124649\tvalid_1's binary_logloss: 0.0447864\n",
            "[570]\ttraining's binary_logloss: 0.0118861\tvalid_1's binary_logloss: 0.0426792\n",
            "[580]\ttraining's binary_logloss: 0.011379\tvalid_1's binary_logloss: 0.0408087\n",
            "[590]\ttraining's binary_logloss: 0.0108801\tvalid_1's binary_logloss: 0.0389807\n",
            "[600]\ttraining's binary_logloss: 0.0104471\tvalid_1's binary_logloss: 0.0375472\n",
            "[610]\ttraining's binary_logloss: 0.00994534\tvalid_1's binary_logloss: 0.0357168\n",
            "[620]\ttraining's binary_logloss: 0.00949488\tvalid_1's binary_logloss: 0.0339151\n",
            "[630]\ttraining's binary_logloss: 0.00901323\tvalid_1's binary_logloss: 0.0322534\n",
            "[640]\ttraining's binary_logloss: 0.00864812\tvalid_1's binary_logloss: 0.0310392\n",
            "[650]\ttraining's binary_logloss: 0.00822662\tvalid_1's binary_logloss: 0.0295559\n",
            "[660]\ttraining's binary_logloss: 0.00782041\tvalid_1's binary_logloss: 0.028066\n",
            "[670]\ttraining's binary_logloss: 0.00751925\tvalid_1's binary_logloss: 0.027032\n",
            "[680]\ttraining's binary_logloss: 0.00721904\tvalid_1's binary_logloss: 0.0259562\n",
            "[690]\ttraining's binary_logloss: 0.00692469\tvalid_1's binary_logloss: 0.0248962\n",
            "[700]\ttraining's binary_logloss: 0.00665946\tvalid_1's binary_logloss: 0.0239784\n",
            "[710]\ttraining's binary_logloss: 0.00636266\tvalid_1's binary_logloss: 0.0229263\n",
            "[720]\ttraining's binary_logloss: 0.00611824\tvalid_1's binary_logloss: 0.0221264\n",
            "[730]\ttraining's binary_logloss: 0.00586413\tvalid_1's binary_logloss: 0.021164\n",
            "[740]\ttraining's binary_logloss: 0.00560116\tvalid_1's binary_logloss: 0.0202418\n",
            "[750]\ttraining's binary_logloss: 0.00535872\tvalid_1's binary_logloss: 0.0194011\n",
            "[760]\ttraining's binary_logloss: 0.00513648\tvalid_1's binary_logloss: 0.0186302\n",
            "[770]\ttraining's binary_logloss: 0.00491066\tvalid_1's binary_logloss: 0.017792\n",
            "[780]\ttraining's binary_logloss: 0.00470743\tvalid_1's binary_logloss: 0.0170658\n",
            "[790]\ttraining's binary_logloss: 0.00447022\tvalid_1's binary_logloss: 0.0162533\n",
            "[800]\ttraining's binary_logloss: 0.00429114\tvalid_1's binary_logloss: 0.0156149\n",
            "[810]\ttraining's binary_logloss: 0.00410535\tvalid_1's binary_logloss: 0.014949\n",
            "[820]\ttraining's binary_logloss: 0.00392472\tvalid_1's binary_logloss: 0.0142741\n",
            "[830]\ttraining's binary_logloss: 0.00377221\tvalid_1's binary_logloss: 0.013755\n",
            "[840]\ttraining's binary_logloss: 0.00362327\tvalid_1's binary_logloss: 0.0131952\n",
            "[850]\ttraining's binary_logloss: 0.00347074\tvalid_1's binary_logloss: 0.0126345\n",
            "[860]\ttraining's binary_logloss: 0.00334672\tvalid_1's binary_logloss: 0.0121678\n",
            "[870]\ttraining's binary_logloss: 0.00319658\tvalid_1's binary_logloss: 0.011621\n",
            "[880]\ttraining's binary_logloss: 0.00306799\tvalid_1's binary_logloss: 0.0111329\n",
            "[890]\ttraining's binary_logloss: 0.00292981\tvalid_1's binary_logloss: 0.0106458\n",
            "[900]\ttraining's binary_logloss: 0.00278821\tvalid_1's binary_logloss: 0.0101246\n",
            "[910]\ttraining's binary_logloss: 0.00267687\tvalid_1's binary_logloss: 0.00971118\n",
            "[920]\ttraining's binary_logloss: 0.00254901\tvalid_1's binary_logloss: 0.00920909\n",
            "[930]\ttraining's binary_logloss: 0.00244584\tvalid_1's binary_logloss: 0.00882856\n",
            "[940]\ttraining's binary_logloss: 0.00235271\tvalid_1's binary_logloss: 0.00851061\n",
            "[950]\ttraining's binary_logloss: 0.0022486\tvalid_1's binary_logloss: 0.0081425\n",
            "[960]\ttraining's binary_logloss: 0.00214692\tvalid_1's binary_logloss: 0.00777355\n",
            "[970]\ttraining's binary_logloss: 0.00205949\tvalid_1's binary_logloss: 0.00749372\n",
            "[980]\ttraining's binary_logloss: 0.00197379\tvalid_1's binary_logloss: 0.00718037\n",
            "[990]\ttraining's binary_logloss: 0.00188569\tvalid_1's binary_logloss: 0.0068525\n",
            "[1000]\ttraining's binary_logloss: 0.0018034\tvalid_1's binary_logloss: 0.00655288\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.0018034\tvalid_1's binary_logloss: 0.00655288\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:45:57,377] Trial 11 finished with value: 0.00655288153199678 and parameters: {'max_bin': 343, 'num_leaves': 113}. Best is trial 7 with value: 0.004795566388927853.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.221662\tvalid_1's binary_logloss: 1.0269\n",
            "[20]\ttraining's binary_logloss: 0.201865\tvalid_1's binary_logloss: 0.927934\n",
            "[30]\ttraining's binary_logloss: 0.189091\tvalid_1's binary_logloss: 0.86756\n",
            "[40]\ttraining's binary_logloss: 0.179424\tvalid_1's binary_logloss: 0.818406\n",
            "[50]\ttraining's binary_logloss: 0.171028\tvalid_1's binary_logloss: 0.776659\n",
            "[60]\ttraining's binary_logloss: 0.163845\tvalid_1's binary_logloss: 0.739291\n",
            "[70]\ttraining's binary_logloss: 0.15724\tvalid_1's binary_logloss: 0.701742\n",
            "[80]\ttraining's binary_logloss: 0.151131\tvalid_1's binary_logloss: 0.672063\n",
            "[90]\ttraining's binary_logloss: 0.145425\tvalid_1's binary_logloss: 0.63841\n",
            "[100]\ttraining's binary_logloss: 0.14081\tvalid_1's binary_logloss: 0.618683\n",
            "[110]\ttraining's binary_logloss: 0.136498\tvalid_1's binary_logloss: 0.596833\n",
            "[120]\ttraining's binary_logloss: 0.132524\tvalid_1's binary_logloss: 0.577794\n",
            "[130]\ttraining's binary_logloss: 0.128649\tvalid_1's binary_logloss: 0.561857\n",
            "[140]\ttraining's binary_logloss: 0.124783\tvalid_1's binary_logloss: 0.542315\n",
            "[150]\ttraining's binary_logloss: 0.121246\tvalid_1's binary_logloss: 0.522474\n",
            "[160]\ttraining's binary_logloss: 0.117769\tvalid_1's binary_logloss: 0.502494\n",
            "[170]\ttraining's binary_logloss: 0.114674\tvalid_1's binary_logloss: 0.484388\n",
            "[180]\ttraining's binary_logloss: 0.111711\tvalid_1's binary_logloss: 0.469497\n",
            "[190]\ttraining's binary_logloss: 0.108719\tvalid_1's binary_logloss: 0.453736\n",
            "[200]\ttraining's binary_logloss: 0.10616\tvalid_1's binary_logloss: 0.441657\n",
            "[210]\ttraining's binary_logloss: 0.1034\tvalid_1's binary_logloss: 0.428679\n",
            "[220]\ttraining's binary_logloss: 0.101017\tvalid_1's binary_logloss: 0.41782\n",
            "[230]\ttraining's binary_logloss: 0.0984427\tvalid_1's binary_logloss: 0.4048\n",
            "[240]\ttraining's binary_logloss: 0.0962361\tvalid_1's binary_logloss: 0.394575\n",
            "[250]\ttraining's binary_logloss: 0.0940224\tvalid_1's binary_logloss: 0.384527\n",
            "[260]\ttraining's binary_logloss: 0.0916238\tvalid_1's binary_logloss: 0.373467\n",
            "[270]\ttraining's binary_logloss: 0.0892631\tvalid_1's binary_logloss: 0.3613\n",
            "[280]\ttraining's binary_logloss: 0.0870415\tvalid_1's binary_logloss: 0.351903\n",
            "[290]\ttraining's binary_logloss: 0.0849763\tvalid_1's binary_logloss: 0.341892\n",
            "[300]\ttraining's binary_logloss: 0.0830535\tvalid_1's binary_logloss: 0.333071\n",
            "[310]\ttraining's binary_logloss: 0.0812266\tvalid_1's binary_logloss: 0.325306\n",
            "[320]\ttraining's binary_logloss: 0.0791479\tvalid_1's binary_logloss: 0.31578\n",
            "[330]\ttraining's binary_logloss: 0.0772719\tvalid_1's binary_logloss: 0.307891\n",
            "[340]\ttraining's binary_logloss: 0.0757455\tvalid_1's binary_logloss: 0.301391\n",
            "[350]\ttraining's binary_logloss: 0.0741364\tvalid_1's binary_logloss: 0.293911\n",
            "[360]\ttraining's binary_logloss: 0.0724046\tvalid_1's binary_logloss: 0.285112\n",
            "[370]\ttraining's binary_logloss: 0.0707877\tvalid_1's binary_logloss: 0.277777\n",
            "[380]\ttraining's binary_logloss: 0.0690961\tvalid_1's binary_logloss: 0.271811\n",
            "[390]\ttraining's binary_logloss: 0.0675203\tvalid_1's binary_logloss: 0.265345\n",
            "[400]\ttraining's binary_logloss: 0.066024\tvalid_1's binary_logloss: 0.258084\n",
            "[410]\ttraining's binary_logloss: 0.0646491\tvalid_1's binary_logloss: 0.252022\n",
            "[420]\ttraining's binary_logloss: 0.0633593\tvalid_1's binary_logloss: 0.247035\n",
            "[430]\ttraining's binary_logloss: 0.0620263\tvalid_1's binary_logloss: 0.240996\n",
            "[440]\ttraining's binary_logloss: 0.0604119\tvalid_1's binary_logloss: 0.23389\n",
            "[450]\ttraining's binary_logloss: 0.0590902\tvalid_1's binary_logloss: 0.227854\n",
            "[460]\ttraining's binary_logloss: 0.057893\tvalid_1's binary_logloss: 0.222891\n",
            "[470]\ttraining's binary_logloss: 0.0564997\tvalid_1's binary_logloss: 0.217084\n",
            "[480]\ttraining's binary_logloss: 0.0551249\tvalid_1's binary_logloss: 0.211379\n",
            "[490]\ttraining's binary_logloss: 0.053871\tvalid_1's binary_logloss: 0.206484\n",
            "[500]\ttraining's binary_logloss: 0.0527429\tvalid_1's binary_logloss: 0.201703\n",
            "[510]\ttraining's binary_logloss: 0.051505\tvalid_1's binary_logloss: 0.196961\n",
            "[520]\ttraining's binary_logloss: 0.0504576\tvalid_1's binary_logloss: 0.192179\n",
            "[530]\ttraining's binary_logloss: 0.0491661\tvalid_1's binary_logloss: 0.186293\n",
            "[540]\ttraining's binary_logloss: 0.0479724\tvalid_1's binary_logloss: 0.181663\n",
            "[550]\ttraining's binary_logloss: 0.0469677\tvalid_1's binary_logloss: 0.178121\n",
            "[560]\ttraining's binary_logloss: 0.045807\tvalid_1's binary_logloss: 0.173228\n",
            "[570]\ttraining's binary_logloss: 0.0446953\tvalid_1's binary_logloss: 0.168935\n",
            "[580]\ttraining's binary_logloss: 0.0436796\tvalid_1's binary_logloss: 0.164774\n",
            "[590]\ttraining's binary_logloss: 0.0427381\tvalid_1's binary_logloss: 0.161878\n",
            "[600]\ttraining's binary_logloss: 0.0417313\tvalid_1's binary_logloss: 0.158212\n",
            "[610]\ttraining's binary_logloss: 0.0409551\tvalid_1's binary_logloss: 0.155219\n",
            "[620]\ttraining's binary_logloss: 0.0400977\tvalid_1's binary_logloss: 0.151906\n",
            "[630]\ttraining's binary_logloss: 0.0392246\tvalid_1's binary_logloss: 0.148421\n",
            "[640]\ttraining's binary_logloss: 0.0384337\tvalid_1's binary_logloss: 0.144917\n",
            "[650]\ttraining's binary_logloss: 0.0376883\tvalid_1's binary_logloss: 0.142098\n",
            "[660]\ttraining's binary_logloss: 0.0370193\tvalid_1's binary_logloss: 0.139556\n",
            "[670]\ttraining's binary_logloss: 0.0362404\tvalid_1's binary_logloss: 0.136602\n",
            "[680]\ttraining's binary_logloss: 0.0354566\tvalid_1's binary_logloss: 0.133372\n",
            "[690]\ttraining's binary_logloss: 0.0347062\tvalid_1's binary_logloss: 0.130082\n",
            "[700]\ttraining's binary_logloss: 0.0339504\tvalid_1's binary_logloss: 0.127384\n",
            "[710]\ttraining's binary_logloss: 0.033237\tvalid_1's binary_logloss: 0.124554\n",
            "[720]\ttraining's binary_logloss: 0.0325399\tvalid_1's binary_logloss: 0.122221\n",
            "[730]\ttraining's binary_logloss: 0.0318984\tvalid_1's binary_logloss: 0.119939\n",
            "[740]\ttraining's binary_logloss: 0.0311656\tvalid_1's binary_logloss: 0.116882\n",
            "[750]\ttraining's binary_logloss: 0.0303832\tvalid_1's binary_logloss: 0.113333\n",
            "[760]\ttraining's binary_logloss: 0.0297091\tvalid_1's binary_logloss: 0.110962\n",
            "[770]\ttraining's binary_logloss: 0.0290963\tvalid_1's binary_logloss: 0.108438\n",
            "[780]\ttraining's binary_logloss: 0.0285663\tvalid_1's binary_logloss: 0.106596\n",
            "[790]\ttraining's binary_logloss: 0.0280733\tvalid_1's binary_logloss: 0.10471\n",
            "[800]\ttraining's binary_logloss: 0.0275408\tvalid_1's binary_logloss: 0.102829\n",
            "[810]\ttraining's binary_logloss: 0.0270504\tvalid_1's binary_logloss: 0.10103\n",
            "[820]\ttraining's binary_logloss: 0.0263772\tvalid_1's binary_logloss: 0.0983691\n",
            "[830]\ttraining's binary_logloss: 0.0257809\tvalid_1's binary_logloss: 0.0960066\n",
            "[840]\ttraining's binary_logloss: 0.0252297\tvalid_1's binary_logloss: 0.0940835\n",
            "[850]\ttraining's binary_logloss: 0.0246872\tvalid_1's binary_logloss: 0.0919704\n",
            "[860]\ttraining's binary_logloss: 0.0241141\tvalid_1's binary_logloss: 0.0895867\n",
            "[870]\ttraining's binary_logloss: 0.0236227\tvalid_1's binary_logloss: 0.0878378\n",
            "[880]\ttraining's binary_logloss: 0.0231425\tvalid_1's binary_logloss: 0.0860398\n",
            "[890]\ttraining's binary_logloss: 0.0227206\tvalid_1's binary_logloss: 0.0845121\n",
            "[900]\ttraining's binary_logloss: 0.0223018\tvalid_1's binary_logloss: 0.0828189\n",
            "[910]\ttraining's binary_logloss: 0.0218652\tvalid_1's binary_logloss: 0.0813981\n",
            "[920]\ttraining's binary_logloss: 0.0213395\tvalid_1's binary_logloss: 0.079588\n",
            "[930]\ttraining's binary_logloss: 0.0209434\tvalid_1's binary_logloss: 0.0782121\n",
            "[940]\ttraining's binary_logloss: 0.0205305\tvalid_1's binary_logloss: 0.0767477\n",
            "[950]\ttraining's binary_logloss: 0.020157\tvalid_1's binary_logloss: 0.0753308\n",
            "[960]\ttraining's binary_logloss: 0.0198057\tvalid_1's binary_logloss: 0.0742046\n",
            "[970]\ttraining's binary_logloss: 0.0194356\tvalid_1's binary_logloss: 0.072744\n",
            "[980]\ttraining's binary_logloss: 0.0190292\tvalid_1's binary_logloss: 0.0710897\n",
            "[990]\ttraining's binary_logloss: 0.0186663\tvalid_1's binary_logloss: 0.0694808\n",
            "[1000]\ttraining's binary_logloss: 0.0182764\tvalid_1's binary_logloss: 0.0679858\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.0182764\tvalid_1's binary_logloss: 0.0679858\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:46:04,751] Trial 12 finished with value: 0.06798575007457662 and parameters: {'max_bin': 420, 'num_leaves': 57}. Best is trial 7 with value: 0.004795566388927853.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.213761\tvalid_1's binary_logloss: 0.98583\n",
            "[20]\ttraining's binary_logloss: 0.189238\tvalid_1's binary_logloss: 0.864231\n",
            "[30]\ttraining's binary_logloss: 0.17294\tvalid_1's binary_logloss: 0.785213\n",
            "[40]\ttraining's binary_logloss: 0.160082\tvalid_1's binary_logloss: 0.716282\n",
            "[50]\ttraining's binary_logloss: 0.148515\tvalid_1's binary_logloss: 0.651967\n",
            "[60]\ttraining's binary_logloss: 0.138692\tvalid_1's binary_logloss: 0.596326\n",
            "[70]\ttraining's binary_logloss: 0.129831\tvalid_1's binary_logloss: 0.550288\n",
            "[80]\ttraining's binary_logloss: 0.121885\tvalid_1's binary_logloss: 0.510948\n",
            "[90]\ttraining's binary_logloss: 0.115017\tvalid_1's binary_logloss: 0.47848\n",
            "[100]\ttraining's binary_logloss: 0.108942\tvalid_1's binary_logloss: 0.449203\n",
            "[110]\ttraining's binary_logloss: 0.103188\tvalid_1's binary_logloss: 0.422743\n",
            "[120]\ttraining's binary_logloss: 0.0982173\tvalid_1's binary_logloss: 0.400914\n",
            "[130]\ttraining's binary_logloss: 0.0935784\tvalid_1's binary_logloss: 0.3802\n",
            "[140]\ttraining's binary_logloss: 0.0890901\tvalid_1's binary_logloss: 0.35874\n",
            "[150]\ttraining's binary_logloss: 0.0849464\tvalid_1's binary_logloss: 0.33797\n",
            "[160]\ttraining's binary_logloss: 0.0807453\tvalid_1's binary_logloss: 0.320102\n",
            "[170]\ttraining's binary_logloss: 0.0772346\tvalid_1's binary_logloss: 0.304193\n",
            "[180]\ttraining's binary_logloss: 0.0741769\tvalid_1's binary_logloss: 0.291129\n",
            "[190]\ttraining's binary_logloss: 0.071097\tvalid_1's binary_logloss: 0.277405\n",
            "[200]\ttraining's binary_logloss: 0.0680759\tvalid_1's binary_logloss: 0.264721\n",
            "[210]\ttraining's binary_logloss: 0.0653603\tvalid_1's binary_logloss: 0.253123\n",
            "[220]\ttraining's binary_logloss: 0.0626189\tvalid_1's binary_logloss: 0.241146\n",
            "[230]\ttraining's binary_logloss: 0.0601678\tvalid_1's binary_logloss: 0.230747\n",
            "[240]\ttraining's binary_logloss: 0.0578015\tvalid_1's binary_logloss: 0.220972\n",
            "[250]\ttraining's binary_logloss: 0.0552953\tvalid_1's binary_logloss: 0.21013\n",
            "[260]\ttraining's binary_logloss: 0.0530633\tvalid_1's binary_logloss: 0.200848\n",
            "[270]\ttraining's binary_logloss: 0.0507844\tvalid_1's binary_logloss: 0.191669\n",
            "[280]\ttraining's binary_logloss: 0.048606\tvalid_1's binary_logloss: 0.182311\n",
            "[290]\ttraining's binary_logloss: 0.0465453\tvalid_1's binary_logloss: 0.17436\n",
            "[300]\ttraining's binary_logloss: 0.0443739\tvalid_1's binary_logloss: 0.165482\n",
            "[310]\ttraining's binary_logloss: 0.0424248\tvalid_1's binary_logloss: 0.158088\n",
            "[320]\ttraining's binary_logloss: 0.0405924\tvalid_1's binary_logloss: 0.150762\n",
            "[330]\ttraining's binary_logloss: 0.0389844\tvalid_1's binary_logloss: 0.143956\n",
            "[340]\ttraining's binary_logloss: 0.0373877\tvalid_1's binary_logloss: 0.137597\n",
            "[350]\ttraining's binary_logloss: 0.0358378\tvalid_1's binary_logloss: 0.131306\n",
            "[360]\ttraining's binary_logloss: 0.0343112\tvalid_1's binary_logloss: 0.125653\n",
            "[370]\ttraining's binary_logloss: 0.0330011\tvalid_1's binary_logloss: 0.12028\n",
            "[380]\ttraining's binary_logloss: 0.0316579\tvalid_1's binary_logloss: 0.114394\n",
            "[390]\ttraining's binary_logloss: 0.030355\tvalid_1's binary_logloss: 0.109655\n",
            "[400]\ttraining's binary_logloss: 0.0291697\tvalid_1's binary_logloss: 0.10523\n",
            "[410]\ttraining's binary_logloss: 0.0281233\tvalid_1's binary_logloss: 0.101355\n",
            "[420]\ttraining's binary_logloss: 0.0271661\tvalid_1's binary_logloss: 0.0979305\n",
            "[430]\ttraining's binary_logloss: 0.0260044\tvalid_1's binary_logloss: 0.0934867\n",
            "[440]\ttraining's binary_logloss: 0.0250097\tvalid_1's binary_logloss: 0.0897442\n",
            "[450]\ttraining's binary_logloss: 0.02394\tvalid_1's binary_logloss: 0.0857333\n",
            "[460]\ttraining's binary_logloss: 0.0230404\tvalid_1's binary_logloss: 0.0824288\n",
            "[470]\ttraining's binary_logloss: 0.0222922\tvalid_1's binary_logloss: 0.0798186\n",
            "[480]\ttraining's binary_logloss: 0.0213105\tvalid_1's binary_logloss: 0.0761826\n",
            "[490]\ttraining's binary_logloss: 0.0204035\tvalid_1's binary_logloss: 0.0730395\n",
            "[500]\ttraining's binary_logloss: 0.0195283\tvalid_1's binary_logloss: 0.0695461\n",
            "[510]\ttraining's binary_logloss: 0.0187668\tvalid_1's binary_logloss: 0.0665895\n",
            "[520]\ttraining's binary_logloss: 0.0180218\tvalid_1's binary_logloss: 0.0638674\n",
            "[530]\ttraining's binary_logloss: 0.0172478\tvalid_1's binary_logloss: 0.0609292\n",
            "[540]\ttraining's binary_logloss: 0.0165483\tvalid_1's binary_logloss: 0.058278\n",
            "[550]\ttraining's binary_logloss: 0.0158702\tvalid_1's binary_logloss: 0.0558911\n",
            "[560]\ttraining's binary_logloss: 0.0152324\tvalid_1's binary_logloss: 0.0534873\n",
            "[570]\ttraining's binary_logloss: 0.0145997\tvalid_1's binary_logloss: 0.0513537\n",
            "[580]\ttraining's binary_logloss: 0.0140805\tvalid_1's binary_logloss: 0.0495597\n",
            "[590]\ttraining's binary_logloss: 0.0135311\tvalid_1's binary_logloss: 0.0474135\n",
            "[600]\ttraining's binary_logloss: 0.0130225\tvalid_1's binary_logloss: 0.0456999\n",
            "[610]\ttraining's binary_logloss: 0.0124816\tvalid_1's binary_logloss: 0.0437236\n",
            "[620]\ttraining's binary_logloss: 0.0119951\tvalid_1's binary_logloss: 0.0420086\n",
            "[630]\ttraining's binary_logloss: 0.0115302\tvalid_1's binary_logloss: 0.040338\n",
            "[640]\ttraining's binary_logloss: 0.0110449\tvalid_1's binary_logloss: 0.0388458\n",
            "[650]\ttraining's binary_logloss: 0.0105565\tvalid_1's binary_logloss: 0.0372849\n",
            "[660]\ttraining's binary_logloss: 0.0101289\tvalid_1's binary_logloss: 0.0358174\n",
            "[670]\ttraining's binary_logloss: 0.00972257\tvalid_1's binary_logloss: 0.0342711\n",
            "[680]\ttraining's binary_logloss: 0.00932685\tvalid_1's binary_logloss: 0.0329461\n",
            "[690]\ttraining's binary_logloss: 0.00895488\tvalid_1's binary_logloss: 0.031575\n",
            "[700]\ttraining's binary_logloss: 0.00861398\tvalid_1's binary_logloss: 0.0303885\n",
            "[710]\ttraining's binary_logloss: 0.00832094\tvalid_1's binary_logloss: 0.0294349\n",
            "[720]\ttraining's binary_logloss: 0.00802077\tvalid_1's binary_logloss: 0.0283404\n",
            "[730]\ttraining's binary_logloss: 0.00774283\tvalid_1's binary_logloss: 0.0272845\n",
            "[740]\ttraining's binary_logloss: 0.00744027\tvalid_1's binary_logloss: 0.0262191\n",
            "[750]\ttraining's binary_logloss: 0.00718099\tvalid_1's binary_logloss: 0.0253041\n",
            "[760]\ttraining's binary_logloss: 0.00685992\tvalid_1's binary_logloss: 0.0242941\n",
            "[770]\ttraining's binary_logloss: 0.0065823\tvalid_1's binary_logloss: 0.0233824\n",
            "[780]\ttraining's binary_logloss: 0.00636462\tvalid_1's binary_logloss: 0.0226816\n",
            "[790]\ttraining's binary_logloss: 0.00614197\tvalid_1's binary_logloss: 0.0218554\n",
            "[800]\ttraining's binary_logloss: 0.0059067\tvalid_1's binary_logloss: 0.021058\n",
            "[810]\ttraining's binary_logloss: 0.00567675\tvalid_1's binary_logloss: 0.0202244\n",
            "[820]\ttraining's binary_logloss: 0.00547901\tvalid_1's binary_logloss: 0.0194699\n",
            "[830]\ttraining's binary_logloss: 0.00528279\tvalid_1's binary_logloss: 0.0188331\n",
            "[840]\ttraining's binary_logloss: 0.00510223\tvalid_1's binary_logloss: 0.0181716\n",
            "[850]\ttraining's binary_logloss: 0.00491204\tvalid_1's binary_logloss: 0.0174934\n",
            "[860]\ttraining's binary_logloss: 0.00473377\tvalid_1's binary_logloss: 0.0168578\n",
            "[870]\ttraining's binary_logloss: 0.00455074\tvalid_1's binary_logloss: 0.0161693\n",
            "[880]\ttraining's binary_logloss: 0.00438996\tvalid_1's binary_logloss: 0.015646\n",
            "[890]\ttraining's binary_logloss: 0.00423138\tvalid_1's binary_logloss: 0.0151018\n",
            "[900]\ttraining's binary_logloss: 0.00406611\tvalid_1's binary_logloss: 0.0145863\n",
            "[910]\ttraining's binary_logloss: 0.00389597\tvalid_1's binary_logloss: 0.0139228\n",
            "[920]\ttraining's binary_logloss: 0.00371782\tvalid_1's binary_logloss: 0.0133313\n",
            "[930]\ttraining's binary_logloss: 0.00355811\tvalid_1's binary_logloss: 0.0127409\n",
            "[940]\ttraining's binary_logloss: 0.00341457\tvalid_1's binary_logloss: 0.0122228\n",
            "[950]\ttraining's binary_logloss: 0.00327453\tvalid_1's binary_logloss: 0.0117443\n",
            "[960]\ttraining's binary_logloss: 0.00316249\tvalid_1's binary_logloss: 0.0113514\n",
            "[970]\ttraining's binary_logloss: 0.00303413\tvalid_1's binary_logloss: 0.0108915\n",
            "[980]\ttraining's binary_logloss: 0.00293076\tvalid_1's binary_logloss: 0.0105273\n",
            "[990]\ttraining's binary_logloss: 0.0028244\tvalid_1's binary_logloss: 0.0101252\n",
            "[1000]\ttraining's binary_logloss: 0.00272352\tvalid_1's binary_logloss: 0.00976916\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.00272352\tvalid_1's binary_logloss: 0.00976916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:46:14,608] Trial 13 finished with value: 0.009769164587673032 and parameters: {'max_bin': 332, 'num_leaves': 104}. Best is trial 7 with value: 0.004795566388927853.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.222609\tvalid_1's binary_logloss: 1.03428\n",
            "[20]\ttraining's binary_logloss: 0.203472\tvalid_1's binary_logloss: 0.938388\n",
            "[30]\ttraining's binary_logloss: 0.191258\tvalid_1's binary_logloss: 0.882719\n",
            "[40]\ttraining's binary_logloss: 0.181841\tvalid_1's binary_logloss: 0.836099\n",
            "[50]\ttraining's binary_logloss: 0.174212\tvalid_1's binary_logloss: 0.796614\n",
            "[60]\ttraining's binary_logloss: 0.16728\tvalid_1's binary_logloss: 0.759845\n",
            "[70]\ttraining's binary_logloss: 0.16093\tvalid_1's binary_logloss: 0.723069\n",
            "[80]\ttraining's binary_logloss: 0.155138\tvalid_1's binary_logloss: 0.690509\n",
            "[90]\ttraining's binary_logloss: 0.150303\tvalid_1's binary_logloss: 0.665114\n",
            "[100]\ttraining's binary_logloss: 0.145733\tvalid_1's binary_logloss: 0.643809\n",
            "[110]\ttraining's binary_logloss: 0.141968\tvalid_1's binary_logloss: 0.624274\n",
            "[120]\ttraining's binary_logloss: 0.138112\tvalid_1's binary_logloss: 0.605322\n",
            "[130]\ttraining's binary_logloss: 0.13408\tvalid_1's binary_logloss: 0.585229\n",
            "[140]\ttraining's binary_logloss: 0.130417\tvalid_1's binary_logloss: 0.564031\n",
            "[150]\ttraining's binary_logloss: 0.127144\tvalid_1's binary_logloss: 0.548028\n",
            "[160]\ttraining's binary_logloss: 0.124322\tvalid_1's binary_logloss: 0.531899\n",
            "[170]\ttraining's binary_logloss: 0.121348\tvalid_1's binary_logloss: 0.516527\n",
            "[180]\ttraining's binary_logloss: 0.118375\tvalid_1's binary_logloss: 0.500508\n",
            "[190]\ttraining's binary_logloss: 0.115715\tvalid_1's binary_logloss: 0.487862\n",
            "[200]\ttraining's binary_logloss: 0.112951\tvalid_1's binary_logloss: 0.474772\n",
            "[210]\ttraining's binary_logloss: 0.110499\tvalid_1's binary_logloss: 0.461894\n",
            "[220]\ttraining's binary_logloss: 0.10804\tvalid_1's binary_logloss: 0.449692\n",
            "[230]\ttraining's binary_logloss: 0.10571\tvalid_1's binary_logloss: 0.438262\n",
            "[240]\ttraining's binary_logloss: 0.103153\tvalid_1's binary_logloss: 0.426115\n",
            "[250]\ttraining's binary_logloss: 0.100577\tvalid_1's binary_logloss: 0.414101\n",
            "[260]\ttraining's binary_logloss: 0.0985808\tvalid_1's binary_logloss: 0.403799\n",
            "[270]\ttraining's binary_logloss: 0.0961245\tvalid_1's binary_logloss: 0.392117\n",
            "[280]\ttraining's binary_logloss: 0.0940548\tvalid_1's binary_logloss: 0.382059\n",
            "[290]\ttraining's binary_logloss: 0.0919841\tvalid_1's binary_logloss: 0.372055\n",
            "[300]\ttraining's binary_logloss: 0.0899343\tvalid_1's binary_logloss: 0.361989\n",
            "[310]\ttraining's binary_logloss: 0.0879784\tvalid_1's binary_logloss: 0.353486\n",
            "[320]\ttraining's binary_logloss: 0.0858582\tvalid_1's binary_logloss: 0.343237\n",
            "[330]\ttraining's binary_logloss: 0.083966\tvalid_1's binary_logloss: 0.335487\n",
            "[340]\ttraining's binary_logloss: 0.0821061\tvalid_1's binary_logloss: 0.327789\n",
            "[350]\ttraining's binary_logloss: 0.0803844\tvalid_1's binary_logloss: 0.321077\n",
            "[360]\ttraining's binary_logloss: 0.0787881\tvalid_1's binary_logloss: 0.313701\n",
            "[370]\ttraining's binary_logloss: 0.076892\tvalid_1's binary_logloss: 0.30536\n",
            "[380]\ttraining's binary_logloss: 0.0752457\tvalid_1's binary_logloss: 0.298737\n",
            "[390]\ttraining's binary_logloss: 0.0738997\tvalid_1's binary_logloss: 0.292659\n",
            "[400]\ttraining's binary_logloss: 0.0723628\tvalid_1's binary_logloss: 0.285573\n",
            "[410]\ttraining's binary_logloss: 0.0708839\tvalid_1's binary_logloss: 0.278562\n",
            "[420]\ttraining's binary_logloss: 0.0695222\tvalid_1's binary_logloss: 0.272245\n",
            "[430]\ttraining's binary_logloss: 0.0679024\tvalid_1's binary_logloss: 0.265161\n",
            "[440]\ttraining's binary_logloss: 0.0665256\tvalid_1's binary_logloss: 0.259109\n",
            "[450]\ttraining's binary_logloss: 0.0650539\tvalid_1's binary_logloss: 0.253482\n",
            "[460]\ttraining's binary_logloss: 0.0637513\tvalid_1's binary_logloss: 0.2472\n",
            "[470]\ttraining's binary_logloss: 0.0625702\tvalid_1's binary_logloss: 0.242002\n",
            "[480]\ttraining's binary_logloss: 0.0612528\tvalid_1's binary_logloss: 0.236592\n",
            "[490]\ttraining's binary_logloss: 0.0599614\tvalid_1's binary_logloss: 0.230282\n",
            "[500]\ttraining's binary_logloss: 0.058613\tvalid_1's binary_logloss: 0.225085\n",
            "[510]\ttraining's binary_logloss: 0.0575175\tvalid_1's binary_logloss: 0.220861\n",
            "[520]\ttraining's binary_logloss: 0.0564462\tvalid_1's binary_logloss: 0.216413\n",
            "[530]\ttraining's binary_logloss: 0.0552444\tvalid_1's binary_logloss: 0.211503\n",
            "[540]\ttraining's binary_logloss: 0.0542076\tvalid_1's binary_logloss: 0.207426\n",
            "[550]\ttraining's binary_logloss: 0.0531208\tvalid_1's binary_logloss: 0.203261\n",
            "[560]\ttraining's binary_logloss: 0.0522019\tvalid_1's binary_logloss: 0.19959\n",
            "[570]\ttraining's binary_logloss: 0.051087\tvalid_1's binary_logloss: 0.19533\n",
            "[580]\ttraining's binary_logloss: 0.0500716\tvalid_1's binary_logloss: 0.191068\n",
            "[590]\ttraining's binary_logloss: 0.04896\tvalid_1's binary_logloss: 0.186085\n",
            "[600]\ttraining's binary_logloss: 0.0478791\tvalid_1's binary_logloss: 0.181428\n",
            "[610]\ttraining's binary_logloss: 0.0470102\tvalid_1's binary_logloss: 0.17798\n",
            "[620]\ttraining's binary_logloss: 0.0460036\tvalid_1's binary_logloss: 0.173799\n",
            "[630]\ttraining's binary_logloss: 0.0450774\tvalid_1's binary_logloss: 0.17033\n",
            "[640]\ttraining's binary_logloss: 0.0441465\tvalid_1's binary_logloss: 0.166586\n",
            "[650]\ttraining's binary_logloss: 0.0432926\tvalid_1's binary_logloss: 0.162882\n",
            "[660]\ttraining's binary_logloss: 0.0425186\tvalid_1's binary_logloss: 0.160001\n",
            "[670]\ttraining's binary_logloss: 0.041695\tvalid_1's binary_logloss: 0.156526\n",
            "[680]\ttraining's binary_logloss: 0.0407617\tvalid_1's binary_logloss: 0.151957\n",
            "[690]\ttraining's binary_logloss: 0.0397794\tvalid_1's binary_logloss: 0.14816\n",
            "[700]\ttraining's binary_logloss: 0.0388763\tvalid_1's binary_logloss: 0.144519\n",
            "[710]\ttraining's binary_logloss: 0.0380856\tvalid_1's binary_logloss: 0.14167\n",
            "[720]\ttraining's binary_logloss: 0.0372156\tvalid_1's binary_logloss: 0.138023\n",
            "[730]\ttraining's binary_logloss: 0.0364893\tvalid_1's binary_logloss: 0.135289\n",
            "[740]\ttraining's binary_logloss: 0.0356873\tvalid_1's binary_logloss: 0.132197\n",
            "[750]\ttraining's binary_logloss: 0.0350256\tvalid_1's binary_logloss: 0.129691\n",
            "[760]\ttraining's binary_logloss: 0.0344275\tvalid_1's binary_logloss: 0.127255\n",
            "[770]\ttraining's binary_logloss: 0.0337325\tvalid_1's binary_logloss: 0.124737\n",
            "[780]\ttraining's binary_logloss: 0.0330481\tvalid_1's binary_logloss: 0.122007\n",
            "[790]\ttraining's binary_logloss: 0.032277\tvalid_1's binary_logloss: 0.119169\n",
            "[800]\ttraining's binary_logloss: 0.0315566\tvalid_1's binary_logloss: 0.116163\n",
            "[810]\ttraining's binary_logloss: 0.0309243\tvalid_1's binary_logloss: 0.113746\n",
            "[820]\ttraining's binary_logloss: 0.0303237\tvalid_1's binary_logloss: 0.111833\n",
            "[830]\ttraining's binary_logloss: 0.0297183\tvalid_1's binary_logloss: 0.109802\n",
            "[840]\ttraining's binary_logloss: 0.0291381\tvalid_1's binary_logloss: 0.107595\n",
            "[850]\ttraining's binary_logloss: 0.0285759\tvalid_1's binary_logloss: 0.105427\n",
            "[860]\ttraining's binary_logloss: 0.0280333\tvalid_1's binary_logloss: 0.103536\n",
            "[870]\ttraining's binary_logloss: 0.0275448\tvalid_1's binary_logloss: 0.101816\n",
            "[880]\ttraining's binary_logloss: 0.0269386\tvalid_1's binary_logloss: 0.0996525\n",
            "[890]\ttraining's binary_logloss: 0.0263469\tvalid_1's binary_logloss: 0.097622\n",
            "[900]\ttraining's binary_logloss: 0.0258289\tvalid_1's binary_logloss: 0.0958208\n",
            "[910]\ttraining's binary_logloss: 0.0253966\tvalid_1's binary_logloss: 0.0943357\n",
            "[920]\ttraining's binary_logloss: 0.0248427\tvalid_1's binary_logloss: 0.0921428\n",
            "[930]\ttraining's binary_logloss: 0.0243405\tvalid_1's binary_logloss: 0.0900617\n",
            "[940]\ttraining's binary_logloss: 0.0238161\tvalid_1's binary_logloss: 0.0881371\n",
            "[950]\ttraining's binary_logloss: 0.0233806\tvalid_1's binary_logloss: 0.0863391\n",
            "[960]\ttraining's binary_logloss: 0.02289\tvalid_1's binary_logloss: 0.0845081\n",
            "[970]\ttraining's binary_logloss: 0.0224524\tvalid_1's binary_logloss: 0.0830277\n",
            "[980]\ttraining's binary_logloss: 0.0219767\tvalid_1's binary_logloss: 0.0813272\n",
            "[990]\ttraining's binary_logloss: 0.0215685\tvalid_1's binary_logloss: 0.0798772\n",
            "[1000]\ttraining's binary_logloss: 0.0211101\tvalid_1's binary_logloss: 0.0782149\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.0211101\tvalid_1's binary_logloss: 0.0782149\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:46:21,462] Trial 14 finished with value: 0.07821492673230133 and parameters: {'max_bin': 264, 'num_leaves': 52}. Best is trial 7 with value: 0.004795566388927853.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.21276\tvalid_1's binary_logloss: 0.978312\n",
            "[20]\ttraining's binary_logloss: 0.187512\tvalid_1's binary_logloss: 0.850876\n",
            "[30]\ttraining's binary_logloss: 0.170698\tvalid_1's binary_logloss: 0.769008\n",
            "[40]\ttraining's binary_logloss: 0.157518\tvalid_1's binary_logloss: 0.698437\n",
            "[50]\ttraining's binary_logloss: 0.145647\tvalid_1's binary_logloss: 0.637073\n",
            "[60]\ttraining's binary_logloss: 0.135491\tvalid_1's binary_logloss: 0.583233\n",
            "[70]\ttraining's binary_logloss: 0.126061\tvalid_1's binary_logloss: 0.538584\n",
            "[80]\ttraining's binary_logloss: 0.117585\tvalid_1's binary_logloss: 0.494505\n",
            "[90]\ttraining's binary_logloss: 0.110282\tvalid_1's binary_logloss: 0.461195\n",
            "[100]\ttraining's binary_logloss: 0.103741\tvalid_1's binary_logloss: 0.431374\n",
            "[110]\ttraining's binary_logloss: 0.0980857\tvalid_1's binary_logloss: 0.403736\n",
            "[120]\ttraining's binary_logloss: 0.0927824\tvalid_1's binary_logloss: 0.377299\n",
            "[130]\ttraining's binary_logloss: 0.0881625\tvalid_1's binary_logloss: 0.356811\n",
            "[140]\ttraining's binary_logloss: 0.0835491\tvalid_1's binary_logloss: 0.335487\n",
            "[150]\ttraining's binary_logloss: 0.0792606\tvalid_1's binary_logloss: 0.31675\n",
            "[160]\ttraining's binary_logloss: 0.0755386\tvalid_1's binary_logloss: 0.30005\n",
            "[170]\ttraining's binary_logloss: 0.0720779\tvalid_1's binary_logloss: 0.286315\n",
            "[180]\ttraining's binary_logloss: 0.0689285\tvalid_1's binary_logloss: 0.272954\n",
            "[190]\ttraining's binary_logloss: 0.065993\tvalid_1's binary_logloss: 0.260201\n",
            "[200]\ttraining's binary_logloss: 0.0630876\tvalid_1's binary_logloss: 0.248106\n",
            "[210]\ttraining's binary_logloss: 0.0603683\tvalid_1's binary_logloss: 0.236523\n",
            "[220]\ttraining's binary_logloss: 0.0577425\tvalid_1's binary_logloss: 0.2245\n",
            "[230]\ttraining's binary_logloss: 0.0550782\tvalid_1's binary_logloss: 0.214351\n",
            "[240]\ttraining's binary_logloss: 0.0526142\tvalid_1's binary_logloss: 0.203823\n",
            "[250]\ttraining's binary_logloss: 0.0503002\tvalid_1's binary_logloss: 0.194033\n",
            "[260]\ttraining's binary_logloss: 0.0480333\tvalid_1's binary_logloss: 0.183775\n",
            "[270]\ttraining's binary_logloss: 0.046043\tvalid_1's binary_logloss: 0.175927\n",
            "[280]\ttraining's binary_logloss: 0.0441957\tvalid_1's binary_logloss: 0.168702\n",
            "[290]\ttraining's binary_logloss: 0.0421763\tvalid_1's binary_logloss: 0.16044\n",
            "[300]\ttraining's binary_logloss: 0.040506\tvalid_1's binary_logloss: 0.153553\n",
            "[310]\ttraining's binary_logloss: 0.0387924\tvalid_1's binary_logloss: 0.147313\n",
            "[320]\ttraining's binary_logloss: 0.0370318\tvalid_1's binary_logloss: 0.14062\n",
            "[330]\ttraining's binary_logloss: 0.0355493\tvalid_1's binary_logloss: 0.134777\n",
            "[340]\ttraining's binary_logloss: 0.0341709\tvalid_1's binary_logloss: 0.129425\n",
            "[350]\ttraining's binary_logloss: 0.0328709\tvalid_1's binary_logloss: 0.123821\n",
            "[360]\ttraining's binary_logloss: 0.0315578\tvalid_1's binary_logloss: 0.118368\n",
            "[370]\ttraining's binary_logloss: 0.0302496\tvalid_1's binary_logloss: 0.113175\n",
            "[380]\ttraining's binary_logloss: 0.0288493\tvalid_1's binary_logloss: 0.108138\n",
            "[390]\ttraining's binary_logloss: 0.0276641\tvalid_1's binary_logloss: 0.103325\n",
            "[400]\ttraining's binary_logloss: 0.0265561\tvalid_1's binary_logloss: 0.099648\n",
            "[410]\ttraining's binary_logloss: 0.0254399\tvalid_1's binary_logloss: 0.095347\n",
            "[420]\ttraining's binary_logloss: 0.0244602\tvalid_1's binary_logloss: 0.0915914\n",
            "[430]\ttraining's binary_logloss: 0.0235363\tvalid_1's binary_logloss: 0.0883176\n",
            "[440]\ttraining's binary_logloss: 0.0225452\tvalid_1's binary_logloss: 0.0843945\n",
            "[450]\ttraining's binary_logloss: 0.0216443\tvalid_1's binary_logloss: 0.0811032\n",
            "[460]\ttraining's binary_logloss: 0.0207935\tvalid_1's binary_logloss: 0.0777553\n",
            "[470]\ttraining's binary_logloss: 0.0198757\tvalid_1's binary_logloss: 0.0743359\n",
            "[480]\ttraining's binary_logloss: 0.0190206\tvalid_1's binary_logloss: 0.0708586\n",
            "[490]\ttraining's binary_logloss: 0.018157\tvalid_1's binary_logloss: 0.0674094\n",
            "[500]\ttraining's binary_logloss: 0.0173172\tvalid_1's binary_logloss: 0.0640253\n",
            "[510]\ttraining's binary_logloss: 0.0166048\tvalid_1's binary_logloss: 0.0611975\n",
            "[520]\ttraining's binary_logloss: 0.0157914\tvalid_1's binary_logloss: 0.0579887\n",
            "[530]\ttraining's binary_logloss: 0.0150263\tvalid_1's binary_logloss: 0.0553117\n",
            "[540]\ttraining's binary_logloss: 0.0144121\tvalid_1's binary_logloss: 0.0530382\n",
            "[550]\ttraining's binary_logloss: 0.0138316\tvalid_1's binary_logloss: 0.0507356\n",
            "[560]\ttraining's binary_logloss: 0.0132942\tvalid_1's binary_logloss: 0.0488057\n",
            "[570]\ttraining's binary_logloss: 0.0127548\tvalid_1's binary_logloss: 0.0466694\n",
            "[580]\ttraining's binary_logloss: 0.0121382\tvalid_1's binary_logloss: 0.0444794\n",
            "[590]\ttraining's binary_logloss: 0.0116031\tvalid_1's binary_logloss: 0.0423108\n",
            "[600]\ttraining's binary_logloss: 0.011116\tvalid_1's binary_logloss: 0.0404165\n",
            "[610]\ttraining's binary_logloss: 0.0106416\tvalid_1's binary_logloss: 0.0386817\n",
            "[620]\ttraining's binary_logloss: 0.0101866\tvalid_1's binary_logloss: 0.0368124\n",
            "[630]\ttraining's binary_logloss: 0.00976697\tvalid_1's binary_logloss: 0.0351893\n",
            "[640]\ttraining's binary_logloss: 0.0092333\tvalid_1's binary_logloss: 0.033057\n",
            "[650]\ttraining's binary_logloss: 0.00886204\tvalid_1's binary_logloss: 0.0316213\n",
            "[660]\ttraining's binary_logloss: 0.00846529\tvalid_1's binary_logloss: 0.0302487\n",
            "[670]\ttraining's binary_logloss: 0.00814846\tvalid_1's binary_logloss: 0.0291225\n",
            "[680]\ttraining's binary_logloss: 0.00776951\tvalid_1's binary_logloss: 0.0278894\n",
            "[690]\ttraining's binary_logloss: 0.00744661\tvalid_1's binary_logloss: 0.0267414\n",
            "[700]\ttraining's binary_logloss: 0.00712206\tvalid_1's binary_logloss: 0.0256234\n",
            "[710]\ttraining's binary_logloss: 0.00678693\tvalid_1's binary_logloss: 0.024337\n",
            "[720]\ttraining's binary_logloss: 0.00651717\tvalid_1's binary_logloss: 0.02348\n",
            "[730]\ttraining's binary_logloss: 0.00622321\tvalid_1's binary_logloss: 0.0224269\n",
            "[740]\ttraining's binary_logloss: 0.00597893\tvalid_1's binary_logloss: 0.0214826\n",
            "[750]\ttraining's binary_logloss: 0.00568969\tvalid_1's binary_logloss: 0.0203687\n",
            "[760]\ttraining's binary_logloss: 0.00544475\tvalid_1's binary_logloss: 0.0195656\n",
            "[770]\ttraining's binary_logloss: 0.00519654\tvalid_1's binary_logloss: 0.0187451\n",
            "[780]\ttraining's binary_logloss: 0.00499275\tvalid_1's binary_logloss: 0.0180105\n",
            "[790]\ttraining's binary_logloss: 0.00476418\tvalid_1's binary_logloss: 0.0171619\n",
            "[800]\ttraining's binary_logloss: 0.00455011\tvalid_1's binary_logloss: 0.0163304\n",
            "[810]\ttraining's binary_logloss: 0.00434502\tvalid_1's binary_logloss: 0.0156093\n",
            "[820]\ttraining's binary_logloss: 0.00414402\tvalid_1's binary_logloss: 0.0148977\n",
            "[830]\ttraining's binary_logloss: 0.00396699\tvalid_1's binary_logloss: 0.0142664\n",
            "[840]\ttraining's binary_logloss: 0.00379912\tvalid_1's binary_logloss: 0.0136896\n",
            "[850]\ttraining's binary_logloss: 0.00365918\tvalid_1's binary_logloss: 0.0132089\n",
            "[860]\ttraining's binary_logloss: 0.00352186\tvalid_1's binary_logloss: 0.0126969\n",
            "[870]\ttraining's binary_logloss: 0.00337328\tvalid_1's binary_logloss: 0.0121481\n",
            "[880]\ttraining's binary_logloss: 0.00322328\tvalid_1's binary_logloss: 0.0115856\n",
            "[890]\ttraining's binary_logloss: 0.00308093\tvalid_1's binary_logloss: 0.0110508\n",
            "[900]\ttraining's binary_logloss: 0.00294311\tvalid_1's binary_logloss: 0.010571\n",
            "[910]\ttraining's binary_logloss: 0.00281212\tvalid_1's binary_logloss: 0.0100984\n",
            "[920]\ttraining's binary_logloss: 0.00269567\tvalid_1's binary_logloss: 0.00969717\n",
            "[930]\ttraining's binary_logloss: 0.00257731\tvalid_1's binary_logloss: 0.00922523\n",
            "[940]\ttraining's binary_logloss: 0.00247604\tvalid_1's binary_logloss: 0.00885372\n",
            "[950]\ttraining's binary_logloss: 0.00237098\tvalid_1's binary_logloss: 0.00849819\n",
            "[960]\ttraining's binary_logloss: 0.00225987\tvalid_1's binary_logloss: 0.0080886\n",
            "[970]\ttraining's binary_logloss: 0.00215725\tvalid_1's binary_logloss: 0.0077231\n",
            "[980]\ttraining's binary_logloss: 0.00206322\tvalid_1's binary_logloss: 0.00739153\n",
            "[990]\ttraining's binary_logloss: 0.00196876\tvalid_1's binary_logloss: 0.00706403\n",
            "[1000]\ttraining's binary_logloss: 0.00188992\tvalid_1's binary_logloss: 0.00676195\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.00188992\tvalid_1's binary_logloss: 0.00676195\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:46:31,995] Trial 15 finished with value: 0.006761954289549327 and parameters: {'max_bin': 370, 'num_leaves': 112}. Best is trial 7 with value: 0.004795566388927853.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.214256\tvalid_1's binary_logloss: 0.987726\n",
            "[20]\ttraining's binary_logloss: 0.189869\tvalid_1's binary_logloss: 0.863186\n",
            "[30]\ttraining's binary_logloss: 0.17399\tvalid_1's binary_logloss: 0.783057\n",
            "[40]\ttraining's binary_logloss: 0.161345\tvalid_1's binary_logloss: 0.714642\n",
            "[50]\ttraining's binary_logloss: 0.150292\tvalid_1's binary_logloss: 0.656371\n",
            "[60]\ttraining's binary_logloss: 0.140237\tvalid_1's binary_logloss: 0.601352\n",
            "[70]\ttraining's binary_logloss: 0.131457\tvalid_1's binary_logloss: 0.557781\n",
            "[80]\ttraining's binary_logloss: 0.123517\tvalid_1's binary_logloss: 0.517426\n",
            "[90]\ttraining's binary_logloss: 0.116528\tvalid_1's binary_logloss: 0.480611\n",
            "[100]\ttraining's binary_logloss: 0.110498\tvalid_1's binary_logloss: 0.452579\n",
            "[110]\ttraining's binary_logloss: 0.104672\tvalid_1's binary_logloss: 0.427103\n",
            "[120]\ttraining's binary_logloss: 0.0996135\tvalid_1's binary_logloss: 0.403407\n",
            "[130]\ttraining's binary_logloss: 0.0948679\tvalid_1's binary_logloss: 0.382987\n",
            "[140]\ttraining's binary_logloss: 0.0904766\tvalid_1's binary_logloss: 0.362625\n",
            "[150]\ttraining's binary_logloss: 0.0865417\tvalid_1's binary_logloss: 0.345658\n",
            "[160]\ttraining's binary_logloss: 0.083027\tvalid_1's binary_logloss: 0.331541\n",
            "[170]\ttraining's binary_logloss: 0.0794202\tvalid_1's binary_logloss: 0.316982\n",
            "[180]\ttraining's binary_logloss: 0.0759926\tvalid_1's binary_logloss: 0.301507\n",
            "[190]\ttraining's binary_logloss: 0.0726575\tvalid_1's binary_logloss: 0.286909\n",
            "[200]\ttraining's binary_logloss: 0.0698011\tvalid_1's binary_logloss: 0.274331\n",
            "[210]\ttraining's binary_logloss: 0.0669775\tvalid_1's binary_logloss: 0.262363\n",
            "[220]\ttraining's binary_logloss: 0.0642568\tvalid_1's binary_logloss: 0.250656\n",
            "[230]\ttraining's binary_logloss: 0.0614187\tvalid_1's binary_logloss: 0.238278\n",
            "[240]\ttraining's binary_logloss: 0.0588592\tvalid_1's binary_logloss: 0.227578\n",
            "[250]\ttraining's binary_logloss: 0.056692\tvalid_1's binary_logloss: 0.219084\n",
            "[260]\ttraining's binary_logloss: 0.0541981\tvalid_1's binary_logloss: 0.208926\n",
            "[270]\ttraining's binary_logloss: 0.0522224\tvalid_1's binary_logloss: 0.201366\n",
            "[280]\ttraining's binary_logloss: 0.0500166\tvalid_1's binary_logloss: 0.192512\n",
            "[290]\ttraining's binary_logloss: 0.0478233\tvalid_1's binary_logloss: 0.183729\n",
            "[300]\ttraining's binary_logloss: 0.0457873\tvalid_1's binary_logloss: 0.174745\n",
            "[310]\ttraining's binary_logloss: 0.0439805\tvalid_1's binary_logloss: 0.167413\n",
            "[320]\ttraining's binary_logloss: 0.0422804\tvalid_1's binary_logloss: 0.160554\n",
            "[330]\ttraining's binary_logloss: 0.0404344\tvalid_1's binary_logloss: 0.153766\n",
            "[340]\ttraining's binary_logloss: 0.0387749\tvalid_1's binary_logloss: 0.146829\n",
            "[350]\ttraining's binary_logloss: 0.0372082\tvalid_1's binary_logloss: 0.140867\n",
            "[360]\ttraining's binary_logloss: 0.0357836\tvalid_1's binary_logloss: 0.135455\n",
            "[370]\ttraining's binary_logloss: 0.0345589\tvalid_1's binary_logloss: 0.130409\n",
            "[380]\ttraining's binary_logloss: 0.0331878\tvalid_1's binary_logloss: 0.125028\n",
            "[390]\ttraining's binary_logloss: 0.0320394\tvalid_1's binary_logloss: 0.120513\n",
            "[400]\ttraining's binary_logloss: 0.0308441\tvalid_1's binary_logloss: 0.115577\n",
            "[410]\ttraining's binary_logloss: 0.0297912\tvalid_1's binary_logloss: 0.111285\n",
            "[420]\ttraining's binary_logloss: 0.0288094\tvalid_1's binary_logloss: 0.107561\n",
            "[430]\ttraining's binary_logloss: 0.0277877\tvalid_1's binary_logloss: 0.103761\n",
            "[440]\ttraining's binary_logloss: 0.0268699\tvalid_1's binary_logloss: 0.0999766\n",
            "[450]\ttraining's binary_logloss: 0.0258365\tvalid_1's binary_logloss: 0.0959281\n",
            "[460]\ttraining's binary_logloss: 0.0248788\tvalid_1's binary_logloss: 0.0923817\n",
            "[470]\ttraining's binary_logloss: 0.023875\tvalid_1's binary_logloss: 0.0884958\n",
            "[480]\ttraining's binary_logloss: 0.0229713\tvalid_1's binary_logloss: 0.0848644\n",
            "[490]\ttraining's binary_logloss: 0.0219898\tvalid_1's binary_logloss: 0.0809534\n",
            "[500]\ttraining's binary_logloss: 0.0209714\tvalid_1's binary_logloss: 0.0768756\n",
            "[510]\ttraining's binary_logloss: 0.0201316\tvalid_1's binary_logloss: 0.0738861\n",
            "[520]\ttraining's binary_logloss: 0.0194149\tvalid_1's binary_logloss: 0.0710334\n",
            "[530]\ttraining's binary_logloss: 0.0186326\tvalid_1's binary_logloss: 0.0678333\n",
            "[540]\ttraining's binary_logloss: 0.0178782\tvalid_1's binary_logloss: 0.0649992\n",
            "[550]\ttraining's binary_logloss: 0.0171856\tvalid_1's binary_logloss: 0.0624726\n",
            "[560]\ttraining's binary_logloss: 0.0165559\tvalid_1's binary_logloss: 0.0603036\n",
            "[570]\ttraining's binary_logloss: 0.0159902\tvalid_1's binary_logloss: 0.0583147\n",
            "[580]\ttraining's binary_logloss: 0.0153468\tvalid_1's binary_logloss: 0.055853\n",
            "[590]\ttraining's binary_logloss: 0.014775\tvalid_1's binary_logloss: 0.0536677\n",
            "[600]\ttraining's binary_logloss: 0.0142167\tvalid_1's binary_logloss: 0.0517608\n",
            "[610]\ttraining's binary_logloss: 0.0136676\tvalid_1's binary_logloss: 0.0496454\n",
            "[620]\ttraining's binary_logloss: 0.0132032\tvalid_1's binary_logloss: 0.0481201\n",
            "[630]\ttraining's binary_logloss: 0.01264\tvalid_1's binary_logloss: 0.0461026\n",
            "[640]\ttraining's binary_logloss: 0.012156\tvalid_1's binary_logloss: 0.0443175\n",
            "[650]\ttraining's binary_logloss: 0.0117752\tvalid_1's binary_logloss: 0.0428869\n",
            "[660]\ttraining's binary_logloss: 0.0113392\tvalid_1's binary_logloss: 0.0412596\n",
            "[670]\ttraining's binary_logloss: 0.0109128\tvalid_1's binary_logloss: 0.0395688\n",
            "[680]\ttraining's binary_logloss: 0.0105113\tvalid_1's binary_logloss: 0.0380669\n",
            "[690]\ttraining's binary_logloss: 0.0101104\tvalid_1's binary_logloss: 0.0365102\n",
            "[700]\ttraining's binary_logloss: 0.00974859\tvalid_1's binary_logloss: 0.0352192\n",
            "[710]\ttraining's binary_logloss: 0.00938978\tvalid_1's binary_logloss: 0.0339298\n",
            "[720]\ttraining's binary_logloss: 0.00899308\tvalid_1's binary_logloss: 0.0323704\n",
            "[730]\ttraining's binary_logloss: 0.00858079\tvalid_1's binary_logloss: 0.0307367\n",
            "[740]\ttraining's binary_logloss: 0.00825947\tvalid_1's binary_logloss: 0.0295408\n",
            "[750]\ttraining's binary_logloss: 0.00794668\tvalid_1's binary_logloss: 0.0284839\n",
            "[760]\ttraining's binary_logloss: 0.00763722\tvalid_1's binary_logloss: 0.0274104\n",
            "[770]\ttraining's binary_logloss: 0.00732299\tvalid_1's binary_logloss: 0.0262549\n",
            "[780]\ttraining's binary_logloss: 0.00704583\tvalid_1's binary_logloss: 0.0253229\n",
            "[790]\ttraining's binary_logloss: 0.00676055\tvalid_1's binary_logloss: 0.024249\n",
            "[800]\ttraining's binary_logloss: 0.00651045\tvalid_1's binary_logloss: 0.0233166\n",
            "[810]\ttraining's binary_logloss: 0.00627164\tvalid_1's binary_logloss: 0.0224586\n",
            "[820]\ttraining's binary_logloss: 0.00603374\tvalid_1's binary_logloss: 0.0216198\n",
            "[830]\ttraining's binary_logloss: 0.00580209\tvalid_1's binary_logloss: 0.0207948\n",
            "[840]\ttraining's binary_logloss: 0.00559275\tvalid_1's binary_logloss: 0.0200225\n",
            "[850]\ttraining's binary_logloss: 0.00538528\tvalid_1's binary_logloss: 0.0192417\n",
            "[860]\ttraining's binary_logloss: 0.00516643\tvalid_1's binary_logloss: 0.0184799\n",
            "[870]\ttraining's binary_logloss: 0.00495892\tvalid_1's binary_logloss: 0.0176787\n",
            "[880]\ttraining's binary_logloss: 0.00480099\tvalid_1's binary_logloss: 0.0171392\n",
            "[890]\ttraining's binary_logloss: 0.00460109\tvalid_1's binary_logloss: 0.0163741\n",
            "[900]\ttraining's binary_logloss: 0.00440929\tvalid_1's binary_logloss: 0.0156757\n",
            "[910]\ttraining's binary_logloss: 0.00421987\tvalid_1's binary_logloss: 0.0149487\n",
            "[920]\ttraining's binary_logloss: 0.00407368\tvalid_1's binary_logloss: 0.0144384\n",
            "[930]\ttraining's binary_logloss: 0.00391445\tvalid_1's binary_logloss: 0.0138351\n",
            "[940]\ttraining's binary_logloss: 0.00378197\tvalid_1's binary_logloss: 0.0133589\n",
            "[950]\ttraining's binary_logloss: 0.00362551\tvalid_1's binary_logloss: 0.0127878\n",
            "[960]\ttraining's binary_logloss: 0.00348933\tvalid_1's binary_logloss: 0.0123012\n",
            "[970]\ttraining's binary_logloss: 0.0033464\tvalid_1's binary_logloss: 0.0118001\n",
            "[980]\ttraining's binary_logloss: 0.00322279\tvalid_1's binary_logloss: 0.0113991\n",
            "[990]\ttraining's binary_logloss: 0.00306148\tvalid_1's binary_logloss: 0.0108117\n",
            "[1000]\ttraining's binary_logloss: 0.00295439\tvalid_1's binary_logloss: 0.0104413\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.00295439\tvalid_1's binary_logloss: 0.0104413\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:46:42,265] Trial 16 finished with value: 0.01044134051650533 and parameters: {'max_bin': 498, 'num_leaves': 101}. Best is trial 7 with value: 0.004795566388927853.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.217539\tvalid_1's binary_logloss: 1.00683\n",
            "[20]\ttraining's binary_logloss: 0.19549\tvalid_1's binary_logloss: 0.894207\n",
            "[30]\ttraining's binary_logloss: 0.181143\tvalid_1's binary_logloss: 0.826913\n",
            "[40]\ttraining's binary_logloss: 0.169793\tvalid_1's binary_logloss: 0.765526\n",
            "[50]\ttraining's binary_logloss: 0.159599\tvalid_1's binary_logloss: 0.709735\n",
            "[60]\ttraining's binary_logloss: 0.151092\tvalid_1's binary_logloss: 0.664693\n",
            "[70]\ttraining's binary_logloss: 0.143141\tvalid_1's binary_logloss: 0.626368\n",
            "[80]\ttraining's binary_logloss: 0.135788\tvalid_1's binary_logloss: 0.586402\n",
            "[90]\ttraining's binary_logloss: 0.129423\tvalid_1's binary_logloss: 0.555833\n",
            "[100]\ttraining's binary_logloss: 0.124108\tvalid_1's binary_logloss: 0.53066\n",
            "[110]\ttraining's binary_logloss: 0.118856\tvalid_1's binary_logloss: 0.504293\n",
            "[120]\ttraining's binary_logloss: 0.113718\tvalid_1's binary_logloss: 0.480055\n",
            "[130]\ttraining's binary_logloss: 0.109482\tvalid_1's binary_logloss: 0.461126\n",
            "[140]\ttraining's binary_logloss: 0.105336\tvalid_1's binary_logloss: 0.438789\n",
            "[150]\ttraining's binary_logloss: 0.10154\tvalid_1's binary_logloss: 0.42101\n",
            "[160]\ttraining's binary_logloss: 0.0979865\tvalid_1's binary_logloss: 0.405542\n",
            "[170]\ttraining's binary_logloss: 0.094759\tvalid_1's binary_logloss: 0.391129\n",
            "[180]\ttraining's binary_logloss: 0.0915221\tvalid_1's binary_logloss: 0.375161\n",
            "[190]\ttraining's binary_logloss: 0.0886099\tvalid_1's binary_logloss: 0.361301\n",
            "[200]\ttraining's binary_logloss: 0.0856825\tvalid_1's binary_logloss: 0.347241\n",
            "[210]\ttraining's binary_logloss: 0.0830421\tvalid_1's binary_logloss: 0.336307\n",
            "[220]\ttraining's binary_logloss: 0.0804862\tvalid_1's binary_logloss: 0.325012\n",
            "[230]\ttraining's binary_logloss: 0.0778885\tvalid_1's binary_logloss: 0.315373\n",
            "[240]\ttraining's binary_logloss: 0.0754004\tvalid_1's binary_logloss: 0.304806\n",
            "[250]\ttraining's binary_logloss: 0.0730754\tvalid_1's binary_logloss: 0.294592\n",
            "[260]\ttraining's binary_logloss: 0.0708217\tvalid_1's binary_logloss: 0.285773\n",
            "[270]\ttraining's binary_logloss: 0.0683359\tvalid_1's binary_logloss: 0.274617\n",
            "[280]\ttraining's binary_logloss: 0.0661514\tvalid_1's binary_logloss: 0.265141\n",
            "[290]\ttraining's binary_logloss: 0.064234\tvalid_1's binary_logloss: 0.255548\n",
            "[300]\ttraining's binary_logloss: 0.0620425\tvalid_1's binary_logloss: 0.246187\n",
            "[310]\ttraining's binary_logloss: 0.0600606\tvalid_1's binary_logloss: 0.238475\n",
            "[320]\ttraining's binary_logloss: 0.0580609\tvalid_1's binary_logloss: 0.229152\n",
            "[330]\ttraining's binary_logloss: 0.0563684\tvalid_1's binary_logloss: 0.222249\n",
            "[340]\ttraining's binary_logloss: 0.0547015\tvalid_1's binary_logloss: 0.215123\n",
            "[350]\ttraining's binary_logloss: 0.0529316\tvalid_1's binary_logloss: 0.207062\n",
            "[360]\ttraining's binary_logloss: 0.0513486\tvalid_1's binary_logloss: 0.20023\n",
            "[370]\ttraining's binary_logloss: 0.0495588\tvalid_1's binary_logloss: 0.192746\n",
            "[380]\ttraining's binary_logloss: 0.0480388\tvalid_1's binary_logloss: 0.185856\n",
            "[390]\ttraining's binary_logloss: 0.0464922\tvalid_1's binary_logloss: 0.179774\n",
            "[400]\ttraining's binary_logloss: 0.0451246\tvalid_1's binary_logloss: 0.174254\n",
            "[410]\ttraining's binary_logloss: 0.0438426\tvalid_1's binary_logloss: 0.169038\n",
            "[420]\ttraining's binary_logloss: 0.0425154\tvalid_1's binary_logloss: 0.16361\n",
            "[430]\ttraining's binary_logloss: 0.0413668\tvalid_1's binary_logloss: 0.159005\n",
            "[440]\ttraining's binary_logloss: 0.0400336\tvalid_1's binary_logloss: 0.152986\n",
            "[450]\ttraining's binary_logloss: 0.0388124\tvalid_1's binary_logloss: 0.14803\n",
            "[460]\ttraining's binary_logloss: 0.0377432\tvalid_1's binary_logloss: 0.144107\n",
            "[470]\ttraining's binary_logloss: 0.0362321\tvalid_1's binary_logloss: 0.138085\n",
            "[480]\ttraining's binary_logloss: 0.0349744\tvalid_1's binary_logloss: 0.132964\n",
            "[490]\ttraining's binary_logloss: 0.0337991\tvalid_1's binary_logloss: 0.128207\n",
            "[500]\ttraining's binary_logloss: 0.0327133\tvalid_1's binary_logloss: 0.123588\n",
            "[510]\ttraining's binary_logloss: 0.031707\tvalid_1's binary_logloss: 0.119619\n",
            "[520]\ttraining's binary_logloss: 0.0306674\tvalid_1's binary_logloss: 0.11537\n",
            "[530]\ttraining's binary_logloss: 0.0296429\tvalid_1's binary_logloss: 0.111252\n",
            "[540]\ttraining's binary_logloss: 0.0287886\tvalid_1's binary_logloss: 0.107743\n",
            "[550]\ttraining's binary_logloss: 0.027903\tvalid_1's binary_logloss: 0.104389\n",
            "[560]\ttraining's binary_logloss: 0.026928\tvalid_1's binary_logloss: 0.100565\n",
            "[570]\ttraining's binary_logloss: 0.0260837\tvalid_1's binary_logloss: 0.0973178\n",
            "[580]\ttraining's binary_logloss: 0.0252722\tvalid_1's binary_logloss: 0.0940033\n",
            "[590]\ttraining's binary_logloss: 0.024536\tvalid_1's binary_logloss: 0.0912483\n",
            "[600]\ttraining's binary_logloss: 0.0238585\tvalid_1's binary_logloss: 0.0887316\n",
            "[610]\ttraining's binary_logloss: 0.0231317\tvalid_1's binary_logloss: 0.0854822\n",
            "[620]\ttraining's binary_logloss: 0.0224118\tvalid_1's binary_logloss: 0.0827508\n",
            "[630]\ttraining's binary_logloss: 0.0216973\tvalid_1's binary_logloss: 0.0798655\n",
            "[640]\ttraining's binary_logloss: 0.0210738\tvalid_1's binary_logloss: 0.0775761\n",
            "[650]\ttraining's binary_logloss: 0.0204448\tvalid_1's binary_logloss: 0.0750391\n",
            "[660]\ttraining's binary_logloss: 0.0197195\tvalid_1's binary_logloss: 0.0723398\n",
            "[670]\ttraining's binary_logloss: 0.01914\tvalid_1's binary_logloss: 0.0700706\n",
            "[680]\ttraining's binary_logloss: 0.0185023\tvalid_1's binary_logloss: 0.0675518\n",
            "[690]\ttraining's binary_logloss: 0.0178495\tvalid_1's binary_logloss: 0.0648996\n",
            "[700]\ttraining's binary_logloss: 0.017309\tvalid_1's binary_logloss: 0.0626448\n",
            "[710]\ttraining's binary_logloss: 0.0168213\tvalid_1's binary_logloss: 0.0609377\n",
            "[720]\ttraining's binary_logloss: 0.0162667\tvalid_1's binary_logloss: 0.0586955\n",
            "[730]\ttraining's binary_logloss: 0.0157832\tvalid_1's binary_logloss: 0.0567811\n",
            "[740]\ttraining's binary_logloss: 0.0153055\tvalid_1's binary_logloss: 0.054899\n",
            "[750]\ttraining's binary_logloss: 0.0148711\tvalid_1's binary_logloss: 0.0532131\n",
            "[760]\ttraining's binary_logloss: 0.0144227\tvalid_1's binary_logloss: 0.0515853\n",
            "[770]\ttraining's binary_logloss: 0.0139759\tvalid_1's binary_logloss: 0.0499729\n",
            "[780]\ttraining's binary_logloss: 0.0135149\tvalid_1's binary_logloss: 0.0483836\n",
            "[790]\ttraining's binary_logloss: 0.0130938\tvalid_1's binary_logloss: 0.0467738\n",
            "[800]\ttraining's binary_logloss: 0.0127366\tvalid_1's binary_logloss: 0.0456459\n",
            "[810]\ttraining's binary_logloss: 0.012399\tvalid_1's binary_logloss: 0.0445186\n",
            "[820]\ttraining's binary_logloss: 0.0120051\tvalid_1's binary_logloss: 0.0431017\n",
            "[830]\ttraining's binary_logloss: 0.011654\tvalid_1's binary_logloss: 0.041914\n",
            "[840]\ttraining's binary_logloss: 0.0112963\tvalid_1's binary_logloss: 0.0406458\n",
            "[850]\ttraining's binary_logloss: 0.0109669\tvalid_1's binary_logloss: 0.0394444\n",
            "[860]\ttraining's binary_logloss: 0.0106421\tvalid_1's binary_logloss: 0.0382136\n",
            "[870]\ttraining's binary_logloss: 0.0103351\tvalid_1's binary_logloss: 0.0371509\n",
            "[880]\ttraining's binary_logloss: 0.0100663\tvalid_1's binary_logloss: 0.036202\n",
            "[890]\ttraining's binary_logloss: 0.00977011\tvalid_1's binary_logloss: 0.0351824\n",
            "[900]\ttraining's binary_logloss: 0.00951406\tvalid_1's binary_logloss: 0.0341986\n",
            "[910]\ttraining's binary_logloss: 0.00926624\tvalid_1's binary_logloss: 0.0333934\n",
            "[920]\ttraining's binary_logloss: 0.00901876\tvalid_1's binary_logloss: 0.0325867\n",
            "[930]\ttraining's binary_logloss: 0.00876235\tvalid_1's binary_logloss: 0.0316966\n",
            "[940]\ttraining's binary_logloss: 0.00852449\tvalid_1's binary_logloss: 0.0307822\n",
            "[950]\ttraining's binary_logloss: 0.00830919\tvalid_1's binary_logloss: 0.0299954\n",
            "[960]\ttraining's binary_logloss: 0.00811764\tvalid_1's binary_logloss: 0.0292648\n",
            "[970]\ttraining's binary_logloss: 0.00790343\tvalid_1's binary_logloss: 0.0285142\n",
            "[980]\ttraining's binary_logloss: 0.00767683\tvalid_1's binary_logloss: 0.0276196\n",
            "[990]\ttraining's binary_logloss: 0.00744812\tvalid_1's binary_logloss: 0.02675\n",
            "[1000]\ttraining's binary_logloss: 0.0072372\tvalid_1's binary_logloss: 0.0259607\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.0072372\tvalid_1's binary_logloss: 0.0259607\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:46:50,886] Trial 17 finished with value: 0.025960675608608964 and parameters: {'max_bin': 334, 'num_leaves': 79}. Best is trial 7 with value: 0.004795566388927853.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.212485\tvalid_1's binary_logloss: 0.97678\n",
            "[20]\ttraining's binary_logloss: 0.187145\tvalid_1's binary_logloss: 0.84655\n",
            "[30]\ttraining's binary_logloss: 0.17004\tvalid_1's binary_logloss: 0.760356\n",
            "[40]\ttraining's binary_logloss: 0.156373\tvalid_1's binary_logloss: 0.6871\n",
            "[50]\ttraining's binary_logloss: 0.144402\tvalid_1's binary_logloss: 0.622087\n",
            "[60]\ttraining's binary_logloss: 0.133611\tvalid_1's binary_logloss: 0.564354\n",
            "[70]\ttraining's binary_logloss: 0.12452\tvalid_1's binary_logloss: 0.522756\n",
            "[80]\ttraining's binary_logloss: 0.116104\tvalid_1's binary_logloss: 0.484073\n",
            "[90]\ttraining's binary_logloss: 0.109217\tvalid_1's binary_logloss: 0.449922\n",
            "[100]\ttraining's binary_logloss: 0.102927\tvalid_1's binary_logloss: 0.422789\n",
            "[110]\ttraining's binary_logloss: 0.0970861\tvalid_1's binary_logloss: 0.396037\n",
            "[120]\ttraining's binary_logloss: 0.0921097\tvalid_1's binary_logloss: 0.372242\n",
            "[130]\ttraining's binary_logloss: 0.0872375\tvalid_1's binary_logloss: 0.349149\n",
            "[140]\ttraining's binary_logloss: 0.0830436\tvalid_1's binary_logloss: 0.329463\n",
            "[150]\ttraining's binary_logloss: 0.0790337\tvalid_1's binary_logloss: 0.311831\n",
            "[160]\ttraining's binary_logloss: 0.0754262\tvalid_1's binary_logloss: 0.295478\n",
            "[170]\ttraining's binary_logloss: 0.0718586\tvalid_1's binary_logloss: 0.279646\n",
            "[180]\ttraining's binary_logloss: 0.0685042\tvalid_1's binary_logloss: 0.265451\n",
            "[190]\ttraining's binary_logloss: 0.0654504\tvalid_1's binary_logloss: 0.253504\n",
            "[200]\ttraining's binary_logloss: 0.0625287\tvalid_1's binary_logloss: 0.241104\n",
            "[210]\ttraining's binary_logloss: 0.059569\tvalid_1's binary_logloss: 0.22872\n",
            "[220]\ttraining's binary_logloss: 0.0567921\tvalid_1's binary_logloss: 0.217173\n",
            "[230]\ttraining's binary_logloss: 0.0543343\tvalid_1's binary_logloss: 0.20631\n",
            "[240]\ttraining's binary_logloss: 0.0519844\tvalid_1's binary_logloss: 0.196892\n",
            "[250]\ttraining's binary_logloss: 0.0495224\tvalid_1's binary_logloss: 0.186548\n",
            "[260]\ttraining's binary_logloss: 0.0470106\tvalid_1's binary_logloss: 0.176408\n",
            "[270]\ttraining's binary_logloss: 0.0449249\tvalid_1's binary_logloss: 0.16848\n",
            "[280]\ttraining's binary_logloss: 0.0427019\tvalid_1's binary_logloss: 0.159136\n",
            "[290]\ttraining's binary_logloss: 0.0408586\tvalid_1's binary_logloss: 0.151856\n",
            "[300]\ttraining's binary_logloss: 0.0391577\tvalid_1's binary_logloss: 0.145381\n",
            "[310]\ttraining's binary_logloss: 0.0374457\tvalid_1's binary_logloss: 0.138548\n",
            "[320]\ttraining's binary_logloss: 0.035727\tvalid_1's binary_logloss: 0.13157\n",
            "[330]\ttraining's binary_logloss: 0.0340791\tvalid_1's binary_logloss: 0.125594\n",
            "[340]\ttraining's binary_logloss: 0.0325587\tvalid_1's binary_logloss: 0.119781\n",
            "[350]\ttraining's binary_logloss: 0.0311053\tvalid_1's binary_logloss: 0.114064\n",
            "[360]\ttraining's binary_logloss: 0.0297175\tvalid_1's binary_logloss: 0.108424\n",
            "[370]\ttraining's binary_logloss: 0.0284011\tvalid_1's binary_logloss: 0.103568\n",
            "[380]\ttraining's binary_logloss: 0.0270711\tvalid_1's binary_logloss: 0.098547\n",
            "[390]\ttraining's binary_logloss: 0.0259841\tvalid_1's binary_logloss: 0.0942313\n",
            "[400]\ttraining's binary_logloss: 0.0247571\tvalid_1's binary_logloss: 0.0890901\n",
            "[410]\ttraining's binary_logloss: 0.0237295\tvalid_1's binary_logloss: 0.085373\n",
            "[420]\ttraining's binary_logloss: 0.0227203\tvalid_1's binary_logloss: 0.0816146\n",
            "[430]\ttraining's binary_logloss: 0.0217454\tvalid_1's binary_logloss: 0.0780452\n",
            "[440]\ttraining's binary_logloss: 0.0207811\tvalid_1's binary_logloss: 0.0743713\n",
            "[450]\ttraining's binary_logloss: 0.0199147\tvalid_1's binary_logloss: 0.0711189\n",
            "[460]\ttraining's binary_logloss: 0.0190076\tvalid_1's binary_logloss: 0.0679115\n",
            "[470]\ttraining's binary_logloss: 0.0180472\tvalid_1's binary_logloss: 0.0640643\n",
            "[480]\ttraining's binary_logloss: 0.0173045\tvalid_1's binary_logloss: 0.061305\n",
            "[490]\ttraining's binary_logloss: 0.0165476\tvalid_1's binary_logloss: 0.0585975\n",
            "[500]\ttraining's binary_logloss: 0.0157799\tvalid_1's binary_logloss: 0.0556584\n",
            "[510]\ttraining's binary_logloss: 0.0150509\tvalid_1's binary_logloss: 0.05309\n",
            "[520]\ttraining's binary_logloss: 0.0144103\tvalid_1's binary_logloss: 0.0506604\n",
            "[530]\ttraining's binary_logloss: 0.0137595\tvalid_1's binary_logloss: 0.0481674\n",
            "[540]\ttraining's binary_logloss: 0.0131192\tvalid_1's binary_logloss: 0.0459454\n",
            "[550]\ttraining's binary_logloss: 0.0125799\tvalid_1's binary_logloss: 0.0440343\n",
            "[560]\ttraining's binary_logloss: 0.0120213\tvalid_1's binary_logloss: 0.0421152\n",
            "[570]\ttraining's binary_logloss: 0.0115396\tvalid_1's binary_logloss: 0.0404383\n",
            "[580]\ttraining's binary_logloss: 0.0110615\tvalid_1's binary_logloss: 0.0387959\n",
            "[590]\ttraining's binary_logloss: 0.0105772\tvalid_1's binary_logloss: 0.0370592\n",
            "[600]\ttraining's binary_logloss: 0.0101899\tvalid_1's binary_logloss: 0.0357034\n",
            "[610]\ttraining's binary_logloss: 0.00973785\tvalid_1's binary_logloss: 0.0340786\n",
            "[620]\ttraining's binary_logloss: 0.00933084\tvalid_1's binary_logloss: 0.0326943\n",
            "[630]\ttraining's binary_logloss: 0.00889715\tvalid_1's binary_logloss: 0.0310879\n",
            "[640]\ttraining's binary_logloss: 0.00852522\tvalid_1's binary_logloss: 0.0297614\n",
            "[650]\ttraining's binary_logloss: 0.00814374\tvalid_1's binary_logloss: 0.0283894\n",
            "[660]\ttraining's binary_logloss: 0.00778467\tvalid_1's binary_logloss: 0.027135\n",
            "[670]\ttraining's binary_logloss: 0.00746753\tvalid_1's binary_logloss: 0.0260867\n",
            "[680]\ttraining's binary_logloss: 0.00714363\tvalid_1's binary_logloss: 0.0249592\n",
            "[690]\ttraining's binary_logloss: 0.00683907\tvalid_1's binary_logloss: 0.0238499\n",
            "[700]\ttraining's binary_logloss: 0.00655886\tvalid_1's binary_logloss: 0.0228701\n",
            "[710]\ttraining's binary_logloss: 0.00626446\tvalid_1's binary_logloss: 0.0217843\n",
            "[720]\ttraining's binary_logloss: 0.00601417\tvalid_1's binary_logloss: 0.020941\n",
            "[730]\ttraining's binary_logloss: 0.00573895\tvalid_1's binary_logloss: 0.0199606\n",
            "[740]\ttraining's binary_logloss: 0.00551316\tvalid_1's binary_logloss: 0.0192665\n",
            "[750]\ttraining's binary_logloss: 0.00529122\tvalid_1's binary_logloss: 0.0184845\n",
            "[760]\ttraining's binary_logloss: 0.00505639\tvalid_1's binary_logloss: 0.0177183\n",
            "[770]\ttraining's binary_logloss: 0.0048441\tvalid_1's binary_logloss: 0.0169794\n",
            "[780]\ttraining's binary_logloss: 0.00463878\tvalid_1's binary_logloss: 0.0162185\n",
            "[790]\ttraining's binary_logloss: 0.00444773\tvalid_1's binary_logloss: 0.0155292\n",
            "[800]\ttraining's binary_logloss: 0.00429414\tvalid_1's binary_logloss: 0.015\n",
            "[810]\ttraining's binary_logloss: 0.00409742\tvalid_1's binary_logloss: 0.0142734\n",
            "[820]\ttraining's binary_logloss: 0.00391506\tvalid_1's binary_logloss: 0.0136863\n",
            "[830]\ttraining's binary_logloss: 0.00374847\tvalid_1's binary_logloss: 0.0130926\n",
            "[840]\ttraining's binary_logloss: 0.00358323\tvalid_1's binary_logloss: 0.0125239\n",
            "[850]\ttraining's binary_logloss: 0.00341741\tvalid_1's binary_logloss: 0.0119498\n",
            "[860]\ttraining's binary_logloss: 0.00325938\tvalid_1's binary_logloss: 0.011354\n",
            "[870]\ttraining's binary_logloss: 0.0031265\tvalid_1's binary_logloss: 0.0108621\n",
            "[880]\ttraining's binary_logloss: 0.0029996\tvalid_1's binary_logloss: 0.0104013\n",
            "[890]\ttraining's binary_logloss: 0.00287294\tvalid_1's binary_logloss: 0.00998056\n",
            "[900]\ttraining's binary_logloss: 0.0027458\tvalid_1's binary_logloss: 0.00953262\n",
            "[910]\ttraining's binary_logloss: 0.00262103\tvalid_1's binary_logloss: 0.00910111\n",
            "[920]\ttraining's binary_logloss: 0.00251497\tvalid_1's binary_logloss: 0.00870983\n",
            "[930]\ttraining's binary_logloss: 0.00242317\tvalid_1's binary_logloss: 0.00839722\n",
            "[940]\ttraining's binary_logloss: 0.00232733\tvalid_1's binary_logloss: 0.00805732\n",
            "[950]\ttraining's binary_logloss: 0.00222257\tvalid_1's binary_logloss: 0.00770436\n",
            "[960]\ttraining's binary_logloss: 0.00214333\tvalid_1's binary_logloss: 0.00742982\n",
            "[970]\ttraining's binary_logloss: 0.00204904\tvalid_1's binary_logloss: 0.00710928\n",
            "[980]\ttraining's binary_logloss: 0.00194845\tvalid_1's binary_logloss: 0.0067656\n",
            "[990]\ttraining's binary_logloss: 0.0018409\tvalid_1's binary_logloss: 0.00638154\n",
            "[1000]\ttraining's binary_logloss: 0.00176303\tvalid_1's binary_logloss: 0.00611377\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.00176303\tvalid_1's binary_logloss: 0.00611377\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:47:01,870] Trial 18 finished with value: 0.006113772759996651 and parameters: {'max_bin': 447, 'num_leaves': 114}. Best is trial 7 with value: 0.004795566388927853.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.211592\tvalid_1's binary_logloss: 0.971084\n",
            "[20]\ttraining's binary_logloss: 0.18609\tvalid_1's binary_logloss: 0.843993\n",
            "[30]\ttraining's binary_logloss: 0.168427\tvalid_1's binary_logloss: 0.755473\n",
            "[40]\ttraining's binary_logloss: 0.15484\tvalid_1's binary_logloss: 0.68537\n",
            "[50]\ttraining's binary_logloss: 0.142762\tvalid_1's binary_logloss: 0.623061\n",
            "[60]\ttraining's binary_logloss: 0.132473\tvalid_1's binary_logloss: 0.567269\n",
            "[70]\ttraining's binary_logloss: 0.122794\tvalid_1's binary_logloss: 0.518983\n",
            "[80]\ttraining's binary_logloss: 0.114194\tvalid_1's binary_logloss: 0.47845\n",
            "[90]\ttraining's binary_logloss: 0.106834\tvalid_1's binary_logloss: 0.44354\n",
            "[100]\ttraining's binary_logloss: 0.100633\tvalid_1's binary_logloss: 0.415071\n",
            "[110]\ttraining's binary_logloss: 0.0946408\tvalid_1's binary_logloss: 0.388572\n",
            "[120]\ttraining's binary_logloss: 0.0890834\tvalid_1's binary_logloss: 0.361943\n",
            "[130]\ttraining's binary_logloss: 0.0841224\tvalid_1's binary_logloss: 0.339079\n",
            "[140]\ttraining's binary_logloss: 0.0796339\tvalid_1's binary_logloss: 0.318006\n",
            "[150]\ttraining's binary_logloss: 0.0754128\tvalid_1's binary_logloss: 0.299565\n",
            "[160]\ttraining's binary_logloss: 0.0716164\tvalid_1's binary_logloss: 0.282316\n",
            "[170]\ttraining's binary_logloss: 0.0680849\tvalid_1's binary_logloss: 0.267031\n",
            "[180]\ttraining's binary_logloss: 0.0645736\tvalid_1's binary_logloss: 0.252052\n",
            "[190]\ttraining's binary_logloss: 0.0613585\tvalid_1's binary_logloss: 0.239146\n",
            "[200]\ttraining's binary_logloss: 0.0583351\tvalid_1's binary_logloss: 0.226701\n",
            "[210]\ttraining's binary_logloss: 0.0555277\tvalid_1's binary_logloss: 0.214907\n",
            "[220]\ttraining's binary_logloss: 0.0529446\tvalid_1's binary_logloss: 0.204474\n",
            "[230]\ttraining's binary_logloss: 0.0506457\tvalid_1's binary_logloss: 0.194564\n",
            "[240]\ttraining's binary_logloss: 0.0483838\tvalid_1's binary_logloss: 0.185569\n",
            "[250]\ttraining's binary_logloss: 0.0462647\tvalid_1's binary_logloss: 0.177254\n",
            "[260]\ttraining's binary_logloss: 0.0441665\tvalid_1's binary_logloss: 0.168406\n",
            "[270]\ttraining's binary_logloss: 0.0418263\tvalid_1's binary_logloss: 0.158062\n",
            "[280]\ttraining's binary_logloss: 0.0398733\tvalid_1's binary_logloss: 0.150267\n",
            "[290]\ttraining's binary_logloss: 0.0379769\tvalid_1's binary_logloss: 0.142671\n",
            "[300]\ttraining's binary_logloss: 0.0362137\tvalid_1's binary_logloss: 0.135364\n",
            "[310]\ttraining's binary_logloss: 0.0344701\tvalid_1's binary_logloss: 0.12864\n",
            "[320]\ttraining's binary_logloss: 0.0328\tvalid_1's binary_logloss: 0.121567\n",
            "[330]\ttraining's binary_logloss: 0.0313755\tvalid_1's binary_logloss: 0.115514\n",
            "[340]\ttraining's binary_logloss: 0.0300077\tvalid_1's binary_logloss: 0.110055\n",
            "[350]\ttraining's binary_logloss: 0.0287593\tvalid_1's binary_logloss: 0.105334\n",
            "[360]\ttraining's binary_logloss: 0.0275633\tvalid_1's binary_logloss: 0.100283\n",
            "[370]\ttraining's binary_logloss: 0.0262125\tvalid_1's binary_logloss: 0.0949338\n",
            "[380]\ttraining's binary_logloss: 0.025058\tvalid_1's binary_logloss: 0.0904073\n",
            "[390]\ttraining's binary_logloss: 0.0239293\tvalid_1's binary_logloss: 0.0860589\n",
            "[400]\ttraining's binary_logloss: 0.0229005\tvalid_1's binary_logloss: 0.082285\n",
            "[410]\ttraining's binary_logloss: 0.0217013\tvalid_1's binary_logloss: 0.0777809\n",
            "[420]\ttraining's binary_logloss: 0.0207469\tvalid_1's binary_logloss: 0.0741486\n",
            "[430]\ttraining's binary_logloss: 0.0197823\tvalid_1's binary_logloss: 0.0704474\n",
            "[440]\ttraining's binary_logloss: 0.0189099\tvalid_1's binary_logloss: 0.0671444\n",
            "[450]\ttraining's binary_logloss: 0.0180015\tvalid_1's binary_logloss: 0.0637287\n",
            "[460]\ttraining's binary_logloss: 0.0171523\tvalid_1's binary_logloss: 0.0607061\n",
            "[470]\ttraining's binary_logloss: 0.0162345\tvalid_1's binary_logloss: 0.0572735\n",
            "[480]\ttraining's binary_logloss: 0.0154646\tvalid_1's binary_logloss: 0.0545227\n",
            "[490]\ttraining's binary_logloss: 0.0147124\tvalid_1's binary_logloss: 0.0517597\n",
            "[500]\ttraining's binary_logloss: 0.0139937\tvalid_1's binary_logloss: 0.0492292\n",
            "[510]\ttraining's binary_logloss: 0.0133088\tvalid_1's binary_logloss: 0.046813\n",
            "[520]\ttraining's binary_logloss: 0.0126986\tvalid_1's binary_logloss: 0.0446465\n",
            "[530]\ttraining's binary_logloss: 0.012131\tvalid_1's binary_logloss: 0.0425089\n",
            "[540]\ttraining's binary_logloss: 0.0114611\tvalid_1's binary_logloss: 0.0400162\n",
            "[550]\ttraining's binary_logloss: 0.010971\tvalid_1's binary_logloss: 0.0382471\n",
            "[560]\ttraining's binary_logloss: 0.0104676\tvalid_1's binary_logloss: 0.0365652\n",
            "[570]\ttraining's binary_logloss: 0.00997729\tvalid_1's binary_logloss: 0.0348013\n",
            "[580]\ttraining's binary_logloss: 0.00951767\tvalid_1's binary_logloss: 0.0330844\n",
            "[590]\ttraining's binary_logloss: 0.00907169\tvalid_1's binary_logloss: 0.0315275\n",
            "[600]\ttraining's binary_logloss: 0.00868911\tvalid_1's binary_logloss: 0.0302166\n",
            "[610]\ttraining's binary_logloss: 0.00832366\tvalid_1's binary_logloss: 0.0290234\n",
            "[620]\ttraining's binary_logloss: 0.00795783\tvalid_1's binary_logloss: 0.0278035\n",
            "[630]\ttraining's binary_logloss: 0.00754964\tvalid_1's binary_logloss: 0.0263994\n",
            "[640]\ttraining's binary_logloss: 0.00715336\tvalid_1's binary_logloss: 0.0249391\n",
            "[650]\ttraining's binary_logloss: 0.00679241\tvalid_1's binary_logloss: 0.0236444\n",
            "[660]\ttraining's binary_logloss: 0.00650515\tvalid_1's binary_logloss: 0.022642\n",
            "[670]\ttraining's binary_logloss: 0.00621318\tvalid_1's binary_logloss: 0.0216692\n",
            "[680]\ttraining's binary_logloss: 0.00594736\tvalid_1's binary_logloss: 0.0206679\n",
            "[690]\ttraining's binary_logloss: 0.00569207\tvalid_1's binary_logloss: 0.019765\n",
            "[700]\ttraining's binary_logloss: 0.00544344\tvalid_1's binary_logloss: 0.0189776\n",
            "[710]\ttraining's binary_logloss: 0.00523177\tvalid_1's binary_logloss: 0.0182658\n",
            "[720]\ttraining's binary_logloss: 0.00501735\tvalid_1's binary_logloss: 0.0175284\n",
            "[730]\ttraining's binary_logloss: 0.00478501\tvalid_1's binary_logloss: 0.0167105\n",
            "[740]\ttraining's binary_logloss: 0.00455194\tvalid_1's binary_logloss: 0.0158602\n",
            "[750]\ttraining's binary_logloss: 0.00432964\tvalid_1's binary_logloss: 0.0151318\n",
            "[760]\ttraining's binary_logloss: 0.0041235\tvalid_1's binary_logloss: 0.0144073\n",
            "[770]\ttraining's binary_logloss: 0.00396022\tvalid_1's binary_logloss: 0.0138169\n",
            "[780]\ttraining's binary_logloss: 0.00378126\tvalid_1's binary_logloss: 0.013216\n",
            "[790]\ttraining's binary_logloss: 0.00359261\tvalid_1's binary_logloss: 0.0125732\n",
            "[800]\ttraining's binary_logloss: 0.00342591\tvalid_1's binary_logloss: 0.0120339\n",
            "[810]\ttraining's binary_logloss: 0.00327828\tvalid_1's binary_logloss: 0.011501\n",
            "[820]\ttraining's binary_logloss: 0.00309094\tvalid_1's binary_logloss: 0.0108227\n",
            "[830]\ttraining's binary_logloss: 0.00294711\tvalid_1's binary_logloss: 0.0103343\n",
            "[840]\ttraining's binary_logloss: 0.00281175\tvalid_1's binary_logloss: 0.00984717\n",
            "[850]\ttraining's binary_logloss: 0.00268519\tvalid_1's binary_logloss: 0.00941771\n",
            "[860]\ttraining's binary_logloss: 0.00257512\tvalid_1's binary_logloss: 0.00904542\n",
            "[870]\ttraining's binary_logloss: 0.00243522\tvalid_1's binary_logloss: 0.00857611\n",
            "[880]\ttraining's binary_logloss: 0.0023283\tvalid_1's binary_logloss: 0.0082313\n",
            "[890]\ttraining's binary_logloss: 0.00221964\tvalid_1's binary_logloss: 0.00783446\n",
            "[900]\ttraining's binary_logloss: 0.00211771\tvalid_1's binary_logloss: 0.00750879\n",
            "[910]\ttraining's binary_logloss: 0.00201054\tvalid_1's binary_logloss: 0.00711749\n",
            "[920]\ttraining's binary_logloss: 0.0019057\tvalid_1's binary_logloss: 0.00676771\n",
            "[930]\ttraining's binary_logloss: 0.00181597\tvalid_1's binary_logloss: 0.00644734\n",
            "[940]\ttraining's binary_logloss: 0.001729\tvalid_1's binary_logloss: 0.00612497\n",
            "[950]\ttraining's binary_logloss: 0.00164908\tvalid_1's binary_logloss: 0.00584525\n",
            "[960]\ttraining's binary_logloss: 0.00156946\tvalid_1's binary_logloss: 0.00556095\n",
            "[970]\ttraining's binary_logloss: 0.00150426\tvalid_1's binary_logloss: 0.00530255\n",
            "[980]\ttraining's binary_logloss: 0.00143491\tvalid_1's binary_logloss: 0.00505877\n",
            "[990]\ttraining's binary_logloss: 0.00136966\tvalid_1's binary_logloss: 0.00483322\n",
            "[1000]\ttraining's binary_logloss: 0.00131004\tvalid_1's binary_logloss: 0.00462846\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.00131004\tvalid_1's binary_logloss: 0.00462846\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:47:12,892] Trial 19 finished with value: 0.0046284648643910705 and parameters: {'max_bin': 354, 'num_leaves': 120}. Best is trial 19 with value: 0.0046284648643910705.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.22099\tvalid_1's binary_logloss: 1.02689\n",
            "[20]\ttraining's binary_logloss: 0.200962\tvalid_1's binary_logloss: 0.9275\n",
            "[30]\ttraining's binary_logloss: 0.188039\tvalid_1's binary_logloss: 0.865572\n",
            "[40]\ttraining's binary_logloss: 0.177887\tvalid_1's binary_logloss: 0.812474\n",
            "[50]\ttraining's binary_logloss: 0.169402\tvalid_1's binary_logloss: 0.766652\n",
            "[60]\ttraining's binary_logloss: 0.162089\tvalid_1's binary_logloss: 0.728816\n",
            "[70]\ttraining's binary_logloss: 0.154828\tvalid_1's binary_logloss: 0.687965\n",
            "[80]\ttraining's binary_logloss: 0.14856\tvalid_1's binary_logloss: 0.656243\n",
            "[90]\ttraining's binary_logloss: 0.142885\tvalid_1's binary_logloss: 0.624405\n",
            "[100]\ttraining's binary_logloss: 0.137942\tvalid_1's binary_logloss: 0.60157\n",
            "[110]\ttraining's binary_logloss: 0.133569\tvalid_1's binary_logloss: 0.578638\n",
            "[120]\ttraining's binary_logloss: 0.129506\tvalid_1's binary_logloss: 0.556456\n",
            "[130]\ttraining's binary_logloss: 0.125776\tvalid_1's binary_logloss: 0.535873\n",
            "[140]\ttraining's binary_logloss: 0.121915\tvalid_1's binary_logloss: 0.515656\n",
            "[150]\ttraining's binary_logloss: 0.118533\tvalid_1's binary_logloss: 0.497592\n",
            "[160]\ttraining's binary_logloss: 0.115198\tvalid_1's binary_logloss: 0.480441\n",
            "[170]\ttraining's binary_logloss: 0.11203\tvalid_1's binary_logloss: 0.4631\n",
            "[180]\ttraining's binary_logloss: 0.108941\tvalid_1's binary_logloss: 0.447354\n",
            "[190]\ttraining's binary_logloss: 0.10593\tvalid_1's binary_logloss: 0.432674\n",
            "[200]\ttraining's binary_logloss: 0.103157\tvalid_1's binary_logloss: 0.419434\n",
            "[210]\ttraining's binary_logloss: 0.100513\tvalid_1's binary_logloss: 0.408017\n",
            "[220]\ttraining's binary_logloss: 0.097883\tvalid_1's binary_logloss: 0.395881\n",
            "[230]\ttraining's binary_logloss: 0.0950768\tvalid_1's binary_logloss: 0.384127\n",
            "[240]\ttraining's binary_logloss: 0.092614\tvalid_1's binary_logloss: 0.371655\n",
            "[250]\ttraining's binary_logloss: 0.0904051\tvalid_1's binary_logloss: 0.361243\n",
            "[260]\ttraining's binary_logloss: 0.0879288\tvalid_1's binary_logloss: 0.350104\n",
            "[270]\ttraining's binary_logloss: 0.0858393\tvalid_1's binary_logloss: 0.340719\n",
            "[280]\ttraining's binary_logloss: 0.0836855\tvalid_1's binary_logloss: 0.331866\n",
            "[290]\ttraining's binary_logloss: 0.0811975\tvalid_1's binary_logloss: 0.322364\n",
            "[300]\ttraining's binary_logloss: 0.0793132\tvalid_1's binary_logloss: 0.314759\n",
            "[310]\ttraining's binary_logloss: 0.0771146\tvalid_1's binary_logloss: 0.304492\n",
            "[320]\ttraining's binary_logloss: 0.0753482\tvalid_1's binary_logloss: 0.297011\n",
            "[330]\ttraining's binary_logloss: 0.0736884\tvalid_1's binary_logloss: 0.289687\n",
            "[340]\ttraining's binary_logloss: 0.0717086\tvalid_1's binary_logloss: 0.281464\n",
            "[350]\ttraining's binary_logloss: 0.0698103\tvalid_1's binary_logloss: 0.27305\n",
            "[360]\ttraining's binary_logloss: 0.0679434\tvalid_1's binary_logloss: 0.265484\n",
            "[370]\ttraining's binary_logloss: 0.0662041\tvalid_1's binary_logloss: 0.258621\n",
            "[380]\ttraining's binary_logloss: 0.0647451\tvalid_1's binary_logloss: 0.252254\n",
            "[390]\ttraining's binary_logloss: 0.0632146\tvalid_1's binary_logloss: 0.246045\n",
            "[400]\ttraining's binary_logloss: 0.0616262\tvalid_1's binary_logloss: 0.239342\n",
            "[410]\ttraining's binary_logloss: 0.0600489\tvalid_1's binary_logloss: 0.233351\n",
            "[420]\ttraining's binary_logloss: 0.0586764\tvalid_1's binary_logloss: 0.228324\n",
            "[430]\ttraining's binary_logloss: 0.0569852\tvalid_1's binary_logloss: 0.220624\n",
            "[440]\ttraining's binary_logloss: 0.0557162\tvalid_1's binary_logloss: 0.214848\n",
            "[450]\ttraining's binary_logloss: 0.05432\tvalid_1's binary_logloss: 0.208897\n",
            "[460]\ttraining's binary_logloss: 0.052957\tvalid_1's binary_logloss: 0.203328\n",
            "[470]\ttraining's binary_logloss: 0.0516055\tvalid_1's binary_logloss: 0.198139\n",
            "[480]\ttraining's binary_logloss: 0.0503346\tvalid_1's binary_logloss: 0.193504\n",
            "[490]\ttraining's binary_logloss: 0.049266\tvalid_1's binary_logloss: 0.189424\n",
            "[500]\ttraining's binary_logloss: 0.0480321\tvalid_1's binary_logloss: 0.18463\n",
            "[510]\ttraining's binary_logloss: 0.0470244\tvalid_1's binary_logloss: 0.180563\n",
            "[520]\ttraining's binary_logloss: 0.0458285\tvalid_1's binary_logloss: 0.17592\n",
            "[530]\ttraining's binary_logloss: 0.0447966\tvalid_1's binary_logloss: 0.172076\n",
            "[540]\ttraining's binary_logloss: 0.0439509\tvalid_1's binary_logloss: 0.16876\n",
            "[550]\ttraining's binary_logloss: 0.0430081\tvalid_1's binary_logloss: 0.16554\n",
            "[560]\ttraining's binary_logloss: 0.042063\tvalid_1's binary_logloss: 0.161881\n",
            "[570]\ttraining's binary_logloss: 0.0410488\tvalid_1's binary_logloss: 0.157667\n",
            "[580]\ttraining's binary_logloss: 0.0400654\tvalid_1's binary_logloss: 0.153698\n",
            "[590]\ttraining's binary_logloss: 0.0392068\tvalid_1's binary_logloss: 0.150178\n",
            "[600]\ttraining's binary_logloss: 0.0384625\tvalid_1's binary_logloss: 0.147166\n",
            "[610]\ttraining's binary_logloss: 0.0375138\tvalid_1's binary_logloss: 0.143438\n",
            "[620]\ttraining's binary_logloss: 0.0365967\tvalid_1's binary_logloss: 0.139436\n",
            "[630]\ttraining's binary_logloss: 0.0355977\tvalid_1's binary_logloss: 0.135477\n",
            "[640]\ttraining's binary_logloss: 0.034814\tvalid_1's binary_logloss: 0.132488\n",
            "[650]\ttraining's binary_logloss: 0.0339819\tvalid_1's binary_logloss: 0.12909\n",
            "[660]\ttraining's binary_logloss: 0.0332276\tvalid_1's binary_logloss: 0.126301\n",
            "[670]\ttraining's binary_logloss: 0.0325604\tvalid_1's binary_logloss: 0.123562\n",
            "[680]\ttraining's binary_logloss: 0.0316817\tvalid_1's binary_logloss: 0.120417\n",
            "[690]\ttraining's binary_logloss: 0.0307985\tvalid_1's binary_logloss: 0.117069\n",
            "[700]\ttraining's binary_logloss: 0.0301198\tvalid_1's binary_logloss: 0.114448\n",
            "[710]\ttraining's binary_logloss: 0.0293994\tvalid_1's binary_logloss: 0.111554\n",
            "[720]\ttraining's binary_logloss: 0.028728\tvalid_1's binary_logloss: 0.108942\n",
            "[730]\ttraining's binary_logloss: 0.0281293\tvalid_1's binary_logloss: 0.106853\n",
            "[740]\ttraining's binary_logloss: 0.0274908\tvalid_1's binary_logloss: 0.10431\n",
            "[750]\ttraining's binary_logloss: 0.0268892\tvalid_1's binary_logloss: 0.101904\n",
            "[760]\ttraining's binary_logloss: 0.0262255\tvalid_1's binary_logloss: 0.0990878\n",
            "[770]\ttraining's binary_logloss: 0.0255083\tvalid_1's binary_logloss: 0.0962374\n",
            "[780]\ttraining's binary_logloss: 0.0249836\tvalid_1's binary_logloss: 0.0941806\n",
            "[790]\ttraining's binary_logloss: 0.0244\tvalid_1's binary_logloss: 0.091949\n",
            "[800]\ttraining's binary_logloss: 0.0238199\tvalid_1's binary_logloss: 0.089757\n",
            "[810]\ttraining's binary_logloss: 0.0232328\tvalid_1's binary_logloss: 0.0876478\n",
            "[820]\ttraining's binary_logloss: 0.0227181\tvalid_1's binary_logloss: 0.0859114\n",
            "[830]\ttraining's binary_logloss: 0.0222189\tvalid_1's binary_logloss: 0.0840869\n",
            "[840]\ttraining's binary_logloss: 0.0216674\tvalid_1's binary_logloss: 0.0817482\n",
            "[850]\ttraining's binary_logloss: 0.0212032\tvalid_1's binary_logloss: 0.0798888\n",
            "[860]\ttraining's binary_logloss: 0.0206838\tvalid_1's binary_logloss: 0.0777348\n",
            "[870]\ttraining's binary_logloss: 0.0202132\tvalid_1's binary_logloss: 0.0759002\n",
            "[880]\ttraining's binary_logloss: 0.0197557\tvalid_1's binary_logloss: 0.0742692\n",
            "[890]\ttraining's binary_logloss: 0.0192939\tvalid_1's binary_logloss: 0.0725492\n",
            "[900]\ttraining's binary_logloss: 0.0189214\tvalid_1's binary_logloss: 0.0710804\n",
            "[910]\ttraining's binary_logloss: 0.0185109\tvalid_1's binary_logloss: 0.0695265\n",
            "[920]\ttraining's binary_logloss: 0.0180772\tvalid_1's binary_logloss: 0.0680804\n",
            "[930]\ttraining's binary_logloss: 0.0176202\tvalid_1's binary_logloss: 0.0663723\n",
            "[940]\ttraining's binary_logloss: 0.017224\tvalid_1's binary_logloss: 0.0648716\n",
            "[950]\ttraining's binary_logloss: 0.0168621\tvalid_1's binary_logloss: 0.0635952\n",
            "[960]\ttraining's binary_logloss: 0.0164525\tvalid_1's binary_logloss: 0.0619319\n",
            "[970]\ttraining's binary_logloss: 0.0160637\tvalid_1's binary_logloss: 0.060264\n",
            "[980]\ttraining's binary_logloss: 0.0157334\tvalid_1's binary_logloss: 0.0591394\n",
            "[990]\ttraining's binary_logloss: 0.0153869\tvalid_1's binary_logloss: 0.057803\n",
            "[1000]\ttraining's binary_logloss: 0.0150319\tvalid_1's binary_logloss: 0.0565975\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.0150319\tvalid_1's binary_logloss: 0.0565975\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:47:20,750] Trial 20 finished with value: 0.056597450784137346 and parameters: {'max_bin': 432, 'num_leaves': 61}. Best is trial 19 with value: 0.0046284648643910705.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.22284\tvalid_1's binary_logloss: 1.03466\n",
            "[20]\ttraining's binary_logloss: 0.203783\tvalid_1's binary_logloss: 0.941328\n",
            "[30]\ttraining's binary_logloss: 0.191689\tvalid_1's binary_logloss: 0.881795\n",
            "[40]\ttraining's binary_logloss: 0.182352\tvalid_1's binary_logloss: 0.835507\n",
            "[50]\ttraining's binary_logloss: 0.174607\tvalid_1's binary_logloss: 0.794989\n",
            "[60]\ttraining's binary_logloss: 0.167662\tvalid_1's binary_logloss: 0.75621\n",
            "[70]\ttraining's binary_logloss: 0.161313\tvalid_1's binary_logloss: 0.721137\n",
            "[80]\ttraining's binary_logloss: 0.155525\tvalid_1's binary_logloss: 0.691786\n",
            "[90]\ttraining's binary_logloss: 0.150656\tvalid_1's binary_logloss: 0.665023\n",
            "[100]\ttraining's binary_logloss: 0.145815\tvalid_1's binary_logloss: 0.640641\n",
            "[110]\ttraining's binary_logloss: 0.141808\tvalid_1's binary_logloss: 0.62225\n",
            "[120]\ttraining's binary_logloss: 0.13795\tvalid_1's binary_logloss: 0.60234\n",
            "[130]\ttraining's binary_logloss: 0.134339\tvalid_1's binary_logloss: 0.585159\n",
            "[140]\ttraining's binary_logloss: 0.130997\tvalid_1's binary_logloss: 0.568757\n",
            "[150]\ttraining's binary_logloss: 0.127449\tvalid_1's binary_logloss: 0.550241\n",
            "[160]\ttraining's binary_logloss: 0.124129\tvalid_1's binary_logloss: 0.533807\n",
            "[170]\ttraining's binary_logloss: 0.121039\tvalid_1's binary_logloss: 0.518661\n",
            "[180]\ttraining's binary_logloss: 0.117836\tvalid_1's binary_logloss: 0.502501\n",
            "[190]\ttraining's binary_logloss: 0.115174\tvalid_1's binary_logloss: 0.489462\n",
            "[200]\ttraining's binary_logloss: 0.112621\tvalid_1's binary_logloss: 0.475674\n",
            "[210]\ttraining's binary_logloss: 0.109934\tvalid_1's binary_logloss: 0.462166\n",
            "[220]\ttraining's binary_logloss: 0.107714\tvalid_1's binary_logloss: 0.451489\n",
            "[230]\ttraining's binary_logloss: 0.105101\tvalid_1's binary_logloss: 0.439257\n",
            "[240]\ttraining's binary_logloss: 0.102871\tvalid_1's binary_logloss: 0.428277\n",
            "[250]\ttraining's binary_logloss: 0.100438\tvalid_1's binary_logloss: 0.415379\n",
            "[260]\ttraining's binary_logloss: 0.0980545\tvalid_1's binary_logloss: 0.405284\n",
            "[270]\ttraining's binary_logloss: 0.0959813\tvalid_1's binary_logloss: 0.395054\n",
            "[280]\ttraining's binary_logloss: 0.0939516\tvalid_1's binary_logloss: 0.383929\n",
            "[290]\ttraining's binary_logloss: 0.0918302\tvalid_1's binary_logloss: 0.374161\n",
            "[300]\ttraining's binary_logloss: 0.0896433\tvalid_1's binary_logloss: 0.363465\n",
            "[310]\ttraining's binary_logloss: 0.0878401\tvalid_1's binary_logloss: 0.355233\n",
            "[320]\ttraining's binary_logloss: 0.0857951\tvalid_1's binary_logloss: 0.347046\n",
            "[330]\ttraining's binary_logloss: 0.0838892\tvalid_1's binary_logloss: 0.337913\n",
            "[340]\ttraining's binary_logloss: 0.0819702\tvalid_1's binary_logloss: 0.329663\n",
            "[350]\ttraining's binary_logloss: 0.0801611\tvalid_1's binary_logloss: 0.322644\n",
            "[360]\ttraining's binary_logloss: 0.0784362\tvalid_1's binary_logloss: 0.314581\n",
            "[370]\ttraining's binary_logloss: 0.0765879\tvalid_1's binary_logloss: 0.306688\n",
            "[380]\ttraining's binary_logloss: 0.075103\tvalid_1's binary_logloss: 0.300572\n",
            "[390]\ttraining's binary_logloss: 0.0734293\tvalid_1's binary_logloss: 0.293313\n",
            "[400]\ttraining's binary_logloss: 0.0717762\tvalid_1's binary_logloss: 0.285968\n",
            "[410]\ttraining's binary_logloss: 0.0704449\tvalid_1's binary_logloss: 0.280194\n",
            "[420]\ttraining's binary_logloss: 0.0692354\tvalid_1's binary_logloss: 0.274389\n",
            "[430]\ttraining's binary_logloss: 0.0675558\tvalid_1's binary_logloss: 0.266563\n",
            "[440]\ttraining's binary_logloss: 0.06622\tvalid_1's binary_logloss: 0.260453\n",
            "[450]\ttraining's binary_logloss: 0.0647398\tvalid_1's binary_logloss: 0.254586\n",
            "[460]\ttraining's binary_logloss: 0.0631606\tvalid_1's binary_logloss: 0.247187\n",
            "[470]\ttraining's binary_logloss: 0.0617855\tvalid_1's binary_logloss: 0.241269\n",
            "[480]\ttraining's binary_logloss: 0.0606569\tvalid_1's binary_logloss: 0.236748\n",
            "[490]\ttraining's binary_logloss: 0.0594913\tvalid_1's binary_logloss: 0.232241\n",
            "[500]\ttraining's binary_logloss: 0.0583783\tvalid_1's binary_logloss: 0.227718\n",
            "[510]\ttraining's binary_logloss: 0.0572212\tvalid_1's binary_logloss: 0.222738\n",
            "[520]\ttraining's binary_logloss: 0.0559636\tvalid_1's binary_logloss: 0.217957\n",
            "[530]\ttraining's binary_logloss: 0.0547846\tvalid_1's binary_logloss: 0.21334\n",
            "[540]\ttraining's binary_logloss: 0.0536179\tvalid_1's binary_logloss: 0.208275\n",
            "[550]\ttraining's binary_logloss: 0.0525865\tvalid_1's binary_logloss: 0.204214\n",
            "[560]\ttraining's binary_logloss: 0.0515092\tvalid_1's binary_logloss: 0.200227\n",
            "[570]\ttraining's binary_logloss: 0.0503435\tvalid_1's binary_logloss: 0.195199\n",
            "[580]\ttraining's binary_logloss: 0.0492128\tvalid_1's binary_logloss: 0.190173\n",
            "[590]\ttraining's binary_logloss: 0.0482324\tvalid_1's binary_logloss: 0.186033\n",
            "[600]\ttraining's binary_logloss: 0.0473405\tvalid_1's binary_logloss: 0.182541\n",
            "[610]\ttraining's binary_logloss: 0.0463273\tvalid_1's binary_logloss: 0.178526\n",
            "[620]\ttraining's binary_logloss: 0.0454397\tvalid_1's binary_logloss: 0.175139\n",
            "[630]\ttraining's binary_logloss: 0.0444689\tvalid_1's binary_logloss: 0.171309\n",
            "[640]\ttraining's binary_logloss: 0.0435639\tvalid_1's binary_logloss: 0.167489\n",
            "[650]\ttraining's binary_logloss: 0.0427859\tvalid_1's binary_logloss: 0.164726\n",
            "[660]\ttraining's binary_logloss: 0.0418794\tvalid_1's binary_logloss: 0.161649\n",
            "[670]\ttraining's binary_logloss: 0.0410605\tvalid_1's binary_logloss: 0.158048\n",
            "[680]\ttraining's binary_logloss: 0.0403001\tvalid_1's binary_logloss: 0.154873\n",
            "[690]\ttraining's binary_logloss: 0.0395117\tvalid_1's binary_logloss: 0.151575\n",
            "[700]\ttraining's binary_logloss: 0.0387931\tvalid_1's binary_logloss: 0.148607\n",
            "[710]\ttraining's binary_logloss: 0.0380105\tvalid_1's binary_logloss: 0.145021\n",
            "[720]\ttraining's binary_logloss: 0.0371407\tvalid_1's binary_logloss: 0.141392\n",
            "[730]\ttraining's binary_logloss: 0.036426\tvalid_1's binary_logloss: 0.138211\n",
            "[740]\ttraining's binary_logloss: 0.0357826\tvalid_1's binary_logloss: 0.135748\n",
            "[750]\ttraining's binary_logloss: 0.0351724\tvalid_1's binary_logloss: 0.1334\n",
            "[760]\ttraining's binary_logloss: 0.0345144\tvalid_1's binary_logloss: 0.130515\n",
            "[770]\ttraining's binary_logloss: 0.0338128\tvalid_1's binary_logloss: 0.12772\n",
            "[780]\ttraining's binary_logloss: 0.0330624\tvalid_1's binary_logloss: 0.124033\n",
            "[790]\ttraining's binary_logloss: 0.0324077\tvalid_1's binary_logloss: 0.121504\n",
            "[800]\ttraining's binary_logloss: 0.0316938\tvalid_1's binary_logloss: 0.118298\n",
            "[810]\ttraining's binary_logloss: 0.0310766\tvalid_1's binary_logloss: 0.115586\n",
            "[820]\ttraining's binary_logloss: 0.0304238\tvalid_1's binary_logloss: 0.112687\n",
            "[830]\ttraining's binary_logloss: 0.0298531\tvalid_1's binary_logloss: 0.110523\n",
            "[840]\ttraining's binary_logloss: 0.0292005\tvalid_1's binary_logloss: 0.10786\n",
            "[850]\ttraining's binary_logloss: 0.0286933\tvalid_1's binary_logloss: 0.105788\n",
            "[860]\ttraining's binary_logloss: 0.0281513\tvalid_1's binary_logloss: 0.103546\n",
            "[870]\ttraining's binary_logloss: 0.0276439\tvalid_1's binary_logloss: 0.101739\n",
            "[880]\ttraining's binary_logloss: 0.0271292\tvalid_1's binary_logloss: 0.0996461\n",
            "[890]\ttraining's binary_logloss: 0.0266037\tvalid_1's binary_logloss: 0.0975649\n",
            "[900]\ttraining's binary_logloss: 0.0261298\tvalid_1's binary_logloss: 0.0958117\n",
            "[910]\ttraining's binary_logloss: 0.0256352\tvalid_1's binary_logloss: 0.0941576\n",
            "[920]\ttraining's binary_logloss: 0.0251405\tvalid_1's binary_logloss: 0.0922406\n",
            "[930]\ttraining's binary_logloss: 0.0246522\tvalid_1's binary_logloss: 0.09053\n",
            "[940]\ttraining's binary_logloss: 0.0242571\tvalid_1's binary_logloss: 0.08895\n",
            "[950]\ttraining's binary_logloss: 0.0237435\tvalid_1's binary_logloss: 0.0872494\n",
            "[960]\ttraining's binary_logloss: 0.0232111\tvalid_1's binary_logloss: 0.0853649\n",
            "[970]\ttraining's binary_logloss: 0.0227921\tvalid_1's binary_logloss: 0.0836624\n",
            "[980]\ttraining's binary_logloss: 0.0223358\tvalid_1's binary_logloss: 0.0819149\n",
            "[990]\ttraining's binary_logloss: 0.0218884\tvalid_1's binary_logloss: 0.0800094\n",
            "[1000]\ttraining's binary_logloss: 0.0214371\tvalid_1's binary_logloss: 0.0783911\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.0214371\tvalid_1's binary_logloss: 0.0783911\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:47:27,907] Trial 21 finished with value: 0.07839107202187524 and parameters: {'max_bin': 402, 'num_leaves': 51}. Best is trial 19 with value: 0.0046284648643910705.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.219074\tvalid_1's binary_logloss: 1.01602\n",
            "[20]\ttraining's binary_logloss: 0.197674\tvalid_1's binary_logloss: 0.910743\n",
            "[30]\ttraining's binary_logloss: 0.18405\tvalid_1's binary_logloss: 0.846797\n",
            "[40]\ttraining's binary_logloss: 0.17321\tvalid_1's binary_logloss: 0.788267\n",
            "[50]\ttraining's binary_logloss: 0.163989\tvalid_1's binary_logloss: 0.735945\n",
            "[60]\ttraining's binary_logloss: 0.155729\tvalid_1's binary_logloss: 0.693589\n",
            "[70]\ttraining's binary_logloss: 0.148152\tvalid_1's binary_logloss: 0.652861\n",
            "[80]\ttraining's binary_logloss: 0.141331\tvalid_1's binary_logloss: 0.6171\n",
            "[90]\ttraining's binary_logloss: 0.135235\tvalid_1's binary_logloss: 0.588076\n",
            "[100]\ttraining's binary_logloss: 0.130067\tvalid_1's binary_logloss: 0.562578\n",
            "[110]\ttraining's binary_logloss: 0.125091\tvalid_1's binary_logloss: 0.538483\n",
            "[120]\ttraining's binary_logloss: 0.12086\tvalid_1's binary_logloss: 0.518095\n",
            "[130]\ttraining's binary_logloss: 0.116519\tvalid_1's binary_logloss: 0.496611\n",
            "[140]\ttraining's binary_logloss: 0.112717\tvalid_1's binary_logloss: 0.476025\n",
            "[150]\ttraining's binary_logloss: 0.10902\tvalid_1's binary_logloss: 0.457956\n",
            "[160]\ttraining's binary_logloss: 0.10543\tvalid_1's binary_logloss: 0.440162\n",
            "[170]\ttraining's binary_logloss: 0.102233\tvalid_1's binary_logloss: 0.423827\n",
            "[180]\ttraining's binary_logloss: 0.0988807\tvalid_1's binary_logloss: 0.40656\n",
            "[190]\ttraining's binary_logloss: 0.0961263\tvalid_1's binary_logloss: 0.392458\n",
            "[200]\ttraining's binary_logloss: 0.0933825\tvalid_1's binary_logloss: 0.379755\n",
            "[210]\ttraining's binary_logloss: 0.0907731\tvalid_1's binary_logloss: 0.366817\n",
            "[220]\ttraining's binary_logloss: 0.0882647\tvalid_1's binary_logloss: 0.354933\n",
            "[230]\ttraining's binary_logloss: 0.0856834\tvalid_1's binary_logloss: 0.343488\n",
            "[240]\ttraining's binary_logloss: 0.0833407\tvalid_1's binary_logloss: 0.333078\n",
            "[250]\ttraining's binary_logloss: 0.0805437\tvalid_1's binary_logloss: 0.320009\n",
            "[260]\ttraining's binary_logloss: 0.0781997\tvalid_1's binary_logloss: 0.309584\n",
            "[270]\ttraining's binary_logloss: 0.0759897\tvalid_1's binary_logloss: 0.300518\n",
            "[280]\ttraining's binary_logloss: 0.0740401\tvalid_1's binary_logloss: 0.292436\n",
            "[290]\ttraining's binary_logloss: 0.071843\tvalid_1's binary_logloss: 0.282456\n",
            "[300]\ttraining's binary_logloss: 0.0697781\tvalid_1's binary_logloss: 0.273553\n",
            "[310]\ttraining's binary_logloss: 0.067798\tvalid_1's binary_logloss: 0.26392\n",
            "[320]\ttraining's binary_logloss: 0.0659441\tvalid_1's binary_logloss: 0.256152\n",
            "[330]\ttraining's binary_logloss: 0.0638654\tvalid_1's binary_logloss: 0.247803\n",
            "[340]\ttraining's binary_logloss: 0.0620893\tvalid_1's binary_logloss: 0.240487\n",
            "[350]\ttraining's binary_logloss: 0.0605298\tvalid_1's binary_logloss: 0.233986\n",
            "[360]\ttraining's binary_logloss: 0.0590104\tvalid_1's binary_logloss: 0.227956\n",
            "[370]\ttraining's binary_logloss: 0.0573\tvalid_1's binary_logloss: 0.220624\n",
            "[380]\ttraining's binary_logloss: 0.0555769\tvalid_1's binary_logloss: 0.213091\n",
            "[390]\ttraining's binary_logloss: 0.0538832\tvalid_1's binary_logloss: 0.206512\n",
            "[400]\ttraining's binary_logloss: 0.0521278\tvalid_1's binary_logloss: 0.199361\n",
            "[410]\ttraining's binary_logloss: 0.0506611\tvalid_1's binary_logloss: 0.194773\n",
            "[420]\ttraining's binary_logloss: 0.0494179\tvalid_1's binary_logloss: 0.190056\n",
            "[430]\ttraining's binary_logloss: 0.0478946\tvalid_1's binary_logloss: 0.183631\n",
            "[440]\ttraining's binary_logloss: 0.0465223\tvalid_1's binary_logloss: 0.178147\n",
            "[450]\ttraining's binary_logloss: 0.0451587\tvalid_1's binary_logloss: 0.172774\n",
            "[460]\ttraining's binary_logloss: 0.0439244\tvalid_1's binary_logloss: 0.167133\n",
            "[470]\ttraining's binary_logloss: 0.0425833\tvalid_1's binary_logloss: 0.161259\n",
            "[480]\ttraining's binary_logloss: 0.0415648\tvalid_1's binary_logloss: 0.157744\n",
            "[490]\ttraining's binary_logloss: 0.0403989\tvalid_1's binary_logloss: 0.152672\n",
            "[500]\ttraining's binary_logloss: 0.0394044\tvalid_1's binary_logloss: 0.148566\n",
            "[510]\ttraining's binary_logloss: 0.0383288\tvalid_1's binary_logloss: 0.144039\n",
            "[520]\ttraining's binary_logloss: 0.0373971\tvalid_1's binary_logloss: 0.140213\n",
            "[530]\ttraining's binary_logloss: 0.0362279\tvalid_1's binary_logloss: 0.135667\n",
            "[540]\ttraining's binary_logloss: 0.0353042\tvalid_1's binary_logloss: 0.132035\n",
            "[550]\ttraining's binary_logloss: 0.0344233\tvalid_1's binary_logloss: 0.128908\n",
            "[560]\ttraining's binary_logloss: 0.0333972\tvalid_1's binary_logloss: 0.124967\n",
            "[570]\ttraining's binary_logloss: 0.0324144\tvalid_1's binary_logloss: 0.120874\n",
            "[580]\ttraining's binary_logloss: 0.0314988\tvalid_1's binary_logloss: 0.117265\n",
            "[590]\ttraining's binary_logloss: 0.0307434\tvalid_1's binary_logloss: 0.114228\n",
            "[600]\ttraining's binary_logloss: 0.0298348\tvalid_1's binary_logloss: 0.110861\n",
            "[610]\ttraining's binary_logloss: 0.0290564\tvalid_1's binary_logloss: 0.107578\n",
            "[620]\ttraining's binary_logloss: 0.0283451\tvalid_1's binary_logloss: 0.104803\n",
            "[630]\ttraining's binary_logloss: 0.027598\tvalid_1's binary_logloss: 0.102067\n",
            "[640]\ttraining's binary_logloss: 0.0269173\tvalid_1's binary_logloss: 0.0994543\n",
            "[650]\ttraining's binary_logloss: 0.0262504\tvalid_1's binary_logloss: 0.097\n",
            "[660]\ttraining's binary_logloss: 0.0255438\tvalid_1's binary_logloss: 0.0941911\n",
            "[670]\ttraining's binary_logloss: 0.0249459\tvalid_1's binary_logloss: 0.0921621\n",
            "[680]\ttraining's binary_logloss: 0.024338\tvalid_1's binary_logloss: 0.089964\n",
            "[690]\ttraining's binary_logloss: 0.0236379\tvalid_1's binary_logloss: 0.0872979\n",
            "[700]\ttraining's binary_logloss: 0.0229284\tvalid_1's binary_logloss: 0.0846538\n",
            "[710]\ttraining's binary_logloss: 0.022296\tvalid_1's binary_logloss: 0.0824951\n",
            "[720]\ttraining's binary_logloss: 0.0217001\tvalid_1's binary_logloss: 0.080322\n",
            "[730]\ttraining's binary_logloss: 0.0210514\tvalid_1's binary_logloss: 0.0779357\n",
            "[740]\ttraining's binary_logloss: 0.0204002\tvalid_1's binary_logloss: 0.0755392\n",
            "[750]\ttraining's binary_logloss: 0.0198207\tvalid_1's binary_logloss: 0.0733367\n",
            "[760]\ttraining's binary_logloss: 0.0192947\tvalid_1's binary_logloss: 0.0713057\n",
            "[770]\ttraining's binary_logloss: 0.0187103\tvalid_1's binary_logloss: 0.0691411\n",
            "[780]\ttraining's binary_logloss: 0.0181957\tvalid_1's binary_logloss: 0.0675825\n",
            "[790]\ttraining's binary_logloss: 0.0176933\tvalid_1's binary_logloss: 0.0657407\n",
            "[800]\ttraining's binary_logloss: 0.0172617\tvalid_1's binary_logloss: 0.064225\n",
            "[810]\ttraining's binary_logloss: 0.0168107\tvalid_1's binary_logloss: 0.0624433\n",
            "[820]\ttraining's binary_logloss: 0.0162735\tvalid_1's binary_logloss: 0.0600341\n",
            "[830]\ttraining's binary_logloss: 0.0158079\tvalid_1's binary_logloss: 0.0583121\n",
            "[840]\ttraining's binary_logloss: 0.0153605\tvalid_1's binary_logloss: 0.056582\n",
            "[850]\ttraining's binary_logloss: 0.0149698\tvalid_1's binary_logloss: 0.0551869\n",
            "[860]\ttraining's binary_logloss: 0.0145647\tvalid_1's binary_logloss: 0.0536439\n",
            "[870]\ttraining's binary_logloss: 0.0142316\tvalid_1's binary_logloss: 0.0524058\n",
            "[880]\ttraining's binary_logloss: 0.0138648\tvalid_1's binary_logloss: 0.0511562\n",
            "[890]\ttraining's binary_logloss: 0.0134907\tvalid_1's binary_logloss: 0.0498636\n",
            "[900]\ttraining's binary_logloss: 0.0131475\tvalid_1's binary_logloss: 0.0486896\n",
            "[910]\ttraining's binary_logloss: 0.0127713\tvalid_1's binary_logloss: 0.0473956\n",
            "[920]\ttraining's binary_logloss: 0.0124379\tvalid_1's binary_logloss: 0.046114\n",
            "[930]\ttraining's binary_logloss: 0.012129\tvalid_1's binary_logloss: 0.0449906\n",
            "[940]\ttraining's binary_logloss: 0.0117923\tvalid_1's binary_logloss: 0.0435211\n",
            "[950]\ttraining's binary_logloss: 0.0115255\tvalid_1's binary_logloss: 0.0426181\n",
            "[960]\ttraining's binary_logloss: 0.0112602\tvalid_1's binary_logloss: 0.0417153\n",
            "[970]\ttraining's binary_logloss: 0.0110065\tvalid_1's binary_logloss: 0.0407497\n",
            "[980]\ttraining's binary_logloss: 0.0107317\tvalid_1's binary_logloss: 0.0398007\n",
            "[990]\ttraining's binary_logloss: 0.0104361\tvalid_1's binary_logloss: 0.0386012\n",
            "[1000]\ttraining's binary_logloss: 0.0101182\tvalid_1's binary_logloss: 0.0374677\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.0101182\tvalid_1's binary_logloss: 0.0374677\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:47:36,185] Trial 22 finished with value: 0.03746767373780975 and parameters: {'max_bin': 397, 'num_leaves': 71}. Best is trial 19 with value: 0.0046284648643910705.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.215028\tvalid_1's binary_logloss: 0.989741\n",
            "[20]\ttraining's binary_logloss: 0.191257\tvalid_1's binary_logloss: 0.871381\n",
            "[30]\ttraining's binary_logloss: 0.175281\tvalid_1's binary_logloss: 0.79135\n",
            "[40]\ttraining's binary_logloss: 0.163104\tvalid_1's binary_logloss: 0.726032\n",
            "[50]\ttraining's binary_logloss: 0.152179\tvalid_1's binary_logloss: 0.667483\n",
            "[60]\ttraining's binary_logloss: 0.142612\tvalid_1's binary_logloss: 0.618584\n",
            "[70]\ttraining's binary_logloss: 0.133982\tvalid_1's binary_logloss: 0.575651\n",
            "[80]\ttraining's binary_logloss: 0.126155\tvalid_1's binary_logloss: 0.535187\n",
            "[90]\ttraining's binary_logloss: 0.119462\tvalid_1's binary_logloss: 0.503026\n",
            "[100]\ttraining's binary_logloss: 0.113587\tvalid_1's binary_logloss: 0.472599\n",
            "[110]\ttraining's binary_logloss: 0.108301\tvalid_1's binary_logloss: 0.446974\n",
            "[120]\ttraining's binary_logloss: 0.103578\tvalid_1's binary_logloss: 0.423054\n",
            "[130]\ttraining's binary_logloss: 0.0984671\tvalid_1's binary_logloss: 0.400048\n",
            "[140]\ttraining's binary_logloss: 0.0941028\tvalid_1's binary_logloss: 0.379463\n",
            "[150]\ttraining's binary_logloss: 0.0904102\tvalid_1's binary_logloss: 0.363411\n",
            "[160]\ttraining's binary_logloss: 0.086715\tvalid_1's binary_logloss: 0.346962\n",
            "[170]\ttraining's binary_logloss: 0.0830058\tvalid_1's binary_logloss: 0.329957\n",
            "[180]\ttraining's binary_logloss: 0.0794112\tvalid_1's binary_logloss: 0.314003\n",
            "[190]\ttraining's binary_logloss: 0.0758597\tvalid_1's binary_logloss: 0.299449\n",
            "[200]\ttraining's binary_logloss: 0.0728686\tvalid_1's binary_logloss: 0.286373\n",
            "[210]\ttraining's binary_logloss: 0.0701453\tvalid_1's binary_logloss: 0.27428\n",
            "[220]\ttraining's binary_logloss: 0.0673818\tvalid_1's binary_logloss: 0.263067\n",
            "[230]\ttraining's binary_logloss: 0.0646579\tvalid_1's binary_logloss: 0.250894\n",
            "[240]\ttraining's binary_logloss: 0.0623469\tvalid_1's binary_logloss: 0.241302\n",
            "[250]\ttraining's binary_logloss: 0.0596978\tvalid_1's binary_logloss: 0.230935\n",
            "[260]\ttraining's binary_logloss: 0.0574039\tvalid_1's binary_logloss: 0.220907\n",
            "[270]\ttraining's binary_logloss: 0.0551536\tvalid_1's binary_logloss: 0.210971\n",
            "[280]\ttraining's binary_logloss: 0.0530704\tvalid_1's binary_logloss: 0.202598\n",
            "[290]\ttraining's binary_logloss: 0.0512768\tvalid_1's binary_logloss: 0.195381\n",
            "[300]\ttraining's binary_logloss: 0.0494139\tvalid_1's binary_logloss: 0.187877\n",
            "[310]\ttraining's binary_logloss: 0.0477326\tvalid_1's binary_logloss: 0.181273\n",
            "[320]\ttraining's binary_logloss: 0.0459392\tvalid_1's binary_logloss: 0.17414\n",
            "[330]\ttraining's binary_logloss: 0.04445\tvalid_1's binary_logloss: 0.168494\n",
            "[340]\ttraining's binary_logloss: 0.0427049\tvalid_1's binary_logloss: 0.161452\n",
            "[350]\ttraining's binary_logloss: 0.0412698\tvalid_1's binary_logloss: 0.156359\n",
            "[360]\ttraining's binary_logloss: 0.0397497\tvalid_1's binary_logloss: 0.149976\n",
            "[370]\ttraining's binary_logloss: 0.0382391\tvalid_1's binary_logloss: 0.14409\n",
            "[380]\ttraining's binary_logloss: 0.0371156\tvalid_1's binary_logloss: 0.139941\n",
            "[390]\ttraining's binary_logloss: 0.0358158\tvalid_1's binary_logloss: 0.134826\n",
            "[400]\ttraining's binary_logloss: 0.0343562\tvalid_1's binary_logloss: 0.129147\n",
            "[410]\ttraining's binary_logloss: 0.0330586\tvalid_1's binary_logloss: 0.124632\n",
            "[420]\ttraining's binary_logloss: 0.0319078\tvalid_1's binary_logloss: 0.120311\n",
            "[430]\ttraining's binary_logloss: 0.0308228\tvalid_1's binary_logloss: 0.116233\n",
            "[440]\ttraining's binary_logloss: 0.0296677\tvalid_1's binary_logloss: 0.111996\n",
            "[450]\ttraining's binary_logloss: 0.0286767\tvalid_1's binary_logloss: 0.108072\n",
            "[460]\ttraining's binary_logloss: 0.0275732\tvalid_1's binary_logloss: 0.103767\n",
            "[470]\ttraining's binary_logloss: 0.0264807\tvalid_1's binary_logloss: 0.099839\n",
            "[480]\ttraining's binary_logloss: 0.0255252\tvalid_1's binary_logloss: 0.0961048\n",
            "[490]\ttraining's binary_logloss: 0.0245334\tvalid_1's binary_logloss: 0.0924589\n",
            "[500]\ttraining's binary_logloss: 0.0236115\tvalid_1's binary_logloss: 0.0888242\n",
            "[510]\ttraining's binary_logloss: 0.0227758\tvalid_1's binary_logloss: 0.0851895\n",
            "[520]\ttraining's binary_logloss: 0.0220199\tvalid_1's binary_logloss: 0.0823006\n",
            "[530]\ttraining's binary_logloss: 0.0213066\tvalid_1's binary_logloss: 0.0793421\n",
            "[540]\ttraining's binary_logloss: 0.0205342\tvalid_1's binary_logloss: 0.0763626\n",
            "[550]\ttraining's binary_logloss: 0.0197387\tvalid_1's binary_logloss: 0.0732422\n",
            "[560]\ttraining's binary_logloss: 0.0188899\tvalid_1's binary_logloss: 0.0698006\n",
            "[570]\ttraining's binary_logloss: 0.0181864\tvalid_1's binary_logloss: 0.0672649\n",
            "[580]\ttraining's binary_logloss: 0.0174784\tvalid_1's binary_logloss: 0.0644817\n",
            "[590]\ttraining's binary_logloss: 0.0168844\tvalid_1's binary_logloss: 0.0622686\n",
            "[600]\ttraining's binary_logloss: 0.0162303\tvalid_1's binary_logloss: 0.0598269\n",
            "[610]\ttraining's binary_logloss: 0.0157386\tvalid_1's binary_logloss: 0.0580523\n",
            "[620]\ttraining's binary_logloss: 0.0151885\tvalid_1's binary_logloss: 0.056001\n",
            "[630]\ttraining's binary_logloss: 0.0146138\tvalid_1's binary_logloss: 0.0535873\n",
            "[640]\ttraining's binary_logloss: 0.0140644\tvalid_1's binary_logloss: 0.0515349\n",
            "[650]\ttraining's binary_logloss: 0.0135569\tvalid_1's binary_logloss: 0.0497358\n",
            "[660]\ttraining's binary_logloss: 0.0130535\tvalid_1's binary_logloss: 0.0479108\n",
            "[670]\ttraining's binary_logloss: 0.0125802\tvalid_1's binary_logloss: 0.0460573\n",
            "[680]\ttraining's binary_logloss: 0.0120909\tvalid_1's binary_logloss: 0.0440262\n",
            "[690]\ttraining's binary_logloss: 0.0116544\tvalid_1's binary_logloss: 0.04226\n",
            "[700]\ttraining's binary_logloss: 0.0111772\tvalid_1's binary_logloss: 0.0405255\n",
            "[710]\ttraining's binary_logloss: 0.0107913\tvalid_1's binary_logloss: 0.0391311\n",
            "[720]\ttraining's binary_logloss: 0.0104142\tvalid_1's binary_logloss: 0.0377845\n",
            "[730]\ttraining's binary_logloss: 0.00999707\tvalid_1's binary_logloss: 0.0361089\n",
            "[740]\ttraining's binary_logloss: 0.00964974\tvalid_1's binary_logloss: 0.0349189\n",
            "[750]\ttraining's binary_logloss: 0.00934994\tvalid_1's binary_logloss: 0.0339379\n",
            "[760]\ttraining's binary_logloss: 0.00903804\tvalid_1's binary_logloss: 0.0328668\n",
            "[770]\ttraining's binary_logloss: 0.00870927\tvalid_1's binary_logloss: 0.0317426\n",
            "[780]\ttraining's binary_logloss: 0.00837369\tvalid_1's binary_logloss: 0.0304404\n",
            "[790]\ttraining's binary_logloss: 0.00802551\tvalid_1's binary_logloss: 0.0292809\n",
            "[800]\ttraining's binary_logloss: 0.00769415\tvalid_1's binary_logloss: 0.0280137\n",
            "[810]\ttraining's binary_logloss: 0.00734182\tvalid_1's binary_logloss: 0.0266506\n",
            "[820]\ttraining's binary_logloss: 0.00703775\tvalid_1's binary_logloss: 0.0255333\n",
            "[830]\ttraining's binary_logloss: 0.0067701\tvalid_1's binary_logloss: 0.0244923\n",
            "[840]\ttraining's binary_logloss: 0.00653176\tvalid_1's binary_logloss: 0.0235519\n",
            "[850]\ttraining's binary_logloss: 0.00630345\tvalid_1's binary_logloss: 0.0226643\n",
            "[860]\ttraining's binary_logloss: 0.00609873\tvalid_1's binary_logloss: 0.0218928\n",
            "[870]\ttraining's binary_logloss: 0.00586399\tvalid_1's binary_logloss: 0.0210539\n",
            "[880]\ttraining's binary_logloss: 0.00565161\tvalid_1's binary_logloss: 0.0202756\n",
            "[890]\ttraining's binary_logloss: 0.00544153\tvalid_1's binary_logloss: 0.0195642\n",
            "[900]\ttraining's binary_logloss: 0.00522707\tvalid_1's binary_logloss: 0.01884\n",
            "[910]\ttraining's binary_logloss: 0.00506957\tvalid_1's binary_logloss: 0.018344\n",
            "[920]\ttraining's binary_logloss: 0.00489782\tvalid_1's binary_logloss: 0.0178241\n",
            "[930]\ttraining's binary_logloss: 0.00473957\tvalid_1's binary_logloss: 0.01729\n",
            "[940]\ttraining's binary_logloss: 0.00456391\tvalid_1's binary_logloss: 0.0166564\n",
            "[950]\ttraining's binary_logloss: 0.00441271\tvalid_1's binary_logloss: 0.0161062\n",
            "[960]\ttraining's binary_logloss: 0.00423894\tvalid_1's binary_logloss: 0.0155\n",
            "[970]\ttraining's binary_logloss: 0.00405926\tvalid_1's binary_logloss: 0.0147489\n",
            "[980]\ttraining's binary_logloss: 0.00390717\tvalid_1's binary_logloss: 0.0142494\n",
            "[990]\ttraining's binary_logloss: 0.00377066\tvalid_1's binary_logloss: 0.0137623\n",
            "[1000]\ttraining's binary_logloss: 0.0036132\tvalid_1's binary_logloss: 0.0131532\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.0036132\tvalid_1's binary_logloss: 0.0131532\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:47:45,499] Trial 23 finished with value: 0.01315318573292496 and parameters: {'max_bin': 287, 'num_leaves': 97}. Best is trial 19 with value: 0.0046284648643910705.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.216242\tvalid_1's binary_logloss: 0.998456\n",
            "[20]\ttraining's binary_logloss: 0.193309\tvalid_1's binary_logloss: 0.883024\n",
            "[30]\ttraining's binary_logloss: 0.177716\tvalid_1's binary_logloss: 0.805464\n",
            "[40]\ttraining's binary_logloss: 0.165755\tvalid_1's binary_logloss: 0.742512\n",
            "[50]\ttraining's binary_logloss: 0.155147\tvalid_1's binary_logloss: 0.686377\n",
            "[60]\ttraining's binary_logloss: 0.145768\tvalid_1's binary_logloss: 0.638201\n",
            "[70]\ttraining's binary_logloss: 0.137523\tvalid_1's binary_logloss: 0.596953\n",
            "[80]\ttraining's binary_logloss: 0.129961\tvalid_1's binary_logloss: 0.557414\n",
            "[90]\ttraining's binary_logloss: 0.123318\tvalid_1's binary_logloss: 0.523502\n",
            "[100]\ttraining's binary_logloss: 0.117783\tvalid_1's binary_logloss: 0.493615\n",
            "[110]\ttraining's binary_logloss: 0.112744\tvalid_1's binary_logloss: 0.472704\n",
            "[120]\ttraining's binary_logloss: 0.107586\tvalid_1's binary_logloss: 0.4488\n",
            "[130]\ttraining's binary_logloss: 0.102897\tvalid_1's binary_logloss: 0.426081\n",
            "[140]\ttraining's binary_logloss: 0.0987855\tvalid_1's binary_logloss: 0.405266\n",
            "[150]\ttraining's binary_logloss: 0.0949624\tvalid_1's binary_logloss: 0.387034\n",
            "[160]\ttraining's binary_logloss: 0.0909809\tvalid_1's binary_logloss: 0.368873\n",
            "[170]\ttraining's binary_logloss: 0.0871527\tvalid_1's binary_logloss: 0.352187\n",
            "[180]\ttraining's binary_logloss: 0.0835298\tvalid_1's binary_logloss: 0.337132\n",
            "[190]\ttraining's binary_logloss: 0.0805042\tvalid_1's binary_logloss: 0.322927\n",
            "[200]\ttraining's binary_logloss: 0.0775775\tvalid_1's binary_logloss: 0.310131\n",
            "[210]\ttraining's binary_logloss: 0.0748214\tvalid_1's binary_logloss: 0.299248\n",
            "[220]\ttraining's binary_logloss: 0.0722567\tvalid_1's binary_logloss: 0.288069\n",
            "[230]\ttraining's binary_logloss: 0.0699281\tvalid_1's binary_logloss: 0.278316\n",
            "[240]\ttraining's binary_logloss: 0.0676763\tvalid_1's binary_logloss: 0.268682\n",
            "[250]\ttraining's binary_logloss: 0.0651297\tvalid_1's binary_logloss: 0.257036\n",
            "[260]\ttraining's binary_logloss: 0.0627885\tvalid_1's binary_logloss: 0.247408\n",
            "[270]\ttraining's binary_logloss: 0.0603216\tvalid_1's binary_logloss: 0.236562\n",
            "[280]\ttraining's binary_logloss: 0.0584386\tvalid_1's binary_logloss: 0.228788\n",
            "[290]\ttraining's binary_logloss: 0.0562711\tvalid_1's binary_logloss: 0.219531\n",
            "[300]\ttraining's binary_logloss: 0.054447\tvalid_1's binary_logloss: 0.212825\n",
            "[310]\ttraining's binary_logloss: 0.0524307\tvalid_1's binary_logloss: 0.204369\n",
            "[320]\ttraining's binary_logloss: 0.0505784\tvalid_1's binary_logloss: 0.196732\n",
            "[330]\ttraining's binary_logloss: 0.0489631\tvalid_1's binary_logloss: 0.190776\n",
            "[340]\ttraining's binary_logloss: 0.0473804\tvalid_1's binary_logloss: 0.183797\n",
            "[350]\ttraining's binary_logloss: 0.0459203\tvalid_1's binary_logloss: 0.178657\n",
            "[360]\ttraining's binary_logloss: 0.0444785\tvalid_1's binary_logloss: 0.172837\n",
            "[370]\ttraining's binary_logloss: 0.0430197\tvalid_1's binary_logloss: 0.166219\n",
            "[380]\ttraining's binary_logloss: 0.0415927\tvalid_1's binary_logloss: 0.160607\n",
            "[390]\ttraining's binary_logloss: 0.0402198\tvalid_1's binary_logloss: 0.155211\n",
            "[400]\ttraining's binary_logloss: 0.0387541\tvalid_1's binary_logloss: 0.149079\n",
            "[410]\ttraining's binary_logloss: 0.0375174\tvalid_1's binary_logloss: 0.144103\n",
            "[420]\ttraining's binary_logloss: 0.0364828\tvalid_1's binary_logloss: 0.14014\n",
            "[430]\ttraining's binary_logloss: 0.0353637\tvalid_1's binary_logloss: 0.135137\n",
            "[440]\ttraining's binary_logloss: 0.0340226\tvalid_1's binary_logloss: 0.130151\n",
            "[450]\ttraining's binary_logloss: 0.0329636\tvalid_1's binary_logloss: 0.125633\n",
            "[460]\ttraining's binary_logloss: 0.0320821\tvalid_1's binary_logloss: 0.122297\n",
            "[470]\ttraining's binary_logloss: 0.0308573\tvalid_1's binary_logloss: 0.117545\n",
            "[480]\ttraining's binary_logloss: 0.0298327\tvalid_1's binary_logloss: 0.113691\n",
            "[490]\ttraining's binary_logloss: 0.0287716\tvalid_1's binary_logloss: 0.109192\n",
            "[500]\ttraining's binary_logloss: 0.0277653\tvalid_1's binary_logloss: 0.105391\n",
            "[510]\ttraining's binary_logloss: 0.0267583\tvalid_1's binary_logloss: 0.101113\n",
            "[520]\ttraining's binary_logloss: 0.0259578\tvalid_1's binary_logloss: 0.0978705\n",
            "[530]\ttraining's binary_logloss: 0.0251104\tvalid_1's binary_logloss: 0.0945097\n",
            "[540]\ttraining's binary_logloss: 0.0244322\tvalid_1's binary_logloss: 0.0921897\n",
            "[550]\ttraining's binary_logloss: 0.0237204\tvalid_1's binary_logloss: 0.0894176\n",
            "[560]\ttraining's binary_logloss: 0.0228749\tvalid_1's binary_logloss: 0.0859288\n",
            "[570]\ttraining's binary_logloss: 0.0220289\tvalid_1's binary_logloss: 0.0821562\n",
            "[580]\ttraining's binary_logloss: 0.0212229\tvalid_1's binary_logloss: 0.0788026\n",
            "[590]\ttraining's binary_logloss: 0.0205024\tvalid_1's binary_logloss: 0.0758721\n",
            "[600]\ttraining's binary_logloss: 0.0197173\tvalid_1's binary_logloss: 0.0726418\n",
            "[610]\ttraining's binary_logloss: 0.0190482\tvalid_1's binary_logloss: 0.0702061\n",
            "[620]\ttraining's binary_logloss: 0.0183971\tvalid_1's binary_logloss: 0.0676848\n",
            "[630]\ttraining's binary_logloss: 0.0178078\tvalid_1's binary_logloss: 0.0652539\n",
            "[640]\ttraining's binary_logloss: 0.017184\tvalid_1's binary_logloss: 0.0628172\n",
            "[650]\ttraining's binary_logloss: 0.0167274\tvalid_1's binary_logloss: 0.0611626\n",
            "[660]\ttraining's binary_logloss: 0.0162789\tvalid_1's binary_logloss: 0.0595731\n",
            "[670]\ttraining's binary_logloss: 0.0157718\tvalid_1's binary_logloss: 0.0573862\n",
            "[680]\ttraining's binary_logloss: 0.0152127\tvalid_1's binary_logloss: 0.0551827\n",
            "[690]\ttraining's binary_logloss: 0.014752\tvalid_1's binary_logloss: 0.0533481\n",
            "[700]\ttraining's binary_logloss: 0.0142413\tvalid_1's binary_logloss: 0.0513379\n",
            "[710]\ttraining's binary_logloss: 0.0136765\tvalid_1's binary_logloss: 0.0491836\n",
            "[720]\ttraining's binary_logloss: 0.0131931\tvalid_1's binary_logloss: 0.0474394\n",
            "[730]\ttraining's binary_logloss: 0.0126921\tvalid_1's binary_logloss: 0.0455569\n",
            "[740]\ttraining's binary_logloss: 0.0122537\tvalid_1's binary_logloss: 0.0440017\n",
            "[750]\ttraining's binary_logloss: 0.0118007\tvalid_1's binary_logloss: 0.0423182\n",
            "[760]\ttraining's binary_logloss: 0.0114161\tvalid_1's binary_logloss: 0.0409567\n",
            "[770]\ttraining's binary_logloss: 0.0109924\tvalid_1's binary_logloss: 0.0393708\n",
            "[780]\ttraining's binary_logloss: 0.010528\tvalid_1's binary_logloss: 0.0375487\n",
            "[790]\ttraining's binary_logloss: 0.0101173\tvalid_1's binary_logloss: 0.035927\n",
            "[800]\ttraining's binary_logloss: 0.00977579\tvalid_1's binary_logloss: 0.034536\n",
            "[810]\ttraining's binary_logloss: 0.00944236\tvalid_1's binary_logloss: 0.0333433\n",
            "[820]\ttraining's binary_logloss: 0.00911043\tvalid_1's binary_logloss: 0.0322226\n",
            "[830]\ttraining's binary_logloss: 0.00879069\tvalid_1's binary_logloss: 0.0310716\n",
            "[840]\ttraining's binary_logloss: 0.00851083\tvalid_1's binary_logloss: 0.030085\n",
            "[850]\ttraining's binary_logloss: 0.00822775\tvalid_1's binary_logloss: 0.0290914\n",
            "[860]\ttraining's binary_logloss: 0.00798608\tvalid_1's binary_logloss: 0.0282858\n",
            "[870]\ttraining's binary_logloss: 0.00773732\tvalid_1's binary_logloss: 0.0275252\n",
            "[880]\ttraining's binary_logloss: 0.00750342\tvalid_1's binary_logloss: 0.0267527\n",
            "[890]\ttraining's binary_logloss: 0.00722896\tvalid_1's binary_logloss: 0.0258653\n",
            "[900]\ttraining's binary_logloss: 0.00700053\tvalid_1's binary_logloss: 0.0250634\n",
            "[910]\ttraining's binary_logloss: 0.00671961\tvalid_1's binary_logloss: 0.0240195\n",
            "[920]\ttraining's binary_logloss: 0.00651266\tvalid_1's binary_logloss: 0.0233246\n",
            "[930]\ttraining's binary_logloss: 0.00630324\tvalid_1's binary_logloss: 0.0226219\n",
            "[940]\ttraining's binary_logloss: 0.00608589\tvalid_1's binary_logloss: 0.0218523\n",
            "[950]\ttraining's binary_logloss: 0.00590425\tvalid_1's binary_logloss: 0.0211666\n",
            "[960]\ttraining's binary_logloss: 0.00573262\tvalid_1's binary_logloss: 0.0205278\n",
            "[970]\ttraining's binary_logloss: 0.00556283\tvalid_1's binary_logloss: 0.0198916\n",
            "[980]\ttraining's binary_logloss: 0.00538592\tvalid_1's binary_logloss: 0.01919\n",
            "[990]\ttraining's binary_logloss: 0.00519161\tvalid_1's binary_logloss: 0.0184626\n",
            "[1000]\ttraining's binary_logloss: 0.00501689\tvalid_1's binary_logloss: 0.0177703\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.00501689\tvalid_1's binary_logloss: 0.0177703\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:47:54,329] Trial 24 finished with value: 0.017770250691637766 and parameters: {'max_bin': 264, 'num_leaves': 89}. Best is trial 19 with value: 0.0046284648643910705.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.220398\tvalid_1's binary_logloss: 1.0203\n",
            "[20]\ttraining's binary_logloss: 0.199807\tvalid_1's binary_logloss: 0.917486\n",
            "[30]\ttraining's binary_logloss: 0.186728\tvalid_1's binary_logloss: 0.856238\n",
            "[40]\ttraining's binary_logloss: 0.176429\tvalid_1's binary_logloss: 0.803986\n",
            "[50]\ttraining's binary_logloss: 0.167268\tvalid_1's binary_logloss: 0.751169\n",
            "[60]\ttraining's binary_logloss: 0.159025\tvalid_1's binary_logloss: 0.707705\n",
            "[70]\ttraining's binary_logloss: 0.151764\tvalid_1's binary_logloss: 0.672456\n",
            "[80]\ttraining's binary_logloss: 0.145449\tvalid_1's binary_logloss: 0.640491\n",
            "[90]\ttraining's binary_logloss: 0.140234\tvalid_1's binary_logloss: 0.614569\n",
            "[100]\ttraining's binary_logloss: 0.13531\tvalid_1's binary_logloss: 0.588232\n",
            "[110]\ttraining's binary_logloss: 0.130664\tvalid_1's binary_logloss: 0.565165\n",
            "[120]\ttraining's binary_logloss: 0.126376\tvalid_1's binary_logloss: 0.544471\n",
            "[130]\ttraining's binary_logloss: 0.122361\tvalid_1's binary_logloss: 0.523113\n",
            "[140]\ttraining's binary_logloss: 0.118614\tvalid_1's binary_logloss: 0.502872\n",
            "[150]\ttraining's binary_logloss: 0.114862\tvalid_1's binary_logloss: 0.485359\n",
            "[160]\ttraining's binary_logloss: 0.111299\tvalid_1's binary_logloss: 0.469539\n",
            "[170]\ttraining's binary_logloss: 0.108099\tvalid_1's binary_logloss: 0.453848\n",
            "[180]\ttraining's binary_logloss: 0.105004\tvalid_1's binary_logloss: 0.439228\n",
            "[190]\ttraining's binary_logloss: 0.102222\tvalid_1's binary_logloss: 0.426907\n",
            "[200]\ttraining's binary_logloss: 0.0992936\tvalid_1's binary_logloss: 0.412832\n",
            "[210]\ttraining's binary_logloss: 0.0965871\tvalid_1's binary_logloss: 0.398882\n",
            "[220]\ttraining's binary_logloss: 0.0941029\tvalid_1's binary_logloss: 0.387964\n",
            "[230]\ttraining's binary_logloss: 0.0911289\tvalid_1's binary_logloss: 0.374625\n",
            "[240]\ttraining's binary_logloss: 0.0886111\tvalid_1's binary_logloss: 0.36391\n",
            "[250]\ttraining's binary_logloss: 0.0860472\tvalid_1's binary_logloss: 0.351934\n",
            "[260]\ttraining's binary_logloss: 0.0840742\tvalid_1's binary_logloss: 0.343499\n",
            "[270]\ttraining's binary_logloss: 0.0818016\tvalid_1's binary_logloss: 0.331526\n",
            "[280]\ttraining's binary_logloss: 0.0795576\tvalid_1's binary_logloss: 0.321283\n",
            "[290]\ttraining's binary_logloss: 0.0774437\tvalid_1's binary_logloss: 0.310733\n",
            "[300]\ttraining's binary_logloss: 0.0757008\tvalid_1's binary_logloss: 0.302147\n",
            "[310]\ttraining's binary_logloss: 0.0737039\tvalid_1's binary_logloss: 0.293282\n",
            "[320]\ttraining's binary_logloss: 0.0718217\tvalid_1's binary_logloss: 0.285358\n",
            "[330]\ttraining's binary_logloss: 0.0699816\tvalid_1's binary_logloss: 0.276977\n",
            "[340]\ttraining's binary_logloss: 0.0682096\tvalid_1's binary_logloss: 0.269912\n",
            "[350]\ttraining's binary_logloss: 0.0666842\tvalid_1's binary_logloss: 0.263277\n",
            "[360]\ttraining's binary_logloss: 0.0651453\tvalid_1's binary_logloss: 0.256812\n",
            "[370]\ttraining's binary_logloss: 0.0635106\tvalid_1's binary_logloss: 0.249373\n",
            "[380]\ttraining's binary_logloss: 0.0619746\tvalid_1's binary_logloss: 0.24301\n",
            "[390]\ttraining's binary_logloss: 0.060435\tvalid_1's binary_logloss: 0.23695\n",
            "[400]\ttraining's binary_logloss: 0.0591777\tvalid_1's binary_logloss: 0.23244\n",
            "[410]\ttraining's binary_logloss: 0.0575945\tvalid_1's binary_logloss: 0.224827\n",
            "[420]\ttraining's binary_logloss: 0.0562315\tvalid_1's binary_logloss: 0.219428\n",
            "[430]\ttraining's binary_logloss: 0.0550182\tvalid_1's binary_logloss: 0.214513\n",
            "[440]\ttraining's binary_logloss: 0.0535601\tvalid_1's binary_logloss: 0.208198\n",
            "[450]\ttraining's binary_logloss: 0.0524957\tvalid_1's binary_logloss: 0.203728\n",
            "[460]\ttraining's binary_logloss: 0.051135\tvalid_1's binary_logloss: 0.198265\n",
            "[470]\ttraining's binary_logloss: 0.0499119\tvalid_1's binary_logloss: 0.192762\n",
            "[480]\ttraining's binary_logloss: 0.0483665\tvalid_1's binary_logloss: 0.185491\n",
            "[490]\ttraining's binary_logloss: 0.0471075\tvalid_1's binary_logloss: 0.180663\n",
            "[500]\ttraining's binary_logloss: 0.0458958\tvalid_1's binary_logloss: 0.176224\n",
            "[510]\ttraining's binary_logloss: 0.0448061\tvalid_1's binary_logloss: 0.171675\n",
            "[520]\ttraining's binary_logloss: 0.0438141\tvalid_1's binary_logloss: 0.167334\n",
            "[530]\ttraining's binary_logloss: 0.042651\tvalid_1's binary_logloss: 0.162341\n",
            "[540]\ttraining's binary_logloss: 0.041623\tvalid_1's binary_logloss: 0.15809\n",
            "[550]\ttraining's binary_logloss: 0.0406622\tvalid_1's binary_logloss: 0.154325\n",
            "[560]\ttraining's binary_logloss: 0.039737\tvalid_1's binary_logloss: 0.151108\n",
            "[570]\ttraining's binary_logloss: 0.0388101\tvalid_1's binary_logloss: 0.148102\n",
            "[580]\ttraining's binary_logloss: 0.0377902\tvalid_1's binary_logloss: 0.144321\n",
            "[590]\ttraining's binary_logloss: 0.0369835\tvalid_1's binary_logloss: 0.141343\n",
            "[600]\ttraining's binary_logloss: 0.036281\tvalid_1's binary_logloss: 0.138639\n",
            "[610]\ttraining's binary_logloss: 0.0353827\tvalid_1's binary_logloss: 0.135336\n",
            "[620]\ttraining's binary_logloss: 0.0344754\tvalid_1's binary_logloss: 0.131533\n",
            "[630]\ttraining's binary_logloss: 0.0334894\tvalid_1's binary_logloss: 0.127313\n",
            "[640]\ttraining's binary_logloss: 0.0326534\tvalid_1's binary_logloss: 0.123846\n",
            "[650]\ttraining's binary_logloss: 0.0317885\tvalid_1's binary_logloss: 0.120261\n",
            "[660]\ttraining's binary_logloss: 0.0309893\tvalid_1's binary_logloss: 0.116981\n",
            "[670]\ttraining's binary_logloss: 0.0302262\tvalid_1's binary_logloss: 0.114115\n",
            "[680]\ttraining's binary_logloss: 0.0294825\tvalid_1's binary_logloss: 0.11107\n",
            "[690]\ttraining's binary_logloss: 0.0287809\tvalid_1's binary_logloss: 0.108303\n",
            "[700]\ttraining's binary_logloss: 0.028132\tvalid_1's binary_logloss: 0.105983\n",
            "[710]\ttraining's binary_logloss: 0.0274037\tvalid_1's binary_logloss: 0.10308\n",
            "[720]\ttraining's binary_logloss: 0.0267218\tvalid_1's binary_logloss: 0.100252\n",
            "[730]\ttraining's binary_logloss: 0.025885\tvalid_1's binary_logloss: 0.0968601\n",
            "[740]\ttraining's binary_logloss: 0.0252889\tvalid_1's binary_logloss: 0.0946048\n",
            "[750]\ttraining's binary_logloss: 0.0246375\tvalid_1's binary_logloss: 0.092156\n",
            "[760]\ttraining's binary_logloss: 0.0241046\tvalid_1's binary_logloss: 0.0901452\n",
            "[770]\ttraining's binary_logloss: 0.023504\tvalid_1's binary_logloss: 0.0878131\n",
            "[780]\ttraining's binary_logloss: 0.0228983\tvalid_1's binary_logloss: 0.0854024\n",
            "[790]\ttraining's binary_logloss: 0.0222699\tvalid_1's binary_logloss: 0.0829942\n",
            "[800]\ttraining's binary_logloss: 0.0217997\tvalid_1's binary_logloss: 0.0812871\n",
            "[810]\ttraining's binary_logloss: 0.0213996\tvalid_1's binary_logloss: 0.0797738\n",
            "[820]\ttraining's binary_logloss: 0.0209322\tvalid_1's binary_logloss: 0.0780569\n",
            "[830]\ttraining's binary_logloss: 0.0203828\tvalid_1's binary_logloss: 0.0758777\n",
            "[840]\ttraining's binary_logloss: 0.0198873\tvalid_1's binary_logloss: 0.0738711\n",
            "[850]\ttraining's binary_logloss: 0.0194857\tvalid_1's binary_logloss: 0.0723099\n",
            "[860]\ttraining's binary_logloss: 0.0190439\tvalid_1's binary_logloss: 0.070637\n",
            "[870]\ttraining's binary_logloss: 0.0185863\tvalid_1's binary_logloss: 0.068989\n",
            "[880]\ttraining's binary_logloss: 0.0181795\tvalid_1's binary_logloss: 0.0674872\n",
            "[890]\ttraining's binary_logloss: 0.0177194\tvalid_1's binary_logloss: 0.0656923\n",
            "[900]\ttraining's binary_logloss: 0.0172572\tvalid_1's binary_logloss: 0.0642042\n",
            "[910]\ttraining's binary_logloss: 0.0168292\tvalid_1's binary_logloss: 0.0626507\n",
            "[920]\ttraining's binary_logloss: 0.016468\tvalid_1's binary_logloss: 0.0613111\n",
            "[930]\ttraining's binary_logloss: 0.016102\tvalid_1's binary_logloss: 0.0598837\n",
            "[940]\ttraining's binary_logloss: 0.0157072\tvalid_1's binary_logloss: 0.058387\n",
            "[950]\ttraining's binary_logloss: 0.015269\tvalid_1's binary_logloss: 0.0567404\n",
            "[960]\ttraining's binary_logloss: 0.0148529\tvalid_1's binary_logloss: 0.0551402\n",
            "[970]\ttraining's binary_logloss: 0.0144963\tvalid_1's binary_logloss: 0.0538774\n",
            "[980]\ttraining's binary_logloss: 0.0141737\tvalid_1's binary_logloss: 0.0526621\n",
            "[990]\ttraining's binary_logloss: 0.0138091\tvalid_1's binary_logloss: 0.0513968\n",
            "[1000]\ttraining's binary_logloss: 0.0135109\tvalid_1's binary_logloss: 0.0503883\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.0135109\tvalid_1's binary_logloss: 0.0503883\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:48:02,088] Trial 25 finished with value: 0.05038827845694872 and parameters: {'max_bin': 382, 'num_leaves': 64}. Best is trial 19 with value: 0.0046284648643910705.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.213665\tvalid_1's binary_logloss: 0.984247\n",
            "[20]\ttraining's binary_logloss: 0.188967\tvalid_1's binary_logloss: 0.85482\n",
            "[30]\ttraining's binary_logloss: 0.172241\tvalid_1's binary_logloss: 0.770559\n",
            "[40]\ttraining's binary_logloss: 0.159512\tvalid_1's binary_logloss: 0.704345\n",
            "[50]\ttraining's binary_logloss: 0.148362\tvalid_1's binary_logloss: 0.645244\n",
            "[60]\ttraining's binary_logloss: 0.137945\tvalid_1's binary_logloss: 0.589342\n",
            "[70]\ttraining's binary_logloss: 0.129248\tvalid_1's binary_logloss: 0.544755\n",
            "[80]\ttraining's binary_logloss: 0.121177\tvalid_1's binary_logloss: 0.506026\n",
            "[90]\ttraining's binary_logloss: 0.11426\tvalid_1's binary_logloss: 0.469846\n",
            "[100]\ttraining's binary_logloss: 0.108165\tvalid_1's binary_logloss: 0.440142\n",
            "[110]\ttraining's binary_logloss: 0.102825\tvalid_1's binary_logloss: 0.415752\n",
            "[120]\ttraining's binary_logloss: 0.0976425\tvalid_1's binary_logloss: 0.390678\n",
            "[130]\ttraining's binary_logloss: 0.0928874\tvalid_1's binary_logloss: 0.37007\n",
            "[140]\ttraining's binary_logloss: 0.0886038\tvalid_1's binary_logloss: 0.351166\n",
            "[150]\ttraining's binary_logloss: 0.0844629\tvalid_1's binary_logloss: 0.333\n",
            "[160]\ttraining's binary_logloss: 0.0805391\tvalid_1's binary_logloss: 0.315901\n",
            "[170]\ttraining's binary_logloss: 0.0767015\tvalid_1's binary_logloss: 0.299844\n",
            "[180]\ttraining's binary_logloss: 0.0731672\tvalid_1's binary_logloss: 0.284652\n",
            "[190]\ttraining's binary_logloss: 0.0698878\tvalid_1's binary_logloss: 0.270504\n",
            "[200]\ttraining's binary_logloss: 0.0671315\tvalid_1's binary_logloss: 0.258503\n",
            "[210]\ttraining's binary_logloss: 0.0641101\tvalid_1's binary_logloss: 0.246792\n",
            "[220]\ttraining's binary_logloss: 0.0612111\tvalid_1's binary_logloss: 0.236183\n",
            "[230]\ttraining's binary_logloss: 0.0587236\tvalid_1's binary_logloss: 0.226184\n",
            "[240]\ttraining's binary_logloss: 0.056287\tvalid_1's binary_logloss: 0.21592\n",
            "[250]\ttraining's binary_logloss: 0.0538464\tvalid_1's binary_logloss: 0.206336\n",
            "[260]\ttraining's binary_logloss: 0.0514239\tvalid_1's binary_logloss: 0.196222\n",
            "[270]\ttraining's binary_logloss: 0.0492706\tvalid_1's binary_logloss: 0.187543\n",
            "[280]\ttraining's binary_logloss: 0.0471863\tvalid_1's binary_logloss: 0.179381\n",
            "[290]\ttraining's binary_logloss: 0.0451134\tvalid_1's binary_logloss: 0.171285\n",
            "[300]\ttraining's binary_logloss: 0.0432762\tvalid_1's binary_logloss: 0.164708\n",
            "[310]\ttraining's binary_logloss: 0.041455\tvalid_1's binary_logloss: 0.157418\n",
            "[320]\ttraining's binary_logloss: 0.0397727\tvalid_1's binary_logloss: 0.151258\n",
            "[330]\ttraining's binary_logloss: 0.0381745\tvalid_1's binary_logloss: 0.144595\n",
            "[340]\ttraining's binary_logloss: 0.0366678\tvalid_1's binary_logloss: 0.1386\n",
            "[350]\ttraining's binary_logloss: 0.035201\tvalid_1's binary_logloss: 0.132807\n",
            "[360]\ttraining's binary_logloss: 0.0335546\tvalid_1's binary_logloss: 0.125642\n",
            "[370]\ttraining's binary_logloss: 0.0320855\tvalid_1's binary_logloss: 0.119469\n",
            "[380]\ttraining's binary_logloss: 0.030718\tvalid_1's binary_logloss: 0.114394\n",
            "[390]\ttraining's binary_logloss: 0.0294262\tvalid_1's binary_logloss: 0.109451\n",
            "[400]\ttraining's binary_logloss: 0.028226\tvalid_1's binary_logloss: 0.104745\n",
            "[410]\ttraining's binary_logloss: 0.026988\tvalid_1's binary_logloss: 0.0997266\n",
            "[420]\ttraining's binary_logloss: 0.0257606\tvalid_1's binary_logloss: 0.0947527\n",
            "[430]\ttraining's binary_logloss: 0.0246402\tvalid_1's binary_logloss: 0.090499\n",
            "[440]\ttraining's binary_logloss: 0.0235951\tvalid_1's binary_logloss: 0.0867257\n",
            "[450]\ttraining's binary_logloss: 0.0226937\tvalid_1's binary_logloss: 0.0832729\n",
            "[460]\ttraining's binary_logloss: 0.0218764\tvalid_1's binary_logloss: 0.0802918\n",
            "[470]\ttraining's binary_logloss: 0.0210039\tvalid_1's binary_logloss: 0.0771015\n",
            "[480]\ttraining's binary_logloss: 0.0202641\tvalid_1's binary_logloss: 0.0744397\n",
            "[490]\ttraining's binary_logloss: 0.0195366\tvalid_1's binary_logloss: 0.0716331\n",
            "[500]\ttraining's binary_logloss: 0.0187342\tvalid_1's binary_logloss: 0.0686723\n",
            "[510]\ttraining's binary_logloss: 0.0179919\tvalid_1's binary_logloss: 0.0657404\n",
            "[520]\ttraining's binary_logloss: 0.0172933\tvalid_1's binary_logloss: 0.063065\n",
            "[530]\ttraining's binary_logloss: 0.0166612\tvalid_1's binary_logloss: 0.0607948\n",
            "[540]\ttraining's binary_logloss: 0.0159517\tvalid_1's binary_logloss: 0.0580891\n",
            "[550]\ttraining's binary_logloss: 0.0152634\tvalid_1's binary_logloss: 0.055618\n",
            "[560]\ttraining's binary_logloss: 0.01458\tvalid_1's binary_logloss: 0.0531022\n",
            "[570]\ttraining's binary_logloss: 0.0140628\tvalid_1's binary_logloss: 0.051331\n",
            "[580]\ttraining's binary_logloss: 0.0135051\tvalid_1's binary_logloss: 0.0491922\n",
            "[590]\ttraining's binary_logloss: 0.0129644\tvalid_1's binary_logloss: 0.0470942\n",
            "[600]\ttraining's binary_logloss: 0.0124248\tvalid_1's binary_logloss: 0.0450266\n",
            "[610]\ttraining's binary_logloss: 0.011875\tvalid_1's binary_logloss: 0.0429442\n",
            "[620]\ttraining's binary_logloss: 0.0113956\tvalid_1's binary_logloss: 0.0411535\n",
            "[630]\ttraining's binary_logloss: 0.0109585\tvalid_1's binary_logloss: 0.0396207\n",
            "[640]\ttraining's binary_logloss: 0.0105827\tvalid_1's binary_logloss: 0.0382171\n",
            "[650]\ttraining's binary_logloss: 0.0101685\tvalid_1's binary_logloss: 0.0367537\n",
            "[660]\ttraining's binary_logloss: 0.00975654\tvalid_1's binary_logloss: 0.0353266\n",
            "[670]\ttraining's binary_logloss: 0.00937074\tvalid_1's binary_logloss: 0.0339624\n",
            "[680]\ttraining's binary_logloss: 0.00901172\tvalid_1's binary_logloss: 0.032619\n",
            "[690]\ttraining's binary_logloss: 0.00867183\tvalid_1's binary_logloss: 0.0314615\n",
            "[700]\ttraining's binary_logloss: 0.00832144\tvalid_1's binary_logloss: 0.0301696\n",
            "[710]\ttraining's binary_logloss: 0.00800306\tvalid_1's binary_logloss: 0.0289902\n",
            "[720]\ttraining's binary_logloss: 0.0076959\tvalid_1's binary_logloss: 0.027915\n",
            "[730]\ttraining's binary_logloss: 0.00738247\tvalid_1's binary_logloss: 0.0267737\n",
            "[740]\ttraining's binary_logloss: 0.00707665\tvalid_1's binary_logloss: 0.0256775\n",
            "[750]\ttraining's binary_logloss: 0.00681416\tvalid_1's binary_logloss: 0.024662\n",
            "[760]\ttraining's binary_logloss: 0.00654609\tvalid_1's binary_logloss: 0.0236399\n",
            "[770]\ttraining's binary_logloss: 0.00632611\tvalid_1's binary_logloss: 0.0228416\n",
            "[780]\ttraining's binary_logloss: 0.00611175\tvalid_1's binary_logloss: 0.0220827\n",
            "[790]\ttraining's binary_logloss: 0.00586324\tvalid_1's binary_logloss: 0.021186\n",
            "[800]\ttraining's binary_logloss: 0.00562482\tvalid_1's binary_logloss: 0.0203384\n",
            "[810]\ttraining's binary_logloss: 0.00540587\tvalid_1's binary_logloss: 0.0194951\n",
            "[820]\ttraining's binary_logloss: 0.00518663\tvalid_1's binary_logloss: 0.0186166\n",
            "[830]\ttraining's binary_logloss: 0.00499357\tvalid_1's binary_logloss: 0.017909\n",
            "[840]\ttraining's binary_logloss: 0.00479648\tvalid_1's binary_logloss: 0.0172015\n",
            "[850]\ttraining's binary_logloss: 0.00459039\tvalid_1's binary_logloss: 0.0165093\n",
            "[860]\ttraining's binary_logloss: 0.00442439\tvalid_1's binary_logloss: 0.015894\n",
            "[870]\ttraining's binary_logloss: 0.00424741\tvalid_1's binary_logloss: 0.0153206\n",
            "[880]\ttraining's binary_logloss: 0.00407054\tvalid_1's binary_logloss: 0.0146661\n",
            "[890]\ttraining's binary_logloss: 0.00389389\tvalid_1's binary_logloss: 0.0140326\n",
            "[900]\ttraining's binary_logloss: 0.00374075\tvalid_1's binary_logloss: 0.0134821\n",
            "[910]\ttraining's binary_logloss: 0.00358698\tvalid_1's binary_logloss: 0.0128866\n",
            "[920]\ttraining's binary_logloss: 0.00343707\tvalid_1's binary_logloss: 0.0123416\n",
            "[930]\ttraining's binary_logloss: 0.00329126\tvalid_1's binary_logloss: 0.0118016\n",
            "[940]\ttraining's binary_logloss: 0.0031584\tvalid_1's binary_logloss: 0.0113101\n",
            "[950]\ttraining's binary_logloss: 0.00301646\tvalid_1's binary_logloss: 0.0107907\n",
            "[960]\ttraining's binary_logloss: 0.00286952\tvalid_1's binary_logloss: 0.0102235\n",
            "[970]\ttraining's binary_logloss: 0.00273402\tvalid_1's binary_logloss: 0.00975602\n",
            "[980]\ttraining's binary_logloss: 0.00261248\tvalid_1's binary_logloss: 0.00932067\n",
            "[990]\ttraining's binary_logloss: 0.00250902\tvalid_1's binary_logloss: 0.00893381\n",
            "[1000]\ttraining's binary_logloss: 0.00241077\tvalid_1's binary_logloss: 0.00855769\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.00241077\tvalid_1's binary_logloss: 0.00855769\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:48:11,910] Trial 26 finished with value: 0.008557693522321653 and parameters: {'max_bin': 286, 'num_leaves': 106}. Best is trial 19 with value: 0.0046284648643910705.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.221951\tvalid_1's binary_logloss: 1.03032\n",
            "[20]\ttraining's binary_logloss: 0.202433\tvalid_1's binary_logloss: 0.933218\n",
            "[30]\ttraining's binary_logloss: 0.189919\tvalid_1's binary_logloss: 0.871299\n",
            "[40]\ttraining's binary_logloss: 0.180396\tvalid_1's binary_logloss: 0.823392\n",
            "[50]\ttraining's binary_logloss: 0.172097\tvalid_1's binary_logloss: 0.782884\n",
            "[60]\ttraining's binary_logloss: 0.1649\tvalid_1's binary_logloss: 0.743005\n",
            "[70]\ttraining's binary_logloss: 0.158019\tvalid_1's binary_logloss: 0.705159\n",
            "[80]\ttraining's binary_logloss: 0.152164\tvalid_1's binary_logloss: 0.673399\n",
            "[90]\ttraining's binary_logloss: 0.14693\tvalid_1's binary_logloss: 0.648869\n",
            "[100]\ttraining's binary_logloss: 0.142574\tvalid_1's binary_logloss: 0.628606\n",
            "[110]\ttraining's binary_logloss: 0.138402\tvalid_1's binary_logloss: 0.606567\n",
            "[120]\ttraining's binary_logloss: 0.134352\tvalid_1's binary_logloss: 0.587136\n",
            "[130]\ttraining's binary_logloss: 0.130706\tvalid_1's binary_logloss: 0.566774\n",
            "[140]\ttraining's binary_logloss: 0.127445\tvalid_1's binary_logloss: 0.54827\n",
            "[150]\ttraining's binary_logloss: 0.124045\tvalid_1's binary_logloss: 0.528431\n",
            "[160]\ttraining's binary_logloss: 0.120798\tvalid_1's binary_logloss: 0.510996\n",
            "[170]\ttraining's binary_logloss: 0.11781\tvalid_1's binary_logloss: 0.495924\n",
            "[180]\ttraining's binary_logloss: 0.115036\tvalid_1's binary_logloss: 0.482525\n",
            "[190]\ttraining's binary_logloss: 0.111951\tvalid_1's binary_logloss: 0.465639\n",
            "[200]\ttraining's binary_logloss: 0.109422\tvalid_1's binary_logloss: 0.453827\n",
            "[210]\ttraining's binary_logloss: 0.106605\tvalid_1's binary_logloss: 0.440943\n",
            "[220]\ttraining's binary_logloss: 0.103956\tvalid_1's binary_logloss: 0.428247\n",
            "[230]\ttraining's binary_logloss: 0.101511\tvalid_1's binary_logloss: 0.417535\n",
            "[240]\ttraining's binary_logloss: 0.0990323\tvalid_1's binary_logloss: 0.406259\n",
            "[250]\ttraining's binary_logloss: 0.0964908\tvalid_1's binary_logloss: 0.396566\n",
            "[260]\ttraining's binary_logloss: 0.0942174\tvalid_1's binary_logloss: 0.386121\n",
            "[270]\ttraining's binary_logloss: 0.0921764\tvalid_1's binary_logloss: 0.376027\n",
            "[280]\ttraining's binary_logloss: 0.0900249\tvalid_1's binary_logloss: 0.366376\n",
            "[290]\ttraining's binary_logloss: 0.0878509\tvalid_1's binary_logloss: 0.356141\n",
            "[300]\ttraining's binary_logloss: 0.0854441\tvalid_1's binary_logloss: 0.345868\n",
            "[310]\ttraining's binary_logloss: 0.083465\tvalid_1's binary_logloss: 0.336872\n",
            "[320]\ttraining's binary_logloss: 0.0816325\tvalid_1's binary_logloss: 0.329003\n",
            "[330]\ttraining's binary_logloss: 0.0793644\tvalid_1's binary_logloss: 0.319652\n",
            "[340]\ttraining's binary_logloss: 0.0775273\tvalid_1's binary_logloss: 0.311515\n",
            "[350]\ttraining's binary_logloss: 0.0756071\tvalid_1's binary_logloss: 0.302413\n",
            "[360]\ttraining's binary_logloss: 0.0737589\tvalid_1's binary_logloss: 0.293889\n",
            "[370]\ttraining's binary_logloss: 0.0720759\tvalid_1's binary_logloss: 0.286527\n",
            "[380]\ttraining's binary_logloss: 0.0703169\tvalid_1's binary_logloss: 0.278582\n",
            "[390]\ttraining's binary_logloss: 0.0686484\tvalid_1's binary_logloss: 0.271979\n",
            "[400]\ttraining's binary_logloss: 0.0673406\tvalid_1's binary_logloss: 0.266621\n",
            "[410]\ttraining's binary_logloss: 0.0657816\tvalid_1's binary_logloss: 0.259485\n",
            "[420]\ttraining's binary_logloss: 0.0644652\tvalid_1's binary_logloss: 0.253919\n",
            "[430]\ttraining's binary_logloss: 0.0629186\tvalid_1's binary_logloss: 0.247259\n",
            "[440]\ttraining's binary_logloss: 0.0614694\tvalid_1's binary_logloss: 0.240746\n",
            "[450]\ttraining's binary_logloss: 0.0601972\tvalid_1's binary_logloss: 0.234958\n",
            "[460]\ttraining's binary_logloss: 0.0589345\tvalid_1's binary_logloss: 0.229446\n",
            "[470]\ttraining's binary_logloss: 0.0576644\tvalid_1's binary_logloss: 0.223959\n",
            "[480]\ttraining's binary_logloss: 0.0564322\tvalid_1's binary_logloss: 0.218857\n",
            "[490]\ttraining's binary_logloss: 0.0553394\tvalid_1's binary_logloss: 0.214393\n",
            "[500]\ttraining's binary_logloss: 0.054114\tvalid_1's binary_logloss: 0.209032\n",
            "[510]\ttraining's binary_logloss: 0.0530368\tvalid_1's binary_logloss: 0.203937\n",
            "[520]\ttraining's binary_logloss: 0.0518349\tvalid_1's binary_logloss: 0.199209\n",
            "[530]\ttraining's binary_logloss: 0.0507261\tvalid_1's binary_logloss: 0.195018\n",
            "[540]\ttraining's binary_logloss: 0.0496594\tvalid_1's binary_logloss: 0.190883\n",
            "[550]\ttraining's binary_logloss: 0.0486559\tvalid_1's binary_logloss: 0.186733\n",
            "[560]\ttraining's binary_logloss: 0.0477317\tvalid_1's binary_logloss: 0.183297\n",
            "[570]\ttraining's binary_logloss: 0.0466958\tvalid_1's binary_logloss: 0.179029\n",
            "[580]\ttraining's binary_logloss: 0.0456989\tvalid_1's binary_logloss: 0.175026\n",
            "[590]\ttraining's binary_logloss: 0.0448511\tvalid_1's binary_logloss: 0.171859\n",
            "[600]\ttraining's binary_logloss: 0.0439495\tvalid_1's binary_logloss: 0.168019\n",
            "[610]\ttraining's binary_logloss: 0.0430071\tvalid_1's binary_logloss: 0.163732\n",
            "[620]\ttraining's binary_logloss: 0.0419744\tvalid_1's binary_logloss: 0.159218\n",
            "[630]\ttraining's binary_logloss: 0.0410918\tvalid_1's binary_logloss: 0.155412\n",
            "[640]\ttraining's binary_logloss: 0.0402628\tvalid_1's binary_logloss: 0.152602\n",
            "[650]\ttraining's binary_logloss: 0.0393124\tvalid_1's binary_logloss: 0.148661\n",
            "[660]\ttraining's binary_logloss: 0.0386067\tvalid_1's binary_logloss: 0.145784\n",
            "[670]\ttraining's binary_logloss: 0.0377001\tvalid_1's binary_logloss: 0.142289\n",
            "[680]\ttraining's binary_logloss: 0.0368279\tvalid_1's binary_logloss: 0.138562\n",
            "[690]\ttraining's binary_logloss: 0.0361366\tvalid_1's binary_logloss: 0.1358\n",
            "[700]\ttraining's binary_logloss: 0.0353507\tvalid_1's binary_logloss: 0.132718\n",
            "[710]\ttraining's binary_logloss: 0.0345887\tvalid_1's binary_logloss: 0.129682\n",
            "[720]\ttraining's binary_logloss: 0.0338831\tvalid_1's binary_logloss: 0.127096\n",
            "[730]\ttraining's binary_logloss: 0.0332736\tvalid_1's binary_logloss: 0.12472\n",
            "[740]\ttraining's binary_logloss: 0.0326336\tvalid_1's binary_logloss: 0.12207\n",
            "[750]\ttraining's binary_logloss: 0.0320083\tvalid_1's binary_logloss: 0.119608\n",
            "[760]\ttraining's binary_logloss: 0.0313119\tvalid_1's binary_logloss: 0.117104\n",
            "[770]\ttraining's binary_logloss: 0.030618\tvalid_1's binary_logloss: 0.114267\n",
            "[780]\ttraining's binary_logloss: 0.0300016\tvalid_1's binary_logloss: 0.111948\n",
            "[790]\ttraining's binary_logloss: 0.0294\tvalid_1's binary_logloss: 0.109663\n",
            "[800]\ttraining's binary_logloss: 0.0288095\tvalid_1's binary_logloss: 0.107394\n",
            "[810]\ttraining's binary_logloss: 0.0282417\tvalid_1's binary_logloss: 0.105106\n",
            "[820]\ttraining's binary_logloss: 0.0275983\tvalid_1's binary_logloss: 0.10291\n",
            "[830]\ttraining's binary_logloss: 0.0269799\tvalid_1's binary_logloss: 0.100479\n",
            "[840]\ttraining's binary_logloss: 0.0263211\tvalid_1's binary_logloss: 0.0983075\n",
            "[850]\ttraining's binary_logloss: 0.0258257\tvalid_1's binary_logloss: 0.096364\n",
            "[860]\ttraining's binary_logloss: 0.025305\tvalid_1's binary_logloss: 0.0944813\n",
            "[870]\ttraining's binary_logloss: 0.0248127\tvalid_1's binary_logloss: 0.0924599\n",
            "[880]\ttraining's binary_logloss: 0.024239\tvalid_1's binary_logloss: 0.0903035\n",
            "[890]\ttraining's binary_logloss: 0.0237385\tvalid_1's binary_logloss: 0.0884455\n",
            "[900]\ttraining's binary_logloss: 0.0232223\tvalid_1's binary_logloss: 0.086646\n",
            "[910]\ttraining's binary_logloss: 0.0227671\tvalid_1's binary_logloss: 0.0848747\n",
            "[920]\ttraining's binary_logloss: 0.0222511\tvalid_1's binary_logloss: 0.0829603\n",
            "[930]\ttraining's binary_logloss: 0.0218244\tvalid_1's binary_logloss: 0.0813922\n",
            "[940]\ttraining's binary_logloss: 0.0213351\tvalid_1's binary_logloss: 0.0793438\n",
            "[950]\ttraining's binary_logloss: 0.0208311\tvalid_1's binary_logloss: 0.0773597\n",
            "[960]\ttraining's binary_logloss: 0.0203869\tvalid_1's binary_logloss: 0.0758032\n",
            "[970]\ttraining's binary_logloss: 0.0199382\tvalid_1's binary_logloss: 0.0743201\n",
            "[980]\ttraining's binary_logloss: 0.0196016\tvalid_1's binary_logloss: 0.0729634\n",
            "[990]\ttraining's binary_logloss: 0.0191906\tvalid_1's binary_logloss: 0.0715068\n",
            "[1000]\ttraining's binary_logloss: 0.0187956\tvalid_1's binary_logloss: 0.0700291\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.0187956\tvalid_1's binary_logloss: 0.0700291\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:48:19,463] Trial 27 finished with value: 0.07002913285545087 and parameters: {'max_bin': 499, 'num_leaves': 55}. Best is trial 19 with value: 0.0046284648643910705.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.213413\tvalid_1's binary_logloss: 0.983316\n",
            "[20]\ttraining's binary_logloss: 0.188402\tvalid_1's binary_logloss: 0.855706\n",
            "[30]\ttraining's binary_logloss: 0.171708\tvalid_1's binary_logloss: 0.774903\n",
            "[40]\ttraining's binary_logloss: 0.158802\tvalid_1's binary_logloss: 0.70648\n",
            "[50]\ttraining's binary_logloss: 0.147168\tvalid_1's binary_logloss: 0.642946\n",
            "[60]\ttraining's binary_logloss: 0.137104\tvalid_1's binary_logloss: 0.591249\n",
            "[70]\ttraining's binary_logloss: 0.12814\tvalid_1's binary_logloss: 0.547859\n",
            "[80]\ttraining's binary_logloss: 0.119856\tvalid_1's binary_logloss: 0.503847\n",
            "[90]\ttraining's binary_logloss: 0.112583\tvalid_1's binary_logloss: 0.466081\n",
            "[100]\ttraining's binary_logloss: 0.106338\tvalid_1's binary_logloss: 0.438024\n",
            "[110]\ttraining's binary_logloss: 0.101103\tvalid_1's binary_logloss: 0.413073\n",
            "[120]\ttraining's binary_logloss: 0.0958837\tvalid_1's binary_logloss: 0.389212\n",
            "[130]\ttraining's binary_logloss: 0.0911791\tvalid_1's binary_logloss: 0.369099\n",
            "[140]\ttraining's binary_logloss: 0.0867832\tvalid_1's binary_logloss: 0.348767\n",
            "[150]\ttraining's binary_logloss: 0.0826591\tvalid_1's binary_logloss: 0.329198\n",
            "[160]\ttraining's binary_logloss: 0.0789737\tvalid_1's binary_logloss: 0.312659\n",
            "[170]\ttraining's binary_logloss: 0.0749952\tvalid_1's binary_logloss: 0.296484\n",
            "[180]\ttraining's binary_logloss: 0.0715664\tvalid_1's binary_logloss: 0.28286\n",
            "[190]\ttraining's binary_logloss: 0.0682075\tvalid_1's binary_logloss: 0.267585\n",
            "[200]\ttraining's binary_logloss: 0.0650464\tvalid_1's binary_logloss: 0.255658\n",
            "[210]\ttraining's binary_logloss: 0.0623769\tvalid_1's binary_logloss: 0.244977\n",
            "[220]\ttraining's binary_logloss: 0.0596659\tvalid_1's binary_logloss: 0.232761\n",
            "[230]\ttraining's binary_logloss: 0.0572009\tvalid_1's binary_logloss: 0.222766\n",
            "[240]\ttraining's binary_logloss: 0.055159\tvalid_1's binary_logloss: 0.214775\n",
            "[250]\ttraining's binary_logloss: 0.0530024\tvalid_1's binary_logloss: 0.205509\n",
            "[260]\ttraining's binary_logloss: 0.0506745\tvalid_1's binary_logloss: 0.196542\n",
            "[270]\ttraining's binary_logloss: 0.0487632\tvalid_1's binary_logloss: 0.188986\n",
            "[280]\ttraining's binary_logloss: 0.0467078\tvalid_1's binary_logloss: 0.180898\n",
            "[290]\ttraining's binary_logloss: 0.0447553\tvalid_1's binary_logloss: 0.17299\n",
            "[300]\ttraining's binary_logloss: 0.0428928\tvalid_1's binary_logloss: 0.165167\n",
            "[310]\ttraining's binary_logloss: 0.0411897\tvalid_1's binary_logloss: 0.158706\n",
            "[320]\ttraining's binary_logloss: 0.0397948\tvalid_1's binary_logloss: 0.15339\n",
            "[330]\ttraining's binary_logloss: 0.0383093\tvalid_1's binary_logloss: 0.147371\n",
            "[340]\ttraining's binary_logloss: 0.0367061\tvalid_1's binary_logloss: 0.141212\n",
            "[350]\ttraining's binary_logloss: 0.0352017\tvalid_1's binary_logloss: 0.134833\n",
            "[360]\ttraining's binary_logloss: 0.0338023\tvalid_1's binary_logloss: 0.129407\n",
            "[370]\ttraining's binary_logloss: 0.0322778\tvalid_1's binary_logloss: 0.122692\n",
            "[380]\ttraining's binary_logloss: 0.0309879\tvalid_1's binary_logloss: 0.117955\n",
            "[390]\ttraining's binary_logloss: 0.029882\tvalid_1's binary_logloss: 0.113811\n",
            "[400]\ttraining's binary_logloss: 0.0285712\tvalid_1's binary_logloss: 0.108499\n",
            "[410]\ttraining's binary_logloss: 0.0274267\tvalid_1's binary_logloss: 0.104109\n",
            "[420]\ttraining's binary_logloss: 0.0261882\tvalid_1's binary_logloss: 0.0988465\n",
            "[430]\ttraining's binary_logloss: 0.0251676\tvalid_1's binary_logloss: 0.094793\n",
            "[440]\ttraining's binary_logloss: 0.0239869\tvalid_1's binary_logloss: 0.0900332\n",
            "[450]\ttraining's binary_logloss: 0.0228887\tvalid_1's binary_logloss: 0.0855327\n",
            "[460]\ttraining's binary_logloss: 0.0218459\tvalid_1's binary_logloss: 0.0815544\n",
            "[470]\ttraining's binary_logloss: 0.0208325\tvalid_1's binary_logloss: 0.0772495\n",
            "[480]\ttraining's binary_logloss: 0.0199321\tvalid_1's binary_logloss: 0.0738328\n",
            "[490]\ttraining's binary_logloss: 0.0190884\tvalid_1's binary_logloss: 0.0703602\n",
            "[500]\ttraining's binary_logloss: 0.0182484\tvalid_1's binary_logloss: 0.0672955\n",
            "[510]\ttraining's binary_logloss: 0.0175854\tvalid_1's binary_logloss: 0.0649515\n",
            "[520]\ttraining's binary_logloss: 0.0169085\tvalid_1's binary_logloss: 0.0624162\n",
            "[530]\ttraining's binary_logloss: 0.0162776\tvalid_1's binary_logloss: 0.0600841\n",
            "[540]\ttraining's binary_logloss: 0.0156599\tvalid_1's binary_logloss: 0.0579056\n",
            "[550]\ttraining's binary_logloss: 0.0150063\tvalid_1's binary_logloss: 0.0552496\n",
            "[560]\ttraining's binary_logloss: 0.0144468\tvalid_1's binary_logloss: 0.0529264\n",
            "[570]\ttraining's binary_logloss: 0.0138156\tvalid_1's binary_logloss: 0.0505403\n",
            "[580]\ttraining's binary_logloss: 0.0131879\tvalid_1's binary_logloss: 0.0482434\n",
            "[590]\ttraining's binary_logloss: 0.0126036\tvalid_1's binary_logloss: 0.0458708\n",
            "[600]\ttraining's binary_logloss: 0.0121581\tvalid_1's binary_logloss: 0.0442128\n",
            "[610]\ttraining's binary_logloss: 0.0116505\tvalid_1's binary_logloss: 0.0422912\n",
            "[620]\ttraining's binary_logloss: 0.0111605\tvalid_1's binary_logloss: 0.0403729\n",
            "[630]\ttraining's binary_logloss: 0.0106878\tvalid_1's binary_logloss: 0.0385596\n",
            "[640]\ttraining's binary_logloss: 0.0102743\tvalid_1's binary_logloss: 0.0371677\n",
            "[650]\ttraining's binary_logloss: 0.00987293\tvalid_1's binary_logloss: 0.0357407\n",
            "[660]\ttraining's binary_logloss: 0.00948854\tvalid_1's binary_logloss: 0.0342918\n",
            "[670]\ttraining's binary_logloss: 0.00906166\tvalid_1's binary_logloss: 0.0326787\n",
            "[680]\ttraining's binary_logloss: 0.00868442\tvalid_1's binary_logloss: 0.0313436\n",
            "[690]\ttraining's binary_logloss: 0.00832756\tvalid_1's binary_logloss: 0.0299474\n",
            "[700]\ttraining's binary_logloss: 0.00796985\tvalid_1's binary_logloss: 0.0287856\n",
            "[710]\ttraining's binary_logloss: 0.0076305\tvalid_1's binary_logloss: 0.0277193\n",
            "[720]\ttraining's binary_logloss: 0.00732238\tvalid_1's binary_logloss: 0.0266071\n",
            "[730]\ttraining's binary_logloss: 0.00701022\tvalid_1's binary_logloss: 0.025369\n",
            "[740]\ttraining's binary_logloss: 0.00673727\tvalid_1's binary_logloss: 0.0243056\n",
            "[750]\ttraining's binary_logloss: 0.00645238\tvalid_1's binary_logloss: 0.0232695\n",
            "[760]\ttraining's binary_logloss: 0.00622183\tvalid_1's binary_logloss: 0.022437\n",
            "[770]\ttraining's binary_logloss: 0.00597142\tvalid_1's binary_logloss: 0.0215149\n",
            "[780]\ttraining's binary_logloss: 0.00571316\tvalid_1's binary_logloss: 0.0205615\n",
            "[790]\ttraining's binary_logloss: 0.0055038\tvalid_1's binary_logloss: 0.019809\n",
            "[800]\ttraining's binary_logloss: 0.00525483\tvalid_1's binary_logloss: 0.0188734\n",
            "[810]\ttraining's binary_logloss: 0.00504074\tvalid_1's binary_logloss: 0.0180862\n",
            "[820]\ttraining's binary_logloss: 0.00481014\tvalid_1's binary_logloss: 0.0171638\n",
            "[830]\ttraining's binary_logloss: 0.00458456\tvalid_1's binary_logloss: 0.0163081\n",
            "[840]\ttraining's binary_logloss: 0.00438323\tvalid_1's binary_logloss: 0.0155468\n",
            "[850]\ttraining's binary_logloss: 0.00422501\tvalid_1's binary_logloss: 0.0150007\n",
            "[860]\ttraining's binary_logloss: 0.00405486\tvalid_1's binary_logloss: 0.0144006\n",
            "[870]\ttraining's binary_logloss: 0.00386704\tvalid_1's binary_logloss: 0.0136778\n",
            "[880]\ttraining's binary_logloss: 0.0037129\tvalid_1's binary_logloss: 0.0131158\n",
            "[890]\ttraining's binary_logloss: 0.00355143\tvalid_1's binary_logloss: 0.012542\n",
            "[900]\ttraining's binary_logloss: 0.00341162\tvalid_1's binary_logloss: 0.0120485\n",
            "[910]\ttraining's binary_logloss: 0.00328411\tvalid_1's binary_logloss: 0.0115998\n",
            "[920]\ttraining's binary_logloss: 0.00315597\tvalid_1's binary_logloss: 0.0111346\n",
            "[930]\ttraining's binary_logloss: 0.00301862\tvalid_1's binary_logloss: 0.0105987\n",
            "[940]\ttraining's binary_logloss: 0.00290119\tvalid_1's binary_logloss: 0.0101644\n",
            "[950]\ttraining's binary_logloss: 0.00276712\tvalid_1's binary_logloss: 0.00971095\n",
            "[960]\ttraining's binary_logloss: 0.00265018\tvalid_1's binary_logloss: 0.00928491\n",
            "[970]\ttraining's binary_logloss: 0.00255345\tvalid_1's binary_logloss: 0.00897536\n",
            "[980]\ttraining's binary_logloss: 0.00244894\tvalid_1's binary_logloss: 0.00862217\n",
            "[990]\ttraining's binary_logloss: 0.00235339\tvalid_1's binary_logloss: 0.0082686\n",
            "[1000]\ttraining's binary_logloss: 0.00226765\tvalid_1's binary_logloss: 0.00796486\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.00226765\tvalid_1's binary_logloss: 0.00796486\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:48:29,940] Trial 28 finished with value: 0.00796485825939478 and parameters: {'max_bin': 418, 'num_leaves': 107}. Best is trial 19 with value: 0.0046284648643910705.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.216412\tvalid_1's binary_logloss: 1.00131\n",
            "[20]\ttraining's binary_logloss: 0.193278\tvalid_1's binary_logloss: 0.885324\n",
            "[30]\ttraining's binary_logloss: 0.178371\tvalid_1's binary_logloss: 0.815247\n",
            "[40]\ttraining's binary_logloss: 0.166556\tvalid_1's binary_logloss: 0.75004\n",
            "[50]\ttraining's binary_logloss: 0.156104\tvalid_1's binary_logloss: 0.692736\n",
            "[60]\ttraining's binary_logloss: 0.147336\tvalid_1's binary_logloss: 0.645313\n",
            "[70]\ttraining's binary_logloss: 0.13883\tvalid_1's binary_logloss: 0.601304\n",
            "[80]\ttraining's binary_logloss: 0.131473\tvalid_1's binary_logloss: 0.566311\n",
            "[90]\ttraining's binary_logloss: 0.124825\tvalid_1's binary_logloss: 0.532057\n",
            "[100]\ttraining's binary_logloss: 0.119306\tvalid_1's binary_logloss: 0.505918\n",
            "[110]\ttraining's binary_logloss: 0.114109\tvalid_1's binary_logloss: 0.479201\n",
            "[120]\ttraining's binary_logloss: 0.109132\tvalid_1's binary_logloss: 0.455236\n",
            "[130]\ttraining's binary_logloss: 0.104591\tvalid_1's binary_logloss: 0.431578\n",
            "[140]\ttraining's binary_logloss: 0.100211\tvalid_1's binary_logloss: 0.410925\n",
            "[150]\ttraining's binary_logloss: 0.0963854\tvalid_1's binary_logloss: 0.392084\n",
            "[160]\ttraining's binary_logloss: 0.0927337\tvalid_1's binary_logloss: 0.374499\n",
            "[170]\ttraining's binary_logloss: 0.0892934\tvalid_1's binary_logloss: 0.356791\n",
            "[180]\ttraining's binary_logloss: 0.085881\tvalid_1's binary_logloss: 0.34012\n",
            "[190]\ttraining's binary_logloss: 0.0829088\tvalid_1's binary_logloss: 0.327956\n",
            "[200]\ttraining's binary_logloss: 0.0800447\tvalid_1's binary_logloss: 0.316081\n",
            "[210]\ttraining's binary_logloss: 0.0770667\tvalid_1's binary_logloss: 0.303203\n",
            "[220]\ttraining's binary_logloss: 0.0744865\tvalid_1's binary_logloss: 0.292066\n",
            "[230]\ttraining's binary_logloss: 0.0719578\tvalid_1's binary_logloss: 0.28218\n",
            "[240]\ttraining's binary_logloss: 0.0693206\tvalid_1's binary_logloss: 0.272101\n",
            "[250]\ttraining's binary_logloss: 0.066953\tvalid_1's binary_logloss: 0.262427\n",
            "[260]\ttraining's binary_logloss: 0.0648604\tvalid_1's binary_logloss: 0.253477\n",
            "[270]\ttraining's binary_logloss: 0.062396\tvalid_1's binary_logloss: 0.242788\n",
            "[280]\ttraining's binary_logloss: 0.0602307\tvalid_1's binary_logloss: 0.234042\n",
            "[290]\ttraining's binary_logloss: 0.0581969\tvalid_1's binary_logloss: 0.225404\n",
            "[300]\ttraining's binary_logloss: 0.0560838\tvalid_1's binary_logloss: 0.216542\n",
            "[310]\ttraining's binary_logloss: 0.0540213\tvalid_1's binary_logloss: 0.20798\n",
            "[320]\ttraining's binary_logloss: 0.0520414\tvalid_1's binary_logloss: 0.199252\n",
            "[330]\ttraining's binary_logloss: 0.0504501\tvalid_1's binary_logloss: 0.192665\n",
            "[340]\ttraining's binary_logloss: 0.0487658\tvalid_1's binary_logloss: 0.18598\n",
            "[350]\ttraining's binary_logloss: 0.0470982\tvalid_1's binary_logloss: 0.178805\n",
            "[360]\ttraining's binary_logloss: 0.0453812\tvalid_1's binary_logloss: 0.17162\n",
            "[370]\ttraining's binary_logloss: 0.0436105\tvalid_1's binary_logloss: 0.16434\n",
            "[380]\ttraining's binary_logloss: 0.0421224\tvalid_1's binary_logloss: 0.158801\n",
            "[390]\ttraining's binary_logloss: 0.0403931\tvalid_1's binary_logloss: 0.151639\n",
            "[400]\ttraining's binary_logloss: 0.0387889\tvalid_1's binary_logloss: 0.145674\n",
            "[410]\ttraining's binary_logloss: 0.0374453\tvalid_1's binary_logloss: 0.140455\n",
            "[420]\ttraining's binary_logloss: 0.0361736\tvalid_1's binary_logloss: 0.135534\n",
            "[430]\ttraining's binary_logloss: 0.0349701\tvalid_1's binary_logloss: 0.131059\n",
            "[440]\ttraining's binary_logloss: 0.0338295\tvalid_1's binary_logloss: 0.126493\n",
            "[450]\ttraining's binary_logloss: 0.0328377\tvalid_1's binary_logloss: 0.122531\n",
            "[460]\ttraining's binary_logloss: 0.0319014\tvalid_1's binary_logloss: 0.118733\n",
            "[470]\ttraining's binary_logloss: 0.0308333\tvalid_1's binary_logloss: 0.114419\n",
            "[480]\ttraining's binary_logloss: 0.029757\tvalid_1's binary_logloss: 0.110401\n",
            "[490]\ttraining's binary_logloss: 0.0286856\tvalid_1's binary_logloss: 0.106328\n",
            "[500]\ttraining's binary_logloss: 0.0277204\tvalid_1's binary_logloss: 0.102707\n",
            "[510]\ttraining's binary_logloss: 0.0268278\tvalid_1's binary_logloss: 0.0992851\n",
            "[520]\ttraining's binary_logloss: 0.0259391\tvalid_1's binary_logloss: 0.0958906\n",
            "[530]\ttraining's binary_logloss: 0.025176\tvalid_1's binary_logloss: 0.0928869\n",
            "[540]\ttraining's binary_logloss: 0.0244459\tvalid_1's binary_logloss: 0.0901413\n",
            "[550]\ttraining's binary_logloss: 0.0236963\tvalid_1's binary_logloss: 0.087349\n",
            "[560]\ttraining's binary_logloss: 0.0230571\tvalid_1's binary_logloss: 0.0850491\n",
            "[570]\ttraining's binary_logloss: 0.0223193\tvalid_1's binary_logloss: 0.0823115\n",
            "[580]\ttraining's binary_logloss: 0.021609\tvalid_1's binary_logloss: 0.0795044\n",
            "[590]\ttraining's binary_logloss: 0.0209207\tvalid_1's binary_logloss: 0.0766164\n",
            "[600]\ttraining's binary_logloss: 0.0202875\tvalid_1's binary_logloss: 0.0741632\n",
            "[610]\ttraining's binary_logloss: 0.0195504\tvalid_1's binary_logloss: 0.0713244\n",
            "[620]\ttraining's binary_logloss: 0.0189231\tvalid_1's binary_logloss: 0.0689132\n",
            "[630]\ttraining's binary_logloss: 0.0183127\tvalid_1's binary_logloss: 0.0665589\n",
            "[640]\ttraining's binary_logloss: 0.0177166\tvalid_1's binary_logloss: 0.0643535\n",
            "[650]\ttraining's binary_logloss: 0.0170958\tvalid_1's binary_logloss: 0.0619171\n",
            "[660]\ttraining's binary_logloss: 0.0165664\tvalid_1's binary_logloss: 0.0598948\n",
            "[670]\ttraining's binary_logloss: 0.0160479\tvalid_1's binary_logloss: 0.058064\n",
            "[680]\ttraining's binary_logloss: 0.0155332\tvalid_1's binary_logloss: 0.0562828\n",
            "[690]\ttraining's binary_logloss: 0.0150287\tvalid_1's binary_logloss: 0.0543043\n",
            "[700]\ttraining's binary_logloss: 0.0145721\tvalid_1's binary_logloss: 0.0525527\n",
            "[710]\ttraining's binary_logloss: 0.0140557\tvalid_1's binary_logloss: 0.050659\n",
            "[720]\ttraining's binary_logloss: 0.0136413\tvalid_1's binary_logloss: 0.0491758\n",
            "[730]\ttraining's binary_logloss: 0.0131814\tvalid_1's binary_logloss: 0.0473794\n",
            "[740]\ttraining's binary_logloss: 0.0127646\tvalid_1's binary_logloss: 0.0458574\n",
            "[750]\ttraining's binary_logloss: 0.0122978\tvalid_1's binary_logloss: 0.0441348\n",
            "[760]\ttraining's binary_logloss: 0.0118935\tvalid_1's binary_logloss: 0.042619\n",
            "[770]\ttraining's binary_logloss: 0.0115126\tvalid_1's binary_logloss: 0.0412\n",
            "[780]\ttraining's binary_logloss: 0.0111288\tvalid_1's binary_logloss: 0.0398087\n",
            "[790]\ttraining's binary_logloss: 0.0107932\tvalid_1's binary_logloss: 0.0385952\n",
            "[800]\ttraining's binary_logloss: 0.0104187\tvalid_1's binary_logloss: 0.0372371\n",
            "[810]\ttraining's binary_logloss: 0.0100773\tvalid_1's binary_logloss: 0.0359699\n",
            "[820]\ttraining's binary_logloss: 0.00972176\tvalid_1's binary_logloss: 0.0346593\n",
            "[830]\ttraining's binary_logloss: 0.00936503\tvalid_1's binary_logloss: 0.0334036\n",
            "[840]\ttraining's binary_logloss: 0.00902758\tvalid_1's binary_logloss: 0.0322374\n",
            "[850]\ttraining's binary_logloss: 0.00873883\tvalid_1's binary_logloss: 0.0311701\n",
            "[860]\ttraining's binary_logloss: 0.00842664\tvalid_1's binary_logloss: 0.0300549\n",
            "[870]\ttraining's binary_logloss: 0.00815516\tvalid_1's binary_logloss: 0.0291137\n",
            "[880]\ttraining's binary_logloss: 0.00788414\tvalid_1's binary_logloss: 0.0282373\n",
            "[890]\ttraining's binary_logloss: 0.00761494\tvalid_1's binary_logloss: 0.0271478\n",
            "[900]\ttraining's binary_logloss: 0.00733711\tvalid_1's binary_logloss: 0.0261337\n",
            "[910]\ttraining's binary_logloss: 0.00707343\tvalid_1's binary_logloss: 0.0252343\n",
            "[920]\ttraining's binary_logloss: 0.00684211\tvalid_1's binary_logloss: 0.0243546\n",
            "[930]\ttraining's binary_logloss: 0.00662182\tvalid_1's binary_logloss: 0.0234894\n",
            "[940]\ttraining's binary_logloss: 0.00638917\tvalid_1's binary_logloss: 0.0227312\n",
            "[950]\ttraining's binary_logloss: 0.00617765\tvalid_1's binary_logloss: 0.0219184\n",
            "[960]\ttraining's binary_logloss: 0.00597649\tvalid_1's binary_logloss: 0.0212266\n",
            "[970]\ttraining's binary_logloss: 0.00576724\tvalid_1's binary_logloss: 0.0205495\n",
            "[980]\ttraining's binary_logloss: 0.00556584\tvalid_1's binary_logloss: 0.0198374\n",
            "[990]\ttraining's binary_logloss: 0.00541956\tvalid_1's binary_logloss: 0.0193392\n",
            "[1000]\ttraining's binary_logloss: 0.00524146\tvalid_1's binary_logloss: 0.0187369\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.00524146\tvalid_1's binary_logloss: 0.0187369\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:48:39,020] Trial 29 finished with value: 0.0187368675758261 and parameters: {'max_bin': 369, 'num_leaves': 87}. Best is trial 19 with value: 0.0046284648643910705.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.220002\tvalid_1's binary_logloss: 1.0191\n",
            "[20]\ttraining's binary_logloss: 0.199352\tvalid_1's binary_logloss: 0.918176\n",
            "[30]\ttraining's binary_logloss: 0.185948\tvalid_1's binary_logloss: 0.854903\n",
            "[40]\ttraining's binary_logloss: 0.175453\tvalid_1's binary_logloss: 0.797959\n",
            "[50]\ttraining's binary_logloss: 0.166598\tvalid_1's binary_logloss: 0.754367\n",
            "[60]\ttraining's binary_logloss: 0.158459\tvalid_1's binary_logloss: 0.711158\n",
            "[70]\ttraining's binary_logloss: 0.15134\tvalid_1's binary_logloss: 0.671939\n",
            "[80]\ttraining's binary_logloss: 0.144934\tvalid_1's binary_logloss: 0.637692\n",
            "[90]\ttraining's binary_logloss: 0.139602\tvalid_1's binary_logloss: 0.612549\n",
            "[100]\ttraining's binary_logloss: 0.134342\tvalid_1's binary_logloss: 0.584267\n",
            "[110]\ttraining's binary_logloss: 0.129094\tvalid_1's binary_logloss: 0.556143\n",
            "[120]\ttraining's binary_logloss: 0.12466\tvalid_1's binary_logloss: 0.534918\n",
            "[130]\ttraining's binary_logloss: 0.120792\tvalid_1's binary_logloss: 0.518245\n",
            "[140]\ttraining's binary_logloss: 0.117227\tvalid_1's binary_logloss: 0.499108\n",
            "[150]\ttraining's binary_logloss: 0.113788\tvalid_1's binary_logloss: 0.481121\n",
            "[160]\ttraining's binary_logloss: 0.110417\tvalid_1's binary_logloss: 0.464335\n",
            "[170]\ttraining's binary_logloss: 0.10749\tvalid_1's binary_logloss: 0.448677\n",
            "[180]\ttraining's binary_logloss: 0.104397\tvalid_1's binary_logloss: 0.432758\n",
            "[190]\ttraining's binary_logloss: 0.101602\tvalid_1's binary_logloss: 0.420146\n",
            "[200]\ttraining's binary_logloss: 0.0987953\tvalid_1's binary_logloss: 0.407634\n",
            "[210]\ttraining's binary_logloss: 0.0963632\tvalid_1's binary_logloss: 0.396078\n",
            "[220]\ttraining's binary_logloss: 0.093702\tvalid_1's binary_logloss: 0.382615\n",
            "[230]\ttraining's binary_logloss: 0.0912473\tvalid_1's binary_logloss: 0.371865\n",
            "[240]\ttraining's binary_logloss: 0.0887376\tvalid_1's binary_logloss: 0.360611\n",
            "[250]\ttraining's binary_logloss: 0.0861921\tvalid_1's binary_logloss: 0.34943\n",
            "[260]\ttraining's binary_logloss: 0.0839693\tvalid_1's binary_logloss: 0.339671\n",
            "[270]\ttraining's binary_logloss: 0.0817596\tvalid_1's binary_logloss: 0.330128\n",
            "[280]\ttraining's binary_logloss: 0.0798962\tvalid_1's binary_logloss: 0.320911\n",
            "[290]\ttraining's binary_logloss: 0.0778015\tvalid_1's binary_logloss: 0.311946\n",
            "[300]\ttraining's binary_logloss: 0.0753727\tvalid_1's binary_logloss: 0.300936\n",
            "[310]\ttraining's binary_logloss: 0.0732033\tvalid_1's binary_logloss: 0.292065\n",
            "[320]\ttraining's binary_logloss: 0.0712184\tvalid_1's binary_logloss: 0.283945\n",
            "[330]\ttraining's binary_logloss: 0.069469\tvalid_1's binary_logloss: 0.27757\n",
            "[340]\ttraining's binary_logloss: 0.0676948\tvalid_1's binary_logloss: 0.270874\n",
            "[350]\ttraining's binary_logloss: 0.0658797\tvalid_1's binary_logloss: 0.262979\n",
            "[360]\ttraining's binary_logloss: 0.0642593\tvalid_1's binary_logloss: 0.256208\n",
            "[370]\ttraining's binary_logloss: 0.0625547\tvalid_1's binary_logloss: 0.248204\n",
            "[380]\ttraining's binary_logloss: 0.0609732\tvalid_1's binary_logloss: 0.241017\n",
            "[390]\ttraining's binary_logloss: 0.0595787\tvalid_1's binary_logloss: 0.235268\n",
            "[400]\ttraining's binary_logloss: 0.05787\tvalid_1's binary_logloss: 0.228007\n",
            "[410]\ttraining's binary_logloss: 0.056483\tvalid_1's binary_logloss: 0.221896\n",
            "[420]\ttraining's binary_logloss: 0.0549185\tvalid_1's binary_logloss: 0.215351\n",
            "[430]\ttraining's binary_logloss: 0.0536449\tvalid_1's binary_logloss: 0.209491\n",
            "[440]\ttraining's binary_logloss: 0.0520925\tvalid_1's binary_logloss: 0.202192\n",
            "[450]\ttraining's binary_logloss: 0.0508312\tvalid_1's binary_logloss: 0.19673\n",
            "[460]\ttraining's binary_logloss: 0.0495746\tvalid_1's binary_logloss: 0.191878\n",
            "[470]\ttraining's binary_logloss: 0.048318\tvalid_1's binary_logloss: 0.1867\n",
            "[480]\ttraining's binary_logloss: 0.0470233\tvalid_1's binary_logloss: 0.180925\n",
            "[490]\ttraining's binary_logloss: 0.0457797\tvalid_1's binary_logloss: 0.175238\n",
            "[500]\ttraining's binary_logloss: 0.0444244\tvalid_1's binary_logloss: 0.169122\n",
            "[510]\ttraining's binary_logloss: 0.0432685\tvalid_1's binary_logloss: 0.164373\n",
            "[520]\ttraining's binary_logloss: 0.0420485\tvalid_1's binary_logloss: 0.159308\n",
            "[530]\ttraining's binary_logloss: 0.0409514\tvalid_1's binary_logloss: 0.155048\n",
            "[540]\ttraining's binary_logloss: 0.0400088\tvalid_1's binary_logloss: 0.151199\n",
            "[550]\ttraining's binary_logloss: 0.0390351\tvalid_1's binary_logloss: 0.146536\n",
            "[560]\ttraining's binary_logloss: 0.0379643\tvalid_1's binary_logloss: 0.142421\n",
            "[570]\ttraining's binary_logloss: 0.0370198\tvalid_1's binary_logloss: 0.138441\n",
            "[580]\ttraining's binary_logloss: 0.0360479\tvalid_1's binary_logloss: 0.134706\n",
            "[590]\ttraining's binary_logloss: 0.0351606\tvalid_1's binary_logloss: 0.13071\n",
            "[600]\ttraining's binary_logloss: 0.0341793\tvalid_1's binary_logloss: 0.12724\n",
            "[610]\ttraining's binary_logloss: 0.0333737\tvalid_1's binary_logloss: 0.12404\n",
            "[620]\ttraining's binary_logloss: 0.0324509\tvalid_1's binary_logloss: 0.120286\n",
            "[630]\ttraining's binary_logloss: 0.0316694\tvalid_1's binary_logloss: 0.117585\n",
            "[640]\ttraining's binary_logloss: 0.0309627\tvalid_1's binary_logloss: 0.114787\n",
            "[650]\ttraining's binary_logloss: 0.0302257\tvalid_1's binary_logloss: 0.112102\n",
            "[660]\ttraining's binary_logloss: 0.0294707\tvalid_1's binary_logloss: 0.109235\n",
            "[670]\ttraining's binary_logloss: 0.0287603\tvalid_1's binary_logloss: 0.106616\n",
            "[680]\ttraining's binary_logloss: 0.0281127\tvalid_1's binary_logloss: 0.104068\n",
            "[690]\ttraining's binary_logloss: 0.0274112\tvalid_1's binary_logloss: 0.101438\n",
            "[700]\ttraining's binary_logloss: 0.0267368\tvalid_1's binary_logloss: 0.0986428\n",
            "[710]\ttraining's binary_logloss: 0.0260016\tvalid_1's binary_logloss: 0.0959567\n",
            "[720]\ttraining's binary_logloss: 0.0252598\tvalid_1's binary_logloss: 0.0930817\n",
            "[730]\ttraining's binary_logloss: 0.0246111\tvalid_1's binary_logloss: 0.0903949\n",
            "[740]\ttraining's binary_logloss: 0.0239836\tvalid_1's binary_logloss: 0.0880881\n",
            "[750]\ttraining's binary_logloss: 0.023312\tvalid_1's binary_logloss: 0.0855565\n",
            "[760]\ttraining's binary_logloss: 0.0227477\tvalid_1's binary_logloss: 0.0835038\n",
            "[770]\ttraining's binary_logloss: 0.0221824\tvalid_1's binary_logloss: 0.0813072\n",
            "[780]\ttraining's binary_logloss: 0.0216317\tvalid_1's binary_logloss: 0.0792088\n",
            "[790]\ttraining's binary_logloss: 0.021074\tvalid_1's binary_logloss: 0.0772649\n",
            "[800]\ttraining's binary_logloss: 0.0204892\tvalid_1's binary_logloss: 0.0749292\n",
            "[810]\ttraining's binary_logloss: 0.0200199\tvalid_1's binary_logloss: 0.0732375\n",
            "[820]\ttraining's binary_logloss: 0.0194828\tvalid_1's binary_logloss: 0.0712355\n",
            "[830]\ttraining's binary_logloss: 0.0190344\tvalid_1's binary_logloss: 0.0695631\n",
            "[840]\ttraining's binary_logloss: 0.0186056\tvalid_1's binary_logloss: 0.0680214\n",
            "[850]\ttraining's binary_logloss: 0.0181663\tvalid_1's binary_logloss: 0.0661847\n",
            "[860]\ttraining's binary_logloss: 0.017767\tvalid_1's binary_logloss: 0.0648684\n",
            "[870]\ttraining's binary_logloss: 0.0173405\tvalid_1's binary_logloss: 0.0632578\n",
            "[880]\ttraining's binary_logloss: 0.0169657\tvalid_1's binary_logloss: 0.0619037\n",
            "[890]\ttraining's binary_logloss: 0.0165672\tvalid_1's binary_logloss: 0.06051\n",
            "[900]\ttraining's binary_logloss: 0.0161579\tvalid_1's binary_logloss: 0.0589899\n",
            "[910]\ttraining's binary_logloss: 0.0157365\tvalid_1's binary_logloss: 0.0573741\n",
            "[920]\ttraining's binary_logloss: 0.0153772\tvalid_1's binary_logloss: 0.0561338\n",
            "[930]\ttraining's binary_logloss: 0.0149674\tvalid_1's binary_logloss: 0.0545063\n",
            "[940]\ttraining's binary_logloss: 0.0146001\tvalid_1's binary_logloss: 0.0530625\n",
            "[950]\ttraining's binary_logloss: 0.0142624\tvalid_1's binary_logloss: 0.0519259\n",
            "[960]\ttraining's binary_logloss: 0.0138538\tvalid_1's binary_logloss: 0.0504821\n",
            "[970]\ttraining's binary_logloss: 0.0135007\tvalid_1's binary_logloss: 0.0492482\n",
            "[980]\ttraining's binary_logloss: 0.0132305\tvalid_1's binary_logloss: 0.048349\n",
            "[990]\ttraining's binary_logloss: 0.0128755\tvalid_1's binary_logloss: 0.0469038\n",
            "[1000]\ttraining's binary_logloss: 0.0125585\tvalid_1's binary_logloss: 0.0457058\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.0125585\tvalid_1's binary_logloss: 0.0457058\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:48:46,536] Trial 30 finished with value: 0.04570576372993326 and parameters: {'max_bin': 283, 'num_leaves': 66}. Best is trial 19 with value: 0.0046284648643910705.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.227404\tvalid_1's binary_logloss: 1.06298\n",
            "[20]\ttraining's binary_logloss: 0.210781\tvalid_1's binary_logloss: 0.980695\n",
            "[30]\ttraining's binary_logloss: 0.200833\tvalid_1's binary_logloss: 0.932386\n",
            "[40]\ttraining's binary_logloss: 0.193087\tvalid_1's binary_logloss: 0.893962\n",
            "[50]\ttraining's binary_logloss: 0.187097\tvalid_1's binary_logloss: 0.861867\n",
            "[60]\ttraining's binary_logloss: 0.181685\tvalid_1's binary_logloss: 0.83109\n",
            "[70]\ttraining's binary_logloss: 0.17684\tvalid_1's binary_logloss: 0.807311\n",
            "[80]\ttraining's binary_logloss: 0.172725\tvalid_1's binary_logloss: 0.786396\n",
            "[90]\ttraining's binary_logloss: 0.168741\tvalid_1's binary_logloss: 0.76452\n",
            "[100]\ttraining's binary_logloss: 0.165524\tvalid_1's binary_logloss: 0.74796\n",
            "[110]\ttraining's binary_logloss: 0.162377\tvalid_1's binary_logloss: 0.730225\n",
            "[120]\ttraining's binary_logloss: 0.159254\tvalid_1's binary_logloss: 0.71257\n",
            "[130]\ttraining's binary_logloss: 0.1562\tvalid_1's binary_logloss: 0.696385\n",
            "[140]\ttraining's binary_logloss: 0.153326\tvalid_1's binary_logloss: 0.681992\n",
            "[150]\ttraining's binary_logloss: 0.150323\tvalid_1's binary_logloss: 0.666752\n",
            "[160]\ttraining's binary_logloss: 0.147577\tvalid_1's binary_logloss: 0.651628\n",
            "[170]\ttraining's binary_logloss: 0.145031\tvalid_1's binary_logloss: 0.63616\n",
            "[180]\ttraining's binary_logloss: 0.142326\tvalid_1's binary_logloss: 0.621476\n",
            "[190]\ttraining's binary_logloss: 0.140024\tvalid_1's binary_logloss: 0.610084\n",
            "[200]\ttraining's binary_logloss: 0.137708\tvalid_1's binary_logloss: 0.597364\n",
            "[210]\ttraining's binary_logloss: 0.135476\tvalid_1's binary_logloss: 0.583618\n",
            "[220]\ttraining's binary_logloss: 0.1332\tvalid_1's binary_logloss: 0.572765\n",
            "[230]\ttraining's binary_logloss: 0.130993\tvalid_1's binary_logloss: 0.560406\n",
            "[240]\ttraining's binary_logloss: 0.128815\tvalid_1's binary_logloss: 0.55136\n",
            "[250]\ttraining's binary_logloss: 0.12684\tvalid_1's binary_logloss: 0.54004\n",
            "[260]\ttraining's binary_logloss: 0.124849\tvalid_1's binary_logloss: 0.529257\n",
            "[270]\ttraining's binary_logloss: 0.123152\tvalid_1's binary_logloss: 0.519343\n",
            "[280]\ttraining's binary_logloss: 0.121131\tvalid_1's binary_logloss: 0.508363\n",
            "[290]\ttraining's binary_logloss: 0.119358\tvalid_1's binary_logloss: 0.498633\n",
            "[300]\ttraining's binary_logloss: 0.117686\tvalid_1's binary_logloss: 0.490255\n",
            "[310]\ttraining's binary_logloss: 0.115999\tvalid_1's binary_logloss: 0.48259\n",
            "[320]\ttraining's binary_logloss: 0.114433\tvalid_1's binary_logloss: 0.474486\n",
            "[330]\ttraining's binary_logloss: 0.112757\tvalid_1's binary_logloss: 0.466314\n",
            "[340]\ttraining's binary_logloss: 0.111329\tvalid_1's binary_logloss: 0.459912\n",
            "[350]\ttraining's binary_logloss: 0.10962\tvalid_1's binary_logloss: 0.451177\n",
            "[360]\ttraining's binary_logloss: 0.10808\tvalid_1's binary_logloss: 0.444262\n",
            "[370]\ttraining's binary_logloss: 0.106414\tvalid_1's binary_logloss: 0.437486\n",
            "[380]\ttraining's binary_logloss: 0.105041\tvalid_1's binary_logloss: 0.431003\n",
            "[390]\ttraining's binary_logloss: 0.103379\tvalid_1's binary_logloss: 0.423464\n",
            "[400]\ttraining's binary_logloss: 0.101982\tvalid_1's binary_logloss: 0.417253\n",
            "[410]\ttraining's binary_logloss: 0.100597\tvalid_1's binary_logloss: 0.409734\n",
            "[420]\ttraining's binary_logloss: 0.0992676\tvalid_1's binary_logloss: 0.402486\n",
            "[430]\ttraining's binary_logloss: 0.0977934\tvalid_1's binary_logloss: 0.396068\n",
            "[440]\ttraining's binary_logloss: 0.0964883\tvalid_1's binary_logloss: 0.390351\n",
            "[450]\ttraining's binary_logloss: 0.0952115\tvalid_1's binary_logloss: 0.384415\n",
            "[460]\ttraining's binary_logloss: 0.0938658\tvalid_1's binary_logloss: 0.378632\n",
            "[470]\ttraining's binary_logloss: 0.0926687\tvalid_1's binary_logloss: 0.373488\n",
            "[480]\ttraining's binary_logloss: 0.0915065\tvalid_1's binary_logloss: 0.367654\n",
            "[490]\ttraining's binary_logloss: 0.0903512\tvalid_1's binary_logloss: 0.363159\n",
            "[500]\ttraining's binary_logloss: 0.0892498\tvalid_1's binary_logloss: 0.359343\n",
            "[510]\ttraining's binary_logloss: 0.088069\tvalid_1's binary_logloss: 0.354055\n",
            "[520]\ttraining's binary_logloss: 0.0869807\tvalid_1's binary_logloss: 0.349977\n",
            "[530]\ttraining's binary_logloss: 0.0859286\tvalid_1's binary_logloss: 0.34518\n",
            "[540]\ttraining's binary_logloss: 0.0847524\tvalid_1's binary_logloss: 0.339718\n",
            "[550]\ttraining's binary_logloss: 0.0837976\tvalid_1's binary_logloss: 0.334654\n",
            "[560]\ttraining's binary_logloss: 0.0826915\tvalid_1's binary_logloss: 0.329974\n",
            "[570]\ttraining's binary_logloss: 0.0817245\tvalid_1's binary_logloss: 0.325019\n",
            "[580]\ttraining's binary_logloss: 0.0804921\tvalid_1's binary_logloss: 0.319607\n",
            "[590]\ttraining's binary_logloss: 0.0794609\tvalid_1's binary_logloss: 0.315267\n",
            "[600]\ttraining's binary_logloss: 0.0785146\tvalid_1's binary_logloss: 0.31144\n",
            "[610]\ttraining's binary_logloss: 0.0774883\tvalid_1's binary_logloss: 0.307229\n",
            "[620]\ttraining's binary_logloss: 0.0764704\tvalid_1's binary_logloss: 0.302737\n",
            "[630]\ttraining's binary_logloss: 0.0755095\tvalid_1's binary_logloss: 0.298111\n",
            "[640]\ttraining's binary_logloss: 0.0746146\tvalid_1's binary_logloss: 0.294586\n",
            "[650]\ttraining's binary_logloss: 0.0738263\tvalid_1's binary_logloss: 0.29081\n",
            "[660]\ttraining's binary_logloss: 0.0728602\tvalid_1's binary_logloss: 0.286979\n",
            "[670]\ttraining's binary_logloss: 0.071755\tvalid_1's binary_logloss: 0.281899\n",
            "[680]\ttraining's binary_logloss: 0.0708745\tvalid_1's binary_logloss: 0.278037\n",
            "[690]\ttraining's binary_logloss: 0.0700846\tvalid_1's binary_logloss: 0.274297\n",
            "[700]\ttraining's binary_logloss: 0.0692604\tvalid_1's binary_logloss: 0.271348\n",
            "[710]\ttraining's binary_logloss: 0.0683555\tvalid_1's binary_logloss: 0.267587\n",
            "[720]\ttraining's binary_logloss: 0.0675252\tvalid_1's binary_logloss: 0.264127\n",
            "[730]\ttraining's binary_logloss: 0.0667383\tvalid_1's binary_logloss: 0.260964\n",
            "[740]\ttraining's binary_logloss: 0.0658537\tvalid_1's binary_logloss: 0.257677\n",
            "[750]\ttraining's binary_logloss: 0.065212\tvalid_1's binary_logloss: 0.254746\n",
            "[760]\ttraining's binary_logloss: 0.0643686\tvalid_1's binary_logloss: 0.251206\n",
            "[770]\ttraining's binary_logloss: 0.0636255\tvalid_1's binary_logloss: 0.247344\n",
            "[780]\ttraining's binary_logloss: 0.0628298\tvalid_1's binary_logloss: 0.244501\n",
            "[790]\ttraining's binary_logloss: 0.0620664\tvalid_1's binary_logloss: 0.241261\n",
            "[800]\ttraining's binary_logloss: 0.0613224\tvalid_1's binary_logloss: 0.23792\n",
            "[810]\ttraining's binary_logloss: 0.0606174\tvalid_1's binary_logloss: 0.234416\n",
            "[820]\ttraining's binary_logloss: 0.059905\tvalid_1's binary_logloss: 0.231671\n",
            "[830]\ttraining's binary_logloss: 0.0592591\tvalid_1's binary_logloss: 0.228987\n",
            "[840]\ttraining's binary_logloss: 0.0584863\tvalid_1's binary_logloss: 0.226037\n",
            "[850]\ttraining's binary_logloss: 0.0578218\tvalid_1's binary_logloss: 0.223207\n",
            "[860]\ttraining's binary_logloss: 0.0572568\tvalid_1's binary_logloss: 0.221058\n",
            "[870]\ttraining's binary_logloss: 0.0564746\tvalid_1's binary_logloss: 0.217797\n",
            "[880]\ttraining's binary_logloss: 0.0557112\tvalid_1's binary_logloss: 0.214428\n",
            "[890]\ttraining's binary_logloss: 0.0551196\tvalid_1's binary_logloss: 0.212139\n",
            "[900]\ttraining's binary_logloss: 0.0544682\tvalid_1's binary_logloss: 0.209334\n",
            "[910]\ttraining's binary_logloss: 0.0537272\tvalid_1's binary_logloss: 0.206155\n",
            "[920]\ttraining's binary_logloss: 0.0529734\tvalid_1's binary_logloss: 0.20301\n",
            "[930]\ttraining's binary_logloss: 0.0524038\tvalid_1's binary_logloss: 0.200504\n",
            "[940]\ttraining's binary_logloss: 0.0517338\tvalid_1's binary_logloss: 0.197473\n",
            "[950]\ttraining's binary_logloss: 0.0511689\tvalid_1's binary_logloss: 0.195162\n",
            "[960]\ttraining's binary_logloss: 0.050504\tvalid_1's binary_logloss: 0.192682\n",
            "[970]\ttraining's binary_logloss: 0.0499109\tvalid_1's binary_logloss: 0.190371\n",
            "[980]\ttraining's binary_logloss: 0.0493651\tvalid_1's binary_logloss: 0.187931\n",
            "[990]\ttraining's binary_logloss: 0.0488397\tvalid_1's binary_logloss: 0.185196\n",
            "[1000]\ttraining's binary_logloss: 0.0482701\tvalid_1's binary_logloss: 0.182688\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.0482701\tvalid_1's binary_logloss: 0.182688\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:48:52,685] Trial 31 finished with value: 0.1826881605838841 and parameters: {'max_bin': 383, 'num_leaves': 32}. Best is trial 19 with value: 0.0046284648643910705.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.216836\tvalid_1's binary_logloss: 1.00066\n",
            "[20]\ttraining's binary_logloss: 0.194046\tvalid_1's binary_logloss: 0.886645\n",
            "[30]\ttraining's binary_logloss: 0.179037\tvalid_1's binary_logloss: 0.812876\n",
            "[40]\ttraining's binary_logloss: 0.167536\tvalid_1's binary_logloss: 0.754214\n",
            "[50]\ttraining's binary_logloss: 0.15677\tvalid_1's binary_logloss: 0.696691\n",
            "[60]\ttraining's binary_logloss: 0.147687\tvalid_1's binary_logloss: 0.650473\n",
            "[70]\ttraining's binary_logloss: 0.139632\tvalid_1's binary_logloss: 0.613352\n",
            "[80]\ttraining's binary_logloss: 0.132102\tvalid_1's binary_logloss: 0.573936\n",
            "[90]\ttraining's binary_logloss: 0.12605\tvalid_1's binary_logloss: 0.543631\n",
            "[100]\ttraining's binary_logloss: 0.120656\tvalid_1's binary_logloss: 0.518674\n",
            "[110]\ttraining's binary_logloss: 0.115326\tvalid_1's binary_logloss: 0.495941\n",
            "[120]\ttraining's binary_logloss: 0.110656\tvalid_1's binary_logloss: 0.470992\n",
            "[130]\ttraining's binary_logloss: 0.10601\tvalid_1's binary_logloss: 0.447201\n",
            "[140]\ttraining's binary_logloss: 0.102049\tvalid_1's binary_logloss: 0.426407\n",
            "[150]\ttraining's binary_logloss: 0.0979434\tvalid_1's binary_logloss: 0.406043\n",
            "[160]\ttraining's binary_logloss: 0.0941495\tvalid_1's binary_logloss: 0.385868\n",
            "[170]\ttraining's binary_logloss: 0.0909851\tvalid_1's binary_logloss: 0.371916\n",
            "[180]\ttraining's binary_logloss: 0.0875991\tvalid_1's binary_logloss: 0.356227\n",
            "[190]\ttraining's binary_logloss: 0.0845717\tvalid_1's binary_logloss: 0.342086\n",
            "[200]\ttraining's binary_logloss: 0.0817334\tvalid_1's binary_logloss: 0.329984\n",
            "[210]\ttraining's binary_logloss: 0.0788729\tvalid_1's binary_logloss: 0.316765\n",
            "[220]\ttraining's binary_logloss: 0.0761133\tvalid_1's binary_logloss: 0.305294\n",
            "[230]\ttraining's binary_logloss: 0.0732555\tvalid_1's binary_logloss: 0.292622\n",
            "[240]\ttraining's binary_logloss: 0.0705868\tvalid_1's binary_logloss: 0.280185\n",
            "[250]\ttraining's binary_logloss: 0.0681438\tvalid_1's binary_logloss: 0.269995\n",
            "[260]\ttraining's binary_logloss: 0.0659852\tvalid_1's binary_logloss: 0.261598\n",
            "[270]\ttraining's binary_logloss: 0.06384\tvalid_1's binary_logloss: 0.253073\n",
            "[280]\ttraining's binary_logloss: 0.0619044\tvalid_1's binary_logloss: 0.244894\n",
            "[290]\ttraining's binary_logloss: 0.0598495\tvalid_1's binary_logloss: 0.236623\n",
            "[300]\ttraining's binary_logloss: 0.0578779\tvalid_1's binary_logloss: 0.228609\n",
            "[310]\ttraining's binary_logloss: 0.0558443\tvalid_1's binary_logloss: 0.220312\n",
            "[320]\ttraining's binary_logloss: 0.0539998\tvalid_1's binary_logloss: 0.21321\n",
            "[330]\ttraining's binary_logloss: 0.0524314\tvalid_1's binary_logloss: 0.207093\n",
            "[340]\ttraining's binary_logloss: 0.0506085\tvalid_1's binary_logloss: 0.200158\n",
            "[350]\ttraining's binary_logloss: 0.048792\tvalid_1's binary_logloss: 0.193117\n",
            "[360]\ttraining's binary_logloss: 0.0470351\tvalid_1's binary_logloss: 0.185121\n",
            "[370]\ttraining's binary_logloss: 0.0454852\tvalid_1's binary_logloss: 0.178594\n",
            "[380]\ttraining's binary_logloss: 0.0439621\tvalid_1's binary_logloss: 0.173242\n",
            "[390]\ttraining's binary_logloss: 0.0425567\tvalid_1's binary_logloss: 0.167468\n",
            "[400]\ttraining's binary_logloss: 0.0411158\tvalid_1's binary_logloss: 0.161568\n",
            "[410]\ttraining's binary_logloss: 0.0397379\tvalid_1's binary_logloss: 0.155935\n",
            "[420]\ttraining's binary_logloss: 0.038619\tvalid_1's binary_logloss: 0.151546\n",
            "[430]\ttraining's binary_logloss: 0.0372734\tvalid_1's binary_logloss: 0.14611\n",
            "[440]\ttraining's binary_logloss: 0.0360833\tvalid_1's binary_logloss: 0.141385\n",
            "[450]\ttraining's binary_logloss: 0.0346312\tvalid_1's binary_logloss: 0.13521\n",
            "[460]\ttraining's binary_logloss: 0.0336124\tvalid_1's binary_logloss: 0.130928\n",
            "[470]\ttraining's binary_logloss: 0.0324192\tvalid_1's binary_logloss: 0.12545\n",
            "[480]\ttraining's binary_logloss: 0.0311588\tvalid_1's binary_logloss: 0.119815\n",
            "[490]\ttraining's binary_logloss: 0.0301919\tvalid_1's binary_logloss: 0.116091\n",
            "[500]\ttraining's binary_logloss: 0.0291065\tvalid_1's binary_logloss: 0.111511\n",
            "[510]\ttraining's binary_logloss: 0.0282626\tvalid_1's binary_logloss: 0.108379\n",
            "[520]\ttraining's binary_logloss: 0.0274042\tvalid_1's binary_logloss: 0.105155\n",
            "[530]\ttraining's binary_logloss: 0.0265259\tvalid_1's binary_logloss: 0.101726\n",
            "[540]\ttraining's binary_logloss: 0.0255969\tvalid_1's binary_logloss: 0.0977106\n",
            "[550]\ttraining's binary_logloss: 0.0248321\tvalid_1's binary_logloss: 0.0950002\n",
            "[560]\ttraining's binary_logloss: 0.0240645\tvalid_1's binary_logloss: 0.0919054\n",
            "[570]\ttraining's binary_logloss: 0.0233277\tvalid_1's binary_logloss: 0.0889674\n",
            "[580]\ttraining's binary_logloss: 0.0225722\tvalid_1's binary_logloss: 0.0861119\n",
            "[590]\ttraining's binary_logloss: 0.0217957\tvalid_1's binary_logloss: 0.0830908\n",
            "[600]\ttraining's binary_logloss: 0.0211043\tvalid_1's binary_logloss: 0.0804877\n",
            "[610]\ttraining's binary_logloss: 0.0204285\tvalid_1's binary_logloss: 0.077804\n",
            "[620]\ttraining's binary_logloss: 0.0197683\tvalid_1's binary_logloss: 0.0751623\n",
            "[630]\ttraining's binary_logloss: 0.0192159\tvalid_1's binary_logloss: 0.0730341\n",
            "[640]\ttraining's binary_logloss: 0.0187053\tvalid_1's binary_logloss: 0.0709598\n",
            "[650]\ttraining's binary_logloss: 0.0181622\tvalid_1's binary_logloss: 0.0687224\n",
            "[660]\ttraining's binary_logloss: 0.0175956\tvalid_1's binary_logloss: 0.0664225\n",
            "[670]\ttraining's binary_logloss: 0.016953\tvalid_1's binary_logloss: 0.0637558\n",
            "[680]\ttraining's binary_logloss: 0.0162973\tvalid_1's binary_logloss: 0.0609676\n",
            "[690]\ttraining's binary_logloss: 0.0157274\tvalid_1's binary_logloss: 0.0587849\n",
            "[700]\ttraining's binary_logloss: 0.0152324\tvalid_1's binary_logloss: 0.0568917\n",
            "[710]\ttraining's binary_logloss: 0.0147552\tvalid_1's binary_logloss: 0.0550107\n",
            "[720]\ttraining's binary_logloss: 0.014289\tvalid_1's binary_logloss: 0.0530422\n",
            "[730]\ttraining's binary_logloss: 0.0138124\tvalid_1's binary_logloss: 0.0512724\n",
            "[740]\ttraining's binary_logloss: 0.0133844\tvalid_1's binary_logloss: 0.0496216\n",
            "[750]\ttraining's binary_logloss: 0.0129914\tvalid_1's binary_logloss: 0.0483393\n",
            "[760]\ttraining's binary_logloss: 0.0125839\tvalid_1's binary_logloss: 0.0470314\n",
            "[770]\ttraining's binary_logloss: 0.0121795\tvalid_1's binary_logloss: 0.0454231\n",
            "[780]\ttraining's binary_logloss: 0.0117547\tvalid_1's binary_logloss: 0.0436863\n",
            "[790]\ttraining's binary_logloss: 0.0114123\tvalid_1's binary_logloss: 0.042412\n",
            "[800]\ttraining's binary_logloss: 0.0110935\tvalid_1's binary_logloss: 0.0413619\n",
            "[810]\ttraining's binary_logloss: 0.0107492\tvalid_1's binary_logloss: 0.0402026\n",
            "[820]\ttraining's binary_logloss: 0.0104304\tvalid_1's binary_logloss: 0.0390109\n",
            "[830]\ttraining's binary_logloss: 0.0101126\tvalid_1's binary_logloss: 0.0375971\n",
            "[840]\ttraining's binary_logloss: 0.00976414\tvalid_1's binary_logloss: 0.0363482\n",
            "[850]\ttraining's binary_logloss: 0.00944727\tvalid_1's binary_logloss: 0.0350086\n",
            "[860]\ttraining's binary_logloss: 0.00918458\tvalid_1's binary_logloss: 0.0340662\n",
            "[870]\ttraining's binary_logloss: 0.00885475\tvalid_1's binary_logloss: 0.0329112\n",
            "[880]\ttraining's binary_logloss: 0.00856398\tvalid_1's binary_logloss: 0.0318086\n",
            "[890]\ttraining's binary_logloss: 0.00827293\tvalid_1's binary_logloss: 0.0307898\n",
            "[900]\ttraining's binary_logloss: 0.00794882\tvalid_1's binary_logloss: 0.0295998\n",
            "[910]\ttraining's binary_logloss: 0.00766113\tvalid_1's binary_logloss: 0.0285137\n",
            "[920]\ttraining's binary_logloss: 0.00739994\tvalid_1's binary_logloss: 0.0275013\n",
            "[930]\ttraining's binary_logloss: 0.00715193\tvalid_1's binary_logloss: 0.0265166\n",
            "[940]\ttraining's binary_logloss: 0.00691252\tvalid_1's binary_logloss: 0.0255736\n",
            "[950]\ttraining's binary_logloss: 0.00670069\tvalid_1's binary_logloss: 0.0247977\n",
            "[960]\ttraining's binary_logloss: 0.0064969\tvalid_1's binary_logloss: 0.0240209\n",
            "[970]\ttraining's binary_logloss: 0.00628369\tvalid_1's binary_logloss: 0.0232152\n",
            "[980]\ttraining's binary_logloss: 0.00607494\tvalid_1's binary_logloss: 0.0224872\n",
            "[990]\ttraining's binary_logloss: 0.00590352\tvalid_1's binary_logloss: 0.0218543\n",
            "[1000]\ttraining's binary_logloss: 0.00572034\tvalid_1's binary_logloss: 0.0211822\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.00572034\tvalid_1's binary_logloss: 0.0211822\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:49:01,842] Trial 32 finished with value: 0.02118215414570918 and parameters: {'max_bin': 419, 'num_leaves': 85}. Best is trial 19 with value: 0.0046284648643910705.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.219278\tvalid_1's binary_logloss: 1.01574\n",
            "[20]\ttraining's binary_logloss: 0.198343\tvalid_1's binary_logloss: 0.910913\n",
            "[30]\ttraining's binary_logloss: 0.184562\tvalid_1's binary_logloss: 0.844347\n",
            "[40]\ttraining's binary_logloss: 0.173888\tvalid_1's binary_logloss: 0.788254\n",
            "[50]\ttraining's binary_logloss: 0.164273\tvalid_1's binary_logloss: 0.739642\n",
            "[60]\ttraining's binary_logloss: 0.15636\tvalid_1's binary_logloss: 0.699348\n",
            "[70]\ttraining's binary_logloss: 0.148855\tvalid_1's binary_logloss: 0.661745\n",
            "[80]\ttraining's binary_logloss: 0.142298\tvalid_1's binary_logloss: 0.627658\n",
            "[90]\ttraining's binary_logloss: 0.136675\tvalid_1's binary_logloss: 0.602742\n",
            "[100]\ttraining's binary_logloss: 0.131412\tvalid_1's binary_logloss: 0.577172\n",
            "[110]\ttraining's binary_logloss: 0.126218\tvalid_1's binary_logloss: 0.547613\n",
            "[120]\ttraining's binary_logloss: 0.121424\tvalid_1's binary_logloss: 0.523804\n",
            "[130]\ttraining's binary_logloss: 0.117452\tvalid_1's binary_logloss: 0.502653\n",
            "[140]\ttraining's binary_logloss: 0.11366\tvalid_1's binary_logloss: 0.485015\n",
            "[150]\ttraining's binary_logloss: 0.109592\tvalid_1's binary_logloss: 0.465725\n",
            "[160]\ttraining's binary_logloss: 0.106164\tvalid_1's binary_logloss: 0.449432\n",
            "[170]\ttraining's binary_logloss: 0.102925\tvalid_1's binary_logloss: 0.432527\n",
            "[180]\ttraining's binary_logloss: 0.0997287\tvalid_1's binary_logloss: 0.417042\n",
            "[190]\ttraining's binary_logloss: 0.0968426\tvalid_1's binary_logloss: 0.402969\n",
            "[200]\ttraining's binary_logloss: 0.0938826\tvalid_1's binary_logloss: 0.389151\n",
            "[210]\ttraining's binary_logloss: 0.0907468\tvalid_1's binary_logloss: 0.376062\n",
            "[220]\ttraining's binary_logloss: 0.0882552\tvalid_1's binary_logloss: 0.364179\n",
            "[230]\ttraining's binary_logloss: 0.0856031\tvalid_1's binary_logloss: 0.352628\n",
            "[240]\ttraining's binary_logloss: 0.0830503\tvalid_1's binary_logloss: 0.340789\n",
            "[250]\ttraining's binary_logloss: 0.0809302\tvalid_1's binary_logloss: 0.331308\n",
            "[260]\ttraining's binary_logloss: 0.0787982\tvalid_1's binary_logloss: 0.322337\n",
            "[270]\ttraining's binary_logloss: 0.0764419\tvalid_1's binary_logloss: 0.311802\n",
            "[280]\ttraining's binary_logloss: 0.0744834\tvalid_1's binary_logloss: 0.303272\n",
            "[290]\ttraining's binary_logloss: 0.0723553\tvalid_1's binary_logloss: 0.293803\n",
            "[300]\ttraining's binary_logloss: 0.0702717\tvalid_1's binary_logloss: 0.284365\n",
            "[310]\ttraining's binary_logloss: 0.068429\tvalid_1's binary_logloss: 0.276338\n",
            "[320]\ttraining's binary_logloss: 0.0663512\tvalid_1's binary_logloss: 0.267145\n",
            "[330]\ttraining's binary_logloss: 0.0646916\tvalid_1's binary_logloss: 0.259583\n",
            "[340]\ttraining's binary_logloss: 0.0627909\tvalid_1's binary_logloss: 0.251365\n",
            "[350]\ttraining's binary_logloss: 0.0610969\tvalid_1's binary_logloss: 0.243969\n",
            "[360]\ttraining's binary_logloss: 0.0595764\tvalid_1's binary_logloss: 0.237793\n",
            "[370]\ttraining's binary_logloss: 0.0579308\tvalid_1's binary_logloss: 0.230754\n",
            "[380]\ttraining's binary_logloss: 0.0562544\tvalid_1's binary_logloss: 0.223421\n",
            "[390]\ttraining's binary_logloss: 0.0548398\tvalid_1's binary_logloss: 0.217593\n",
            "[400]\ttraining's binary_logloss: 0.0534372\tvalid_1's binary_logloss: 0.212359\n",
            "[410]\ttraining's binary_logloss: 0.05205\tvalid_1's binary_logloss: 0.206985\n",
            "[420]\ttraining's binary_logloss: 0.0506022\tvalid_1's binary_logloss: 0.200939\n",
            "[430]\ttraining's binary_logloss: 0.0493978\tvalid_1's binary_logloss: 0.195777\n",
            "[440]\ttraining's binary_logloss: 0.0482108\tvalid_1's binary_logloss: 0.190969\n",
            "[450]\ttraining's binary_logloss: 0.0471141\tvalid_1's binary_logloss: 0.186564\n",
            "[460]\ttraining's binary_logloss: 0.0457106\tvalid_1's binary_logloss: 0.181177\n",
            "[470]\ttraining's binary_logloss: 0.044444\tvalid_1's binary_logloss: 0.175634\n",
            "[480]\ttraining's binary_logloss: 0.0432688\tvalid_1's binary_logloss: 0.170113\n",
            "[490]\ttraining's binary_logloss: 0.0419648\tvalid_1's binary_logloss: 0.164295\n",
            "[500]\ttraining's binary_logloss: 0.0408549\tvalid_1's binary_logloss: 0.159922\n",
            "[510]\ttraining's binary_logloss: 0.0396404\tvalid_1's binary_logloss: 0.154796\n",
            "[520]\ttraining's binary_logloss: 0.0386554\tvalid_1's binary_logloss: 0.151164\n",
            "[530]\ttraining's binary_logloss: 0.0376803\tvalid_1's binary_logloss: 0.146894\n",
            "[540]\ttraining's binary_logloss: 0.0366946\tvalid_1's binary_logloss: 0.143284\n",
            "[550]\ttraining's binary_logloss: 0.0358324\tvalid_1's binary_logloss: 0.140177\n",
            "[560]\ttraining's binary_logloss: 0.0350444\tvalid_1's binary_logloss: 0.137446\n",
            "[570]\ttraining's binary_logloss: 0.0341438\tvalid_1's binary_logloss: 0.134223\n",
            "[580]\ttraining's binary_logloss: 0.0331639\tvalid_1's binary_logloss: 0.129847\n",
            "[590]\ttraining's binary_logloss: 0.0322392\tvalid_1's binary_logloss: 0.12606\n",
            "[600]\ttraining's binary_logloss: 0.0312969\tvalid_1's binary_logloss: 0.121995\n",
            "[610]\ttraining's binary_logloss: 0.0303266\tvalid_1's binary_logloss: 0.117807\n",
            "[620]\ttraining's binary_logloss: 0.0294664\tvalid_1's binary_logloss: 0.11455\n",
            "[630]\ttraining's binary_logloss: 0.0285752\tvalid_1's binary_logloss: 0.110531\n",
            "[640]\ttraining's binary_logloss: 0.0279187\tvalid_1's binary_logloss: 0.108054\n",
            "[650]\ttraining's binary_logloss: 0.0271975\tvalid_1's binary_logloss: 0.105091\n",
            "[660]\ttraining's binary_logloss: 0.0264081\tvalid_1's binary_logloss: 0.101267\n",
            "[670]\ttraining's binary_logloss: 0.0256325\tvalid_1's binary_logloss: 0.0980079\n",
            "[680]\ttraining's binary_logloss: 0.0250091\tvalid_1's binary_logloss: 0.0952616\n",
            "[690]\ttraining's binary_logloss: 0.0244628\tvalid_1's binary_logloss: 0.0930145\n",
            "[700]\ttraining's binary_logloss: 0.0239514\tvalid_1's binary_logloss: 0.0911799\n",
            "[710]\ttraining's binary_logloss: 0.0233358\tvalid_1's binary_logloss: 0.0887718\n",
            "[720]\ttraining's binary_logloss: 0.0227494\tvalid_1's binary_logloss: 0.0862373\n",
            "[730]\ttraining's binary_logloss: 0.0221117\tvalid_1's binary_logloss: 0.0835476\n",
            "[740]\ttraining's binary_logloss: 0.0214686\tvalid_1's binary_logloss: 0.08109\n",
            "[750]\ttraining's binary_logloss: 0.020824\tvalid_1's binary_logloss: 0.0785718\n",
            "[760]\ttraining's binary_logloss: 0.0203138\tvalid_1's binary_logloss: 0.0766219\n",
            "[770]\ttraining's binary_logloss: 0.0197278\tvalid_1's binary_logloss: 0.0738883\n",
            "[780]\ttraining's binary_logloss: 0.0192216\tvalid_1's binary_logloss: 0.0719427\n",
            "[790]\ttraining's binary_logloss: 0.0187632\tvalid_1's binary_logloss: 0.0700407\n",
            "[800]\ttraining's binary_logloss: 0.0183042\tvalid_1's binary_logloss: 0.0683338\n",
            "[810]\ttraining's binary_logloss: 0.0177556\tvalid_1's binary_logloss: 0.06616\n",
            "[820]\ttraining's binary_logloss: 0.0173159\tvalid_1's binary_logloss: 0.0644479\n",
            "[830]\ttraining's binary_logloss: 0.0169393\tvalid_1's binary_logloss: 0.0630558\n",
            "[840]\ttraining's binary_logloss: 0.0164847\tvalid_1's binary_logloss: 0.0613866\n",
            "[850]\ttraining's binary_logloss: 0.0160607\tvalid_1's binary_logloss: 0.0598074\n",
            "[860]\ttraining's binary_logloss: 0.0156087\tvalid_1's binary_logloss: 0.0580944\n",
            "[870]\ttraining's binary_logloss: 0.0151384\tvalid_1's binary_logloss: 0.0561427\n",
            "[880]\ttraining's binary_logloss: 0.0147737\tvalid_1's binary_logloss: 0.0547715\n",
            "[890]\ttraining's binary_logloss: 0.0143705\tvalid_1's binary_logloss: 0.053115\n",
            "[900]\ttraining's binary_logloss: 0.0139975\tvalid_1's binary_logloss: 0.0516925\n",
            "[910]\ttraining's binary_logloss: 0.0136092\tvalid_1's binary_logloss: 0.050175\n",
            "[920]\ttraining's binary_logloss: 0.0132523\tvalid_1's binary_logloss: 0.0488188\n",
            "[930]\ttraining's binary_logloss: 0.0129058\tvalid_1's binary_logloss: 0.0474541\n",
            "[940]\ttraining's binary_logloss: 0.0125444\tvalid_1's binary_logloss: 0.0460246\n",
            "[950]\ttraining's binary_logloss: 0.0122512\tvalid_1's binary_logloss: 0.0450039\n",
            "[960]\ttraining's binary_logloss: 0.0119533\tvalid_1's binary_logloss: 0.043964\n",
            "[970]\ttraining's binary_logloss: 0.0116258\tvalid_1's binary_logloss: 0.042677\n",
            "[980]\ttraining's binary_logloss: 0.0113219\tvalid_1's binary_logloss: 0.0416106\n",
            "[990]\ttraining's binary_logloss: 0.0110396\tvalid_1's binary_logloss: 0.0402765\n",
            "[1000]\ttraining's binary_logloss: 0.0107807\tvalid_1's binary_logloss: 0.0393617\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.0107807\tvalid_1's binary_logloss: 0.0393617\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:49:10,073] Trial 33 finished with value: 0.03936174137497749 and parameters: {'max_bin': 388, 'num_leaves': 70}. Best is trial 19 with value: 0.0046284648643910705.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.223214\tvalid_1's binary_logloss: 1.03662\n",
            "[20]\ttraining's binary_logloss: 0.204669\tvalid_1's binary_logloss: 0.943759\n",
            "[30]\ttraining's binary_logloss: 0.192801\tvalid_1's binary_logloss: 0.887315\n",
            "[40]\ttraining's binary_logloss: 0.183605\tvalid_1's binary_logloss: 0.841688\n",
            "[50]\ttraining's binary_logloss: 0.176223\tvalid_1's binary_logloss: 0.802758\n",
            "[60]\ttraining's binary_logloss: 0.169457\tvalid_1's binary_logloss: 0.764796\n",
            "[70]\ttraining's binary_logloss: 0.163362\tvalid_1's binary_logloss: 0.731602\n",
            "[80]\ttraining's binary_logloss: 0.157817\tvalid_1's binary_logloss: 0.701842\n",
            "[90]\ttraining's binary_logloss: 0.152925\tvalid_1's binary_logloss: 0.677539\n",
            "[100]\ttraining's binary_logloss: 0.148669\tvalid_1's binary_logloss: 0.657247\n",
            "[110]\ttraining's binary_logloss: 0.144802\tvalid_1's binary_logloss: 0.636022\n",
            "[120]\ttraining's binary_logloss: 0.140564\tvalid_1's binary_logloss: 0.614705\n",
            "[130]\ttraining's binary_logloss: 0.137082\tvalid_1's binary_logloss: 0.596543\n",
            "[140]\ttraining's binary_logloss: 0.133323\tvalid_1's binary_logloss: 0.575107\n",
            "[150]\ttraining's binary_logloss: 0.1298\tvalid_1's binary_logloss: 0.555949\n",
            "[160]\ttraining's binary_logloss: 0.126772\tvalid_1's binary_logloss: 0.539797\n",
            "[170]\ttraining's binary_logloss: 0.123759\tvalid_1's binary_logloss: 0.523701\n",
            "[180]\ttraining's binary_logloss: 0.120859\tvalid_1's binary_logloss: 0.508727\n",
            "[190]\ttraining's binary_logloss: 0.117918\tvalid_1's binary_logloss: 0.493407\n",
            "[200]\ttraining's binary_logloss: 0.115227\tvalid_1's binary_logloss: 0.479706\n",
            "[210]\ttraining's binary_logloss: 0.112751\tvalid_1's binary_logloss: 0.467654\n",
            "[220]\ttraining's binary_logloss: 0.109878\tvalid_1's binary_logloss: 0.45311\n",
            "[230]\ttraining's binary_logloss: 0.107673\tvalid_1's binary_logloss: 0.441534\n",
            "[240]\ttraining's binary_logloss: 0.105435\tvalid_1's binary_logloss: 0.429505\n",
            "[250]\ttraining's binary_logloss: 0.103137\tvalid_1's binary_logloss: 0.419846\n",
            "[260]\ttraining's binary_logloss: 0.100786\tvalid_1's binary_logloss: 0.407131\n",
            "[270]\ttraining's binary_logloss: 0.0984528\tvalid_1's binary_logloss: 0.395044\n",
            "[280]\ttraining's binary_logloss: 0.0965067\tvalid_1's binary_logloss: 0.386479\n",
            "[290]\ttraining's binary_logloss: 0.0945678\tvalid_1's binary_logloss: 0.377088\n",
            "[300]\ttraining's binary_logloss: 0.0929689\tvalid_1's binary_logloss: 0.369316\n",
            "[310]\ttraining's binary_logloss: 0.0911298\tvalid_1's binary_logloss: 0.360974\n",
            "[320]\ttraining's binary_logloss: 0.0893299\tvalid_1's binary_logloss: 0.353233\n",
            "[330]\ttraining's binary_logloss: 0.0876686\tvalid_1's binary_logloss: 0.34571\n",
            "[340]\ttraining's binary_logloss: 0.0860205\tvalid_1's binary_logloss: 0.339257\n",
            "[350]\ttraining's binary_logloss: 0.0841592\tvalid_1's binary_logloss: 0.332355\n",
            "[360]\ttraining's binary_logloss: 0.0821602\tvalid_1's binary_logloss: 0.322855\n",
            "[370]\ttraining's binary_logloss: 0.0803911\tvalid_1's binary_logloss: 0.315771\n",
            "[380]\ttraining's binary_logloss: 0.0785493\tvalid_1's binary_logloss: 0.308639\n",
            "[390]\ttraining's binary_logloss: 0.0769649\tvalid_1's binary_logloss: 0.302269\n",
            "[400]\ttraining's binary_logloss: 0.0754144\tvalid_1's binary_logloss: 0.295102\n",
            "[410]\ttraining's binary_logloss: 0.0739298\tvalid_1's binary_logloss: 0.288794\n",
            "[420]\ttraining's binary_logloss: 0.0725975\tvalid_1's binary_logloss: 0.283215\n",
            "[430]\ttraining's binary_logloss: 0.071156\tvalid_1's binary_logloss: 0.278096\n",
            "[440]\ttraining's binary_logloss: 0.0699414\tvalid_1's binary_logloss: 0.273601\n",
            "[450]\ttraining's binary_logloss: 0.0687159\tvalid_1's binary_logloss: 0.268745\n",
            "[460]\ttraining's binary_logloss: 0.0673301\tvalid_1's binary_logloss: 0.262677\n",
            "[470]\ttraining's binary_logloss: 0.0659928\tvalid_1's binary_logloss: 0.257031\n",
            "[480]\ttraining's binary_logloss: 0.0646438\tvalid_1's binary_logloss: 0.25114\n",
            "[490]\ttraining's binary_logloss: 0.0631801\tvalid_1's binary_logloss: 0.245059\n",
            "[500]\ttraining's binary_logloss: 0.0618241\tvalid_1's binary_logloss: 0.239326\n",
            "[510]\ttraining's binary_logloss: 0.0605843\tvalid_1's binary_logloss: 0.234082\n",
            "[520]\ttraining's binary_logloss: 0.0592807\tvalid_1's binary_logloss: 0.227966\n",
            "[530]\ttraining's binary_logloss: 0.0581572\tvalid_1's binary_logloss: 0.223412\n",
            "[540]\ttraining's binary_logloss: 0.0569742\tvalid_1's binary_logloss: 0.218533\n",
            "[550]\ttraining's binary_logloss: 0.0558851\tvalid_1's binary_logloss: 0.214258\n",
            "[560]\ttraining's binary_logloss: 0.0548233\tvalid_1's binary_logloss: 0.210186\n",
            "[570]\ttraining's binary_logloss: 0.0536823\tvalid_1's binary_logloss: 0.205707\n",
            "[580]\ttraining's binary_logloss: 0.0526928\tvalid_1's binary_logloss: 0.202086\n",
            "[590]\ttraining's binary_logloss: 0.0515584\tvalid_1's binary_logloss: 0.197866\n",
            "[600]\ttraining's binary_logloss: 0.0506447\tvalid_1's binary_logloss: 0.194296\n",
            "[610]\ttraining's binary_logloss: 0.0496412\tvalid_1's binary_logloss: 0.189648\n",
            "[620]\ttraining's binary_logloss: 0.0487408\tvalid_1's binary_logloss: 0.186144\n",
            "[630]\ttraining's binary_logloss: 0.0477476\tvalid_1's binary_logloss: 0.181837\n",
            "[640]\ttraining's binary_logloss: 0.0468737\tvalid_1's binary_logloss: 0.177896\n",
            "[650]\ttraining's binary_logloss: 0.0458751\tvalid_1's binary_logloss: 0.174119\n",
            "[660]\ttraining's binary_logloss: 0.0449993\tvalid_1's binary_logloss: 0.170785\n",
            "[670]\ttraining's binary_logloss: 0.0440382\tvalid_1's binary_logloss: 0.166777\n",
            "[680]\ttraining's binary_logloss: 0.0431858\tvalid_1's binary_logloss: 0.163635\n",
            "[690]\ttraining's binary_logloss: 0.0423889\tvalid_1's binary_logloss: 0.160972\n",
            "[700]\ttraining's binary_logloss: 0.0416733\tvalid_1's binary_logloss: 0.158096\n",
            "[710]\ttraining's binary_logloss: 0.0408322\tvalid_1's binary_logloss: 0.155271\n",
            "[720]\ttraining's binary_logloss: 0.0399836\tvalid_1's binary_logloss: 0.151502\n",
            "[730]\ttraining's binary_logloss: 0.0393238\tvalid_1's binary_logloss: 0.14874\n",
            "[740]\ttraining's binary_logloss: 0.0384779\tvalid_1's binary_logloss: 0.145778\n",
            "[750]\ttraining's binary_logloss: 0.0378822\tvalid_1's binary_logloss: 0.143654\n",
            "[760]\ttraining's binary_logloss: 0.0372178\tvalid_1's binary_logloss: 0.141153\n",
            "[770]\ttraining's binary_logloss: 0.0365975\tvalid_1's binary_logloss: 0.139018\n",
            "[780]\ttraining's binary_logloss: 0.0358143\tvalid_1's binary_logloss: 0.136181\n",
            "[790]\ttraining's binary_logloss: 0.0350861\tvalid_1's binary_logloss: 0.132971\n",
            "[800]\ttraining's binary_logloss: 0.0343793\tvalid_1's binary_logloss: 0.130026\n",
            "[810]\ttraining's binary_logloss: 0.0337489\tvalid_1's binary_logloss: 0.127428\n",
            "[820]\ttraining's binary_logloss: 0.0330042\tvalid_1's binary_logloss: 0.124485\n",
            "[830]\ttraining's binary_logloss: 0.0324162\tvalid_1's binary_logloss: 0.122083\n",
            "[840]\ttraining's binary_logloss: 0.0319009\tvalid_1's binary_logloss: 0.120174\n",
            "[850]\ttraining's binary_logloss: 0.0313668\tvalid_1's binary_logloss: 0.118051\n",
            "[860]\ttraining's binary_logloss: 0.0308628\tvalid_1's binary_logloss: 0.116219\n",
            "[870]\ttraining's binary_logloss: 0.0302814\tvalid_1's binary_logloss: 0.113977\n",
            "[880]\ttraining's binary_logloss: 0.0297537\tvalid_1's binary_logloss: 0.112186\n",
            "[890]\ttraining's binary_logloss: 0.0291827\tvalid_1's binary_logloss: 0.110056\n",
            "[900]\ttraining's binary_logloss: 0.0286773\tvalid_1's binary_logloss: 0.108306\n",
            "[910]\ttraining's binary_logloss: 0.02822\tvalid_1's binary_logloss: 0.106664\n",
            "[920]\ttraining's binary_logloss: 0.0277889\tvalid_1's binary_logloss: 0.105294\n",
            "[930]\ttraining's binary_logloss: 0.0273015\tvalid_1's binary_logloss: 0.103688\n",
            "[940]\ttraining's binary_logloss: 0.026797\tvalid_1's binary_logloss: 0.101641\n",
            "[950]\ttraining's binary_logloss: 0.0262449\tvalid_1's binary_logloss: 0.0992665\n",
            "[960]\ttraining's binary_logloss: 0.0257656\tvalid_1's binary_logloss: 0.097632\n",
            "[970]\ttraining's binary_logloss: 0.0253511\tvalid_1's binary_logloss: 0.0962067\n",
            "[980]\ttraining's binary_logloss: 0.0248483\tvalid_1's binary_logloss: 0.0941041\n",
            "[990]\ttraining's binary_logloss: 0.0243826\tvalid_1's binary_logloss: 0.0922311\n",
            "[1000]\ttraining's binary_logloss: 0.0239653\tvalid_1's binary_logloss: 0.0904667\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.0239653\tvalid_1's binary_logloss: 0.0904667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:49:17,206] Trial 34 finished with value: 0.09046670951091881 and parameters: {'max_bin': 487, 'num_leaves': 49}. Best is trial 19 with value: 0.0046284648643910705.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.22623\tvalid_1's binary_logloss: 1.05515\n",
            "[20]\ttraining's binary_logloss: 0.209409\tvalid_1's binary_logloss: 0.973389\n",
            "[30]\ttraining's binary_logloss: 0.198816\tvalid_1's binary_logloss: 0.920945\n",
            "[40]\ttraining's binary_logloss: 0.190624\tvalid_1's binary_logloss: 0.881694\n",
            "[50]\ttraining's binary_logloss: 0.18429\tvalid_1's binary_logloss: 0.84562\n",
            "[60]\ttraining's binary_logloss: 0.178531\tvalid_1's binary_logloss: 0.813001\n",
            "[70]\ttraining's binary_logloss: 0.173524\tvalid_1's binary_logloss: 0.790138\n",
            "[80]\ttraining's binary_logloss: 0.16892\tvalid_1's binary_logloss: 0.763753\n",
            "[90]\ttraining's binary_logloss: 0.164915\tvalid_1's binary_logloss: 0.74271\n",
            "[100]\ttraining's binary_logloss: 0.161315\tvalid_1's binary_logloss: 0.723288\n",
            "[110]\ttraining's binary_logloss: 0.158038\tvalid_1's binary_logloss: 0.706988\n",
            "[120]\ttraining's binary_logloss: 0.154685\tvalid_1's binary_logloss: 0.687993\n",
            "[130]\ttraining's binary_logloss: 0.151508\tvalid_1's binary_logloss: 0.671877\n",
            "[140]\ttraining's binary_logloss: 0.14844\tvalid_1's binary_logloss: 0.65572\n",
            "[150]\ttraining's binary_logloss: 0.145613\tvalid_1's binary_logloss: 0.640582\n",
            "[160]\ttraining's binary_logloss: 0.142993\tvalid_1's binary_logloss: 0.627193\n",
            "[170]\ttraining's binary_logloss: 0.140388\tvalid_1's binary_logloss: 0.61352\n",
            "[180]\ttraining's binary_logloss: 0.137926\tvalid_1's binary_logloss: 0.600392\n",
            "[190]\ttraining's binary_logloss: 0.135603\tvalid_1's binary_logloss: 0.588628\n",
            "[200]\ttraining's binary_logloss: 0.133062\tvalid_1's binary_logloss: 0.576122\n",
            "[210]\ttraining's binary_logloss: 0.130881\tvalid_1's binary_logloss: 0.56528\n",
            "[220]\ttraining's binary_logloss: 0.128501\tvalid_1's binary_logloss: 0.552288\n",
            "[230]\ttraining's binary_logloss: 0.126334\tvalid_1's binary_logloss: 0.540818\n",
            "[240]\ttraining's binary_logloss: 0.124322\tvalid_1's binary_logloss: 0.53082\n",
            "[250]\ttraining's binary_logloss: 0.122116\tvalid_1's binary_logloss: 0.521873\n",
            "[260]\ttraining's binary_logloss: 0.119986\tvalid_1's binary_logloss: 0.512344\n",
            "[270]\ttraining's binary_logloss: 0.117966\tvalid_1's binary_logloss: 0.502243\n",
            "[280]\ttraining's binary_logloss: 0.116082\tvalid_1's binary_logloss: 0.492405\n",
            "[290]\ttraining's binary_logloss: 0.114382\tvalid_1's binary_logloss: 0.483426\n",
            "[300]\ttraining's binary_logloss: 0.112345\tvalid_1's binary_logloss: 0.47229\n",
            "[310]\ttraining's binary_logloss: 0.110875\tvalid_1's binary_logloss: 0.465125\n",
            "[320]\ttraining's binary_logloss: 0.109084\tvalid_1's binary_logloss: 0.456485\n",
            "[330]\ttraining's binary_logloss: 0.10717\tvalid_1's binary_logloss: 0.447782\n",
            "[340]\ttraining's binary_logloss: 0.105461\tvalid_1's binary_logloss: 0.4385\n",
            "[350]\ttraining's binary_logloss: 0.10375\tvalid_1's binary_logloss: 0.43003\n",
            "[360]\ttraining's binary_logloss: 0.102211\tvalid_1's binary_logloss: 0.422329\n",
            "[370]\ttraining's binary_logloss: 0.100383\tvalid_1's binary_logloss: 0.413172\n",
            "[380]\ttraining's binary_logloss: 0.0987889\tvalid_1's binary_logloss: 0.405898\n",
            "[390]\ttraining's binary_logloss: 0.0972736\tvalid_1's binary_logloss: 0.399611\n",
            "[400]\ttraining's binary_logloss: 0.0958581\tvalid_1's binary_logloss: 0.392035\n",
            "[410]\ttraining's binary_logloss: 0.0944538\tvalid_1's binary_logloss: 0.384389\n",
            "[420]\ttraining's binary_logloss: 0.0929743\tvalid_1's binary_logloss: 0.377419\n",
            "[430]\ttraining's binary_logloss: 0.0914883\tvalid_1's binary_logloss: 0.370421\n",
            "[440]\ttraining's binary_logloss: 0.0902173\tvalid_1's binary_logloss: 0.364727\n",
            "[450]\ttraining's binary_logloss: 0.0889242\tvalid_1's binary_logloss: 0.358511\n",
            "[460]\ttraining's binary_logloss: 0.0873914\tvalid_1's binary_logloss: 0.351758\n",
            "[470]\ttraining's binary_logloss: 0.0861372\tvalid_1's binary_logloss: 0.345489\n",
            "[480]\ttraining's binary_logloss: 0.0850209\tvalid_1's binary_logloss: 0.340542\n",
            "[490]\ttraining's binary_logloss: 0.0837293\tvalid_1's binary_logloss: 0.334531\n",
            "[500]\ttraining's binary_logloss: 0.0825402\tvalid_1's binary_logloss: 0.329558\n",
            "[510]\ttraining's binary_logloss: 0.0815105\tvalid_1's binary_logloss: 0.325108\n",
            "[520]\ttraining's binary_logloss: 0.0801984\tvalid_1's binary_logloss: 0.319581\n",
            "[530]\ttraining's binary_logloss: 0.0791566\tvalid_1's binary_logloss: 0.314476\n",
            "[540]\ttraining's binary_logloss: 0.077879\tvalid_1's binary_logloss: 0.308753\n",
            "[550]\ttraining's binary_logloss: 0.0765504\tvalid_1's binary_logloss: 0.303431\n",
            "[560]\ttraining's binary_logloss: 0.0753399\tvalid_1's binary_logloss: 0.297897\n",
            "[570]\ttraining's binary_logloss: 0.0742918\tvalid_1's binary_logloss: 0.293085\n",
            "[580]\ttraining's binary_logloss: 0.0733193\tvalid_1's binary_logloss: 0.288672\n",
            "[590]\ttraining's binary_logloss: 0.0722017\tvalid_1's binary_logloss: 0.284212\n",
            "[600]\ttraining's binary_logloss: 0.0712553\tvalid_1's binary_logloss: 0.280048\n",
            "[610]\ttraining's binary_logloss: 0.0702431\tvalid_1's binary_logloss: 0.275583\n",
            "[620]\ttraining's binary_logloss: 0.0692603\tvalid_1's binary_logloss: 0.270615\n",
            "[630]\ttraining's binary_logloss: 0.0683215\tvalid_1's binary_logloss: 0.266134\n",
            "[640]\ttraining's binary_logloss: 0.0673492\tvalid_1's binary_logloss: 0.261858\n",
            "[650]\ttraining's binary_logloss: 0.0665328\tvalid_1's binary_logloss: 0.258519\n",
            "[660]\ttraining's binary_logloss: 0.0655306\tvalid_1's binary_logloss: 0.254081\n",
            "[670]\ttraining's binary_logloss: 0.0647663\tvalid_1's binary_logloss: 0.250518\n",
            "[680]\ttraining's binary_logloss: 0.0639125\tvalid_1's binary_logloss: 0.246802\n",
            "[690]\ttraining's binary_logloss: 0.0630514\tvalid_1's binary_logloss: 0.242891\n",
            "[700]\ttraining's binary_logloss: 0.0621463\tvalid_1's binary_logloss: 0.238705\n",
            "[710]\ttraining's binary_logloss: 0.0611843\tvalid_1's binary_logloss: 0.234237\n",
            "[720]\ttraining's binary_logloss: 0.0604126\tvalid_1's binary_logloss: 0.231384\n",
            "[730]\ttraining's binary_logloss: 0.0595585\tvalid_1's binary_logloss: 0.228163\n",
            "[740]\ttraining's binary_logloss: 0.0587281\tvalid_1's binary_logloss: 0.224382\n",
            "[750]\ttraining's binary_logloss: 0.0578831\tvalid_1's binary_logloss: 0.221355\n",
            "[760]\ttraining's binary_logloss: 0.057125\tvalid_1's binary_logloss: 0.218535\n",
            "[770]\ttraining's binary_logloss: 0.0564016\tvalid_1's binary_logloss: 0.215886\n",
            "[780]\ttraining's binary_logloss: 0.0556247\tvalid_1's binary_logloss: 0.212641\n",
            "[790]\ttraining's binary_logloss: 0.0546779\tvalid_1's binary_logloss: 0.209416\n",
            "[800]\ttraining's binary_logloss: 0.053899\tvalid_1's binary_logloss: 0.206036\n",
            "[810]\ttraining's binary_logloss: 0.0531899\tvalid_1's binary_logloss: 0.202717\n",
            "[820]\ttraining's binary_logloss: 0.0524616\tvalid_1's binary_logloss: 0.199963\n",
            "[830]\ttraining's binary_logloss: 0.0517122\tvalid_1's binary_logloss: 0.196802\n",
            "[840]\ttraining's binary_logloss: 0.0510031\tvalid_1's binary_logloss: 0.193494\n",
            "[850]\ttraining's binary_logloss: 0.050314\tvalid_1's binary_logloss: 0.190889\n",
            "[860]\ttraining's binary_logloss: 0.0496423\tvalid_1's binary_logloss: 0.18794\n",
            "[870]\ttraining's binary_logloss: 0.0489463\tvalid_1's binary_logloss: 0.185375\n",
            "[880]\ttraining's binary_logloss: 0.0482582\tvalid_1's binary_logloss: 0.182391\n",
            "[890]\ttraining's binary_logloss: 0.0476352\tvalid_1's binary_logloss: 0.180138\n",
            "[900]\ttraining's binary_logloss: 0.0469635\tvalid_1's binary_logloss: 0.177077\n",
            "[910]\ttraining's binary_logloss: 0.0463218\tvalid_1's binary_logloss: 0.174684\n",
            "[920]\ttraining's binary_logloss: 0.0457452\tvalid_1's binary_logloss: 0.172427\n",
            "[930]\ttraining's binary_logloss: 0.0450292\tvalid_1's binary_logloss: 0.169617\n",
            "[940]\ttraining's binary_logloss: 0.044392\tvalid_1's binary_logloss: 0.166938\n",
            "[950]\ttraining's binary_logloss: 0.0437947\tvalid_1's binary_logloss: 0.164219\n",
            "[960]\ttraining's binary_logloss: 0.0431873\tvalid_1's binary_logloss: 0.162229\n",
            "[970]\ttraining's binary_logloss: 0.042672\tvalid_1's binary_logloss: 0.160346\n",
            "[980]\ttraining's binary_logloss: 0.0421053\tvalid_1's binary_logloss: 0.157951\n",
            "[990]\ttraining's binary_logloss: 0.0415933\tvalid_1's binary_logloss: 0.155852\n",
            "[1000]\ttraining's binary_logloss: 0.040968\tvalid_1's binary_logloss: 0.153492\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.040968\tvalid_1's binary_logloss: 0.153492\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:49:23,479] Trial 35 finished with value: 0.1534920082098732 and parameters: {'max_bin': 334, 'num_leaves': 36}. Best is trial 19 with value: 0.0046284648643910705.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.218306\tvalid_1's binary_logloss: 1.00896\n",
            "[20]\ttraining's binary_logloss: 0.196726\tvalid_1's binary_logloss: 0.90272\n",
            "[30]\ttraining's binary_logloss: 0.182807\tvalid_1's binary_logloss: 0.835991\n",
            "[40]\ttraining's binary_logloss: 0.171414\tvalid_1's binary_logloss: 0.773013\n",
            "[50]\ttraining's binary_logloss: 0.161842\tvalid_1's binary_logloss: 0.72171\n",
            "[60]\ttraining's binary_logloss: 0.15344\tvalid_1's binary_logloss: 0.679977\n",
            "[70]\ttraining's binary_logloss: 0.145736\tvalid_1's binary_logloss: 0.639472\n",
            "[80]\ttraining's binary_logloss: 0.138871\tvalid_1's binary_logloss: 0.603049\n",
            "[90]\ttraining's binary_logloss: 0.132989\tvalid_1's binary_logloss: 0.575076\n",
            "[100]\ttraining's binary_logloss: 0.12724\tvalid_1's binary_logloss: 0.547117\n",
            "[110]\ttraining's binary_logloss: 0.122093\tvalid_1's binary_logloss: 0.520814\n",
            "[120]\ttraining's binary_logloss: 0.117521\tvalid_1's binary_logloss: 0.497112\n",
            "[130]\ttraining's binary_logloss: 0.113286\tvalid_1's binary_logloss: 0.475315\n",
            "[140]\ttraining's binary_logloss: 0.109404\tvalid_1's binary_logloss: 0.456528\n",
            "[150]\ttraining's binary_logloss: 0.105643\tvalid_1's binary_logloss: 0.437318\n",
            "[160]\ttraining's binary_logloss: 0.102017\tvalid_1's binary_logloss: 0.418755\n",
            "[170]\ttraining's binary_logloss: 0.0984035\tvalid_1's binary_logloss: 0.402715\n",
            "[180]\ttraining's binary_logloss: 0.0949738\tvalid_1's binary_logloss: 0.388074\n",
            "[190]\ttraining's binary_logloss: 0.0919433\tvalid_1's binary_logloss: 0.374745\n",
            "[200]\ttraining's binary_logloss: 0.0891257\tvalid_1's binary_logloss: 0.361372\n",
            "[210]\ttraining's binary_logloss: 0.0864501\tvalid_1's binary_logloss: 0.348616\n",
            "[220]\ttraining's binary_logloss: 0.0839407\tvalid_1's binary_logloss: 0.337546\n",
            "[230]\ttraining's binary_logloss: 0.0813705\tvalid_1's binary_logloss: 0.32614\n",
            "[240]\ttraining's binary_logloss: 0.0788657\tvalid_1's binary_logloss: 0.314229\n",
            "[250]\ttraining's binary_logloss: 0.0765476\tvalid_1's binary_logloss: 0.30513\n",
            "[260]\ttraining's binary_logloss: 0.0744073\tvalid_1's binary_logloss: 0.295261\n",
            "[270]\ttraining's binary_logloss: 0.0721976\tvalid_1's binary_logloss: 0.286278\n",
            "[280]\ttraining's binary_logloss: 0.0699118\tvalid_1's binary_logloss: 0.27518\n",
            "[290]\ttraining's binary_logloss: 0.0677941\tvalid_1's binary_logloss: 0.266202\n",
            "[300]\ttraining's binary_logloss: 0.0656984\tvalid_1's binary_logloss: 0.257071\n",
            "[310]\ttraining's binary_logloss: 0.0639216\tvalid_1's binary_logloss: 0.249908\n",
            "[320]\ttraining's binary_logloss: 0.0622069\tvalid_1's binary_logloss: 0.242816\n",
            "[330]\ttraining's binary_logloss: 0.0606235\tvalid_1's binary_logloss: 0.236587\n",
            "[340]\ttraining's binary_logloss: 0.0588146\tvalid_1's binary_logloss: 0.229881\n",
            "[350]\ttraining's binary_logloss: 0.0570252\tvalid_1's binary_logloss: 0.22222\n",
            "[360]\ttraining's binary_logloss: 0.0554206\tvalid_1's binary_logloss: 0.215699\n",
            "[370]\ttraining's binary_logloss: 0.0540937\tvalid_1's binary_logloss: 0.210479\n",
            "[380]\ttraining's binary_logloss: 0.0523727\tvalid_1's binary_logloss: 0.203173\n",
            "[390]\ttraining's binary_logloss: 0.0508683\tvalid_1's binary_logloss: 0.197265\n",
            "[400]\ttraining's binary_logloss: 0.0495052\tvalid_1's binary_logloss: 0.191346\n",
            "[410]\ttraining's binary_logloss: 0.0482137\tvalid_1's binary_logloss: 0.186481\n",
            "[420]\ttraining's binary_logloss: 0.0467217\tvalid_1's binary_logloss: 0.180674\n",
            "[430]\ttraining's binary_logloss: 0.0453929\tvalid_1's binary_logloss: 0.175487\n",
            "[440]\ttraining's binary_logloss: 0.0440932\tvalid_1's binary_logloss: 0.170423\n",
            "[450]\ttraining's binary_logloss: 0.0427418\tvalid_1's binary_logloss: 0.165359\n",
            "[460]\ttraining's binary_logloss: 0.0413806\tvalid_1's binary_logloss: 0.159717\n",
            "[470]\ttraining's binary_logloss: 0.0401858\tvalid_1's binary_logloss: 0.155354\n",
            "[480]\ttraining's binary_logloss: 0.0389783\tvalid_1's binary_logloss: 0.149968\n",
            "[490]\ttraining's binary_logloss: 0.0378586\tvalid_1's binary_logloss: 0.145502\n",
            "[500]\ttraining's binary_logloss: 0.036668\tvalid_1's binary_logloss: 0.14021\n",
            "[510]\ttraining's binary_logloss: 0.0355685\tvalid_1's binary_logloss: 0.13514\n",
            "[520]\ttraining's binary_logloss: 0.0346223\tvalid_1's binary_logloss: 0.131686\n",
            "[530]\ttraining's binary_logloss: 0.0336252\tvalid_1's binary_logloss: 0.127852\n",
            "[540]\ttraining's binary_logloss: 0.0326995\tvalid_1's binary_logloss: 0.123975\n",
            "[550]\ttraining's binary_logloss: 0.0317751\tvalid_1's binary_logloss: 0.119914\n",
            "[560]\ttraining's binary_logloss: 0.0309033\tvalid_1's binary_logloss: 0.116013\n",
            "[570]\ttraining's binary_logloss: 0.030141\tvalid_1's binary_logloss: 0.113342\n",
            "[580]\ttraining's binary_logloss: 0.029412\tvalid_1's binary_logloss: 0.11068\n",
            "[590]\ttraining's binary_logloss: 0.0286169\tvalid_1's binary_logloss: 0.107227\n",
            "[600]\ttraining's binary_logloss: 0.0278108\tvalid_1's binary_logloss: 0.1039\n",
            "[610]\ttraining's binary_logloss: 0.0270207\tvalid_1's binary_logloss: 0.100774\n",
            "[620]\ttraining's binary_logloss: 0.0263061\tvalid_1's binary_logloss: 0.0981442\n",
            "[630]\ttraining's binary_logloss: 0.0255241\tvalid_1's binary_logloss: 0.0949397\n",
            "[640]\ttraining's binary_logloss: 0.0248932\tvalid_1's binary_logloss: 0.0922532\n",
            "[650]\ttraining's binary_logloss: 0.0241512\tvalid_1's binary_logloss: 0.0893256\n",
            "[660]\ttraining's binary_logloss: 0.0235158\tvalid_1's binary_logloss: 0.0869872\n",
            "[670]\ttraining's binary_logloss: 0.0227162\tvalid_1's binary_logloss: 0.0838421\n",
            "[680]\ttraining's binary_logloss: 0.0220395\tvalid_1's binary_logloss: 0.081194\n",
            "[690]\ttraining's binary_logloss: 0.0214143\tvalid_1's binary_logloss: 0.0785136\n",
            "[700]\ttraining's binary_logloss: 0.0208275\tvalid_1's binary_logloss: 0.0763127\n",
            "[710]\ttraining's binary_logloss: 0.0201934\tvalid_1's binary_logloss: 0.0736133\n",
            "[720]\ttraining's binary_logloss: 0.0195618\tvalid_1's binary_logloss: 0.0710392\n",
            "[730]\ttraining's binary_logloss: 0.018999\tvalid_1's binary_logloss: 0.0689498\n",
            "[740]\ttraining's binary_logloss: 0.0184259\tvalid_1's binary_logloss: 0.0666206\n",
            "[750]\ttraining's binary_logloss: 0.0179587\tvalid_1's binary_logloss: 0.0649198\n",
            "[760]\ttraining's binary_logloss: 0.0174864\tvalid_1's binary_logloss: 0.0631746\n",
            "[770]\ttraining's binary_logloss: 0.0170512\tvalid_1's binary_logloss: 0.0616426\n",
            "[780]\ttraining's binary_logloss: 0.0165177\tvalid_1's binary_logloss: 0.0596604\n",
            "[790]\ttraining's binary_logloss: 0.0159899\tvalid_1's binary_logloss: 0.0578064\n",
            "[800]\ttraining's binary_logloss: 0.0155261\tvalid_1's binary_logloss: 0.0561057\n",
            "[810]\ttraining's binary_logloss: 0.0150765\tvalid_1's binary_logloss: 0.0544727\n",
            "[820]\ttraining's binary_logloss: 0.0146777\tvalid_1's binary_logloss: 0.0531272\n",
            "[830]\ttraining's binary_logloss: 0.0143022\tvalid_1's binary_logloss: 0.0519041\n",
            "[840]\ttraining's binary_logloss: 0.0139481\tvalid_1's binary_logloss: 0.0506596\n",
            "[850]\ttraining's binary_logloss: 0.0135585\tvalid_1's binary_logloss: 0.0492389\n",
            "[860]\ttraining's binary_logloss: 0.0132407\tvalid_1's binary_logloss: 0.0482025\n",
            "[870]\ttraining's binary_logloss: 0.012876\tvalid_1's binary_logloss: 0.046868\n",
            "[880]\ttraining's binary_logloss: 0.0125533\tvalid_1's binary_logloss: 0.0456032\n",
            "[890]\ttraining's binary_logloss: 0.0122247\tvalid_1's binary_logloss: 0.0444552\n",
            "[900]\ttraining's binary_logloss: 0.0118745\tvalid_1's binary_logloss: 0.0431294\n",
            "[910]\ttraining's binary_logloss: 0.011538\tvalid_1's binary_logloss: 0.0418848\n",
            "[920]\ttraining's binary_logloss: 0.0112196\tvalid_1's binary_logloss: 0.0406521\n",
            "[930]\ttraining's binary_logloss: 0.0109066\tvalid_1's binary_logloss: 0.0395085\n",
            "[940]\ttraining's binary_logloss: 0.0106093\tvalid_1's binary_logloss: 0.038447\n",
            "[950]\ttraining's binary_logloss: 0.010332\tvalid_1's binary_logloss: 0.0375367\n",
            "[960]\ttraining's binary_logloss: 0.0100939\tvalid_1's binary_logloss: 0.0366332\n",
            "[970]\ttraining's binary_logloss: 0.0098575\tvalid_1's binary_logloss: 0.0358483\n",
            "[980]\ttraining's binary_logloss: 0.00961705\tvalid_1's binary_logloss: 0.0348694\n",
            "[990]\ttraining's binary_logloss: 0.00931313\tvalid_1's binary_logloss: 0.0337833\n",
            "[1000]\ttraining's binary_logloss: 0.00909066\tvalid_1's binary_logloss: 0.0329903\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.00909066\tvalid_1's binary_logloss: 0.0329903\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:49:32,045] Trial 36 finished with value: 0.03299029657209078 and parameters: {'max_bin': 360, 'num_leaves': 74}. Best is trial 19 with value: 0.0046284648643910705.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.220471\tvalid_1's binary_logloss: 1.02162\n",
            "[20]\ttraining's binary_logloss: 0.200252\tvalid_1's binary_logloss: 0.920492\n",
            "[30]\ttraining's binary_logloss: 0.187194\tvalid_1's binary_logloss: 0.86042\n",
            "[40]\ttraining's binary_logloss: 0.176874\tvalid_1's binary_logloss: 0.807216\n",
            "[50]\ttraining's binary_logloss: 0.168036\tvalid_1's binary_logloss: 0.760938\n",
            "[60]\ttraining's binary_logloss: 0.160361\tvalid_1's binary_logloss: 0.722979\n",
            "[70]\ttraining's binary_logloss: 0.153442\tvalid_1's binary_logloss: 0.684269\n",
            "[80]\ttraining's binary_logloss: 0.147106\tvalid_1's binary_logloss: 0.651831\n",
            "[90]\ttraining's binary_logloss: 0.141713\tvalid_1's binary_logloss: 0.623428\n",
            "[100]\ttraining's binary_logloss: 0.137\tvalid_1's binary_logloss: 0.600659\n",
            "[110]\ttraining's binary_logloss: 0.132114\tvalid_1's binary_logloss: 0.576789\n",
            "[120]\ttraining's binary_logloss: 0.127694\tvalid_1's binary_logloss: 0.556182\n",
            "[130]\ttraining's binary_logloss: 0.123777\tvalid_1's binary_logloss: 0.533859\n",
            "[140]\ttraining's binary_logloss: 0.120133\tvalid_1's binary_logloss: 0.514557\n",
            "[150]\ttraining's binary_logloss: 0.116598\tvalid_1's binary_logloss: 0.496048\n",
            "[160]\ttraining's binary_logloss: 0.113578\tvalid_1's binary_logloss: 0.482031\n",
            "[170]\ttraining's binary_logloss: 0.110286\tvalid_1's binary_logloss: 0.465547\n",
            "[180]\ttraining's binary_logloss: 0.10707\tvalid_1's binary_logloss: 0.450103\n",
            "[190]\ttraining's binary_logloss: 0.10423\tvalid_1's binary_logloss: 0.437084\n",
            "[200]\ttraining's binary_logloss: 0.1014\tvalid_1's binary_logloss: 0.423711\n",
            "[210]\ttraining's binary_logloss: 0.0987456\tvalid_1's binary_logloss: 0.410049\n",
            "[220]\ttraining's binary_logloss: 0.0963094\tvalid_1's binary_logloss: 0.399193\n",
            "[230]\ttraining's binary_logloss: 0.0937188\tvalid_1's binary_logloss: 0.385611\n",
            "[240]\ttraining's binary_logloss: 0.0912467\tvalid_1's binary_logloss: 0.373772\n",
            "[250]\ttraining's binary_logloss: 0.0889777\tvalid_1's binary_logloss: 0.363105\n",
            "[260]\ttraining's binary_logloss: 0.0865883\tvalid_1's binary_logloss: 0.352389\n",
            "[270]\ttraining's binary_logloss: 0.0846961\tvalid_1's binary_logloss: 0.344247\n",
            "[280]\ttraining's binary_logloss: 0.0826223\tvalid_1's binary_logloss: 0.334895\n",
            "[290]\ttraining's binary_logloss: 0.0802956\tvalid_1's binary_logloss: 0.325395\n",
            "[300]\ttraining's binary_logloss: 0.0782234\tvalid_1's binary_logloss: 0.316553\n",
            "[310]\ttraining's binary_logloss: 0.0763436\tvalid_1's binary_logloss: 0.308293\n",
            "[320]\ttraining's binary_logloss: 0.0745822\tvalid_1's binary_logloss: 0.300748\n",
            "[330]\ttraining's binary_logloss: 0.0724924\tvalid_1's binary_logloss: 0.290655\n",
            "[340]\ttraining's binary_logloss: 0.0706127\tvalid_1's binary_logloss: 0.282566\n",
            "[350]\ttraining's binary_logloss: 0.0686767\tvalid_1's binary_logloss: 0.274052\n",
            "[360]\ttraining's binary_logloss: 0.0669126\tvalid_1's binary_logloss: 0.26674\n",
            "[370]\ttraining's binary_logloss: 0.0652339\tvalid_1's binary_logloss: 0.259699\n",
            "[380]\ttraining's binary_logloss: 0.0637001\tvalid_1's binary_logloss: 0.253109\n",
            "[390]\ttraining's binary_logloss: 0.0621636\tvalid_1's binary_logloss: 0.246122\n",
            "[400]\ttraining's binary_logloss: 0.0604566\tvalid_1's binary_logloss: 0.238106\n",
            "[410]\ttraining's binary_logloss: 0.05901\tvalid_1's binary_logloss: 0.231782\n",
            "[420]\ttraining's binary_logloss: 0.0575096\tvalid_1's binary_logloss: 0.225607\n",
            "[430]\ttraining's binary_logloss: 0.0559396\tvalid_1's binary_logloss: 0.218238\n",
            "[440]\ttraining's binary_logloss: 0.0544651\tvalid_1's binary_logloss: 0.21052\n",
            "[450]\ttraining's binary_logloss: 0.0530647\tvalid_1's binary_logloss: 0.204509\n",
            "[460]\ttraining's binary_logloss: 0.051913\tvalid_1's binary_logloss: 0.199761\n",
            "[470]\ttraining's binary_logloss: 0.0507941\tvalid_1's binary_logloss: 0.195315\n",
            "[480]\ttraining's binary_logloss: 0.0495878\tvalid_1's binary_logloss: 0.190104\n",
            "[490]\ttraining's binary_logloss: 0.0483138\tvalid_1's binary_logloss: 0.184815\n",
            "[500]\ttraining's binary_logloss: 0.0471836\tvalid_1's binary_logloss: 0.18004\n",
            "[510]\ttraining's binary_logloss: 0.0459298\tvalid_1's binary_logloss: 0.174673\n",
            "[520]\ttraining's binary_logloss: 0.0449903\tvalid_1's binary_logloss: 0.170922\n",
            "[530]\ttraining's binary_logloss: 0.0438087\tvalid_1's binary_logloss: 0.165628\n",
            "[540]\ttraining's binary_logloss: 0.042783\tvalid_1's binary_logloss: 0.162131\n",
            "[550]\ttraining's binary_logloss: 0.0417084\tvalid_1's binary_logloss: 0.157887\n",
            "[560]\ttraining's binary_logloss: 0.0407742\tvalid_1's binary_logloss: 0.153657\n",
            "[570]\ttraining's binary_logloss: 0.0399507\tvalid_1's binary_logloss: 0.15031\n",
            "[580]\ttraining's binary_logloss: 0.0389838\tvalid_1's binary_logloss: 0.146455\n",
            "[590]\ttraining's binary_logloss: 0.0379656\tvalid_1's binary_logloss: 0.14234\n",
            "[600]\ttraining's binary_logloss: 0.0370551\tvalid_1's binary_logloss: 0.138995\n",
            "[610]\ttraining's binary_logloss: 0.0359613\tvalid_1's binary_logloss: 0.134734\n",
            "[620]\ttraining's binary_logloss: 0.0350766\tvalid_1's binary_logloss: 0.131181\n",
            "[630]\ttraining's binary_logloss: 0.0342159\tvalid_1's binary_logloss: 0.12776\n",
            "[640]\ttraining's binary_logloss: 0.0333977\tvalid_1's binary_logloss: 0.124514\n",
            "[650]\ttraining's binary_logloss: 0.0326811\tvalid_1's binary_logloss: 0.121298\n",
            "[660]\ttraining's binary_logloss: 0.0320225\tvalid_1's binary_logloss: 0.118912\n",
            "[670]\ttraining's binary_logloss: 0.0313896\tvalid_1's binary_logloss: 0.116421\n",
            "[680]\ttraining's binary_logloss: 0.0308269\tvalid_1's binary_logloss: 0.114327\n",
            "[690]\ttraining's binary_logloss: 0.0299765\tvalid_1's binary_logloss: 0.111117\n",
            "[700]\ttraining's binary_logloss: 0.0292406\tvalid_1's binary_logloss: 0.108731\n",
            "[710]\ttraining's binary_logloss: 0.0285325\tvalid_1's binary_logloss: 0.105907\n",
            "[720]\ttraining's binary_logloss: 0.0278142\tvalid_1's binary_logloss: 0.103171\n",
            "[730]\ttraining's binary_logloss: 0.0270509\tvalid_1's binary_logloss: 0.100446\n",
            "[740]\ttraining's binary_logloss: 0.0263903\tvalid_1's binary_logloss: 0.0978894\n",
            "[750]\ttraining's binary_logloss: 0.0257362\tvalid_1's binary_logloss: 0.0953445\n",
            "[760]\ttraining's binary_logloss: 0.0251751\tvalid_1's binary_logloss: 0.0931718\n",
            "[770]\ttraining's binary_logloss: 0.0244946\tvalid_1's binary_logloss: 0.0908204\n",
            "[780]\ttraining's binary_logloss: 0.0238722\tvalid_1's binary_logloss: 0.0881754\n",
            "[790]\ttraining's binary_logloss: 0.0232667\tvalid_1's binary_logloss: 0.0860175\n",
            "[800]\ttraining's binary_logloss: 0.0226998\tvalid_1's binary_logloss: 0.0833771\n",
            "[810]\ttraining's binary_logloss: 0.0221088\tvalid_1's binary_logloss: 0.0810165\n",
            "[820]\ttraining's binary_logloss: 0.0215106\tvalid_1's binary_logloss: 0.0785628\n",
            "[830]\ttraining's binary_logloss: 0.0210377\tvalid_1's binary_logloss: 0.0768582\n",
            "[840]\ttraining's binary_logloss: 0.0206266\tvalid_1's binary_logloss: 0.0753892\n",
            "[850]\ttraining's binary_logloss: 0.0200492\tvalid_1's binary_logloss: 0.0732592\n",
            "[860]\ttraining's binary_logloss: 0.0195751\tvalid_1's binary_logloss: 0.0715329\n",
            "[870]\ttraining's binary_logloss: 0.0190445\tvalid_1's binary_logloss: 0.0696638\n",
            "[880]\ttraining's binary_logloss: 0.0186212\tvalid_1's binary_logloss: 0.0681047\n",
            "[890]\ttraining's binary_logloss: 0.0181398\tvalid_1's binary_logloss: 0.0663604\n",
            "[900]\ttraining's binary_logloss: 0.0177408\tvalid_1's binary_logloss: 0.0646785\n",
            "[910]\ttraining's binary_logloss: 0.0172704\tvalid_1's binary_logloss: 0.0629061\n",
            "[920]\ttraining's binary_logloss: 0.0168159\tvalid_1's binary_logloss: 0.0613249\n",
            "[930]\ttraining's binary_logloss: 0.0164348\tvalid_1's binary_logloss: 0.0600719\n",
            "[940]\ttraining's binary_logloss: 0.0160684\tvalid_1's binary_logloss: 0.0588335\n",
            "[950]\ttraining's binary_logloss: 0.0156457\tvalid_1's binary_logloss: 0.0573909\n",
            "[960]\ttraining's binary_logloss: 0.0151842\tvalid_1's binary_logloss: 0.05565\n",
            "[970]\ttraining's binary_logloss: 0.0147997\tvalid_1's binary_logloss: 0.0542505\n",
            "[980]\ttraining's binary_logloss: 0.0144012\tvalid_1's binary_logloss: 0.0525178\n",
            "[990]\ttraining's binary_logloss: 0.0140624\tvalid_1's binary_logloss: 0.0512832\n",
            "[1000]\ttraining's binary_logloss: 0.0137084\tvalid_1's binary_logloss: 0.0498756\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.0137084\tvalid_1's binary_logloss: 0.0498756\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:49:39,964] Trial 37 finished with value: 0.0498756413398959 and parameters: {'max_bin': 441, 'num_leaves': 63}. Best is trial 19 with value: 0.0046284648643910705.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.227009\tvalid_1's binary_logloss: 1.05919\n",
            "[20]\ttraining's binary_logloss: 0.210592\tvalid_1's binary_logloss: 0.979303\n",
            "[30]\ttraining's binary_logloss: 0.200549\tvalid_1's binary_logloss: 0.928695\n",
            "[40]\ttraining's binary_logloss: 0.192766\tvalid_1's binary_logloss: 0.891472\n",
            "[50]\ttraining's binary_logloss: 0.186653\tvalid_1's binary_logloss: 0.85924\n",
            "[60]\ttraining's binary_logloss: 0.181143\tvalid_1's binary_logloss: 0.830643\n",
            "[70]\ttraining's binary_logloss: 0.176259\tvalid_1's binary_logloss: 0.80139\n",
            "[80]\ttraining's binary_logloss: 0.17193\tvalid_1's binary_logloss: 0.776877\n",
            "[90]\ttraining's binary_logloss: 0.168017\tvalid_1's binary_logloss: 0.757859\n",
            "[100]\ttraining's binary_logloss: 0.16438\tvalid_1's binary_logloss: 0.739177\n",
            "[110]\ttraining's binary_logloss: 0.161085\tvalid_1's binary_logloss: 0.724339\n",
            "[120]\ttraining's binary_logloss: 0.157999\tvalid_1's binary_logloss: 0.708776\n",
            "[130]\ttraining's binary_logloss: 0.154895\tvalid_1's binary_logloss: 0.690044\n",
            "[140]\ttraining's binary_logloss: 0.151987\tvalid_1's binary_logloss: 0.677196\n",
            "[150]\ttraining's binary_logloss: 0.149261\tvalid_1's binary_logloss: 0.662732\n",
            "[160]\ttraining's binary_logloss: 0.146441\tvalid_1's binary_logloss: 0.648081\n",
            "[170]\ttraining's binary_logloss: 0.143686\tvalid_1's binary_logloss: 0.633182\n",
            "[180]\ttraining's binary_logloss: 0.141245\tvalid_1's binary_logloss: 0.620154\n",
            "[190]\ttraining's binary_logloss: 0.138872\tvalid_1's binary_logloss: 0.60809\n",
            "[200]\ttraining's binary_logloss: 0.136513\tvalid_1's binary_logloss: 0.596959\n",
            "[210]\ttraining's binary_logloss: 0.134388\tvalid_1's binary_logloss: 0.587209\n",
            "[220]\ttraining's binary_logloss: 0.132293\tvalid_1's binary_logloss: 0.576845\n",
            "[230]\ttraining's binary_logloss: 0.130146\tvalid_1's binary_logloss: 0.565151\n",
            "[240]\ttraining's binary_logloss: 0.128081\tvalid_1's binary_logloss: 0.555659\n",
            "[250]\ttraining's binary_logloss: 0.126059\tvalid_1's binary_logloss: 0.546869\n",
            "[260]\ttraining's binary_logloss: 0.124055\tvalid_1's binary_logloss: 0.537091\n",
            "[270]\ttraining's binary_logloss: 0.122243\tvalid_1's binary_logloss: 0.526374\n",
            "[280]\ttraining's binary_logloss: 0.120376\tvalid_1's binary_logloss: 0.518576\n",
            "[290]\ttraining's binary_logloss: 0.118355\tvalid_1's binary_logloss: 0.507157\n",
            "[300]\ttraining's binary_logloss: 0.116617\tvalid_1's binary_logloss: 0.498629\n",
            "[310]\ttraining's binary_logloss: 0.11486\tvalid_1's binary_logloss: 0.488873\n",
            "[320]\ttraining's binary_logloss: 0.113314\tvalid_1's binary_logloss: 0.481243\n",
            "[330]\ttraining's binary_logloss: 0.111813\tvalid_1's binary_logloss: 0.472955\n",
            "[340]\ttraining's binary_logloss: 0.110193\tvalid_1's binary_logloss: 0.465155\n",
            "[350]\ttraining's binary_logloss: 0.108665\tvalid_1's binary_logloss: 0.457708\n",
            "[360]\ttraining's binary_logloss: 0.10707\tvalid_1's binary_logloss: 0.448664\n",
            "[370]\ttraining's binary_logloss: 0.105561\tvalid_1's binary_logloss: 0.441473\n",
            "[380]\ttraining's binary_logloss: 0.103886\tvalid_1's binary_logloss: 0.43323\n",
            "[390]\ttraining's binary_logloss: 0.102405\tvalid_1's binary_logloss: 0.426231\n",
            "[400]\ttraining's binary_logloss: 0.101027\tvalid_1's binary_logloss: 0.420125\n",
            "[410]\ttraining's binary_logloss: 0.0997224\tvalid_1's binary_logloss: 0.414269\n",
            "[420]\ttraining's binary_logloss: 0.0985432\tvalid_1's binary_logloss: 0.409061\n",
            "[430]\ttraining's binary_logloss: 0.0972009\tvalid_1's binary_logloss: 0.402854\n",
            "[440]\ttraining's binary_logloss: 0.0957041\tvalid_1's binary_logloss: 0.394479\n",
            "[450]\ttraining's binary_logloss: 0.0942847\tvalid_1's binary_logloss: 0.386877\n",
            "[460]\ttraining's binary_logloss: 0.0930299\tvalid_1's binary_logloss: 0.381211\n",
            "[470]\ttraining's binary_logloss: 0.0917202\tvalid_1's binary_logloss: 0.375054\n",
            "[480]\ttraining's binary_logloss: 0.0903193\tvalid_1's binary_logloss: 0.368242\n",
            "[490]\ttraining's binary_logloss: 0.0891024\tvalid_1's binary_logloss: 0.361743\n",
            "[500]\ttraining's binary_logloss: 0.0879116\tvalid_1's binary_logloss: 0.357134\n",
            "[510]\ttraining's binary_logloss: 0.0866358\tvalid_1's binary_logloss: 0.351139\n",
            "[520]\ttraining's binary_logloss: 0.085454\tvalid_1's binary_logloss: 0.345872\n",
            "[530]\ttraining's binary_logloss: 0.0842403\tvalid_1's binary_logloss: 0.340168\n",
            "[540]\ttraining's binary_logloss: 0.0830642\tvalid_1's binary_logloss: 0.335127\n",
            "[550]\ttraining's binary_logloss: 0.0820025\tvalid_1's binary_logloss: 0.329805\n",
            "[560]\ttraining's binary_logloss: 0.0809433\tvalid_1's binary_logloss: 0.324833\n",
            "[570]\ttraining's binary_logloss: 0.0799665\tvalid_1's binary_logloss: 0.320623\n",
            "[580]\ttraining's binary_logloss: 0.0788873\tvalid_1's binary_logloss: 0.31596\n",
            "[590]\ttraining's binary_logloss: 0.0778307\tvalid_1's binary_logloss: 0.310452\n",
            "[600]\ttraining's binary_logloss: 0.0768298\tvalid_1's binary_logloss: 0.305287\n",
            "[610]\ttraining's binary_logloss: 0.0758161\tvalid_1's binary_logloss: 0.300484\n",
            "[620]\ttraining's binary_logloss: 0.0748079\tvalid_1's binary_logloss: 0.295675\n",
            "[630]\ttraining's binary_logloss: 0.0738594\tvalid_1's binary_logloss: 0.29123\n",
            "[640]\ttraining's binary_logloss: 0.0728667\tvalid_1's binary_logloss: 0.286721\n",
            "[650]\ttraining's binary_logloss: 0.0719558\tvalid_1's binary_logloss: 0.282827\n",
            "[660]\ttraining's binary_logloss: 0.0710759\tvalid_1's binary_logloss: 0.279017\n",
            "[670]\ttraining's binary_logloss: 0.0701915\tvalid_1's binary_logloss: 0.274765\n",
            "[680]\ttraining's binary_logloss: 0.0693693\tvalid_1's binary_logloss: 0.270952\n",
            "[690]\ttraining's binary_logloss: 0.0683923\tvalid_1's binary_logloss: 0.265871\n",
            "[700]\ttraining's binary_logloss: 0.0674709\tvalid_1's binary_logloss: 0.261782\n",
            "[710]\ttraining's binary_logloss: 0.0666436\tvalid_1's binary_logloss: 0.257905\n",
            "[720]\ttraining's binary_logloss: 0.065748\tvalid_1's binary_logloss: 0.254509\n",
            "[730]\ttraining's binary_logloss: 0.0649267\tvalid_1's binary_logloss: 0.250667\n",
            "[740]\ttraining's binary_logloss: 0.0640992\tvalid_1's binary_logloss: 0.247316\n",
            "[750]\ttraining's binary_logloss: 0.0633905\tvalid_1's binary_logloss: 0.244069\n",
            "[760]\ttraining's binary_logloss: 0.0627114\tvalid_1's binary_logloss: 0.241632\n",
            "[770]\ttraining's binary_logloss: 0.0619244\tvalid_1's binary_logloss: 0.23846\n",
            "[780]\ttraining's binary_logloss: 0.0612153\tvalid_1's binary_logloss: 0.23544\n",
            "[790]\ttraining's binary_logloss: 0.0603256\tvalid_1's binary_logloss: 0.231399\n",
            "[800]\ttraining's binary_logloss: 0.0594382\tvalid_1's binary_logloss: 0.227968\n",
            "[810]\ttraining's binary_logloss: 0.0587671\tvalid_1's binary_logloss: 0.225231\n",
            "[820]\ttraining's binary_logloss: 0.0579917\tvalid_1's binary_logloss: 0.222474\n",
            "[830]\ttraining's binary_logloss: 0.0572531\tvalid_1's binary_logloss: 0.219711\n",
            "[840]\ttraining's binary_logloss: 0.0565238\tvalid_1's binary_logloss: 0.216684\n",
            "[850]\ttraining's binary_logloss: 0.0557379\tvalid_1's binary_logloss: 0.213566\n",
            "[860]\ttraining's binary_logloss: 0.0550259\tvalid_1's binary_logloss: 0.210423\n",
            "[870]\ttraining's binary_logloss: 0.0542871\tvalid_1's binary_logloss: 0.207398\n",
            "[880]\ttraining's binary_logloss: 0.0536476\tvalid_1's binary_logloss: 0.204725\n",
            "[890]\ttraining's binary_logloss: 0.052982\tvalid_1's binary_logloss: 0.201916\n",
            "[900]\ttraining's binary_logloss: 0.0522978\tvalid_1's binary_logloss: 0.199306\n",
            "[910]\ttraining's binary_logloss: 0.0515098\tvalid_1's binary_logloss: 0.19552\n",
            "[920]\ttraining's binary_logloss: 0.0509449\tvalid_1's binary_logloss: 0.193349\n",
            "[930]\ttraining's binary_logloss: 0.050377\tvalid_1's binary_logloss: 0.191112\n",
            "[940]\ttraining's binary_logloss: 0.0496536\tvalid_1's binary_logloss: 0.188144\n",
            "[950]\ttraining's binary_logloss: 0.049075\tvalid_1's binary_logloss: 0.185259\n",
            "[960]\ttraining's binary_logloss: 0.0485557\tvalid_1's binary_logloss: 0.18292\n",
            "[970]\ttraining's binary_logloss: 0.0479697\tvalid_1's binary_logloss: 0.179729\n",
            "[980]\ttraining's binary_logloss: 0.0472859\tvalid_1's binary_logloss: 0.176695\n",
            "[990]\ttraining's binary_logloss: 0.0467119\tvalid_1's binary_logloss: 0.174313\n",
            "[1000]\ttraining's binary_logloss: 0.0461601\tvalid_1's binary_logloss: 0.172196\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.0461601\tvalid_1's binary_logloss: 0.172196\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:49:46,206] Trial 38 finished with value: 0.17219625828873986 and parameters: {'max_bin': 375, 'num_leaves': 33}. Best is trial 19 with value: 0.0046284648643910705.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 10 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.218569\tvalid_1's binary_logloss: 1.0089\n",
            "[20]\ttraining's binary_logloss: 0.197236\tvalid_1's binary_logloss: 0.903054\n",
            "[30]\ttraining's binary_logloss: 0.183346\tvalid_1's binary_logloss: 0.837906\n",
            "[40]\ttraining's binary_logloss: 0.17251\tvalid_1's binary_logloss: 0.779962\n",
            "[50]\ttraining's binary_logloss: 0.163131\tvalid_1's binary_logloss: 0.729505\n",
            "[60]\ttraining's binary_logloss: 0.15452\tvalid_1's binary_logloss: 0.685115\n",
            "[70]\ttraining's binary_logloss: 0.146852\tvalid_1's binary_logloss: 0.646805\n",
            "[80]\ttraining's binary_logloss: 0.140108\tvalid_1's binary_logloss: 0.60922\n",
            "[90]\ttraining's binary_logloss: 0.13432\tvalid_1's binary_logloss: 0.5793\n",
            "[100]\ttraining's binary_logloss: 0.129148\tvalid_1's binary_logloss: 0.555319\n",
            "[110]\ttraining's binary_logloss: 0.124446\tvalid_1's binary_logloss: 0.530334\n",
            "[120]\ttraining's binary_logloss: 0.119988\tvalid_1's binary_logloss: 0.507642\n",
            "[130]\ttraining's binary_logloss: 0.115835\tvalid_1's binary_logloss: 0.484949\n",
            "[140]\ttraining's binary_logloss: 0.112207\tvalid_1's binary_logloss: 0.467237\n",
            "[150]\ttraining's binary_logloss: 0.108351\tvalid_1's binary_logloss: 0.446864\n",
            "[160]\ttraining's binary_logloss: 0.105038\tvalid_1's binary_logloss: 0.432978\n",
            "[170]\ttraining's binary_logloss: 0.101482\tvalid_1's binary_logloss: 0.416622\n",
            "[180]\ttraining's binary_logloss: 0.0983411\tvalid_1's binary_logloss: 0.401174\n",
            "[190]\ttraining's binary_logloss: 0.0955747\tvalid_1's binary_logloss: 0.38843\n",
            "[200]\ttraining's binary_logloss: 0.0923255\tvalid_1's binary_logloss: 0.373199\n",
            "[210]\ttraining's binary_logloss: 0.0897426\tvalid_1's binary_logloss: 0.362254\n",
            "[220]\ttraining's binary_logloss: 0.0871353\tvalid_1's binary_logloss: 0.350519\n",
            "[230]\ttraining's binary_logloss: 0.0845913\tvalid_1's binary_logloss: 0.339286\n",
            "[240]\ttraining's binary_logloss: 0.0821153\tvalid_1's binary_logloss: 0.328479\n",
            "[250]\ttraining's binary_logloss: 0.0793393\tvalid_1's binary_logloss: 0.316144\n",
            "[260]\ttraining's binary_logloss: 0.0767174\tvalid_1's binary_logloss: 0.305773\n",
            "[270]\ttraining's binary_logloss: 0.0745026\tvalid_1's binary_logloss: 0.296285\n",
            "[280]\ttraining's binary_logloss: 0.072464\tvalid_1's binary_logloss: 0.288192\n",
            "[290]\ttraining's binary_logloss: 0.0703248\tvalid_1's binary_logloss: 0.280195\n",
            "[300]\ttraining's binary_logloss: 0.0682969\tvalid_1's binary_logloss: 0.271203\n",
            "[310]\ttraining's binary_logloss: 0.0662733\tvalid_1's binary_logloss: 0.262204\n",
            "[320]\ttraining's binary_logloss: 0.0646322\tvalid_1's binary_logloss: 0.254821\n",
            "[330]\ttraining's binary_logloss: 0.0629091\tvalid_1's binary_logloss: 0.248408\n",
            "[340]\ttraining's binary_logloss: 0.061149\tvalid_1's binary_logloss: 0.240121\n",
            "[350]\ttraining's binary_logloss: 0.0593128\tvalid_1's binary_logloss: 0.232384\n",
            "[360]\ttraining's binary_logloss: 0.0575366\tvalid_1's binary_logloss: 0.225486\n",
            "[370]\ttraining's binary_logloss: 0.0559913\tvalid_1's binary_logloss: 0.218863\n",
            "[380]\ttraining's binary_logloss: 0.0546809\tvalid_1's binary_logloss: 0.213056\n",
            "[390]\ttraining's binary_logloss: 0.0531038\tvalid_1's binary_logloss: 0.207263\n",
            "[400]\ttraining's binary_logloss: 0.0516083\tvalid_1's binary_logloss: 0.200193\n",
            "[410]\ttraining's binary_logloss: 0.050159\tvalid_1's binary_logloss: 0.19353\n",
            "[420]\ttraining's binary_logloss: 0.0486815\tvalid_1's binary_logloss: 0.187223\n",
            "[430]\ttraining's binary_logloss: 0.0474778\tvalid_1's binary_logloss: 0.182414\n",
            "[440]\ttraining's binary_logloss: 0.0460537\tvalid_1's binary_logloss: 0.176141\n",
            "[450]\ttraining's binary_logloss: 0.0446916\tvalid_1's binary_logloss: 0.170719\n",
            "[460]\ttraining's binary_logloss: 0.0431907\tvalid_1's binary_logloss: 0.164224\n",
            "[470]\ttraining's binary_logloss: 0.0416462\tvalid_1's binary_logloss: 0.157618\n",
            "[480]\ttraining's binary_logloss: 0.0404161\tvalid_1's binary_logloss: 0.152801\n",
            "[490]\ttraining's binary_logloss: 0.0394279\tvalid_1's binary_logloss: 0.149215\n",
            "[500]\ttraining's binary_logloss: 0.0384162\tvalid_1's binary_logloss: 0.145247\n",
            "[510]\ttraining's binary_logloss: 0.0373982\tvalid_1's binary_logloss: 0.140916\n",
            "[520]\ttraining's binary_logloss: 0.036185\tvalid_1's binary_logloss: 0.135589\n",
            "[530]\ttraining's binary_logloss: 0.0351339\tvalid_1's binary_logloss: 0.13168\n",
            "[540]\ttraining's binary_logloss: 0.034061\tvalid_1's binary_logloss: 0.127487\n",
            "[550]\ttraining's binary_logloss: 0.0330329\tvalid_1's binary_logloss: 0.12326\n",
            "[560]\ttraining's binary_logloss: 0.0320544\tvalid_1's binary_logloss: 0.119548\n",
            "[570]\ttraining's binary_logloss: 0.0311405\tvalid_1's binary_logloss: 0.116251\n",
            "[580]\ttraining's binary_logloss: 0.0301363\tvalid_1's binary_logloss: 0.112623\n",
            "[590]\ttraining's binary_logloss: 0.0292152\tvalid_1's binary_logloss: 0.10914\n",
            "[600]\ttraining's binary_logloss: 0.0283843\tvalid_1's binary_logloss: 0.106095\n",
            "[610]\ttraining's binary_logloss: 0.0275651\tvalid_1's binary_logloss: 0.102537\n",
            "[620]\ttraining's binary_logloss: 0.0267795\tvalid_1's binary_logloss: 0.0994349\n",
            "[630]\ttraining's binary_logloss: 0.0260851\tvalid_1's binary_logloss: 0.0967729\n",
            "[640]\ttraining's binary_logloss: 0.0254073\tvalid_1's binary_logloss: 0.0937333\n",
            "[650]\ttraining's binary_logloss: 0.0247527\tvalid_1's binary_logloss: 0.0913734\n",
            "[660]\ttraining's binary_logloss: 0.024039\tvalid_1's binary_logloss: 0.0885641\n",
            "[670]\ttraining's binary_logloss: 0.0233567\tvalid_1's binary_logloss: 0.0854773\n",
            "[680]\ttraining's binary_logloss: 0.0227559\tvalid_1's binary_logloss: 0.0830615\n",
            "[690]\ttraining's binary_logloss: 0.0221227\tvalid_1's binary_logloss: 0.080482\n",
            "[700]\ttraining's binary_logloss: 0.0215842\tvalid_1's binary_logloss: 0.0787039\n",
            "[710]\ttraining's binary_logloss: 0.0209747\tvalid_1's binary_logloss: 0.0765059\n",
            "[720]\ttraining's binary_logloss: 0.0204147\tvalid_1's binary_logloss: 0.0746424\n",
            "[730]\ttraining's binary_logloss: 0.0198032\tvalid_1's binary_logloss: 0.072353\n",
            "[740]\ttraining's binary_logloss: 0.0192566\tvalid_1's binary_logloss: 0.0704743\n",
            "[750]\ttraining's binary_logloss: 0.0187567\tvalid_1's binary_logloss: 0.0685946\n",
            "[760]\ttraining's binary_logloss: 0.0183291\tvalid_1's binary_logloss: 0.0671731\n",
            "[770]\ttraining's binary_logloss: 0.0178322\tvalid_1's binary_logloss: 0.0654343\n",
            "[780]\ttraining's binary_logloss: 0.0174047\tvalid_1's binary_logloss: 0.0636404\n",
            "[790]\ttraining's binary_logloss: 0.0169353\tvalid_1's binary_logloss: 0.0618295\n",
            "[800]\ttraining's binary_logloss: 0.0164383\tvalid_1's binary_logloss: 0.0598695\n",
            "[810]\ttraining's binary_logloss: 0.015981\tvalid_1's binary_logloss: 0.0582829\n",
            "[820]\ttraining's binary_logloss: 0.0155592\tvalid_1's binary_logloss: 0.0567774\n",
            "[830]\ttraining's binary_logloss: 0.0151707\tvalid_1's binary_logloss: 0.0552311\n",
            "[840]\ttraining's binary_logloss: 0.0146806\tvalid_1's binary_logloss: 0.0532225\n",
            "[850]\ttraining's binary_logloss: 0.0142999\tvalid_1's binary_logloss: 0.051891\n",
            "[860]\ttraining's binary_logloss: 0.0139464\tvalid_1's binary_logloss: 0.0505308\n",
            "[870]\ttraining's binary_logloss: 0.0136017\tvalid_1's binary_logloss: 0.0492129\n",
            "[880]\ttraining's binary_logloss: 0.0132525\tvalid_1's binary_logloss: 0.0480346\n",
            "[890]\ttraining's binary_logloss: 0.0128764\tvalid_1's binary_logloss: 0.0465112\n",
            "[900]\ttraining's binary_logloss: 0.0125638\tvalid_1's binary_logloss: 0.0453555\n",
            "[910]\ttraining's binary_logloss: 0.0122445\tvalid_1's binary_logloss: 0.0441502\n",
            "[920]\ttraining's binary_logloss: 0.0119483\tvalid_1's binary_logloss: 0.0429832\n",
            "[930]\ttraining's binary_logloss: 0.0116145\tvalid_1's binary_logloss: 0.0416372\n",
            "[940]\ttraining's binary_logloss: 0.0112825\tvalid_1's binary_logloss: 0.0404102\n",
            "[950]\ttraining's binary_logloss: 0.0109921\tvalid_1's binary_logloss: 0.0393495\n",
            "[960]\ttraining's binary_logloss: 0.0107181\tvalid_1's binary_logloss: 0.0384482\n",
            "[970]\ttraining's binary_logloss: 0.0104103\tvalid_1's binary_logloss: 0.0374037\n",
            "[980]\ttraining's binary_logloss: 0.0101415\tvalid_1's binary_logloss: 0.0364342\n",
            "[990]\ttraining's binary_logloss: 0.009824\tvalid_1's binary_logloss: 0.0353062\n",
            "[1000]\ttraining's binary_logloss: 0.00958064\tvalid_1's binary_logloss: 0.0344151\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.00958064\tvalid_1's binary_logloss: 0.0344151\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-08-23 03:49:54,386] Trial 39 finished with value: 0.034415119935764175 and parameters: {'max_bin': 320, 'num_leaves': 73}. Best is trial 19 with value: 0.0046284648643910705.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3huPinTX5gd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b3bd4daf-777f-4a3e-9e86-54d479a5662a"
      },
      "source": [
        "study.best_params"
      ],
      "execution_count": 295,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_bin': 354, 'num_leaves': 120}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 295
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwZ0MSzwX5fI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lgbm_params = {\n",
        "    'learning_rate': 0.05,\n",
        "    'num_leaves': 120,\n",
        "    'boosting_type' : 'gbdt',\n",
        "    'reg_alpha' : 1,\n",
        "    'reg_lambda' : 1,\n",
        "    'objective': 'binary',\n",
        "    'max_bin': 354,\n",
        "    'metric': 'auc',\n",
        "}\n",
        "\n",
        "#categorical_features = ['job','education','housing','loan','contact','poutcome',\"income\",'goodincome','married',\"single\",'housing+loan']\n",
        "#X_train[categorical_features]=X_train[categorical_features].astype('category')"
      ],
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWZdFFibcUv9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2b52b252-9d65-49ba-b4b9-296d87866fae"
      },
      "source": [
        "%%time\n",
        "models = []\n",
        "\n",
        "for i in range(10):\n",
        "    models.append(bagging(i))"
      ],
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's auc: 0.797342\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's auc: 0.796309\n",
            "[3]\tvalid_0's auc: 0.795805\n",
            "[4]\tvalid_0's auc: 0.795709\n",
            "[5]\tvalid_0's auc: 0.795937\n",
            "[6]\tvalid_0's auc: 0.794926\n",
            "[7]\tvalid_0's auc: 0.802274\n",
            "[8]\tvalid_0's auc: 0.807351\n",
            "[9]\tvalid_0's auc: 0.806143\n",
            "[10]\tvalid_0's auc: 0.807557\n",
            "[11]\tvalid_0's auc: 0.808668\n",
            "[12]\tvalid_0's auc: 0.808366\n",
            "[13]\tvalid_0's auc: 0.809723\n",
            "[14]\tvalid_0's auc: 0.810261\n",
            "[15]\tvalid_0's auc: 0.809732\n",
            "[16]\tvalid_0's auc: 0.809955\n",
            "[17]\tvalid_0's auc: 0.808878\n",
            "[18]\tvalid_0's auc: 0.810406\n",
            "[19]\tvalid_0's auc: 0.811062\n",
            "[20]\tvalid_0's auc: 0.811242\n",
            "[21]\tvalid_0's auc: 0.811531\n",
            "[22]\tvalid_0's auc: 0.811404\n",
            "[23]\tvalid_0's auc: 0.811351\n",
            "[24]\tvalid_0's auc: 0.811045\n",
            "[25]\tvalid_0's auc: 0.811876\n",
            "[26]\tvalid_0's auc: 0.813329\n",
            "[27]\tvalid_0's auc: 0.813631\n",
            "[28]\tvalid_0's auc: 0.814629\n",
            "[29]\tvalid_0's auc: 0.815338\n",
            "[30]\tvalid_0's auc: 0.81529\n",
            "[31]\tvalid_0's auc: 0.815058\n",
            "[32]\tvalid_0's auc: 0.815089\n",
            "[33]\tvalid_0's auc: 0.815316\n",
            "[34]\tvalid_0's auc: 0.817071\n",
            "[35]\tvalid_0's auc: 0.818104\n",
            "[36]\tvalid_0's auc: 0.818231\n",
            "[37]\tvalid_0's auc: 0.818069\n",
            "[38]\tvalid_0's auc: 0.818415\n",
            "[39]\tvalid_0's auc: 0.818008\n",
            "[40]\tvalid_0's auc: 0.817955\n",
            "[41]\tvalid_0's auc: 0.818428\n",
            "[42]\tvalid_0's auc: 0.817894\n",
            "[43]\tvalid_0's auc: 0.818332\n",
            "[44]\tvalid_0's auc: 0.818004\n",
            "[45]\tvalid_0's auc: 0.817785\n",
            "[46]\tvalid_0's auc: 0.818004\n",
            "[47]\tvalid_0's auc: 0.818341\n",
            "[48]\tvalid_0's auc: 0.81806\n",
            "[49]\tvalid_0's auc: 0.818424\n",
            "[50]\tvalid_0's auc: 0.8188\n",
            "[51]\tvalid_0's auc: 0.818993\n",
            "[52]\tvalid_0's auc: 0.819579\n",
            "[53]\tvalid_0's auc: 0.820026\n",
            "[54]\tvalid_0's auc: 0.820113\n",
            "[55]\tvalid_0's auc: 0.820376\n",
            "[56]\tvalid_0's auc: 0.820726\n",
            "[57]\tvalid_0's auc: 0.820708\n",
            "[58]\tvalid_0's auc: 0.821067\n",
            "[59]\tvalid_0's auc: 0.821671\n",
            "[60]\tvalid_0's auc: 0.821794\n",
            "[61]\tvalid_0's auc: 0.821907\n",
            "[62]\tvalid_0's auc: 0.822074\n",
            "[63]\tvalid_0's auc: 0.822153\n",
            "[64]\tvalid_0's auc: 0.821872\n",
            "[65]\tvalid_0's auc: 0.821934\n",
            "[66]\tvalid_0's auc: 0.821978\n",
            "[67]\tvalid_0's auc: 0.822048\n",
            "[68]\tvalid_0's auc: 0.821706\n",
            "[69]\tvalid_0's auc: 0.822144\n",
            "[70]\tvalid_0's auc: 0.822687\n",
            "[71]\tvalid_0's auc: 0.822748\n",
            "[72]\tvalid_0's auc: 0.822441\n",
            "[73]\tvalid_0's auc: 0.822599\n",
            "[74]\tvalid_0's auc: 0.822406\n",
            "[75]\tvalid_0's auc: 0.823282\n",
            "[76]\tvalid_0's auc: 0.824035\n",
            "[77]\tvalid_0's auc: 0.823614\n",
            "[78]\tvalid_0's auc: 0.823851\n",
            "[79]\tvalid_0's auc: 0.823947\n",
            "[80]\tvalid_0's auc: 0.823956\n",
            "[81]\tvalid_0's auc: 0.82435\n",
            "[82]\tvalid_0's auc: 0.82449\n",
            "[83]\tvalid_0's auc: 0.824787\n",
            "[84]\tvalid_0's auc: 0.824796\n",
            "[85]\tvalid_0's auc: 0.824525\n",
            "[86]\tvalid_0's auc: 0.824595\n",
            "[87]\tvalid_0's auc: 0.824131\n",
            "[88]\tvalid_0's auc: 0.823711\n",
            "[89]\tvalid_0's auc: 0.823798\n",
            "[90]\tvalid_0's auc: 0.823754\n",
            "[91]\tvalid_0's auc: 0.823781\n",
            "[92]\tvalid_0's auc: 0.824498\n",
            "[93]\tvalid_0's auc: 0.824175\n",
            "[94]\tvalid_0's auc: 0.823851\n",
            "Early stopping, best iteration is:\n",
            "[84]\tvalid_0's auc: 0.824796\n",
            "[1]\tvalid_0's auc: 0.8062\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's auc: 0.808821\n",
            "[3]\tvalid_0's auc: 0.806467\n",
            "[4]\tvalid_0's auc: 0.806515\n",
            "[5]\tvalid_0's auc: 0.810463\n",
            "[6]\tvalid_0's auc: 0.809627\n",
            "[7]\tvalid_0's auc: 0.81045\n",
            "[8]\tvalid_0's auc: 0.811548\n",
            "[9]\tvalid_0's auc: 0.813539\n",
            "[10]\tvalid_0's auc: 0.817386\n",
            "[11]\tvalid_0's auc: 0.817671\n",
            "[12]\tvalid_0's auc: 0.819023\n",
            "[13]\tvalid_0's auc: 0.819785\n",
            "[14]\tvalid_0's auc: 0.823597\n",
            "[15]\tvalid_0's auc: 0.825597\n",
            "[16]\tvalid_0's auc: 0.82698\n",
            "[17]\tvalid_0's auc: 0.828345\n",
            "[18]\tvalid_0's auc: 0.829615\n",
            "[19]\tvalid_0's auc: 0.828801\n",
            "[20]\tvalid_0's auc: 0.829054\n",
            "[21]\tvalid_0's auc: 0.829492\n",
            "[22]\tvalid_0's auc: 0.830276\n",
            "[23]\tvalid_0's auc: 0.830923\n",
            "[24]\tvalid_0's auc: 0.831575\n",
            "[25]\tvalid_0's auc: 0.831107\n",
            "[26]\tvalid_0's auc: 0.830809\n",
            "[27]\tvalid_0's auc: 0.831606\n",
            "[28]\tvalid_0's auc: 0.831672\n",
            "[29]\tvalid_0's auc: 0.83267\n",
            "[30]\tvalid_0's auc: 0.832818\n",
            "[31]\tvalid_0's auc: 0.83365\n",
            "[32]\tvalid_0's auc: 0.833532\n",
            "[33]\tvalid_0's auc: 0.833856\n",
            "[34]\tvalid_0's auc: 0.834018\n",
            "[35]\tvalid_0's auc: 0.834079\n",
            "[36]\tvalid_0's auc: 0.833965\n",
            "[37]\tvalid_0's auc: 0.833825\n",
            "[38]\tvalid_0's auc: 0.833545\n",
            "[39]\tvalid_0's auc: 0.834009\n",
            "[40]\tvalid_0's auc: 0.833729\n",
            "[41]\tvalid_0's auc: 0.834403\n",
            "[42]\tvalid_0's auc: 0.834341\n",
            "[43]\tvalid_0's auc: 0.834026\n",
            "[44]\tvalid_0's auc: 0.835287\n",
            "[45]\tvalid_0's auc: 0.836595\n",
            "[46]\tvalid_0's auc: 0.837313\n",
            "[47]\tvalid_0's auc: 0.837882\n",
            "[48]\tvalid_0's auc: 0.837751\n",
            "[49]\tvalid_0's auc: 0.838258\n",
            "[50]\tvalid_0's auc: 0.838609\n",
            "[51]\tvalid_0's auc: 0.838705\n",
            "[52]\tvalid_0's auc: 0.838819\n",
            "[53]\tvalid_0's auc: 0.838941\n",
            "[54]\tvalid_0's auc: 0.839217\n",
            "[55]\tvalid_0's auc: 0.84004\n",
            "[56]\tvalid_0's auc: 0.840329\n",
            "[57]\tvalid_0's auc: 0.840617\n",
            "[58]\tvalid_0's auc: 0.840915\n",
            "[59]\tvalid_0's auc: 0.841038\n",
            "[60]\tvalid_0's auc: 0.84116\n",
            "[61]\tvalid_0's auc: 0.841554\n",
            "[62]\tvalid_0's auc: 0.842035\n",
            "[63]\tvalid_0's auc: 0.842333\n",
            "[64]\tvalid_0's auc: 0.842456\n",
            "[65]\tvalid_0's auc: 0.842679\n",
            "[66]\tvalid_0's auc: 0.842688\n",
            "[67]\tvalid_0's auc: 0.843038\n",
            "[68]\tvalid_0's auc: 0.84295\n",
            "[69]\tvalid_0's auc: 0.843493\n",
            "[70]\tvalid_0's auc: 0.843554\n",
            "[71]\tvalid_0's auc: 0.843782\n",
            "[72]\tvalid_0's auc: 0.84365\n",
            "[73]\tvalid_0's auc: 0.844176\n",
            "[74]\tvalid_0's auc: 0.843957\n",
            "[75]\tvalid_0's auc: 0.844228\n",
            "[76]\tvalid_0's auc: 0.844403\n",
            "[77]\tvalid_0's auc: 0.84464\n",
            "[78]\tvalid_0's auc: 0.844596\n",
            "[79]\tvalid_0's auc: 0.844832\n",
            "[80]\tvalid_0's auc: 0.84506\n",
            "[81]\tvalid_0's auc: 0.845033\n",
            "[82]\tvalid_0's auc: 0.844963\n",
            "[83]\tvalid_0's auc: 0.844963\n",
            "[84]\tvalid_0's auc: 0.8452\n",
            "[85]\tvalid_0's auc: 0.845322\n",
            "[86]\tvalid_0's auc: 0.845226\n",
            "[87]\tvalid_0's auc: 0.845375\n",
            "[88]\tvalid_0's auc: 0.84534\n",
            "[89]\tvalid_0's auc: 0.84534\n",
            "[90]\tvalid_0's auc: 0.845419\n",
            "[91]\tvalid_0's auc: 0.845926\n",
            "[92]\tvalid_0's auc: 0.846058\n",
            "[93]\tvalid_0's auc: 0.845874\n",
            "[94]\tvalid_0's auc: 0.84527\n",
            "[95]\tvalid_0's auc: 0.845559\n",
            "[96]\tvalid_0's auc: 0.845436\n",
            "[97]\tvalid_0's auc: 0.845541\n",
            "[98]\tvalid_0's auc: 0.845427\n",
            "[99]\tvalid_0's auc: 0.845182\n",
            "[100]\tvalid_0's auc: 0.845016\n",
            "[101]\tvalid_0's auc: 0.845103\n",
            "[102]\tvalid_0's auc: 0.845252\n",
            "Early stopping, best iteration is:\n",
            "[92]\tvalid_0's auc: 0.846058\n",
            "[1]\tvalid_0's auc: 0.779774\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's auc: 0.78696\n",
            "[3]\tvalid_0's auc: 0.787411\n",
            "[4]\tvalid_0's auc: 0.790006\n",
            "[5]\tvalid_0's auc: 0.797622\n",
            "[6]\tvalid_0's auc: 0.798637\n",
            "[7]\tvalid_0's auc: 0.801438\n",
            "[8]\tvalid_0's auc: 0.802484\n",
            "[9]\tvalid_0's auc: 0.804992\n",
            "[10]\tvalid_0's auc: 0.807644\n",
            "[11]\tvalid_0's auc: 0.806983\n",
            "[12]\tvalid_0's auc: 0.809382\n",
            "[13]\tvalid_0's auc: 0.810082\n",
            "[14]\tvalid_0's auc: 0.811859\n",
            "[15]\tvalid_0's auc: 0.81213\n",
            "[16]\tvalid_0's auc: 0.813089\n",
            "[17]\tvalid_0's auc: 0.813684\n",
            "[18]\tvalid_0's auc: 0.81392\n",
            "[19]\tvalid_0's auc: 0.814279\n",
            "[20]\tvalid_0's auc: 0.814502\n",
            "[21]\tvalid_0's auc: 0.814839\n",
            "[22]\tvalid_0's auc: 0.815102\n",
            "[23]\tvalid_0's auc: 0.815754\n",
            "[24]\tvalid_0's auc: 0.815763\n",
            "[25]\tvalid_0's auc: 0.816691\n",
            "[26]\tvalid_0's auc: 0.8174\n",
            "[27]\tvalid_0's auc: 0.818546\n",
            "[28]\tvalid_0's auc: 0.817986\n",
            "[29]\tvalid_0's auc: 0.819155\n",
            "[30]\tvalid_0's auc: 0.819772\n",
            "[31]\tvalid_0's auc: 0.8207\n",
            "[32]\tvalid_0's auc: 0.821452\n",
            "[33]\tvalid_0's auc: 0.821514\n",
            "[34]\tvalid_0's auc: 0.82217\n",
            "[35]\tvalid_0's auc: 0.821387\n",
            "[36]\tvalid_0's auc: 0.821212\n",
            "[37]\tvalid_0's auc: 0.821877\n",
            "[38]\tvalid_0's auc: 0.821544\n",
            "[39]\tvalid_0's auc: 0.821886\n",
            "[40]\tvalid_0's auc: 0.822013\n",
            "[41]\tvalid_0's auc: 0.821872\n",
            "[42]\tvalid_0's auc: 0.821978\n",
            "[43]\tvalid_0's auc: 0.822126\n",
            "[44]\tvalid_0's auc: 0.821802\n",
            "Early stopping, best iteration is:\n",
            "[34]\tvalid_0's auc: 0.82217\n",
            "[1]\tvalid_0's auc: 0.769078\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's auc: 0.785542\n",
            "[3]\tvalid_0's auc: 0.786724\n",
            "[4]\tvalid_0's auc: 0.788877\n",
            "[5]\tvalid_0's auc: 0.790698\n",
            "[6]\tvalid_0's auc: 0.789525\n",
            "[7]\tvalid_0's auc: 0.789136\n",
            "[8]\tvalid_0's auc: 0.787669\n",
            "[9]\tvalid_0's auc: 0.788427\n",
            "[10]\tvalid_0's auc: 0.791985\n",
            "[11]\tvalid_0's auc: 0.792908\n",
            "[12]\tvalid_0's auc: 0.794865\n",
            "[13]\tvalid_0's auc: 0.795587\n",
            "[14]\tvalid_0's auc: 0.795797\n",
            "[15]\tvalid_0's auc: 0.796103\n",
            "[16]\tvalid_0's auc: 0.79707\n",
            "[17]\tvalid_0's auc: 0.798326\n",
            "[18]\tvalid_0's auc: 0.798335\n",
            "[19]\tvalid_0's auc: 0.798733\n",
            "[20]\tvalid_0's auc: 0.798751\n",
            "[21]\tvalid_0's auc: 0.800865\n",
            "[22]\tvalid_0's auc: 0.802007\n",
            "[23]\tvalid_0's auc: 0.803206\n",
            "[24]\tvalid_0's auc: 0.803513\n",
            "[25]\tvalid_0's auc: 0.804248\n",
            "[26]\tvalid_0's auc: 0.804729\n",
            "[27]\tvalid_0's auc: 0.804887\n",
            "[28]\tvalid_0's auc: 0.804664\n",
            "[29]\tvalid_0's auc: 0.805788\n",
            "[30]\tvalid_0's auc: 0.804856\n",
            "[31]\tvalid_0's auc: 0.805683\n",
            "[32]\tvalid_0's auc: 0.806432\n",
            "[33]\tvalid_0's auc: 0.806165\n",
            "[34]\tvalid_0's auc: 0.806611\n",
            "[35]\tvalid_0's auc: 0.806935\n",
            "[36]\tvalid_0's auc: 0.807815\n",
            "[37]\tvalid_0's auc: 0.808021\n",
            "[38]\tvalid_0's auc: 0.807347\n",
            "[39]\tvalid_0's auc: 0.806961\n",
            "[40]\tvalid_0's auc: 0.807504\n",
            "[41]\tvalid_0's auc: 0.807452\n",
            "[42]\tvalid_0's auc: 0.807224\n",
            "[43]\tvalid_0's auc: 0.80746\n",
            "[44]\tvalid_0's auc: 0.807898\n",
            "[45]\tvalid_0's auc: 0.808379\n",
            "[46]\tvalid_0's auc: 0.808336\n",
            "[47]\tvalid_0's auc: 0.807872\n",
            "[48]\tvalid_0's auc: 0.808248\n",
            "[49]\tvalid_0's auc: 0.807705\n",
            "[50]\tvalid_0's auc: 0.808397\n",
            "[51]\tvalid_0's auc: 0.808493\n",
            "[52]\tvalid_0's auc: 0.808804\n",
            "[53]\tvalid_0's auc: 0.80904\n",
            "[54]\tvalid_0's auc: 0.8089\n",
            "[55]\tvalid_0's auc: 0.810196\n",
            "[56]\tvalid_0's auc: 0.811132\n",
            "[57]\tvalid_0's auc: 0.811658\n",
            "[58]\tvalid_0's auc: 0.81276\n",
            "[59]\tvalid_0's auc: 0.814108\n",
            "[60]\tvalid_0's auc: 0.813601\n",
            "[61]\tvalid_0's auc: 0.813356\n",
            "[62]\tvalid_0's auc: 0.81417\n",
            "[63]\tvalid_0's auc: 0.815255\n",
            "[64]\tvalid_0's auc: 0.815246\n",
            "[65]\tvalid_0's auc: 0.814896\n",
            "[66]\tvalid_0's auc: 0.815658\n",
            "[67]\tvalid_0's auc: 0.815185\n",
            "[68]\tvalid_0's auc: 0.816384\n",
            "[69]\tvalid_0's auc: 0.816682\n",
            "[70]\tvalid_0's auc: 0.816874\n",
            "[71]\tvalid_0's auc: 0.816979\n",
            "[72]\tvalid_0's auc: 0.817548\n",
            "[73]\tvalid_0's auc: 0.817601\n",
            "[74]\tvalid_0's auc: 0.817697\n",
            "[75]\tvalid_0's auc: 0.817802\n",
            "[76]\tvalid_0's auc: 0.818109\n",
            "[77]\tvalid_0's auc: 0.81859\n",
            "[78]\tvalid_0's auc: 0.81894\n",
            "[79]\tvalid_0's auc: 0.819317\n",
            "[80]\tvalid_0's auc: 0.819553\n",
            "[81]\tvalid_0's auc: 0.819308\n",
            "[82]\tvalid_0's auc: 0.819352\n",
            "[83]\tvalid_0's auc: 0.819229\n",
            "[84]\tvalid_0's auc: 0.819623\n",
            "[85]\tvalid_0's auc: 0.819623\n",
            "[86]\tvalid_0's auc: 0.820034\n",
            "[87]\tvalid_0's auc: 0.819859\n",
            "[88]\tvalid_0's auc: 0.82063\n",
            "[89]\tvalid_0's auc: 0.820271\n",
            "[90]\tvalid_0's auc: 0.820437\n",
            "[91]\tvalid_0's auc: 0.820936\n",
            "[92]\tvalid_0's auc: 0.820761\n",
            "[93]\tvalid_0's auc: 0.820761\n",
            "[94]\tvalid_0's auc: 0.820735\n",
            "[95]\tvalid_0's auc: 0.820297\n",
            "[96]\tvalid_0's auc: 0.820026\n",
            "[97]\tvalid_0's auc: 0.819877\n",
            "[98]\tvalid_0's auc: 0.819815\n",
            "[99]\tvalid_0's auc: 0.819702\n",
            "[100]\tvalid_0's auc: 0.819982\n",
            "[101]\tvalid_0's auc: 0.820069\n",
            "Early stopping, best iteration is:\n",
            "[91]\tvalid_0's auc: 0.820936\n",
            "[1]\tvalid_0's auc: 0.786496\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's auc: 0.787398\n",
            "[3]\tvalid_0's auc: 0.7963\n",
            "[4]\tvalid_0's auc: 0.795346\n",
            "[5]\tvalid_0's auc: 0.794987\n",
            "[6]\tvalid_0's auc: 0.79676\n",
            "[7]\tvalid_0's auc: 0.795447\n",
            "[8]\tvalid_0's auc: 0.795394\n",
            "[9]\tvalid_0's auc: 0.796475\n",
            "[10]\tvalid_0's auc: 0.796379\n",
            "[11]\tvalid_0's auc: 0.797075\n",
            "[12]\tvalid_0's auc: 0.796475\n",
            "[13]\tvalid_0's auc: 0.796987\n",
            "[14]\tvalid_0's auc: 0.797464\n",
            "[15]\tvalid_0's auc: 0.797556\n",
            "[16]\tvalid_0's auc: 0.797294\n",
            "[17]\tvalid_0's auc: 0.798287\n",
            "[18]\tvalid_0's auc: 0.79886\n",
            "[19]\tvalid_0's auc: 0.797018\n",
            "[20]\tvalid_0's auc: 0.797206\n",
            "[21]\tvalid_0's auc: 0.79669\n",
            "[22]\tvalid_0's auc: 0.796957\n",
            "[23]\tvalid_0's auc: 0.796655\n",
            "[24]\tvalid_0's auc: 0.796646\n",
            "[25]\tvalid_0's auc: 0.795967\n",
            "[26]\tvalid_0's auc: 0.796212\n",
            "[27]\tvalid_0's auc: 0.79728\n",
            "[28]\tvalid_0's auc: 0.798418\n",
            "Early stopping, best iteration is:\n",
            "[18]\tvalid_0's auc: 0.79886\n",
            "[1]\tvalid_0's auc: 0.803093\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's auc: 0.802243\n",
            "[3]\tvalid_0's auc: 0.798274\n",
            "[4]\tvalid_0's auc: 0.799534\n",
            "[5]\tvalid_0's auc: 0.797867\n",
            "[6]\tvalid_0's auc: 0.799429\n",
            "[7]\tvalid_0's auc: 0.799552\n",
            "[8]\tvalid_0's auc: 0.800712\n",
            "[9]\tvalid_0's auc: 0.801968\n",
            "[10]\tvalid_0's auc: 0.805128\n",
            "[11]\tvalid_0's auc: 0.807754\n",
            "[12]\tvalid_0's auc: 0.808927\n",
            "[13]\tvalid_0's auc: 0.810336\n",
            "[14]\tvalid_0's auc: 0.811084\n",
            "[15]\tvalid_0's auc: 0.812218\n",
            "[16]\tvalid_0's auc: 0.814901\n",
            "[17]\tvalid_0's auc: 0.81466\n",
            "[18]\tvalid_0's auc: 0.81459\n",
            "[19]\tvalid_0's auc: 0.815662\n",
            "[20]\tvalid_0's auc: 0.81589\n",
            "[21]\tvalid_0's auc: 0.817509\n",
            "[22]\tvalid_0's auc: 0.818564\n",
            "[23]\tvalid_0's auc: 0.819929\n",
            "[24]\tvalid_0's auc: 0.819956\n",
            "[25]\tvalid_0's auc: 0.820682\n",
            "[26]\tvalid_0's auc: 0.820958\n",
            "[27]\tvalid_0's auc: 0.820752\n",
            "[28]\tvalid_0's auc: 0.82242\n",
            "[29]\tvalid_0's auc: 0.823492\n",
            "[30]\tvalid_0's auc: 0.824726\n",
            "[31]\tvalid_0's auc: 0.825089\n",
            "[32]\tvalid_0's auc: 0.824932\n",
            "[33]\tvalid_0's auc: 0.825501\n",
            "[34]\tvalid_0's auc: 0.826862\n",
            "[35]\tvalid_0's auc: 0.827352\n",
            "[36]\tvalid_0's auc: 0.828166\n",
            "[37]\tvalid_0's auc: 0.828665\n",
            "[38]\tvalid_0's auc: 0.829698\n",
            "[39]\tvalid_0's auc: 0.829794\n",
            "[40]\tvalid_0's auc: 0.829208\n",
            "[41]\tvalid_0's auc: 0.829076\n",
            "[42]\tvalid_0's auc: 0.829777\n",
            "[43]\tvalid_0's auc: 0.829855\n",
            "[44]\tvalid_0's auc: 0.830845\n",
            "[45]\tvalid_0's auc: 0.831974\n",
            "[46]\tvalid_0's auc: 0.831772\n",
            "[47]\tvalid_0's auc: 0.832201\n",
            "[48]\tvalid_0's auc: 0.83221\n",
            "[49]\tvalid_0's auc: 0.83298\n",
            "[50]\tvalid_0's auc: 0.832858\n",
            "[51]\tvalid_0's auc: 0.833208\n",
            "[52]\tvalid_0's auc: 0.833435\n",
            "[53]\tvalid_0's auc: 0.833943\n",
            "[54]\tvalid_0's auc: 0.833987\n",
            "[55]\tvalid_0's auc: 0.834197\n",
            "[56]\tvalid_0's auc: 0.834959\n",
            "[57]\tvalid_0's auc: 0.834976\n",
            "[58]\tvalid_0's auc: 0.835344\n",
            "[59]\tvalid_0's auc: 0.835422\n",
            "[60]\tvalid_0's auc: 0.83551\n",
            "[61]\tvalid_0's auc: 0.835431\n",
            "[62]\tvalid_0's auc: 0.835948\n",
            "[63]\tvalid_0's auc: 0.836175\n",
            "[64]\tvalid_0's auc: 0.836245\n",
            "[65]\tvalid_0's auc: 0.837077\n",
            "[66]\tvalid_0's auc: 0.836875\n",
            "[67]\tvalid_0's auc: 0.837016\n",
            "[68]\tvalid_0's auc: 0.836814\n",
            "[69]\tvalid_0's auc: 0.837707\n",
            "[70]\tvalid_0's auc: 0.837987\n",
            "[71]\tvalid_0's auc: 0.837637\n",
            "[72]\tvalid_0's auc: 0.838276\n",
            "[73]\tvalid_0's auc: 0.837821\n",
            "[74]\tvalid_0's auc: 0.837856\n",
            "[75]\tvalid_0's auc: 0.837856\n",
            "[76]\tvalid_0's auc: 0.838364\n",
            "[77]\tvalid_0's auc: 0.838425\n",
            "[78]\tvalid_0's auc: 0.838188\n",
            "[79]\tvalid_0's auc: 0.83867\n",
            "[80]\tvalid_0's auc: 0.838862\n",
            "[81]\tvalid_0's auc: 0.838897\n",
            "[82]\tvalid_0's auc: 0.839256\n",
            "[83]\tvalid_0's auc: 0.839808\n",
            "[84]\tvalid_0's auc: 0.839466\n",
            "[85]\tvalid_0's auc: 0.83972\n",
            "[86]\tvalid_0's auc: 0.83972\n",
            "[87]\tvalid_0's auc: 0.840202\n",
            "[88]\tvalid_0's auc: 0.840272\n",
            "[89]\tvalid_0's auc: 0.84021\n",
            "[90]\tvalid_0's auc: 0.840473\n",
            "[91]\tvalid_0's auc: 0.840491\n",
            "[92]\tvalid_0's auc: 0.840709\n",
            "[93]\tvalid_0's auc: 0.840342\n",
            "[94]\tvalid_0's auc: 0.839974\n",
            "[95]\tvalid_0's auc: 0.839344\n",
            "[96]\tvalid_0's auc: 0.839423\n",
            "[97]\tvalid_0's auc: 0.839528\n",
            "[98]\tvalid_0's auc: 0.839729\n",
            "[99]\tvalid_0's auc: 0.839536\n",
            "[100]\tvalid_0's auc: 0.839747\n",
            "[101]\tvalid_0's auc: 0.839843\n",
            "[102]\tvalid_0's auc: 0.83993\n",
            "Early stopping, best iteration is:\n",
            "[92]\tvalid_0's auc: 0.840709\n",
            "[1]\tvalid_0's auc: 0.762767\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's auc: 0.764771\n",
            "[3]\tvalid_0's auc: 0.766692\n",
            "[4]\tvalid_0's auc: 0.777306\n",
            "[5]\tvalid_0's auc: 0.783792\n",
            "[6]\tvalid_0's auc: 0.786466\n",
            "[7]\tvalid_0's auc: 0.789512\n",
            "[8]\tvalid_0's auc: 0.790203\n",
            "[9]\tvalid_0's auc: 0.791455\n",
            "[10]\tvalid_0's auc: 0.792812\n",
            "[11]\tvalid_0's auc: 0.793508\n",
            "[12]\tvalid_0's auc: 0.792593\n",
            "[13]\tvalid_0's auc: 0.794199\n",
            "[14]\tvalid_0's auc: 0.795784\n",
            "[15]\tvalid_0's auc: 0.796309\n",
            "[16]\tvalid_0's auc: 0.796497\n",
            "[17]\tvalid_0's auc: 0.795976\n",
            "[18]\tvalid_0's auc: 0.796501\n",
            "[19]\tvalid_0's auc: 0.797263\n",
            "[20]\tvalid_0's auc: 0.798379\n",
            "[21]\tvalid_0's auc: 0.799517\n",
            "[22]\tvalid_0's auc: 0.800033\n",
            "[23]\tvalid_0's auc: 0.799582\n",
            "[24]\tvalid_0's auc: 0.799022\n",
            "[25]\tvalid_0's auc: 0.800344\n",
            "[26]\tvalid_0's auc: 0.800493\n",
            "[27]\tvalid_0's auc: 0.800318\n",
            "[28]\tvalid_0's auc: 0.801368\n",
            "[29]\tvalid_0's auc: 0.80216\n",
            "[30]\tvalid_0's auc: 0.801994\n",
            "[31]\tvalid_0's auc: 0.802939\n",
            "[32]\tvalid_0's auc: 0.803701\n",
            "[33]\tvalid_0's auc: 0.804147\n",
            "[34]\tvalid_0's auc: 0.80371\n",
            "[35]\tvalid_0's auc: 0.803762\n",
            "[36]\tvalid_0's auc: 0.802834\n",
            "[37]\tvalid_0's auc: 0.802082\n",
            "[38]\tvalid_0's auc: 0.802449\n",
            "[39]\tvalid_0's auc: 0.802099\n",
            "[40]\tvalid_0's auc: 0.801495\n",
            "[41]\tvalid_0's auc: 0.801084\n",
            "[42]\tvalid_0's auc: 0.801644\n",
            "[43]\tvalid_0's auc: 0.801267\n",
            "Early stopping, best iteration is:\n",
            "[33]\tvalid_0's auc: 0.804147\n",
            "[1]\tvalid_0's auc: 0.774737\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's auc: 0.783087\n",
            "[3]\tvalid_0's auc: 0.785122\n",
            "[4]\tvalid_0's auc: 0.788794\n",
            "[5]\tvalid_0's auc: 0.786575\n",
            "[6]\tvalid_0's auc: 0.789901\n",
            "[7]\tvalid_0's auc: 0.790562\n",
            "[8]\tvalid_0's auc: 0.79205\n",
            "[9]\tvalid_0's auc: 0.792996\n",
            "[10]\tvalid_0's auc: 0.792737\n",
            "[11]\tvalid_0's auc: 0.792676\n",
            "[12]\tvalid_0's auc: 0.791359\n",
            "[13]\tvalid_0's auc: 0.792934\n",
            "[14]\tvalid_0's auc: 0.793346\n",
            "[15]\tvalid_0's auc: 0.794659\n",
            "[16]\tvalid_0's auc: 0.79549\n",
            "[17]\tvalid_0's auc: 0.796615\n",
            "[18]\tvalid_0's auc: 0.797486\n",
            "[19]\tvalid_0's auc: 0.799394\n",
            "[20]\tvalid_0's auc: 0.800169\n",
            "[21]\tvalid_0's auc: 0.800567\n",
            "[22]\tvalid_0's auc: 0.80104\n",
            "[23]\tvalid_0's auc: 0.800418\n",
            "[24]\tvalid_0's auc: 0.801998\n",
            "[25]\tvalid_0's auc: 0.80079\n",
            "[26]\tvalid_0's auc: 0.800764\n",
            "[27]\tvalid_0's auc: 0.800786\n",
            "[28]\tvalid_0's auc: 0.800567\n",
            "[29]\tvalid_0's auc: 0.799639\n",
            "[30]\tvalid_0's auc: 0.799911\n",
            "[31]\tvalid_0's auc: 0.799762\n",
            "[32]\tvalid_0's auc: 0.800847\n",
            "[33]\tvalid_0's auc: 0.800729\n",
            "[34]\tvalid_0's auc: 0.800821\n",
            "Early stopping, best iteration is:\n",
            "[24]\tvalid_0's auc: 0.801998\n",
            "[1]\tvalid_0's auc: 0.79356\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's auc: 0.791324\n",
            "[3]\tvalid_0's auc: 0.792418\n",
            "[4]\tvalid_0's auc: 0.794243\n",
            "[5]\tvalid_0's auc: 0.795709\n",
            "[6]\tvalid_0's auc: 0.796869\n",
            "[7]\tvalid_0's auc: 0.801176\n",
            "[8]\tvalid_0's auc: 0.799867\n",
            "[9]\tvalid_0's auc: 0.800357\n",
            "[10]\tvalid_0's auc: 0.800362\n",
            "[11]\tvalid_0's auc: 0.801438\n",
            "[12]\tvalid_0's auc: 0.802292\n",
            "[13]\tvalid_0's auc: 0.802948\n",
            "[14]\tvalid_0's auc: 0.802383\n",
            "[15]\tvalid_0's auc: 0.8023\n",
            "[16]\tvalid_0's auc: 0.803758\n",
            "[17]\tvalid_0's auc: 0.802952\n",
            "[18]\tvalid_0's auc: 0.804099\n",
            "[19]\tvalid_0's auc: 0.805613\n",
            "[20]\tvalid_0's auc: 0.80634\n",
            "[21]\tvalid_0's auc: 0.804511\n",
            "[22]\tvalid_0's auc: 0.805469\n",
            "[23]\tvalid_0's auc: 0.80746\n",
            "[24]\tvalid_0's auc: 0.807075\n",
            "[25]\tvalid_0's auc: 0.806821\n",
            "[26]\tvalid_0's auc: 0.807399\n",
            "[27]\tvalid_0's auc: 0.807198\n",
            "[28]\tvalid_0's auc: 0.807027\n",
            "[29]\tvalid_0's auc: 0.807316\n",
            "[30]\tvalid_0's auc: 0.806756\n",
            "[31]\tvalid_0's auc: 0.80722\n",
            "[32]\tvalid_0's auc: 0.806563\n",
            "[33]\tvalid_0's auc: 0.806572\n",
            "Early stopping, best iteration is:\n",
            "[23]\tvalid_0's auc: 0.80746\n",
            "[1]\tvalid_0's auc: 0.798405\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's auc: 0.802405\n",
            "[3]\tvalid_0's auc: 0.807259\n",
            "[4]\tvalid_0's auc: 0.809964\n",
            "[5]\tvalid_0's auc: 0.808401\n",
            "[6]\tvalid_0's auc: 0.808331\n",
            "[7]\tvalid_0's auc: 0.809443\n",
            "[8]\tvalid_0's auc: 0.808927\n",
            "[9]\tvalid_0's auc: 0.813211\n",
            "[10]\tvalid_0's auc: 0.813316\n",
            "[11]\tvalid_0's auc: 0.814725\n",
            "[12]\tvalid_0's auc: 0.815872\n",
            "[13]\tvalid_0's auc: 0.816292\n",
            "[14]\tvalid_0's auc: 0.817233\n",
            "[15]\tvalid_0's auc: 0.818117\n",
            "[16]\tvalid_0's auc: 0.81905\n",
            "[17]\tvalid_0's auc: 0.818953\n",
            "[18]\tvalid_0's auc: 0.819487\n",
            "[19]\tvalid_0's auc: 0.819632\n",
            "[20]\tvalid_0's auc: 0.81964\n",
            "[21]\tvalid_0's auc: 0.819938\n",
            "[22]\tvalid_0's auc: 0.820581\n",
            "[23]\tvalid_0's auc: 0.820875\n",
            "[24]\tvalid_0's auc: 0.822065\n",
            "[25]\tvalid_0's auc: 0.821619\n",
            "[26]\tvalid_0's auc: 0.822153\n",
            "[27]\tvalid_0's auc: 0.822126\n",
            "[28]\tvalid_0's auc: 0.822179\n",
            "[29]\tvalid_0's auc: 0.821903\n",
            "[30]\tvalid_0's auc: 0.821956\n",
            "[31]\tvalid_0's auc: 0.823155\n",
            "[32]\tvalid_0's auc: 0.823067\n",
            "[33]\tvalid_0's auc: 0.824065\n",
            "[34]\tvalid_0's auc: 0.825247\n",
            "[35]\tvalid_0's auc: 0.825238\n",
            "[36]\tvalid_0's auc: 0.825496\n",
            "[37]\tvalid_0's auc: 0.826398\n",
            "[38]\tvalid_0's auc: 0.826836\n",
            "[39]\tvalid_0's auc: 0.826993\n",
            "[40]\tvalid_0's auc: 0.826757\n",
            "[41]\tvalid_0's auc: 0.827019\n",
            "[42]\tvalid_0's auc: 0.826844\n",
            "[43]\tvalid_0's auc: 0.826341\n",
            "[44]\tvalid_0's auc: 0.826052\n",
            "[45]\tvalid_0's auc: 0.826892\n",
            "[46]\tvalid_0's auc: 0.826429\n",
            "[47]\tvalid_0's auc: 0.82638\n",
            "[48]\tvalid_0's auc: 0.8267\n",
            "[49]\tvalid_0's auc: 0.827278\n",
            "[50]\tvalid_0's auc: 0.827759\n",
            "[51]\tvalid_0's auc: 0.827807\n",
            "[52]\tvalid_0's auc: 0.828394\n",
            "[53]\tvalid_0's auc: 0.828831\n",
            "[54]\tvalid_0's auc: 0.828919\n",
            "[55]\tvalid_0's auc: 0.829006\n",
            "[56]\tvalid_0's auc: 0.828831\n",
            "[57]\tvalid_0's auc: 0.828691\n",
            "[58]\tvalid_0's auc: 0.829208\n",
            "[59]\tvalid_0's auc: 0.829313\n",
            "[60]\tvalid_0's auc: 0.829803\n",
            "[61]\tvalid_0's auc: 0.830057\n",
            "[62]\tvalid_0's auc: 0.830249\n",
            "[63]\tvalid_0's auc: 0.830442\n",
            "[64]\tvalid_0's auc: 0.830486\n",
            "[65]\tvalid_0's auc: 0.830214\n",
            "[66]\tvalid_0's auc: 0.830503\n",
            "[67]\tvalid_0's auc: 0.831002\n",
            "[68]\tvalid_0's auc: 0.831142\n",
            "[69]\tvalid_0's auc: 0.830678\n",
            "[70]\tvalid_0's auc: 0.830862\n",
            "[71]\tvalid_0's auc: 0.830774\n",
            "[72]\tvalid_0's auc: 0.83102\n",
            "[73]\tvalid_0's auc: 0.830985\n",
            "[74]\tvalid_0's auc: 0.831396\n",
            "[75]\tvalid_0's auc: 0.831361\n",
            "[76]\tvalid_0's auc: 0.831361\n",
            "[77]\tvalid_0's auc: 0.83095\n",
            "[78]\tvalid_0's auc: 0.83095\n",
            "[79]\tvalid_0's auc: 0.830827\n",
            "[80]\tvalid_0's auc: 0.8313\n",
            "[81]\tvalid_0's auc: 0.831002\n",
            "[82]\tvalid_0's auc: 0.830433\n",
            "[83]\tvalid_0's auc: 0.830135\n",
            "[84]\tvalid_0's auc: 0.830127\n",
            "Early stopping, best iteration is:\n",
            "[74]\tvalid_0's auc: 0.831396\n",
            "CPU times: user 8.67 s, sys: 483 ms, total: 9.16 s\n",
            "Wall time: 7.31 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-PgQHOycU00",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "50bbccf6-f0da-4628-b7ed-051d4a55f99d"
      },
      "source": [
        "y_preds = []\n",
        "\n",
        "for m in models:\n",
        "    y_preds.append(m.predict(X_test, num_iteration=m.best_iteration))\n",
        "\n",
        "y_preds_bagging = sum(y_preds)/len(y_preds)\n",
        "# auc を計算する\n",
        "auc = roc_auc_score(y_test, y_preds_bagging)\n",
        "print(auc)"
      ],
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8431230312030025\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW0hWYCRcUy3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "336b9160-cc15-4424-8eb8-b32797c388c0"
      },
      "source": [
        "y_subs = []\n",
        "\n",
        "for m in models:\n",
        "    y_subs.append(m.predict(X_sub, num_iteration=m.best_iteration))\n",
        "\n",
        "y_subs_bagging = sum(y_subs)/len(y_subs)\n",
        "# auc を計算する\n",
        "y_subs_bagging"
      ],
      "execution_count": 299,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.89931745, 0.26417224, 0.21214072, ..., 0.5327362 , 0.10564403,\n",
              "       0.63575175])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 299
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "746B_92sc2W4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5ffeadcd-3dd7-4374-f6e9-8bc114ec5193"
      },
      "source": [
        "percentage=0.37\n",
        "y_sub = (y_subs_bagging > percentage).astype(int)\n",
        "\n",
        "sub['B'] = y_sub\n",
        "sub.to_csv('submission_lightgbm_kfold.csv', index=False, header=False)\n",
        "\n",
        "sum(sub[\"B\"]),len(sub[\"B\"])"
      ],
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8831, 18050)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 305
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QwzruIxc2cK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "b099e031-e314-4ce9-c1f8-9230ecd30105"
      },
      "source": [
        "files.download('submission_lightgbm_kfold.csv')"
      ],
      "execution_count": 307,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_0686a5cd-1622-4dab-96e8-2dce0656422d\", \"submission_lightgbm_kfold.csv\", 133290)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvdTrUWpc2Z1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}